USE whoknows;

DROP TABLE IF EXISTS users;
DROP TABLE IF EXISTS pages;

CREATE TABLE users (
  id INT PRIMARY KEY AUTO_INCREMENT,
  username VARCHAR(255) NOT NULL UNIQUE,
  email VARCHAR(255) NOT NULL UNIQUE,
  password VARCHAR(255) NOT NULL
);

INSERT INTO users (username, email, password)
    VALUES ('admin', 'keamonk1@stud.kea.dk', '5f4dcc3b5aa765d61d8327deb882cf99');

CREATE TABLE pages (
    title VARCHAR(255) PRIMARY KEY UNIQUE,
    url VARCHAR(255) NOT NULL UNIQUE,
    language ENUM('en', 'da') NOT NULL DEFAULT 'en',
    last_updated TIMESTAMP,
    content TEXT NOT NULL
);


INSERT INTO pages VALUES('Fortran','http://web.archive.org/web/20081220110619/http://en.wikipedia.org:80/wiki/Fortran','en','2008-12-20 00:00:00',replace('Fortran\nThe Fortran Automatic Coding System for the IBM 704 (October 15, 1956), the first Programmer''s Reference Manual for Fortran\nParadigm\nmulti-paradigm: procedural, imperative, structured, object-oriented\nAppeared in\n1957\nDesigned by\nJohn Backus\nDeveloper\nJohn Backus & IBM\nTyping discipline\nstrong, static\nMajor implementations\nAbsoft, GFortran, G95, Intel, Lahey/Fujitsu, Open Watcom, Pathscale, PGI, Silverfrost, Sun, XL Fortran, Visual Fortran, others\nInfluenced\nALGOL 58, PL/I\nFortran (previously FORTRAN[1]) is a general-purpose,[2] procedural,[3] imperative programming language that is especially suited to numeric computation and scientific computing. Originally developed by IBM in the 1950s for scientific and engineering applications, Fortran came to dominate this area of programming early on and has been in continual use for over half a century in computationally intensive areas such as numerical weather prediction, finite element analysis, computational fluid dynamics (CFD), computational physics, and computational chemistry. It is one of the most popular languages in the area of High-performance computing and programs to benchmark and rank the world''s fastest supercomputers are written in Fortran[4].\nFortran (a blend word derived from The IBM Mathematical Formula Translating System) encompasses a lineage of versions, each of which evolved to add extensions to the language while usually retaining compatibility with previous versions. Successive versions have added support for processing of character-based data (FORTRAN 77), array programming, module-based programming and object-based programming (Fortran 90 / 95), and object-oriented and generic programming (Fortran 2003).\n1 History\n1.1 FORTRAN\n1.2 FORTRAN II\n1.2.1 Simple Fortran II program\n1.3 FORTRAN III\n1.4 FORTRAN IV\n1.5 FORTRAN 66\n1.6 FORTRAN 77\n1.7 Fortran 90\n1.7.1 Obsolescence & deletions\n1.8 Fortran 95\n1.8.1 Conditional compilation and varying length strings\n1.9 Fortran 2003\n1.10 Fortran 2008\n1.11 The legacy of FORTRAN\n2 Language features\n3 Portability\n4 Variants of Fortran\n4.1 Specific variants\n4.1.1 FOR TRANSIT for the IBM 650\n4.2 Fortran-based languages\n5 Code examples\n6 FORTRAN quotations\n7 Letter O considered harmful\n8 See also\n9 References\n9.1 Textbooks\n9.2 "Core" language standards\n9.3 Related standards\n10 Notes\n11\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nAn IBM 704 mainframe (image courtesy of LLNL)\nFORTRAN code on a punch card, showing the specialized uses of columns 1-5, 6 and 73-80.\nIn late 1953, John W. Backus submitted a proposal to his superiors at IBM to develop a more efficient alternative to assembly language for programming their IBM 704 mainframe computer. Backus'' historic FORTRAN team consisted of programmers Richard Goldberg, Sheldon F. Best, Harlan Herrick, Peter Sheridan, Roy Nutt, Robert Nelson, Irving Ziller, Lois Haibt and David Sayre.[5]\nA draft specification for The IBM Mathematical Formula Translating System was completed by mid-1954. The first manual for FORTRAN appeared in October 1956, with the first FORTRAN compiler delivered in April 1957. This was an optimizing compiler, because customers were reluctant to use a high-level programming language unless its compiler could generate code whose performance was comparable to that of hand-coded assembly language.\nWhile the community was skeptical that this new method could possibly out-perform hand-coding, it reduced the amount of programming statements necessary to operate a machine by a factor of 20, and quickly gained acceptance. Said creator John Backus during a 1979 interview with Think, the IBM employee magazine, "Much of my work has come from being lazy. I didn''t like writing programs, and so, when I was working on the IBM 701 (an early computer), writing programs for computing missile trajectories, I started work on a programming system to make it easier to write programs."[6]\nThe language was widely adopted by scientists for writing numerically intensive programs, which encouraged compiler writers to produce compilers that could generate faster and more efficient code. The inclusion of a complex number data type in the language made Fortran especially suited to technical applications such as electrical engineering.\nBy 1960, versions of FORTRAN were available for the IBM 709, 650, 1620, and 7090 computers. Significantly, the increasing popularity of FORTRAN spurred competing computer manufacturers to provide FORTRAN compilers for their machines, so that by 1963 over 40 FORTRAN compilers existed. For these reasons, FORTRAN is considered to be the first widely used programming language supported across a variety of computer architectures.\nThe development of FORTRAN paralleled the early evolution of compiler technology; indeed many advances in the theory and design of compilers were specifically motivated by the need to generate efficient code for FORTRAN programs.\nFORTRAN\nThe initial release of FORTRAN for the IBM 704 contained 32 statements, including:\nDIMENSION and EQUIVALENCE statements\nAssignment statements\nThree-way arithmetic IF statement.[7]\nIF statements for checking exceptions (ACCUMULATOR OVERFLOW, QUOTIENT OVERFLOW, and DIVIDE CHECK); and IF statements for manipulating sense switches and sense lights\nGOTO, computed GOTO, ASSIGN, and assigned GOTO\nDO loops\nFormatted I/O: FORMAT, READ, READ INPUT TAPE, WRITE, WRITE OUTPUT TAPE, PRINT, and PUNCH\nUnformatted I/O: READ TAPE, READ DRUM, WRITE TAPE, and WRITE DRUM\nOther I/O: END FILE, REWIND, and BACKSPACE\nPAUSE, STOP, and CONTINUE\nFREQUENCY statement (for providing optimization hints to the compiler)[8]\nFORTRAN II\nIBM''s FORTRAN II appeared in 1958. The main enhancement was to support procedural programming by allowing user-written subroutines and functions. Six new statements were introduced:\nSUBROUTINE, FUNCTION, and END\nCALL and RETURN\nCOMMON\nOver the next few years, FORTRAN II would also add support for the DOUBLE PRECISION and COMPLEX data types.\nSimple Fortran II program\nThis program, for Heron''s formula, has one data card input, with simple zero-data edit check. If one of the input values is zero or negative, then the program will end with an error code of "STOP 1" in the job control card listing following the execution of the program. Normal output will be one line printed with A, B, C, and AREA on the "report" page following the compilation with no specific units are stated; and with a normal "STOP" in the job card listing.\nC AREA OF A TRIANGLE WITH A STANDARD SQUARE ROOT FUNCTION\nC INPUT - CARD READER UNIT 5, INTEGER INPUT\nC OUTPUT - LINE PRINTER UNIT 6, REAL OUTPUT\nC INPUT ERROR DISPLAY ERROR OUTPUT CODE 1 IN JOB CONTROL LISTING\nREAD INPUT TAPE 5, 501, IA, IB, IC\n501 FORMAT (3I5)\nC IA, IB, AND IC MAY NOT BE NEGATIVE\nC FURTHERMORE, THE SUM OF TWO SIDES OF A TRIANGLE\nC IS GREATER THAN THE THIRD SIDE, SO WE CHECK FOR THAT, TOO\nIF (IA) 777, 777, 701\n701 IF (IB) 777, 777, 702\n702 IF (IC) 777, 777, 703\n703 IF (IA+IB-IC) 777,777,704\n704 IF (IA+IC-IB) 777,777,705\n705 IF (IB+IC-IA) 777,777,799\n777 STOP 1\nC USING HERON''S FORMULA WE CALCULATE THE\nC AREA OF THE TRIANGLE\n799 S = FLOATF (IA + IB + IC) / 2.0\nAREA = SQRT( S * (S - FLOATF(IA)) * (S - FLOATF(IB)) *\n+\n(S - FLOATF(IC)))\nWRITE OUTPUT TAPE 6, 601, IA, IB, IC, AREA\n601 FORMAT (4H A= ,I5,5H\nB= ,I5,5H\nC= ,I5,8H\nAREA= ,F10.2,\n+\n13H SQUARE UNITS)\nSTOP\nEND\nFORTRAN III\nA FORTRAN coding form, formerly printed on paper and intended to be used by programmers to prepare programs for punching onto cards by card punch operators. Now obsolete.\nIBM also developed a FORTRAN III in 1958 that allowed for inline assembler code among other features; however, this version was never released as a product. Like the 704 FORTRAN and FORTRAN II, FORTRAN III included machine-dependent features that made code written in it unportable from machine to machine. Early versions of FORTRAN provided by other vendors suffered from the same disadvantage.\nFORTRAN IV\nStarting in 1961, as a result of customer demands, IBM began development of a FORTRAN IV that removed the machine-dependent features of FORTRAN II (such as READ INPUT TAPE), while adding new features such as a LOGICAL data type, logical Boolean expressions and the logical IF statement as an alternative to the arithmetic IF statement. FORTRAN IV was eventually released in 1962, first for the IBM 7030 ("Stretch") computer, followed by versions for the IBM 7090 and IBM 7094.\nBy 1965, Fortran IV was supposed to be the "standard" and in compliance with American Standards Association X3.4.3 FORTRAN Working Group.[9]\nFORTRAN 66\nPerhaps the most significant development in the early history of FORTRAN was the decision by the American Standards Association (now ANSI) to form a committee to develop an "American Standard Fortran." The resulting two standards, approved in March 1966, defined two languages, FORTRAN (based on FORTRAN IV, which had served as a de facto standard), and Basic FORTRAN (based on FORTRAN II, but stripped of its machine-dependent features). The FORTRAN defined by the first standard became known as FORTRAN 66 (although many continued to refer to it as FORTRAN IV, the language upon which the standard was largely based). FORTRAN 66 effectively became the first "industry-standard" version of FORTRAN. FORTRAN 66 included:\nMain program, SUBROUTINE, FUNCTION, and BLOCK DATA program units\nINTEGER, REAL, DOUBLE PRECISION, COMPLEX, and LOGICAL data types\nCOMMON, DIMENSION, and EQUIVALENCE statements\nDATA statement for specifying initial values\nIntrinsic and EXTERNAL (e.g., library) functions\nAssignment statement\nGOTO, assigned GOTO, and computed GOTO statements\nLogical IF and arithmetic (three-way) IF statements\nDO loops\nREAD, WRITE, BACKSPACE, REWIND, and ENDFILE statements for sequential I/O\nFORMAT statement\nCALL, RETURN, PAUSE, and STOP statements\nHollerith constants in DATA and FORMAT statements, and as actual arguments to procedures\nIdentifiers of up to six characters in length\nComment lines\nFORTRAN 77\nAfter the release of the FORTRAN 66 standard, compiler vendors introduced a number of extensions to "Standard Fortran", prompting ANSI in 1969 to begin work on revising the 1966 standard. Final drafts of this revised standard circulated in 1977, leading to formal approval of the new FORTRAN standard in April 1978. The new standard, known as FORTRAN 77, added a number of significant features to address many of the shortcomings of FORTRAN 66:\nBlock IF and END IF statements, with optional ELSE and ELSE IF clauses, to provide improved language support for structured programming\nDO loop extensions, including parameter expressions, negative increments, and zero trip counts\nOPEN, CLOSE, and INQUIRE statements for improved I/O capability\nDirect-access file I/O\nIMPLICIT statement\nCHARACTER data type, with vastly expanded facilities for character input and output and processing of character-based data\nPARAMETER statement for specifying constants\nSAVE statement for persistent local variables\nGeneric names for intrinsic functions\nA set of intrinsics (LGE, LGT, LLE, LLT) for lexical comparison of strings, based upon the ASCII collating sequence.\n(ASCII functions were demanded by the U. S. Department of Defense, in their conditional approval vote.)\nIn this revision of the standard, a number of features were removed or altered in a manner that might invalidate previously standard-conforming programs. (Removal was the only allowable alternative to X3J3 at that time, since the concept of "deprecation" was not yet available for ANSI standards.) While most of the 24 items in the conflict list (see Appendix A2 of X3.9-1978) addressed loopholes or pathological cases permitted by the previous standard but rarely used, a small number of specific capabilities were deliberately removed, such as:\nHollerith constants and Hollerith data, such as:\nGREET = 12HHELLO THERE!\nReading into a H edit (Hollerith field) descriptor in a FORMAT specification.\nOverindexing of array bounds by subscripts.\nDIMENSION A(10,5)\nY= A(11,1)\nTransfer of control into the range of a DO loop (also known as "Extended Range").\nAn important practical extension to FORTRAN 77 was the release of MIL-STD-1753 in 1978. This specification, developed by the U. S. Department of Defense, standardized a number of features implemented by most FORTRAN 77 compilers but not included in the ANSI FORTRAN 77 standard. These features would eventually be incorporated into the Fortran 90 standard.\nDO WHILE and END DO statements\nINCLUDE statement\nIMPLICIT NONE variant of the IMPLICIT statement\nBit manipulation intrinsic functions, based on similar functions included in Industrial Real-Time Fortran (ANSI/ISA S61.1 (1976))\nThe IEEE 1003.9 POSIX Standard, released in 1991, provided a simple means for Fortran-77 programmers to issue POSIX system calls. Over 100 calls were defined in the document — allowing access to POSIX-compatible process control, signal handling, file system control, device control, procedure pointing, and stream I/O in a portable manner.\nThe development of a revised standard to succeed FORTRAN 77 would be repeatedly delayed as the standardization process struggled to keep up with rapid changes in computing and programming practice. In the meantime, as the "Standard FORTRAN" for nearly fifteen years, FORTRAN 77 would become the historically most important dialect.\nControl Data Corporation computers had another version of FORTRAN 77, called Minnesota FORTRAN, with variations in output constructs, special uses of COMMONs and DATA statements, optimizations code levels for compiling, and detailed error listings, extensive warning messages, and debugs.[10]\nFortran 90\nThe much delayed successor to FORTRAN 77, informally known as Fortran 90, was finally released as an ISO standard in 1991 and an ANSI Standard in 1992. This major revision added many new features to reflect the significant changes in programming practice that had evolved since the 1978 standard:\nFree-form source input, also with lowercase Fortran keywords\nIdentifiers up to 31 characters in length\nInline comments\nAbility to operate on arrays (or array sections) as a whole, thus greatly simplifying math and engineering computations.\nwhole, partial and masked array assignment statements and array expressions, such as\nX(1:N)=R(1:N)*COS(A(1:N)))\nWHERE statement for selective array assignment\narray-valued constants and expressions,\nuser-defined array-valued functions and array constructors.\nRECURSIVE procedures\nModules, to group related procedures and data together, and make them available to other program units, including the capability to limit the accessibility to only specific parts of the module.\nA vastly improved argument-passing mechanism, allowing interfaces to be checked at compile time\nUser-written interfaces for generic procedures\nOperator overloading\nDerived/abstract data types\nNew data type declaration syntax, to specify the data type and other attributes of variables\nDynamic memory allocation by means of the ALLOCATABLE attribute and the ALLOCATE and DEALLOCATE statements\nPOINTER attribute, pointer assignment, and NULLIFY statement to facilitate the creation and manipulation of dynamic data structures\nStructured looping constructs, with an END DO statement for loop termination, and EXIT and CYCLE statements for "breaking out" of normal DO loop iterations in an orderly way\nSELECT . . . CASE construct for multi-way selection\nPortable specification of numerical precision under the user''s control\nNew and enhanced intrinsic procedures.\nObsolescence & deletions\nUnlike the previous revision, Fortran 90 did not delete any features. (Appendix B.1 says, "The list of deleted features in this standard is empty.") Any standard-conforming FORTRAN 77 program is also standard-conforming under Fortran 90, and either standard should be usable to define its behavior.\nA small set of features were identified as "obsolescent" and expected to be removed in a future standard.\nObsolescent feature\nExample\nStatus / 95\nArithmetic IF-statement\nIF (X) 10, 20, 30\nNon-integer DO parameters or control variables\nDO 9 X= 1.7, 1.6, -0.1\nDeleted\nShared DO-loop termination or\ntermination with a statement\nother than END DO or CONTINUE\nDO 9 J= 1, 10\nDO 9 K= 1, 10\n9\nL= J + K\nBranching to END IF\nfrom outside a block\n66\nGO TO 77 ; . . .\nIF (E) THEN ;\n. . .\n77\nEND IF\nDeleted\nAlternate return\nCALL SUBR( X, Y *100, *200 )\nPAUSE statement\nPAUSE 600\nDeleted\nASSIGN statement\nand assigned GO TO statement\n100\n. . .\nASSIGN 100 TO H\n. . .\nGO TO H . . .\nDeleted\nAssigned FORMAT specifiers\nASSIGN F TO 606\nDeleted\nH edit descriptors\n606 FORMAT ( 9H1GOODBYE. )\nDeleted\nComputed GO TO statement\nGO TO (10, 20, 30, 40), index\n(Obso.)\nStatement functions\nFOIL( X, Y )= X**2 + 2*X*Y + Y**2\n(Obso.)\nDATA statements\namong executable statements\nX= 27.3\nDATA A, B, C / 5.0, 12.0. 13.0 /\n. . .\n(Obso.)\nCHARACTER* form of CHARACTER declaration\nCHARACTER*8 STRING\n! Use CHARACTER(8)\n(Obso.)\nAssumed character length functions\nFixed form source code\n* Column 1 contains * or ! or C for comments.\nC\nColumn 6 for continuation.\nFortran 95\nFortran 95 was a minor revision, mostly to resolve some outstanding issues from the Fortran 90 standard. Nevertheless, Fortran 95 also added a number of extensions, notably from the High Performance Fortran specification:\nFORALL and nested WHERE constructs to aid vectorization\nUser-defined PURE and ELEMENTAL procedures\nPointer initialization and structure default initialization.\nA number of intrinsic functions were extended (for example a dim argument was added to the maxloc intrinsic).\nSeveral features noted in Fortran 90 to be deprecated were removed from Fortran 95:\nDO statements using REAL and DOUBLE PRECISION variables\nBranching to an END IF statement from outside its block\nPAUSE statement\nASSIGN and assigned GOTO statement, and assigned format specifiers\nH edit descriptor.\nAn important supplement to Fortran 95 was the ISO technical report TR-15581: Enhanced Data Type Facilities, informally known as the Allocatable TR. This specification defined enhanced use of ALLOCATABLE arrays, prior to the availability of fully Fortran 2003-compliant Fortran compilers. Such uses include ALLOCATABLE arrays as derived type components, in procedure dummy argument lists, and as function return values. (ALLOCATABLE arrays are preferable to POINTER-based arrays because ALLOCATABLE arrays are guaranteed by Fortran 95 to be deallocated automatically when they go out of scope, eliminating the possibility of memory leakage. In addition, aliasing is not an issue for optimization of array references, allowing compilers to generate faster code than in the case of pointers.)\nAnother important supplement to Fortran 95 was the ISO technical report TR-15580: Floating-point exception handling, informally known as the IEEE TR. This specification defined support for IEEE floating-point arithmetic and floating point exception handling.\nConditional compilation and varying length strings\nIn addition to the mandatory "Base language" (defined in ISO/IEC 1539-1 : 1997), the Fortran 95 language also includes two optional modules:\nVarying character strings (ISO/IEC 1539-2 : 2000)\nConditional compilation (ISO/IEC 1539-3 : 1998)\nwhich, together, comprise the multi-part International Standard (ISO/IEC 1539).\nAccording to the standards developers, "the optional parts describe self-contained features which have been requested by a substantial body of users and/or implementors, but which are not deemed to be of sufficient generality for them to be required in all standard-conforming Fortran compilers." Nevertheless, if a standard-conforming Fortran does provide such options, then they "must be provided in accordance with the description of those facilities in the appropriate Part of the Standard."\nFortran 2003\nThe most recent standard, Fortran 2003, is a major revision introducing many new features. A comprehensive summary of the new features of Fortran 2003 is available at the Fortran Working Group (WG5) official Web site.[11]\nFrom that article, the major enhancements for this revision include:\nDerived type enhancements: parameterized derived types, improved control of accessibility, improved structure constructors, and finalizers.\nObject oriented programming support: type extension and inheritance, polymorphism, dynamic type allocation, and type-bound procedures.\nData manipulation enhancements: allocatable components (incorporating TR 15581), deferred type parameters, VOLATILE attribute, explicit type specification in array constructors and allocate statements, pointer enhancements, extended initialization expressions, and enhanced intrinsic procedures.\nInput/output enhancements: asynchronous transfer, stream access, user specified transfer operations for derived types, user specified control of rounding during format conversions, named constants for preconnected units, the FLUSH statement, regularization of keywords, and access to error messages.\nProcedure pointers.\nSupport for IEEE floating-point arithmetic and floating point exception handling (incorporating TR 15580).\nInteroperability with the C programming language.\nSupport for international usage: access to ISO 10646 4-byte characters and choice of decimal or comma in numeric formatted input/output.\nEnhanced integration with the host operating system: access to command line arguments, environment variables, and processor error messages.\nAn important supplement to Fortran 2003 was the ISO technical report TR-19767: Enhanced module facilities in Fortran. This report provided submodules, which make Fortran modules more similar to Modula-2 modules. They are similar to Ada private child subunits. This allows the specification and implementation of a module to be expressed in separate program units, which improves packaging of large libraries, allows preservation of trade secrets while publishing definitive interfaces, and prevents compilation cascades.\nFortran 2008\nEfforts are underway to develop a revision to Fortran 2003, tentatively called Fortran 2008. As with Fortran 95, this is intended to be a minor upgrade, incorporating clarifications and corrections to Fortran 2003, as well as introducing a select few new capabilities. As of February 2007, the proposed new capabilities included[12]\nCo-array Fortran – a parallel processing model\nBIT data type\nIn August 2007, the BIT data type was removed. In February 2008, Coarrays were scaled back: Parallel I/O and teams were removed.\nThe complete original work plan is available at http://j3-fortran.org/doc/year/07/07-010.html.\nThe legacy of FORTRAN\nSince Fortran has been in use for more than fifty years, there is a vast body of Fortran in daily use throughout the scientific and engineering communities. It is the primary language for some of the most intensive supercomputing tasks, such as weather and climate modeling, computational fluid dynamics, computational chemistry, computational economics, and computational physics. Even today, half a century later, many of the floating-point benchmarks to gauge the performance of new computer processors are still written in Fortran (e.g., CFP2006, the floating-point component of the SPEC CPU2006 benchmarks).\nLanguage features\nThe Fortran language features described are intended to be a fairly comprehensive overview of the Fortran language; full details may be found in any of several Fortran textbooks. Only those features widely used in new programs are described, as few of the historic features are used in modern programs. Still, most have been retained in the language to maintain backward compatibility.\nFor more details on this topic, see Fortran language features.\nPortability\nPortability was a problem in the early days because there was no agreed standard—not even IBM''s reference manual—and computer companies vied to differentiate their offerings from others by providing incompatible features. Standards have improved portability. The 1966 standard provided a reference syntax and semantics, but vendors continued to provide incompatible extensions. Although careful programmers were coming to realize that use of incompatible extensions caused expensive portability problems, and were therefore using programs such as The PFORT Verifier, it was not until after the 1977 standard, when the National Bureau of Standards (now NIST) published FIPS PUB 69, that processors purchased by the U.S. Government were required to diagnose extensions of the standard. Rather than offer two processors, essentially every compiler eventually had at least an option to diagnose extensions.\nIncompatible extensions were not the only portability problem. For numerical calculations, it is important to take account of the characteristics of the arithmetic. This was addressed by Fox et al. in the context of the 1966 standard by the PORT library. The ideas therein became widely used, and were eventually incorporated into the 1990 standard by way of intrinsic inquiry functions. The widespread (now almost universal) adoption of the IEEE 754 standard for binary floating-point arithmetic has essentially removed this problem.\nAccess to the computing environment (e.g. the program''s command line, environment variables, textual explanation of error conditions) remained a problem until it was addressed by the 2003 standard.\nLarge collections of "library" software that could be described as being loosely-related to engineering and scientific calculations, such as graphics libraries, have been written in C, and therefore access to them presented a portability problem. This has been addressed by incorporation of C interoperability into the 2003 standard.\nIt is now possible (and relatively easy) to write an entirely portable program in Fortran, even without recourse to a preprocessor.\nVariants of Fortran\nSpecific variants\nVendors of high-performance scientific computers (e.g., Burroughs, CDC, Cray, Honeywell, IBM, Texas Instruments, and UNIVAC) added extensions to Fortran to take advantage of special hardware features such as instruction cache, CPU pipelines, and vector arrays. For example, one of IBM''s FORTRAN compilers (H Extended IUP) had a level of optimization which reordered the machine language instructions to keep multiple internal arithmetic units busy simultaneously. Another example is CFD, a special variant of Fortran designed specifically for the ILLIAC IV supercomputer, running at NASA''s Ames Research Center. IBM Research Labs also developed an extended FORTRAN-based language called "VECTRAN" for processing of vectors and matricies.\nObject-Oriented Fortran was an object-oriented extension of Fortran, in which data items can be grouped into objects, which can be instantiated and executed in parallel. It was available for Sun, Iris, iPSC, and nCUBE, but is no longer supported.\nSuch machine-specific extensions have either disappeared over time or have had elements incorporated into the main standards; the major remaining extension is OpenMP, which is a cross-platform extension for shared memory programming. One new extension, CoArray Fortran, is intended to support parallel programming.\nFOR TRANSIT for the IBM 650\n"FOR TRANSIT" was the name of a reduced version of the IBM 704 FORTRAN language, which was implemented for the IBM 650, using a translator program developed at Carnegie [13] in the late 1950s. The following comment appears in the IBM Reference Manual ("FOR TRANSIT Automatic Coding System" C28-4038, Copyright 1957, 1959 by IBM):\nThe FORTRAN system was designed for a more complex machine than the 650, and consequently some of the 32 statements found in the FORTRAN Programmer''s Reference Manual are not acceptable to the FOR TRANSIT system. In addition, certain restrictions to the FORTRAN language have been added. However, none of these restrictions make a source program written for FOR TRANSIT incompatible with the FORTRAN system for the 704.\nThe permissible statements were:\nArithmetic assignment statements, e.g. a = b\nGO to n\nGO TO (n1, n2, ..., nm), i\nIF (a) n1, n2, n3\nPAUSE\nSTOP\nDO n i = m1, m2\nCONTINUE\nEND\nREAD n, list\nPUNCH n, list\nDIMENSION V, V, V, ...\nEQUIVALENCE (a,b,c), (d,c), ...\nUp to ten subroutines could be used in one program.\nFOR TRANSIT statements were limited to columns 7 thru 56, only. Punched cards were used for input and output on the IBM 650. Three passes were required to translate source code to the "IT" language, then to compile the IT statements into SOAP assembly language, and finally to produce the object program, which could then be loaded into the machine to run the program (using punched cards for data input, and outputting results onto punched cards.)\nTwo versions existed for the 650s with a 2000 word memory drum: FOR TRANSIT I (S) and FOR TRANSIT II, the latter for machines equipped with indexing registers and automatic floating point decimal (bi-quinary) arithmetic. Appendix A of the manual included wiring diagrams for the IBM 533 control panel.\nFortran-based languages\nPrior to FORTRAN 77, a number of preprocessors were commonly used to provide a friendlier language, with the advantage that the preprocessed code could be compiled on any machine with a standard FORTRAN compiler. Popular preprocessors included FLECS, MORTRAN, Ratfor, and Ratfiv. (Ratfor and Ratfiv, for example, implemented a remarkably C-like language, outputting preprocessed code in standard FORTRAN 66.[14])\nThe Fortran-95 Standard includes an optional Part 3 which defines an optional conditional compilation capability. This capability is often referred to as "CoCo".\nMany Fortran compilers have integrated subsets of the C preprocessor into their systems.\nSIMSCRIPT is an application specific Fortran preprocessor for modeling and simulating large discrete systems.\nF (programming language) was designed to be a clean subset of Fortran 95 that attempted to remove the redundant, unstructured, and deprecated features of Fortran, such as the EQUIVALENCE statement. F retains the array features added in Fortran 90, and removes control statements that were obsoleted by structured programming constructs added both Fortran 77 and Fortran 90. F is described by its creators as "a compiled, structured, array programming language especially well suited to education and scientific computing." "F Programming Language Homepage)".\nCode examples\nThe sample programs can be compiled and run with any standard Fortran compiler (see the end of this article for lists of compilers). Most modern Fortran compilers expect a file with a .f or .for extension (for FORTRAN 66 or FORTRAN 77 fixed-form source, although the FORTRAN 66 dialect may have to be selected specifically with a command-line option) or .f90/.f95 extension (for Fortran 90/95 free-form source, respectively).\nFor more details on this topic, see Wikibooks:Fortran/Fortran examples.\nFORTRAN quotations\nWikiquote has a collection of quotations related to: Fortran\nFor a programming language with a half-century legacy, FORTRAN not surprisingly has accumulated its share of jokes and folklore.\nLetter O considered harmful\nDuring the same Fortran Standards Committee meeting at which the name "FORTRAN 77" was chosen, a technical proposal was somehow smuggled into the official distribution, bearing the title, "Letter O considered harmful". This deceptively simple proposal purported to address the confusion that sometimes arises between the letter "O" and the numeral zero, by eliminating the letter from allowable variable names. However, the method proposed was to eliminate the letter from the character set entirely (thereby retaining 48 as the number of lexical characters, which the colon had increased to 49).\nAmong the "PRO" arguments was the assertion that this would also promote structured programming, by making it impossible to use the notorious GO TO statement as before. (Troublesome FORMAT statements would be eliminated, as well.)\nThe sole "CON" argument conceded that "this might invalidate some existing programs" but noted that most of these "probably were non-conforming, anyway".[15] [16]\nSee also\nAlphabetical list of programming languages\nReferences\nTextbooks\nAkin, Ed (2003). Object Oriented Programming via Fortran 90/95 (1st ed.). Cambridge University Press. ISBN 0-521-52408-3.\nEtter, D. M. (1990). Structured FORTRAN 77 for Engineers and Scientists (3rd ed.). The Benjamin/Cummings Publishing Company, Inc.. ISBN 0-8053-0051-1.\nChapman, Stephen J. (2007). Fortran 95/2003 for Scientists and Engineers (3rd ed.). McGraw-Hill. ISBN 978-0-07-319157-7.\nChapman, Stephen J. (2003). Fortran 90/95 for Scientists and Engineers (2nd ed.). McGraw-Hill. ISBN 0-07-282575-8.\nChivers, Ian; Jane Sleightholme (2006). Introduction to Programming with Fortran (1st ed.). Springer. ISBN 1-84628-053-2.\nEllis, T. M. R.; Ivor R. Phillips, Thomas M. Lahey (1994). Fortran 90 Programming (1st ed.). Addison Wesley. ISBN 0-201-54446-6.\nKupferschmid, Michael (2002). Classical Fortran: Programming for Engineering and Scientific Applications. Marcel Dekker (CRC Press). ISBN 0-8247-0802-4.\nMcCracken, Daniel D. (1961). A Guide to Fortran Programming. Wiley.\nMcCracken, Daniel D. (1965). A Guide to Fortran IV Programming. Wiley.\nMetcalf, Michael; John Reid, Malcolm Cohen (2004). Fortran 95/2003 Explained. Oxford University Press. ISBN 0-19-852693-8.\nNyhoff, Larry; Sanford Leestma (1995). FORTRAN 77 for Engineers and Scientists with an Introduction to Fortran 90 (4th ed.). Prentice Hall. ISBN 0-13-363003-X.\nda Cunha, Rudnei Dias (2005). Introdução à Linguagem de Programação Fortran 90. Editora da Universidade Federal do Rio Grande do Sul. ISBN 85-7025-829-1.\nMartínez Baena, Javier; Ignario Requena Ramos, Nicolás Marín Ruiz (2006). Programación estructurada con Fortran 90/95. Universidad de Granada. ISBN 84-338-3923-3.\n"Core" language standards\nANSI X3.9-1966. USA Standard FORTRAN. American National Standards Institute.\nInformally known as FORTRAN 66.\nANSI X3.9-1978. American National Standard – Programming Language FORTRAN. American National Standards Institute.\nAlso known as ISO 1539-1980, informally known as FORTRAN 77.\nANSI X3.198-1992 (R1997). American National Standard – Programming Language Fortran Extended. American National Standards Institute.\nInformally known as Fortran 90.\nISO/IEC 1539-1:1997. Information technology – Programming languages – Fortran – Part 1: Base language.\nInformally known as Fortran 95. There are a further two parts to this standard. Part 1 has been formally adopted by ANSI.\nISO/IEC 1539-1:2004. Information technology – Programming languages – Fortran – Part 1: Base language.\nInformally known as Fortran 2003.\nRelated standards\nWilfried Kneis (October 1981). "Draft standard Industrial Real-Time FORTRAN". ACM SIGPLAN Notices (ACM Press) 16 (7): 45–60. doi:10.1145/947864.947868.\nMIL-STD-1753. DoD Supplement to X3.9-1978. U. S. Government Printing Office.\nPOSIX 1003.9-1992. POSIX FORTRAN 77 Language Interface – Part 1: Binding for System Application Program Interface [API]. The Institute of Electrical and Electronics Engineers, Inc. http://standards.ieee.org/reading/ieee/std_public/description/posix/1003.9-1992_desc.html.\nISO 8651-1:1988 Information processing systems -- Computer graphics -- Graphical Kernel System (GKS) language bindings -- Part 1: FORTRAN\nNotes\n^ The names of earlier versions of the language through FORTRAN 77 were conventionally spelled in all-caps (FORTRAN 77 was the version in which the use of lowercase letters in keywords was strictly nonstandard). The capitalization has been dropped in referring to newer versions beginning with Fortran 90. The official language standards now refer to the language as "Fortran." Because the capitalisation (or lack thereof) of the word FORTRAN was never 100% consistent in actual usage, and because many hold impassioned beliefs on the issue, this article, rather than attempt to be normative, adopts the convention of using the all-caps FORTRAN in referring to versions of FORTRAN through FORTRAN 77 and the title-caps Fortran in referring to versions of Fortran from Fortran 90 onward. This convention is reflected in the capitalization of FORTRAN in the ANSI X3.9-1966 (FORTRAN 66) and ANSI X3.9-1978 (FORTRAN 77) standards and the title caps Fortran in the ANSI X3.198-1992 (Fortran 90) standard.\n^ Since FORTRAN 77, which introduced the CHARACTER data type.\n^ Since FORTRAN II (1958).\n^ http://en.wikipedia.org/wiki/LINPACK and http://www.top500.org/project/linpack\n^ http://www.softwarepreservation.org/projects/FORTRAN/index.html#By_FORTRAN_project_members\n^ Fortran creator John Backus dies - Gadgets - MSNBC.com\n^ Note: It is commonly believed that this statement corresponded to a three-way branch instruction on the IBM 704. This is not true, the 704 branch instructions all contained only one destination address (e.g., TZE — Transfer AC Zero, TNZ — Transfer AC Not Zero, TPL — Transfer AC Plus, TMI — Transfer AC Minus). The machine (and its successors in the 700/7000 series) did have a three-way skip instruction (CAS — Compare AC with Storage), which was probably the origin of this belief, but using this instruction to implement the IF would consume 4 instruction words, require the constant Zero in a word of storage, and take 3 machine cycles to execute; using the Transfer instructions to implement the IF could be done in 1 to 3 instruction words, required no constants in storage, and take 1 to 3 machine cycles to execute. An optimizing compiler like FORTRAN would most likely select the more compact and usually faster Transfers instead of the Compare (use of Transfers also allowed the FREQUENCY statement to optimize IFs, which could not be done using the Compare). Also the Compare considered −0 and +0 to be different values while the Transfer Zero and Transfer Not Zero considered them to be the same.\n^ The FREQUENCY statement in FORTRAN was used originally and optionally to give branch probabilities for the three branch cases of the Arithmetic IF statement to bias the way code was generated and order of the basic blocks of code generated, in the global optimisation sense, were arranged in memory for optimality. The first FORTRAN compiler used this weighting to do a Monte Carlo simulation of the run-time generated code at compile time. It was very sophisticated for its time. This technique is documented in the original article in 1957 on the first FORTRAN compiler implementation by J. Backus, et al. Many years later, the FREQUENCY statement had no effect on the code, and was treated as a comment statement, since the compilers no longer did this kind of compile-time simulation. Below is a part of the 1957 paper, "The FORTRAN Automatic Coding System" by Backus, et al., with this snippet on the FREQUENCY statement and its use in a compile-time Monte Carlo simulation of the run-time to optimise the code generated. Quoting …\nThe fundamental unit of program is the basic block; a basic block is a stretch of program which has a single entry point and a single exit point. The purpose of section 4 is to prepare for section 5 a table of predecessors (PRED table) which enumerates the basic blocks and lists for every basic block each of the basic blocks which can be its immediate predecessor in flow, together with the absolute frequency of each such basic block link. This table is obtained by an actual "execution" of the program in Monte-Carlo fashion, in which the outcome of conditional transfers arising out of IF-type statements and computed GO TO''S is determined by a random number generator suitably weighted according to whatever FREQUENCY statements have been provided.\n^ McCracken, Daniel D. (1965(3rd printing 1968)). A Guide to FORTRAN IV Programming. John Wiley & Sons, Inc., New York. LCCCN 65-26848.\nPreface p. v\n^ Chilton Computing with FORTRAN\n^ Fortran Working Group (WG5). It may also be downloaded as a PDF file or gzipped PostScript file.\n^ A full list is in the report available at http://www.fortran.bcs.org/2006/ukfortran06.pdfPDF (24.2 KB).\n^ "Internal Translator (IT) A Compiler for the IBM 650", by A. J. Perlis, J. W. Smith, and H. R. Van Zoeren, Computation Center, Carnegie Institute of Technology\n^ This is not altogether surprising, as Brian Kernighan, one of the co-creators of Ratfor, is also co-author of The C Programming Language.\n^ X3J3 post-meeting distribution for meeting held at Brookhaven National Laboratory in November 1976.\n^ "The obliteration of O", Computer Weekly, March 3, 1977\nThe external links in this article may not follow Wikipedia''s content policies or guidelines.\nPlease improve this article by removing excessive or inappropriate external links.\nWikibooks has a book on the topic of\nFortran\nHistory\n"The FORTRAN Automatic Coding System" (1.39 MB) — 1957 copy describes the design and implementation of the first FORTRAN compiler by the IBM team\nEarly Fortran manuals and The very first Fortran manual, by John Backus (6.11 MB) dated [1956-10-15]\nHistory of FORTRAN and Systems Manual for 704/ /709 FORTRAN (13.5 MB)\nFORTRAN at HOPL site\n"The IBM CE Manual for FORTRAN I, II, and 709" from 1959 (3.82 MB)\n"A History of Language Processor Technology in IBM" (1.45 MB) — by F.E. Allen, IBM Journal of Research and Development, v.25, no.5, September 1981\nStandards\nComprehensive Fortran Standards Documents by GFortran\nJTC1/SC22/WG5 — The ISO/IEC Fortran Working Group\nANSI(R) X3.9-1978 Fortran 77 Standard\nMIL-STD 1753 DoD Extensions to Fortran 77\nISO/IEC 1539:1991 Fortran 90 Standard\nfinal draft Fortran 95 Standard\nWG5 (2003) ISO/IEC JTC1/SC22/WG5 N1578 Final Committee Draft of Fortran 2003 standard\nTutorials\nProfessional Programmer''s Guide to FORTRAN 77 (493 KB) — Guide written by Clive G. Page of the University of Leicester\nUnit 7.1 FORTRAN 77 and Unit 7.2 Fortran 90 — Part of ASPIRE''s "Computational Science Textbook" project\nUser Notes on FORTRAN Programming (UNFP) — An open cooperative guide\nReferences\nThe Professional Programmer''s Guide to FORTRAN 77\nFortran 77, 90, 95, 2003 Information & Resources\nFortran 77 — FORTRAN 77 documentation\nFortran 77 4.0 Reference Manual (851 KB)\nFortran 90 Reference Card\nCode repositories\nFortran 90 Software Repository — Numerical Algorithms Group\nHigh-Precision Software Directory — Computational Research Division of Lawrence Berkeley National Laboratory\nNational HPCC Software Exchange (defunct) Department of Computer Science at the University of Tennessee at Knoxville\nNetlib Repository at the University of Tennessee at Knoxville and Oak Ridge National Laboratory\nSoftware from Alan J. Miller Logistic Regression, TOMS algorithms, Special code for F, Applied Statistics Algorithms and NAS compilers\nOpen source compilers\nGFortran — The GNU Fortran compiler, part of GCC. Distributed as part of GCC as of GCC 4.0. Replaced g77.\ng95 — Free, open source Fortran 95 compiler and runtime libraries\nOpen64 — Open Research Compiler. Suite of optimizing compiler development tools for Intel Itanium (Linux)\nOpen Watcom — A joint effort between SciTech Software Inc, Sybase and the Open Source development community to maintain Fortran cross compilers and tools\nNon-open source compilers\nIntel Fortran Compiler\nAbsoft Fortran 95/90/77 and C/C++ compilers for Windows, Mac OS 9 and OS X, Linux IA32 and AMD Opteron and AMD Athlon 64-bit processors\nIBM Fortran 95 compilers for AIX, Blue Gene, and Linux\nLahey/Fujitsu — Fortran 95 compilers for Linux and Windows\nNAGWare Fortran 95 compiler with 2003 features for Linux, Windows, and Unix on many platforms\nPathScale — Fortran 95, C, and C++ compilers for Linux on MIPS, AMD Opteron and Intel 64-bit and 32-bit x86 CPUs\nPGI Fortran 95, C and C++ Compilers for 32-bit and 64-bit AMD64 and IA32 processor-based Linux and Windows systems\nSilverfrost (was Salford) — Personal edition (Windows)\nSun Studio Compiler Suite — From Sun Microsystems; compiles optimized and parallelized code for the Solaris OS on SPARC and x86/x64 platforms, and Linux on x86/x64 platforms\nIntegrated Development Environment\nPhotran — An IDE for Fortran 77, 90, and 95 based on Eclipse and the CDT.\nGraphical libraries/GUI\nDISLIN — A high-level plotting library for displaying data as curves, polar plots, bar graphs, pie charts, 3D-color plots, surfaces, contours and maps\nf90gl — Public domain implementation of the official Fortran 90 bindings for OpenGL (Linux, Mac OS X, Solaris, UNIX, Windows)\nftcl — A Fortran–Tcl/TK interface\ng2 graphical library — Portable and 2D graphics library (Linux, Mac OS X, OpenVMS, Solaris, UNIX, Windows)GNU LGPL\nGrWin Graphics Library — Free graphics routine library for Fortran (Windows)\npilib — Platform Independent Library for Fortran 90/95 (Linux, Mac OS X, UNIX, Windows) GNU LGPL\nPLplot — A Scientific Plotting Library (Linux, Mac OS X, MS-DOS, Unix, Windows) GNU LGPL\nMATFOR — A Scientific Graphical Numerical Library (Linux, Mac OS X, MS-DOS, SuSe, Windows)\nTesting Frameworks\nFUnit — a unit testing framework.\nMiscellaneous\ncomp.lang.fortran on Usenet\nFortran — Open Directory category\nFORTRAN Coding form (41.2 KB)\nFortran (G77 and Gfortran) installation and configuration guide for Windows operating system\nFortran Tutorial Links\n"http://en.wikipedia.org/wiki/Fortran"\nCategories: Fortran | Array programming languages | Procedural programming languages | Numerical programming languages | Object-oriented programming languages | Parallel computing | FORTRAN programming language family | Computer and telecommunication standardsHidden category: Wikipedia external links cleanup','\n',char(10)));
INSERT INTO pages VALUES('Algorithm','http://web.archive.org/web/20081217070911/http://en.wikipedia.org:80/wiki/Algorithm','en','2008-12-17 00:00:00',replace('Flowcharts are often used to graphically represent algorithms.\nIn mathematics, computing, linguistics and related subjects, an algorithm is a sequence of finite instructions, often used for calculation and data processing. It is formally a type of effective method in which a list of well-defined instructions for completing a task will, when given an initial state, proceed through a well-defined series of successive states, eventually terminating in an end-state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as probabilistic algorithms, incorporate randomness.\nA partial formalization of the concept began with attempts to solve the Entscheidungsproblem (the "decision problem") posed by David Hilbert in 1928. Subsequent formalizations were framed as attempts to define "effective calculability" (Kleene 1943:274) or "effective method" (Rosser 1939:225); those formalizations included the Gödel-Herbrand-Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church''s lambda calculus of 1936, Emil Post''s "Formulation 1" of 1936, and Alan Turing''s Turing machines of 1936–7 and 1939.\n1 Etymology\n2 Why algorithms are necessary: an informal definition\n3 Formalization of algorithms\n3.1 Termination\n3.2 Expressing algorithms\n3.3 Implementation\n4 Example\n4.1 Algorithmic analysis\n5 Classes\n5.1 Classification by implementation\n5.2 Classification by design paradigm\n5.3 Classification by field of study\n5.4 Classification by complexity\n5.5 Classification by computing power\n6 Legal issues\n7 History: Development of the notion of "algorithm"\n7.1 Origin of the word\n7.2 Discrete and distinguishable symbols\n7.3 Manipulation of symbols as "place holders" for numbers: algebra\n7.4 Mechanical contrivances with discrete states\n7.5 Mathematics during the 1800s up to the mid-1900s\n7.6 Emil Post (1936) and Alan Turing (1936-7, 1939)\n7.7 J. B. Rosser (1939) and S. C. Kleene (1943)\n7.8 History after 1950\n8 References\n8.1 Secondary references\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nEtymology\nKhwārizmī, Persian astronomer and mathematician, wrote a treatise in 825 AD, On Calculation with Hindu Numerals. (See algorism). It was translated into Latin in the 12th century as Algoritmi de numero Indorum (al-Daffa 1977), which title was likely intended to mean "Algoritmi on the numbers of the Indians", where "Algoritmi" was the translator''s rendition of the author''s name; but people misunderstanding the title treated Algoritmi as a Latin plural and this led to the word "algorithm" (Latin algorismus) coming to mean "calculation method". The intrusive "th" is most likely due to a false cognate with the Greek ἀριθμός (arithmos) meaning "number".The bible uses algorithims but convenientially frowns upon it\nWhy algorithms are necessary: an informal definition\nNo generally accepted formal definition of "algorithm" exists yet.\nAn informal definition could be "an algorithm is a process that calculates something." For some people, a program is only an algorithm if it stops eventually. For others, a program is only an algorithm if it stops before a given number of calculation steps.\nA prototypical example of an "algorithm" is Euclid''s algorithm to determine the maximum common divisor of two integers greater than one: "subtract the smaller number from the larger one; repeat until you get a zero or a one." This procedure is known to stop always and the number of subtractions needed is always smaller than the larger of the two numbers.\nWe can derive clues to the issues involved and an informal meaning of the word from the following quotation from Boolos & Jeffrey (1974, 1999) (boldface added):\nNo human being can write fast enough or long enough or small enough to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols (Boolos & Jeffrey 1974, 1999, p. 19)\nThe words "enumerably infinite" mean "countable using integers perhaps extending to infinity." Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that "creates" output integers from an arbitrary "input" integer or integers that, in theory, can be chosen from 0 to infinity. Thus we might expect an algorithm to be an algebraic equation such as y = m + n — two arbitrary "input variables" m and n that produce an output y. As we see in Algorithm characterizations — the word algorithm implies much more than this, something on the order of (for our addition example):\nPrecise instructions (in language understood by "the computer") for a "fast, efficient, good" process that specifies the "moves" of "the computer" (machine or human, equipped with the necessary internally-contained information and capabilities) to find, decode, and then munch arbitrary input integers/symbols m and n, symbols + and = ... and (reliably, correctly, "effectively") produce, in a "reasonable" time, output-integer y at a specified place and in a specified format.\nThe concept of algorithm is also used to define the notion of decidability. That notion is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related with our customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.\nFor a detailed presentation of the various points of view around the definition of "algorithm" see Algorithm characterizations. For examples of simple addition algorithms specified in the detailed manner described in Algorithm characterizations, see Algorithm examples.\nFormalization of algorithms\nAlgorithms are essential to the way computers process information. Many computer programs contain algorithms that specify the specific instructions a computer should perform (in a specific order) to carry out a specified task, such as calculating employees’ paychecks or printing students’ report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Savage (1987) and Gurevich (2000):\n...Turing''s informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine (Gurevich 2000:1)...according to Savage [1987], an algorithm is a computational process defined by a Turing machine. (Gurevich 2000:3)\nTypically, when an algorithm is associated with processing information, data is read from an input source, written to an output device, and/or stored for further processing. Stored data is regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.\nFor any such computational process, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise. That is, any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).\nBecause an algorithm is a precise list of precise steps, the order of computation will always be critical to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom", an idea that is described more formally by flow of control.\nSo far, this discussion of the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception, and it attempts to describe a task in discrete, "mechanical" means. Unique to this conception of formalized algorithms is the assignment operation, setting the value of a variable. It derives from the intuition of "memory" as a scratchpad. There is an example below of such an assignment.\nFor some alternate conceptions of what constitutes an algorithm see functional programming and logic programming .\nTermination\nSome writers restrict the definition of algorithm to procedures that eventually finish. In such a category Kleene places the "decision procedure or decision method or algorithm for the question" (Kleene 1952:136). Others, including Kleene, include procedures that could run forever without stopping; such a procedure has been called a "computational method" (Knuth 1997:5) or "calculation procedure or algorithm" (Kleene 1952:137); however, Kleene notes that such a method must eventually exhibit "some object" (Kleene 1952:137).\nMinsky makes the pertinent observation, in regards to determining whether an algorithm will eventually terminate (from a particular starting state):\nBut if the length of the process is not known in advance, then "trying" it may not be decisive, because if the process does go on forever — then at no time will we ever be sure of the answer (Minsky 1967:105).\nAs it happens, no other method can do any better, as was shown by Alan Turing with his celebrated result on the undecidability of the so-called halting problem. There is no algorithmic procedure for determining of arbitrary algorithms whether or not they terminate from given starting states. The analysis of algorithms for their likelihood of termination is called termination analysis.\nSee the examples of (im-)"proper" subtraction at partial function for more about what can happen when an algorithm fails for certain of its input numbers — e.g., (i) non-termination, (ii) production of "junk" (output in the wrong format to be considered a number) or no number(s) at all (halt ends the computation with no output), (iii) wrong number(s), or (iv) a combination of these. Kleene proposed that the production of "junk" or failure to produce a number is solved by having the algorithm detect these instances and produce e.g., an error message (he suggested "0"), or preferably, force the algorithm into an endless loop (Kleene 1952:322). Davis does this to his subtraction algorithm — he fixes his algorithm in a second example so that it is proper subtraction (Davis 1958:12-15). Along with the logical outcomes "true" and "false" Kleene also proposes the use of a third logical symbol "u" — undecided (Kleene 1952:326) — thus an algorithm will always produce something when confronted with a "proposition". The problem of wrong answers must be solved with an independent "proof" of the algorithm e.g., using induction:\nWe normally require auxiliary evidence for this (that the algorithm correctly defines a mu recursive function), e.g., in the form of an inductive proof that, for each argument value, the computation terminates with a unique value (Minsky 1967:186).\nExpressing algorithms\nAlgorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, and programming languages. Natural language expressions of algorithms tend to be verbose and ambiguous, and are rarely used for complex or technical algorithms. Pseudocode and flowcharts are structured ways to express algorithms that avoid many of the ambiguities common in natural language statements, while remaining independent of a particular implementation language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but are often used as a way to define or document algorithms.\nThere is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see more at finite state machine and state transition table), as flowcharts (see more at state diagram), or as a form of rudimentary machine code or assembly code called "sets of quadruples" (see more at Turing machine).\nSometimes it is helpful in the description of an algorithm to supplement small "flow charts" (state diagrams) with natural-language and/or arithmetic expressions written inside "block diagrams" to summarize what the "flow charts" are accomplishing.\nRepresentations of algorithms are generally classed into three accepted levels of Turing machine description (Sipser 2006:157):\n1 High-level description:\n"...prose to describe an algorithm, ignoring the implementation details. At this level we do not need to mention how the machine manages its tape or head"\n2 Implementation description:\n"...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level we do not give details of states or transition function"\n3 Formal description:\nMost detailed, "lowest level", gives the Turing machine''s "state table".\nFor an example of the simple algorithm "Add m+n" described in all three levels see Algorithm examples.\nImplementation\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.\nExample\nOne of the simplest algorithms is to find the largest number in an (unsorted) list of numbers. The solution necessarily requires looking at every number in the list, but only once at each. From this follows a simple algorithm, which can be stated in a high-level description English prose, as:\nHigh-level description:\nAssume the first item is largest.\nLook at each of the remaining items in the list and if it is larger than the largest item so far, make a note of it.\nThe last noted item is the largest in the list when the process is complete.\n(Quasi-)formal description: Written in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:\nAlgorithm LargestNumber\nInput: A non-empty list of numbers L.\nOutput: The largest number in the list L.\nlargest ← L0\nfor each item in the list L≥1, do\nif the item > largest, then\nlargest ← the item\nreturn largest\n"←" is a loose shorthand for "changes to". For instance, "largest ← item" means that the value of largest changes to the value of item.\n"return" terminates the algorithm and outputs the value that follows.\nFor a more complex example of an algorithm, see Euclid''s algorithm for the greatest common divisor, one of the earliest algorithms known.\nAlgorithmic analysis\nAs it happens, it is important to know how much of a particular resource (such as time or storage) is required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers; for example, the algorithm above has a time requirement of O(n), using the big O notation with n as the length of the list. At all times the algorithm only needs to remember two values: the largest number found so far, and its current position in the input list. Therefore it is said to have a space requirement of O(1), if the space required to store the input numbers is not counted, or O (log n) if it is counted.\nDifferent algorithms may complete the same task with a different set of instructions in less or more time, space, or effort than others. For example, given two different recipes for making potato salad, one may have peel the potato before boil the potato while the other presents the steps in the reverse order, yet they both call for these steps to be repeated for all potatoes and end when the potato salad is ready to be eaten.\nThe analysis and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation.\nClasses\nThere are various ways to classify algorithms, each with its own merits.\nClassification by implementation\nOne way to classify algorithms is by implementation means.\nRecursion or iteration: A recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition matches, which is a method common to functional programming. Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. Some problems are naturally suited for one implementation or the other. For example, towers of hanoi is well understood in recursive implementation. Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.\nLogical: An algorithm may be viewed as controlled logical deduction. This notion may be expressed as: Algorithm = logic + control (Kowalski 1979). The logic component expresses the axioms that may be used in the computation and the control component determines the way in which deduction is applied to the axioms. This is the basis for the logic programming paradigm. In pure logic programming languages the control component is fixed and algorithms are specified by supplying only the logic component. The appeal of this approach is the elegant semantics: a change in the axioms has a well defined change in the algorithm.\nSerial or parallel or distributed: Algorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. Those computers are sometimes called serial computers. An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. Parallel algorithms take advantage of computer architectures where several processors can work on a problem at the same time, whereas distributed algorithms utilize multiple machines connected with a network. Parallel or distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. Sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable. Some problems have no parallel algorithms, and are called inherently serial problems.\nDeterministic or non-deterministic: Deterministic algorithms solve the problem with exact decision at every step of the algorithm whereas non-deterministic algorithm solve problems via guessing although typical guesses are made more accurate through the use of heuristics.\nExact or approximate: While many algorithms reach an exact solution, approximation algorithms seek an approximation that is close to the true solution. Approximation may use either a deterministic or a random strategy. Such algorithms have practical value for many hard problems.\nClassification by design paradigm\nAnother way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories will include many different types of algorithms. Some commonly found paradigms include:\nDivide and conquer. A divide and conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem (usually recursively), until the instances are small enough to solve easily. One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data after dividing data into segments and sorting of entire data can be obtained in conquer phase by merging them. A simpler variant of divide and conquer is called decrease and conquer algorithm, that solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. Divide and conquer divides the problem into multiple subproblems and so conquer stage will be more complex than decrease and conquer algorithms. An example of decrease and conquer algorithm is binary search algorithm.\nDynamic programming. When a problem shows optimal substructure, meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems, and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. For example, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. Dynamic programming and memoization go together. The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.\nThe greedy method. A greedy algorithm is similar to a dynamic programming algorithm, but the difference is that solutions to the subproblems do not have to be known at each stage; instead a "greedy" choice can be made of what looks best for the moment. The greedy method extends the solution with the best possible decision (not all feasible decisions) at an algorithmic stage based on the current local optimum and the best decision (not all possible decisions) made in previous stage. It is not exhaustive, and does not give accurate answer to many problems. But when it works, it will be the fastest method. The most popular greedy algorithm is finding the minimal spanning tree as given by Kruskal.\nLinear programming. When solving a problem using linear programming, specific inequalities involving the inputs are found and then an attempt is made to maximize (or minimize) some linear function of the inputs. Many problems (such as the maximum flow for directed graphs) can be stated in a linear programming way, and then be solved by a ''generic'' algorithm such as the simplex algorithm. A more complex variant of linear programming is called integer programming, where the solution space is restricted to the integers.\nReduction. This technique involves solving a difficult problem by transforming it into a better known problem for which we have (hopefully) asymptotically optimal algorithms. The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm''s. For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion) and then pulling out the middle element in the sorted list (the cheap portion). This technique is also known as transform and conquer.\nSearch and enumeration. Many problems (such as playing chess) can be modeled as problems on graphs. A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. This category also includes search algorithms, branch and bound enumeration and backtracking.\nThe probabilistic and heuristic paradigm. Algorithms belonging to this class fit the definition of an algorithm more loosely.\nProbabilistic algorithms are those that make some choices randomly (or pseudo-randomly); for some problems, it can in fact be proven that the fastest solutions must involve some randomness.\nGenetic algorithms attempt to find solutions to problems by mimicking biological evolutionary processes, with a cycle of random mutations yielding successive generations of "solutions". Thus, they emulate reproduction and "survival of the fittest". In genetic programming, this approach is extended to algorithms, by regarding the algorithm itself as a "solution" to a problem.\nHeuristic algorithms, whose general purpose is not to find an optimal solution, but an approximate solution where the time or resources are limited. They are not practical to find perfect solutions. An example of this would be local search, tabu search, or simulated annealing algorithms, a class of heuristic probabilistic algorithms that vary the solution of a problem by a random amount. The name "simulated annealing" alludes to the metallurgic term meaning the heating and cooling of metal to achieve freedom from defects. The purpose of the random variance is to find close to globally optimal solutions rather than simply locally optimal ones, the idea being that the random element will be decreased as the algorithm settles down to a solution.\nClassification by field of study\nList of algorithms\nEvery field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.\nFields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was originally invented for optimization of resource consumption in industry, but is now used in solving a broad range of problems in many fields.\nClassification by complexity\nComplexity class and Parameterized Complexity\nAlgorithms can be classified by the amount of time they need to complete compared to their input size. There is a wide variety: some algorithms complete in linear time relative to input size, some do so in an exponential amount of time or even worse, and some never halt. Additionally, some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.\nClassification by computing power\nAnother way to classify algorithms is by computing power. This is typically done by considering some collection (class) of algorithms. A recursive class of algorithms is one that includes algorithms for all Turing computable functions. Looking at classes of algorithms allows for the possibility of restricting the available computational resources (time and memory) used in a computation. A subrecursive class of algorithms is one in which not all Turing computable functions can be obtained. For example, the algorithms that run in polynomial time suffice for many important types of computation but do not exhaust all Turing computable functions. The class of algorithms implemented by primitive recursive functions is another subrecursive class.\nBurgin (2005, p. 24) uses a generalized definition of algorithms that relaxes the common requirement that the output of the algorithm that computes a function must be determined after a finite number of steps. He defines a super-recursive class of algorithms as "a class of algorithms in which it is possible to compute functions not computable by any Turing machine" (Burgin 2005, p. 107). This is closely related to the study of methods of hypercomputation.\nLegal issues\nSoftware patents for a general overview of the patentability of software, including computer-implemented algorithms.\nAlgorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals do not constitute "processes" (USPTO 2006) and hence algorithms are not patentable (as in Gottschalk v. Benson). However, practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is highly controversial, and there are highly criticized patents involving algorithms, especially data compression algorithms, such as Unisys'' LZW patent.\nAdditionally, some cryptographic algorithms have export restrictions (see export of cryptography).\nHistory: Development of the notion of "algorithm"\nOrigin of the word\nThe word algorithm comes from the name of the 9th century Persian mathematician Abu Abdullah Muhammad ibn Musa al-Khwarizmi whose works introduced Indian numerals and algebraic concepts. He worked in Baghdad at the time when it was the centre of scientific studies and trade. The word algorism originally referred only to the rules of performing arithmetic using Arabic numerals but evolved via European Latin translation of al-Khwarizmi''s name into algorithm by the 18th century. The word evolved to include all definite procedures for solving problems or performing tasks.\nDiscrete and distinguishable symbols\nTally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks, or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p.16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post-Turing machine computations.\nManipulation of symbols as "place holders" for numbers: algebra\nThe work of the ancient Greek geometers, Persian mathematician Al-Khwarizmi (often considered the "father of algebra" and from whose name the terms "algorism" and "algorithm" are derived), and Western European mathematicians culminated in Leibniz''s notion of the calculus ratiocinator (ca 1680):\n"A good century and a half ahead of his time, Leibniz proposed an algebra of logic, an algebra that would specify the rules for manipulating logical concepts in the manner that ordinary algebra specifies the rules for manipulating numbers" (Davis 2000:1)\nMechanical contrivances with discrete states\nThe clock: Bolter credits the invention of the weight-driven clock as “The key invention [of Europe in the Middle Ages]", in particular the verge escapement (Bolter 1984:24) that provides us with the tick and tock of a mechanical clock. “The accurate automatic machine” (Bolter 1984:26) led immediately to "mechanical automata" beginning in the thirteenth century and finally to “computational machines" – the difference engine and analytical engines of Charles Babbage and Countess Ada Lovelace (Bolter p.33–34, p.204–206).\nJacquard loom, Hollerith punch cards, telegraphy and telephony — the electromechanical relay: Bell and Newell (1971) indicate that the Jacquard loom (1801), precursor to Hollerith cards (punch cards, 1887), and “telephone switching technologies” were the roots of a tree leading to the development of the first computers (Bell and Newell diagram p. 39, cf Davis 2000). By the mid-1800s the telegraph, the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as “dots and dashes” a common sound. By the late 1800s the ticker tape (ca 1870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the Teletype (ca 1910) with its punched-paper use of Baudot code on tape.\nTelephone-switching networks of electromechanical relays (invented 1835) was behind the work of George Stibitz (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the “burdensome’ use of mechanical calculators with gears. "He went home one evening in 1937 intending to test his idea.... When the tinkering was over, Stibitz had constructed a binary adding device". (Valley News, p. 13).\nDavis (2000) observes the particular importance of the electromechanical relay (with its two "binary states" open and closed):\nIt was only with the development, beginning in the 1930s, of electromechanical calculators using electrical relays, that machines were built having the scope Babbage had envisioned." (Davis, p. 14).\nMathematics during the 1800s up to the mid-1900s\nSymbols and rules: In rapid succession the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano''s The principles of arithmetic, presented by a new method (1888) was "the first attempt at an axiomatization of mathematics in a symbolic language" (van Heijenoort:81ff).\nBut Heijenoort gives Frege (1879) this kudos: Frege’s is "perhaps the most important single work ever written in logic. ... in which we see a " ''formula language'', that is a lingua characterica, a language written with special symbols, "for pure thought", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules" (van Heijenoort:1). The work of Frege was further simplified and amplified by Alfred North Whitehead and Bertrand Russell in their Principia Mathematica (1910–1913).\nThe paradoxes: At the same time a number of disturbing paradoxes appeared in the literature, in particular the Burali-Forti paradox (1897), the Russell paradox (1902–03), and the Richard Paradox (Dixon 1906, cf Kleene 1952:36–40). The resultant considerations led to Kurt Gödel’s paper (1931) — he specifically cites the paradox of the liar — that completely reduces rules of recursion to numbers.\nEffective calculability: In an effort to solve the Entscheidungsproblem defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an "effective method" or "effective calculation" or "effective calculability" (i.e., a calculation that would succeed). In rapid succession the following appeared: Alonzo Church, Stephen Kleene and J.B. Rosser''s λ-calculus, (cf footnote in Alonzo Church 1936a:90, 1936b:110) a finely-honed definition of "general recursion" from the work of Gödel acting on suggestions of Jacques Herbrand (cf Gödel''s Princeton lectures of 1934) and subsequent simplifications by Kleene (1935-6:237ff, 1943:255ff). Church''s proof (1936:88ff) that the Entscheidungsproblem was unsolvable, Emil Post''s definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction (cf "Formulation I", Post 1936:289-290). Alan Turing''s proof of that the Entscheidungsproblem was unsolvable by use of his "a- [automatic-] machine"(Turing 1936-7:116ff) -- in effect almost identical to Post''s "formulation", J. Barkley Rosser''s definition of "effective method" in terms of "a machine" (Rosser 1939:226). S. C. Kleene''s proposal of a precursor to "Church thesis" that he called "Thesis I" (Kleene 1943:273–274), and a few years later Kleene''s renaming his Thesis "Church''s Thesis" (Kleene 1952:300, 317) and proposing "Turing''s Thesis" (Kleene 1952:376).\nEmil Post (1936) and Alan Turing (1936-7, 1939)\nHere is a remarkable coincidence of two men not knowing each other but describing a process of men-as-computers working on computations — and they yield virtually identical definitions.\nEmil Post (1936) described the actions of a "computer" (human being) as follows:\n"...two concepts are involved: that of a symbol space in which the work leading from problem to answer is to be carried out, and a fixed unalterable set of directions.\nHis symbol space would be\n"a two way infinite sequence of spaces or boxes... The problem solver or worker is to move and work in this symbol space, being capable of being in, and operating in but one box at a time.... a box is to admit of but two possible conditions, i.e., being empty or unmarked, and having a single mark in it, say a vertical stroke.\n"One box is to be singled out and called the starting point. ...a specific problem is to be given in symbolic form by a finite number of boxes [i.e., INPUT] being marked with a stroke. Likewise the answer [i.e., OUTPUT] is to be given in symbolic form by such a configuration of marked boxes....\n"A set of directions applicable to a general problem sets up a deterministic process when applied to each specific problem. This process will terminate only when it comes to the direction of type (C ) [i.e., STOP]." (U p. 289–290) See more at Post-Turing machine\nAlan Turing’s work (1936, 1939:160) preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing’s biographer believed that Turing’s use of a typewriter-like model derived from a youthful interest: “Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter; and he could well have begun by asking himself what was meant by calling a typewriter ''mechanical''" (Hodges, p. 96). Given the prevalence of Morse code and telegraphy, ticker tape machines, and Teletypes we might conjecture that all were influences.\nTuring — his model of computation is now called a Turing machine — begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and "states of mind". But he continues a step further and creates a machine as a model of computation of numbers (Turing 1936-7:116).\n"Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child''s arithmetic book....I assume then that the computation is carried out on one-dimensional paper, i.e., on a tape divided into squares. I shall also suppose that the number of symbols which may be printed is finite....\n"The behavior of the computer at any moment is determined by the symbols which he is observing, and his "state of mind" at that moment. We may suppose that there is a bound B to the number of symbols or squares which the computer can observe at one moment. If he wishes to observe more, he must use successive observations. We will also suppose that the number of states of mind which need be taken into account is finite...\n"Let us imagine that the operations performed by the computer to be split up into ''simple operations'' which are so elementary that it is not easy to imagine them further divided" (Turing 1936-7:136).\nTuring''s reduction yields the following:\n"The simple operations must therefore include:\n"(a) Changes of the symbol on one of the observed squares\n"(b) Changes of one of the squares observed to another square within L squares of one of the previously observed squares.\n"It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must therefore be taken to be one of the following:\n"(A) A possible change (a) of symbol together with a possible change of state of mind.\n"(B) A possible change (b) of observed squares, together with a possible change of state of mind"\n"We may now construct a machine to do the work of this computer." (Turing 1936-7:136)\nA few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:\n"A function is said to be "effectively calculable" if its values can be found by some purely mechanical process. Although it is fairly easy to get an intuitive grasp of this idea, it is neverthessless desirable to have some more definite, mathematical expressible definition . . . [he discusses the history of the definition pretty much as presented above with respect to Gödel, Herbrand, Kleene, Church, Turing and Post] . . . We may take this statement literally, understanding by a purely mechanical process one which could be carried out by a machine. It is possible to give a mathematical description, in a certain normal form, of the structures of these machines. The development of these ideas leads to the author''s definition of a computable function, and to an identification of computability † with effective calculability . . . .\n"† We shall use the expression "computable function" to mean a function calculable by a machine, and we let "effectively calculabile" refer to the intuitive idea without particular identification with any one of these definitions."(Turing 1939:160)\nJ. B. Rosser (1939) and S. C. Kleene (1943)\nJ. Barkley Rosser boldly defined an ‘effective [mathematical] method’ in the following manner (boldface added):\n"''Effective method'' is used here in the rather special sense of a method each step of which is precisely determined and which is certain to produce the answer in a finite number of steps. With this special meaning, three different precise definitions have been given to date. [his footnote #5; see discussion immediately below]. The simplest of these to state (due to Post and Turing) says essentially that an effective method of solving certain sets of problems exists if one can build a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer. All three definitions are equivalent, so it doesn''t matter which one is used. Moreover, the fact that all three are equivalent is a very strong argument for the correctness of any one." (Rosser 1939:225–6)\nRosser''s footnote #5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular Church''s use of it in his An Unsolvable Problem of Elementary Number Theory (1936); (2) Herbrand and Gödel and their use of recursion in particular Gödel''s use in his famous paper On Formally Undecidable Propositions of Principia Mathematica and Related Systems I (1931); and (3) Post (1936) and Turing (1936-7) in their mechanism-models of computation.\nStephen C. Kleene defined as his now-famous "Thesis I" known as the Church-Turing thesis. But he did this in the following context (boldface in original):\n"12. Algorithmic theories... In setting up a complete algorithmic theory, what we do is to describe a procedure, performable for each set of values of the independent variables, which procedure necessarily terminates and in such manner that from the outcome we can read a definite answer, "yes" or "no," to the question, "is the predicate value true?”" (Kleene 1943:273)\nHistory after 1950\nA number of efforts have been directed toward further refinement of the definition of "algorithm", and activity is on-going because of issues surrounding, in particular, foundations of mathematics (especially the Church-Turing Thesis) and philosophy of mind (especially arguments around artificial intelligence). For more, see Algorithm characterizations.\nWikibooks has a book on the topic of\nAlgorithms\nAt Wikiversity you can learn more and teach others about Algorithm at:\nThe Department of Algorithm\nAbstract machine\nAlgorithm characterizations\nAlgorithm design\nAlgorithmic efficiency (describes ways of estimating, measuring and improving an algorithms speed)\nAlgorithm engineering\nAlgorithm examples\nAlgorithmic music\nAlgorithmic trading\nComputability theory (computer science)\nComputational complexity theory\nData structure\nHeuristics\nIntroduction to Algorithms\nImportant algorithm-related publications\nList of algorithms\nList of algorithm general topics\nList of terms relating to algorithms and data structures\nPartial function\nParameterized Complexity\nPerformance analysis measuring the actual performance of an algorithm\nRun-time analysis (non-intuitive) estimation of run times, not analysis at run-time! (see Performance analysis above\nTheory of computation\nReferences\nAxt, P. (1959) On a Subrecursive Hierarchy and Primitive Recursive Degrees, Transactions of the American Mathematical Society 92, pp. 85-105\nBlass, Andreas; Gurevich, Yuri (2003), "Algorithms: A Quest for Absolute Definitions", Bulletin of European Association for Theoretical Computer Science 81, http://research.microsoft.com/~gurevich/Opera/164.pdf . Includes an excellent bibliography of 56 references.\nBoolos, George; Jeffrey, Richard (1974, 1980, 1989, 1999), Computability and Logic (4th ed.), Cambridge University Press, London, ISBN 0-521-20402-X : cf. Chapter 3 Turing machines where they discuss "certain enumerable sets not effectively (mechanically) enumerable".\nBurgin, M. Super-recursive algorithms, Monographs in computer science, Springer, 2005. ISBN 0387955690\nCampagnolo, M.L., Moore, C., and Costa, J.F. (2000) An analog characterization of the subrecursive functions. In Proc. of the 4th Conference on Real Numbers and Computers, Odense University, pp. 91-109\nChurch, Alonzo (1936a). "An Unsolvable Problem of Elementary Number Theory". The American Journal of Mathematics 58: 345–363. doi:10.2307/2371045.\nReprinted in The Undecidable, p. 89ff. The first expression of "Church''s Thesis". See in particular page 100 (The Undecidable) where he defines the notion of "effective calculability" in terms of "an algorithm", and he uses the word "terminates", etc.\nChurch, Alonzo (1936b). "A Note on the Entscheidungsproblem". Journal of Symbolic Logic 1 no. 1 and volume 1 no. 3.\nReprinted in The Undecidable, p. 110ff. Church shows that the Entscheidungsproblem is unsolvable in about 3 pages of text and 3 pages of footnotes.\nDaffa'', Ali Abdullah al- (1977). The Muslim contribution to mathematics. London: Croom Helm. ISBN 0-85664-464-1.\nDavis, Martin (1965). The Undecidable: Basic Papers On Undecidable Propositions, Unsolvable Problems and Computable Functions. New York: Raven Press.\nDavis gives commentary before each article. Papers of Gödel, Alonzo Church, Turing, Rosser, Kleene, and Emil Post are included; those cited in the article are listed here by author''s name.\nDavis, Martin (2000). Engines of Logic: Mathematicians and the Origin of the Computer. New York: W. W. Nortion.\nDavis offers concise biographies of Leibniz, Boole, Frege, Cantor, Hilbert, Gödel and Turing with von Neumann as the show-stealing villain. Very brief bios of Joseph-Marie Jacquard, Babbage, Ada Lovelace, Claude Shannon, Howard Aiken, etc.\nThis article incorporates text from the NIST Dictionary of Algorithms and Data Structures, which, as a U.S. government publication, is in the public domain. Source: algorithm.\nDennett, Daniel (1995). Darwin''s Dangerous Idea. New York: Touchstone/Simon & Schuster.\nYuri Gurevich, Sequential Abstract State Machines Capture Sequential Algorithms, ACM Transactions on Computational Logic, Vol 1, no 1 (July 2000), pages 77–111. Includes bibliography of 33 sources.\nKleene C., Stephen (1936). "General Recursive Functions of Natural Numbers". Mathematische Annalen Band 112, Heft 5: 727–742. doi:10.1007/BF01565439.\nPresented to the American Mathematical Society, September 1935. Reprinted in The Undecidable, p. 237ff. Kleene''s definition of "general recursion" (known now as mu-recursion) was used by Church in his 1935 paper An Unsolvable Problem of Elementary Number Theory that proved the "decision problem" to be "undecidable" (i.e., a negative result).\nKleene C., Stephen (1943). "Recursive Predicates and Quantifiers". American Mathematical Society Transactions Volume 54, No. 1: 41–73. doi:10.2307/1990131.\nReprinted in The Undecidable, p. 255ff. Kleene refined his definition of "general recursion" and proceeded in his chapter "12. Algorithmic theories" to posit "Thesis I" (p. 274); he would later repeat this thesis (in Kleene 1952:300) and name it "Church''s Thesis"(Kleene 1952:317) (i.e., the Church Thesis).\nKleene, Stephen C. (First Edition 1952). Introduction to Metamathematics (Tenth Edition 1991 ed.). North-Holland Publishing Company.\nExcellent — accessible, readable — reference source for mathematical "foundations".\nKnuth, Donald (1997). Fundamental Algorithms, Third Edition. Reading, Massachusetts: Addison-Wesley. ISBN 0201896834.\nKosovsky, N. K. Elements of Mathematical Logic and its Application to the theory of Subrecursive Algorithms, LSU Publ., Leningrad, 1981\nKowalski, Robert (1979). "Algorithm=Logic+Control". Communications of the ACM (ACM Press) 22 (7): 424–436. doi:10.1145/359131.359136. ISSN 0001-0782.\nA. A. Markov (1954) Theory of algorithms. [Translated by Jacques J. Schorr-Kon and PST staff] Imprint Moscow, Academy of Sciences of the USSR, 1954 [i.e., Jerusalem, Israel Program for Scientific Translations, 1961; available from the Office of Technical Services, U.S. Dept. of Commerce, Washington] Description 444 p. 28 cm. Added t.p. in Russian Translation of Works of the Mathematical Institute, Academy of Sciences of the USSR, v. 42. Original title: Teoriya algerifmov. [QA248.M2943 Dartmouth College library. U.S. Dept. of Commerce, Office of Technical Services, number OTS 60-51085.]\nMinsky, Marvin (1967). Computation: Finite and Infinite Machines (First ed.). Prentice-Hall, Englewood Cliffs, NJ.\nMinsky expands his "...idea of an algorithm — an effective procedure..." in chapter 5.1 Computability, Effective Procedues and Algorithms. Infinite machines."\nPost, Emil (1936). "Finite Combinatory Processes, Formulation I". The Journal of Symbolic Logic 1: pp.103–105. doi:10.2307/2269031.\nReprinted in The Undecidable, p. 289ff. Post defines a simple algorithmic-like process of a man writing marks or erasing marks and going from box to box and eventually halting, as he follows a list of simple instructions. This is cited by Kleene as one source of his "Thesis I", the so-called Church-Turing thesis.\nRosser, J.B. (1939). "An Informal Exposition of Proofs of Godel''s Theorem and Church''s Theorem". Journal of Symbolic Logic 4.\nReprinted in The Undecidable, p. 223ff. Herein is Rosser''s famous definition of "effective method": "...a method each step of which is precisely predetermined and which is certain to produce the answer in a finite number of steps... a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer" (p. 225–226, The Undecidable)\nSipser, Michael (2006). Introduction to the Theory of Computation. PWS Publishing Company.\nStone, Harold S.. Introduction to Computer Organization and Data Structures (1972 ed.). McGraw-Hill, New York.\nCf in particular the first chapter titled: Algorithms, Turing Machines, and Programs. His succinct informal definition: "...any sequence of instructions that can be obeyed by a robot, is called an algorithm" (p. 4).\nTuring, Alan M. (1936-7). "On Computable Numbers, With An Application to the Entscheidungsproblem". Proceedings of the London Mathematical Society series 2, volume 42: 230–265. doi:10.1112/plms/s2-42.1.230. . Corrections, ibid, vol. 43(1937) pp.544-546. Reprinted in The Undecidable, p. 116ff. Turing''s famous paper completed as a Master''s dissertation while at King''s College Cambridge UK.\nTuring, Alan M. (1939). "Systems of Logic Based on Ordinals". Proceedings of the London Mathematical Society series 2, volume 45: 161–228. doi:10.1112/plms/s2-45.1.161.\nReprinted in The Undecidable, p. 155ff. Turing''s paper that defined "the oracle" was his PhD thesis while at Princeton USA.\nUnited States Patent and Trademark Office (2006), 2106.02 **>Mathematical Algorithms< - 2100 Patentability, Manual of Patent Examining Procedure (MPEP). Latest revision August 2006\nSecondary references\nBolter, David J.. Turing''s Man: Western Culture in the Computer Age ((1984) ed.). The University of North Carolina Press, Chapel Hill NC. , ISBN 0-8078-4108-0 pbk.\nDilson, Jesse. The Abacus ((1968,1994) ed.). St. Martin''s Press, NY. , ISBN 0-312-10409-X (pbk.)\nvan Heijenoort, Jean. From Frege to Gödel, A Source Book in Mathematical Logic, 1879–1931 ((1967) ed.). Harvard University Press, Cambridge, MA. , 3rd edition 1976[?], ISBN 0-674-32449-8 (pbk.)\nHodges, Andrew. Alan Turing: The Enigma ((1983) ed.). Simon and Schuster, New York. , ISBN 0-671-49207-1. Cf Chapter "The Spirit of Truth" for a history leading to, and a discussion of, his proof.\nEric W. Weisstein, Algorithm at MathWorld.\nAlgorithms in Everyday Mathematics\nAlgorithms at the Open Directory Project\nSortier- und Suchalgorithmen (German)\n"http://en.wikipedia.org/wiki/Algorithm"\nCategories: Algorithms | Arabic words and phrases | Discrete mathematics | Mathematical logic | Theoretical computer science | Articles with example pseudocodeHidden category: Wikipedia articles incorporating text from the NIST Dictionary of Algorithms and Data Structures','\n',char(10)));
INSERT INTO pages VALUES('MATLAB','http://web.archive.org/web/20090110165251/http://en.wikipedia.org:80/wiki/Matlab','en','2009-01-10 00:00:00',replace('( Matlab)\nFor the subdistrict in Chandpur District, Bangladesh, see Matlab Upazila.\nMATLAB\nMATLAB R2008a running on Ubuntu Linux 7.10 to train and test a Support Vector Machine via calling a C program SVM Light.\nDeveloped by\nThe MathWorks\nLatest release\nR2008b / 09 October 2008; 93 days ago\nOS\nCross-platform[1]\nType\nTechnical computing\nLicense\nProprietary\nWebsite\nMATLAB product page\nM-code\nParadigm\nimperative\nAppeared in\nlate 1970s\nDesigned by\nCleve Moler\nDeveloper\nThe MathWorks\nTyping discipline\ndynamic\nOS\nCross-platform\nMATLAB is a numerical computing environment and programming language. Created by The MathWorks, MATLAB allows easy matrix manipulation, plotting of functions and data, implementation of algorithms, creation of user interfaces, and interfacing with programs in other languages. Although it is numeric only, an optional toolbox uses the MuPAD symbolic engine, allowing access to computer algebra capabilities. An additional package, Simulink, adds graphical multidomain simulation and Model-Based Design for dynamic and embedded systems.\nIn 2004, MathWorks claimed that MATLAB is used by more than one million people across industry and the academic world.[2]\n1 History\n2 Syntax\n2.1 Variables\n2.2 Vectors/Matrices\n2.3 Semicolon\n2.4 Graphics\n3 Limitations\n4 Interactions with other languages\n4.1 Calling C and Fortran functions\n4.2 Interactions with Java and ActiveX\n5 Release history\n6 References\n7 Further reading\n8\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nA portmanteau for "matrix laboratory", MATLAB was invented in the late 1970s by Cleve Moler, then chairman of the computer science department at the University of New Mexico.[3] He designed it to give his students access to LINPACK and EISPACK without having to learn Fortran. It soon spread to other universities and found a strong audience within the applied mathematics community. Jack Little, an engineer, was exposed to it during a visit Moler made to Stanford University in 1983. Recognizing its commercial potential, he joined with Moler and Steve Bangert. They rewrote MATLAB in C and founded The MathWorks in 1984 to continue its development. These rewritten libraries were known as JACKPAC. In 2000, MATLAB was rewritten to use a newer set of libraries for matrix manipulation, LAPACK[4].\nMATLAB was first adopted by control design engineers, Little''s specialty, but quickly spread to many other domains. It is now also used in education, in particular the teaching of linear algebra and numerical analysis, and is popular amongst scientists involved with image processing.[3]\nSyntax\nThis article is written like a manual or guidebook. Please help rewrite this article from a neutral point of view. Mark blatant copyright violations for speedy deletion, using {{db-copyvio}}.(October 2008)\nMATLAB is built around the MATLAB language, sometimes called M-code or simply M. The simplest way to execute M-code is to type it in at the prompt, >> , in the Command Window, one of the elements of the MATLAB Desktop. In this way, MATLAB can be used as an interactive mathematical shell. Sequences of commands can be saved in a text file, typically using the MATLAB Editor, as a script or encapsulated into a function, extending the commands available.[5]\nVariables\nVariables are defined with the assignment operator, =. MATLAB is dynamically typed, meaning that variables can be assigned without declaring their type, except if they are to be treated as symbolic objects[6], and that their type can change. Values can come from constants, from computation involving values of other variables, or from the output of a function. For example:\n>> x = 17\nx =\n17\n>> x = ''hat''\nx =\nhat\n>> x = [3*4, pi/2]\nx =\n12.0000\n1.5708\n>> y = 3*sin(x)\ny =\n-1.6097\n3.0000\nVectors/Matrices\nMATLAB is a "Matrix Laboratory", and as such it provides many convenient ways for creating vectors, matrices, and multi-dimensional arrays. In the MATLAB vernacular, a vector refers to a one dimensional (1×N or N×1) matrix, commonly referred to as an array in other programming languages. A matrix generally refers to a 2-dimensional array, i.e. an m×n array where m and n are greater than 1. Arrays with more than two dimensions are referred to as multidimensional arrays.\nMATLAB provides a simple way to define simple arrays using the syntax: init:increment:terminator. For instance:\n>> array = 1:2:9\narray =\n1 3 5 7 9\ndefines a variable named array (or assigns a new value to an existing variable with the name array) which is an array consisting of the values 1, 3, 5, 7, and 9. That is, the array starts at 1 (the init value), increments with each step from the previous value by 2 (the increment value), and stops once it reaches (or to avoid exceeding) 9 (the terminator value).\n>> array = 1:3:9\narray =\n1 4 7\nthe increment value can actually be left out of this syntax (along with one of the colons), to use a default value of 1.\n>> ari = 1:5\nari =\n1 2 3 4 5\nassigns to the variable named ari an array with the values 1, 2, 3, 4, and 5, since the default value of 1 is used as the incrementer.\nIndexing is one-based[7], which is the usual convention for matrices in mathematics. This is atypical for programming languages, whose arrays more often start with zero.\nMatrices can be defined by separating the elements of a row with blank space or comma and using a semicolon to terminate each row. The list of elements should be surrounded by square brackets: []. Parentheses: () are used to access elements and subarrays (they are also used to denote a function argument list).\n>> A = [16 3 2 13; 5 10 11 8; 9 6 7 12; 4 15 14 1]\nA =\n16\n3\n2 13\n5 10 11\n8\n9\n6\n7 12\n4 15 14\n1\n>> A(2,3)\nans =\n11\n>> A(2:4,3:4)\nans =\n11 8\n7 12\n14 1\nA square identity matrix of size n can be generated using the function eye, and matrices of any size with zeros or ones can be generated with the functions zeros and ones, respectively.\n>> eye(3)\nans =\n1 0 0\n0 1 0\n0 0 1\n>> zeros(2,3)\nans =\n0 0 0\n0 0 0\n>> ones(2,3)\nans =\n1 1 1\n1 1 1\nMost MATLAB functions can accept matrices and will apply themselves to each element. For example, mod(2*J,n) will multiply every element in "J" by 2, and then reduce each element modulo "n". MATLAB does include standard "for" and "while" loops, but using MATLAB''s vectorized notation often produces code that is easier to read and faster to execute. This code, excerpted from the function magic.m, creates a magic square M for odd values of n (MATLAB function meshgrid is used here to generate square matrices I and J containing 1:n).\n[J,I] = meshgrid(1:n);\nA = mod(I+J-(n+3)/2,n);\nB = mod(I+2*J-2,n);\nM = n*A + B + 1;\nSemicolon\nIn many other languages, the semicolon is required to terminate commands. In MATLAB the semicolon is optional. If a statement is not terminated with a semicolon, then the result of the statement is displayed. A statement that does not explicitly return a result, for instance ''clc'', will behave the same whether or not a semicolon is included.[8]\nGraphics\nFunction plot can be used to produce a graph from two vectors x and y. The code:\nx = 0:pi/100:2*pi;\ny = sin(x);\nplot(x,y)\nproduces the following figure of the sine function:\nThree-dimensional graphics can be produced using the functions surf, plot3 or mesh.\n[X,Y] = meshgrid(-10:0.25:10,-10:0.25:10);\nf = sinc(sqrt((X/pi).^2+(Y/pi).^2));\nmesh(X,Y,f);\naxis([-10 10 -10 10 -0.3 1])\nxlabel(''{\bfx}'')\nylabel(''{\bfy}'')\nzlabel(''{\bfsinc} ({\bfR})'')\nhidden off\n[X,Y] = meshgrid(-10:0.25:10,-10:0.25:10);\nf = sinc(sqrt((X/pi).^2+(Y/pi).^2));\nsurf(X,Y,f);\naxis([-10 10 -10 10 -0.3 1])\nxlabel(''{\bfx}'')\nylabel(''{\bfy}'')\nzlabel(''{\bfsinc} ({\bfR})'')\nThis code produces a wireframe 3D plot of the two-dimensional unnormalized sinc function:\nThis code produces a surface 3D plot of the two-dimensional unnormalized sinc function:\nLimitations\nFor a long time there was criticism that because MATLAB is a proprietary product of The MathWorks, users are subject to vendor lock-in.[9][10] Recently an additional tool called the MATLAB Builder under the Application Deployment tools section has been provided to deploy MATLAB functions as library files which can be used with .NET or Java application building environment. But the drawback is that the computer where the application has to be deployed needs MCR (MATLAB Component Runtime) for the MATLAB files to function normally. MCR can be distributed freely with library files generated by the MATLAB compiler.\nMATLAB, like Fortran, Visual Basic and Ada, uses parentheses, e.g. y = f(x), for both indexing into an array and calling a function. Although this syntax can facilitate a switch between a procedure and a lookup table, both of which correspond to mathematical functions, a careful reading of the code may be required to establish the intent.\nMATLAB lacks a package system, like those found in modern languages such as Java and Python, where classes can be resolved unambiguously, e.g. Java''s java.lang.System.out.println(). In MATLAB, all functions share the global namespace, and precedence of functions with the same name is determined by the order in which they appear in the user''s MATLAB path and other subtle rules.[11] As such, two users may experience different results when executing what otherwise appears to be the same code when their paths are different.\nMany functions have a different behavior with matrix and vector arguments. Since vectors are matrices of one row or one column, this can give unexpected results. For instance, function sum(A) where A is a matrix gives a row vector containing the sum of each column of A, and sum(v) where v is a column or row vector gives the sum of its elements; hence the programmer must be careful if the matrix argument of sum can degenerate into a single-row array.[12] While sum and many similar functions accept an optional argument to specify a direction, others, like plot,[13] do not, and require additional checks. There are other cases where MATLAB''s interpretation of code may not be consistently what the user intended (e.g. how spaces are handled inside brackets as separators where it makes sense but not where it doesn''t, or backslash escape sequences which are interpreted by some functions like fprintf but not directly by the language parser because it wouldn''t be convenient for Windows directories). What might be considered as a convenience for commands typed interactively where the user can check that MATLAB does what the user wants may be less supportive of the need to construct reusable code.\nArray indexing is one-based which is the common convention for matrices in mathematics, but does not accommodate any indexing convention of sequences that have zero or negative indices. For instance, in MATLAB the DFT (or FFT) is defined with the DC component at index 1 instead of index 0, which is not consistent with the standard definition of the DFT in any literature. This one-based indexing convention is hard coded into MATLAB, making it difficult for a user to define their own zero-based or negative indexed arrays to concisely model an idea having non-positive indices.\nM-code written for a specific release of MATLAB often does not run with earlier releases as it may use some of the newer features. To give just one example: save(''x'',''filename'') saves the variable x in a file. The variable can be loaded with load(''filename'') in the same MATLAB release. However, if saved with MATLAB version 7 or later, it cannot be loaded with MATLAB version 6 or earlier. As workaround, in MATLAB version 7 save(''x'',''filename'',''-v6'') generates a file that can be read with version 6. However, executing save(''x'',''filename'',''-v6'') in version 6 causes an error message.\nInteractions with other languages\nCalling C and Fortran functions\nMATLAB can call functions and subroutines written in C programming language or Fortran. A wrapper function is created allowing MATLAB data types to be passed and returned. The dynamically loadable object files created by compiling such functions are termed "MEX-files", although the file name extension depends on the operating system and processor. [14][15]\nInteractions with Java and ActiveX\nLibraries written in Java or ActiveX can be directly called from MATLAB and many MATLAB libraries (for example XML or SQL support) are implemented as wrappers around Java or ActiveX libraries. Calling MATLAB from Java is more complicated, but can be done with MATLAB extension[16], which is sold separately by MathWorks.\nRelease history\nDate - release name - version [17]:\n2008, R2008b, 7.7\n2008, R2008a, 7.6\n2007, R2007b, 7.5\n2007, R2007a, 7.4\n2006, R2006b, 7.3\n2006, R2006a, 7.2\n2005, R14SP3, 7.1\n2005, R14SP2, 7.0.4\n2004, R14SP1, 7.0.1\n2004, R14, 7\n2003, R13SP2, 6.5.2\n2003, R13SP1, 6.5.1\n2002, R13. 6.5\n2001, R12.1, 6.1\n2000, R12, 6.0\n1999, R11.1, 5.3.1\n1999, R11, 5.3\n1998, R10.1, 5.2.1\n1998, R10, 5.2\n1997, R9.1, 5.1.1\n1997, R9, 5.1\n1996, R8, 5.0\n1994, R7, 4.2c\n1992, R?, 4\n1990, R?, 3.5\n1987, R?, 3\n1986, R?, 2\n1984, R?, 1.0\nReferences\n^ The MathWorks - MATLAB - Requirements\n^ Richard Goering, "Matlab edges closer to electronic design automation world," EE Times, 10/04/2004\n^ a b Cleve Moler, the creator of MATLAB (December 2004). "The Origins of MATLAB". Retrieved on April 15, 2007.\n^ Note from Cleve Moler in a Mathworks newsletter Cleve Moler, the creator of MATLAB (2000). "MATLAB Incorporates LAPACK". Retrieved on December 20, 2008.\n^ MATLAB technical documentation\n^ sym function Documentation for the MATLAB Symbolic Toolbox\n^ MATLAB\n^ The MathWorks, MATLAB Function Reference, accessed 12 October 2006.\n^ Jan Stafford, "The Wrong Choice: Locked in by license restrictions," SearchOpenSource.com, 21 May 2003\n^ Richard Goering, "Matlab edges closer to electronic design automation world," EE Times, 10/04/2004\n^ MATLAB Path - Precedence Rules\n^ MATLAB Function Reference - SUM\n^ plot :: Functions (MATLAB Function Reference)\n^ "MATLAB external interface guide".\n^ Spielman, Dan (2004-02-10). "Connecting C and Matlab".\nYale University, Computer Science Department. Retrieved on 2008-05-20.\n^ MathWorks: MATLAB Builder JA\n^ Cleve Moler (January 2006). "The Growth of MATLAB and The MathWorks over Two Decades" (PDF). Retrieved on August 18, 2008.\nFurther reading\nGilat, Amos (2004). MATLAB: An Introduction with Applications 2nd Edition. John Wiley & Sons. ISBN 978-0-471-69420-5.\nQuarteroni, Alfio; Fausto Saleri (2006). Scientific Computing with MATLAB and Octave. Springer. ISBN 978-3-540-32612-0.\nWikibooks'' Programming has more about this subject:\nMATLAB\nMATLAB overview, at The MathWorks website\nMATLAB at the Open Directory Project\nInformation about the history of and inspiration for MATLAB, written by Cleve Moler\ncomp.soft-sys.matlab\nLiteratePrograms (MATLAB)\nOfficial blogs\nv • d • e\nNumerical software\nOpen source\nFreeMat · GNU Octave · R · Scilab\nFreeware\nADMB\nRetail\nGAUSS · LabVIEW · MATLAB · Mathematica\nList\n• Comparison\n"http://en.wikipedia.org/wiki/MATLAB"\nCategories: Data analysis software | Array programming languages | IRIX software | Numerical programming languages | Linux numerical analysis software | Windows software | Plotting software | Proprietary cross-platform softwareHidden categories: Wikipedia articles needing style editing from October 2008 | All articles needing style editing | All articles with unsourced statements | Articles with unsourced statements since April 2008','\n',char(10)));
INSERT INTO pages VALUES('JavaScript','http://web.archive.org/web/20081218123622/http://en.wikipedia.org:80/wiki/Javascript','en','2008-12-18 00:00:00',replace('( Javascript)\nNot to be confused with Java (programming language).\nJavaScript\nParadigm\nMulti-paradigm: prototype-based, functional, imperative, scripting\nAppeared in\n1995\nDesigned by\nBrendan Eich\nDeveloper\nNetscape Communications Corporation, Mozilla Foundation\nLatest release\n1.8/ 2008\nTyping discipline\ndynamic, weak, duck\nMajor implementations\nSpiderMonkey, Rhino, KJS, JavaScriptCore\nDialects\nJScript, JScript .NET\nInfluenced by\nSelf, C, Scheme, Perl, Python, Java\nThis article is part of\nthe JavaScript series.\nJavaScript\nJavaScript syntax\nECMAScript\nJavaScript topics\nThis box: view • talk • edit\nJavaScript is a scripting language widely used for client-side web development. It was the originating dialect of the ECMAScript standard. It is a dynamic, weakly typed, prototype-based language with first-class functions. JavaScript was influenced by many languages and was designed to look like Java, but be easier for non-programmers to work with.[1][2]\nAlthough best known for its use in websites (as client-side JavaScript), JavaScript is also used to enable scripting access to objects embedded in other applications (see below).\nJavaScript, despite the name, is essentially unrelated to the Java programming language, although both have the common C syntax, and JavaScript copies many Java names and naming conventions. The language''s name is the result of a co-marketing deal between Netscape and Sun, in exchange for Netscape bundling Sun''s Java runtime with their then-dominant browser. The key design principles within JavaScript are inherited from the Self and Scheme programming languages.[3]\n"JavaScript" is a trademark of Sun Microsystems. It was used under license for technology invented and implemented by Netscape Communications and current entities such as the Mozilla Foundation.[4]\n1 History and naming\n2 Features\n2.1 Imperative and structured\n2.2 Dynamic\n2.3 Functional\n2.4 Prototype-based\n2.5 Miscellaneous\n3 Syntax\n4 Use in web pages\n4.1 Compatibility considerations\n4.2 Security\n4.2.1 Cross-site vulnerabilities\n4.2.2 Misunderstanding the client-server boundary\n4.2.3 Browser and plugin coding errors\n4.2.4 Sandbox implementation errors\n5 Uses outside web pages\n6 Debugging\n7 Versions\n8 Related languages\n9 See also\n10 References\n11 Bibliography\n12\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory and naming\nJavaScript was originally developed by Brendan Eich of Netscape under the name Mocha, which was later renamed to LiveScript, and finally to JavaScript.[5] The change of name from LiveScript to JavaScript roughly coincided with Netscape adding support for Java technology in its Netscape Navigator web browser. JavaScript was first introduced and deployed in the Netscape browser version 2.0B3 in December 1995. The naming has caused confusion, giving the impression that the language is a spin-off of Java, and it has been characterized by many as a marketing ploy by Netscape to give JavaScript the cachet of what was then the hot new web-programming language.[6][7]\nMicrosoft named its dialect of the language JScript to avoid trademark issues. JScript was first supported in Internet Explorer version 3.0, released in August 1996, and it included Y2K-compliant date functions, unlike those based on java.util.Date in JavaScript at the time. The dialects are perceived to be so similar that the terms "JavaScript" and "JScript" are often used interchangeably (including in this article). Microsoft, however, notes dozens of ways in which JScript is not ECMA compliant.\nNetscape submitted JavaScript to Ecma International for standardization resulting in the standardized version named ECMAScript.[8]\nThe flexibility of JavaScript has made it one of the most popular programming languages on the web and also one of the easier languages to learn. In regards to demographics, the language is extremely widespread in India with the United States, Russia and Ukraine also using it as a staple in their online programming. As the web continues to expand, the use of JavaScript looks like it will become more popular especially in Europe and Asia. [9]\nFeatures\nImperative and structured\nJavaScript supports all the structured programming syntax in C (e.g., if statements, while loops, switch statements, etc.). One partial exception is scoping: C-style block-level scoping is not supported. JavaScript 1.7, however, supports block-level scoping with the let keyword. Like C, JavaScript makes a distinction between expressions and statements.\nDynamic\ndynamic typing\nAs in most scripting languages, types are associated with values, not variables. For example, a variable x could be bound to a number, then later rebound to a string. JavaScript supports various ways to test the type of an object, including duck typing.[10]\nobjects as associative arrays\nJavaScript is almost entirely object-based. Objects are associative arrays, augmented with prototypes (see below). Object property names are associative array keys: obj.x = 10 and obj["x"] = 10 are equivalent, the dot notation being merely syntactic sugar. Properties and their values can be added, changed, or deleted at run-time. The properties of an object can also be enumerated via a for...in loop.\nrun-time evaluation\nJavaScript includes an eval function that can execute statements provided as strings at run-time.\nFunctional\nfirst-class functions\nFunctions are first-class; they are objects themselves. As such, they have properties and can be passed around and interacted with like any other object.\ninner functions and closures\nInner functions (functions defined within other functions) are created each time the outer function is invoked, and variables of the outer functions for that invocation continue to exist as long as the inner functions still exist, even after that invocation is finished (e.g. if the inner function was returned, it still has access to the outer function''s variables) — this is the mechanism behind closures within JavaScript.\nPrototype-based\nprototypes\nJavaScript uses prototypes instead of classes for defining object properties, including methods, and inheritance. It is possible to simulate many class-based features with prototypes in JavaScript.\nfunctions as object constructors\nFunctions double as object constructors along with their typical role. Prefixing a function call with new creates a new object and calls that function with its local this keyword bound to that object for that invocation. The function''s prototype property determines the new object''s prototype.\nfunctions as methods\nUnlike many object-oriented languages, there is no distinction between a function definition and a method definition. Rather, the distinction occurs during function calling; a function can be called as a method. When a function is invoked as a method of an object, the function''s local this keyword is bound to that object for that invocation.\nMiscellaneous\nrun-time environment\nJavaScript typically relies on a run-time environment (e.g. in a web browser) to provide objects and methods by which scripts can interact with "the outside world". (This is not a language feature per se, but it is common in most JavaScript implementations.)\nvariadic functions\nAn indefinite number of parameters can be passed to a function. The function can both access them through formal parameters and the local arguments object.\narray and object literals\nLike many scripting languages, arrays and objects (associative arrays in other languages) can each be created with a succinct shortcut syntax. In fact, these literals form the basis of the JSON data format.\nregular expressions\nJavaScript also supports regular expressions in a manner similar to Perl, which provide a concise and powerful syntax for text manipulation that is more sophisticated than the built-in string functions.\nSyntax\nMain article: JavaScript syntax\nAs of 2008, the latest version of the language is JavaScript 1.8. It is a superset of ECMAScript (ECMA-262) Edition 3. Extensions to the language, including partial E4X (ECMA-357) support and experimental features considered for inclusion into ECMAScript Edition 4, are documented here.\nSample code:\nvar c = (function(id){\n/**\n*\nFunctionDeclaration to be used as a constructor.\n*/\nfunction MyConstructor(id) {\nthis.id = id;\nthis.init();\n}\nMyConstructor.prototype = {\ninit : function() { // function expression.\n// block statement with label.\nincrementI : {\n// Function scope (no block scope).\nvar x = 10;\n}\nthis.id += x;\n},\ntoString : function() {\nreturn "MyConstructor: id = " + this.id;\n}\n};\nreturn new MyConstructor(id); // statement.\n})(12);\nThe result of c + "" is "MyConstructor: id = 22";\nUse in web pages\nMain article: Client-side JavaScript\nAjax (programming)\nThe primary use of JavaScript is to write functions that are embedded in or included from HTML pages and interact with the Document Object Model (DOM) of the page. Some simple examples of this usage are:\nOpening or popping up a new window with programmatic control over the size, position, and attributes of the new window (i.e. whether the menus, toolbars, etc. are visible).\nValidation of web form input values to make sure that they will be accepted before they are submitted to the server.\nChanging images as the mouse cursor moves over them: This effect is often used to draw the user''s attention to important links displayed as graphical elements.\nBecause JavaScript code can run locally in a user''s browser (rather than on a remote server) it can respond to user actions quickly, making an application feel more responsive. Furthermore, JavaScript code can detect user actions which HTML alone cannot, such as individual keystrokes. Applications such as Gmail take advantage of this: much of the user-interface logic is written in JavaScript, and JavaScript dispatches requests for information (such as the content of an e-mail message) to the server. The wider trend of Ajax programming similarly exploits this strength.\nA JavaScript engine (also known as JavaScript interpreter or JavaScript implementation) is an interpreter that interprets JavaScript source code and executes the script accordingly. The first ever JavaScript engine was created by Brendan Eich at Netscape Communications Corporation, for the Netscape Navigator web browser. The engine, code-named SpiderMonkey, is implemented in C. It has since been updated (in JavaScript 1.5) to conform to ECMA-262 Edition 3. The Rhino engine, created primarily by Norris Boyd (also at Netscape) is a JavaScript implementation in Java. Rhino, like SpiderMonkey, is ECMA-262 Edition 3 compliant.\nThe most common host environment for JavaScript is by far a web browser. Web browsers typically use the public API to create "host objects" responsible for reflecting the DOM into JavaScript. The web server is another common application of the engine. A JavaScript webserver would expose host objects representing an HTTP request and response objects, which a JavaScript program could then manipulate to dynamically generate web pages.\nA minimal example of a web page containing JavaScript (using HTML 4.01 syntax) would be:\nCompatibility considerations\nMain articles: Web Interoperability and Web accessibility\nThe DOM interfaces for manipulating web pages are not part of the ECMAScript standard, or of JavaScript itself. Officially, they are defined by a separate standardization effort by the W3C; in practice, browser implementations differ from the standards and from each other, and not all browsers execute JavaScript.\nTo deal with these differences, JavaScript authors can attempt to write standards-compliant code which will also be executed correctly by most browsers; failing that, they can write code that checks for the presence of certain browser features and behaves differently if they are not available.[11] In some cases, two browsers may both implement a feature but with different behavior, and authors may find it practical to detect what browser is running and change their script''s behavior to match.[12][13] Programmers may also use libraries or toolkits which take browser differences into account.\nFurthermore, scripts will not work for all users. For example, a user may:\nuse an old or rare browser with incomplete or unusual DOM support,\nuse a PDA or mobile phone browser which cannot execute JavaScript,\nhave JavaScript execution disabled as a security precaution,\nor be visually or otherwise disabled and use a speech browser\nTo support these users, web authors can try to create pages which degrade gracefully on user agents (browsers) which do not support the page''s JavaScript.\nSecurity\nJavaScript and the DOM provide the potential for malicious authors to deliver scripts to run on a client computer via the web. Browser authors contain this risk using two restrictions. First, scripts run in a sandbox in which they can only perform web-related actions, not general-purpose programming tasks like creating files. Second, scripts are constrained by the same origin policy: scripts from one web site do not have access to information such as usernames, passwords, or cookies sent to another site. Most JavaScript-related security bugs are breaches of either the same origin policy or the sandbox.\nCross-site vulnerabilities\nMain articles: Cross-site scripting and Cross-site request forgery\nA common JavaScript-related security problem is cross-site scripting, or XSS, a violation of the same-origin policy. XSS vulnerabilities occur when an attacker is able to cause a trusted web site, such as an online banking website, to include a malicious script in the webpage presented to a victim. The script in this example can then access the banking application with the privileges of the victim, potentially disclosing secret information or transferring money without the victim''s authorization.\nXSS vulnerabilities can also occur because of implementation mistakes by browser authors.[14]\nXSS is related to cross-site request forgery or XSRF. In XSRF one website causes a victim''s browser to generate fraudulent requests to another site with the victim''s legitimate HTTP cookies attached to the request.\nMisunderstanding the client-server boundary\nClient-server applications, whether they involve JavaScript or not, must assume that untrusted clients may be under the control of attackers. Thus any secret embedded in JavaScript could be extracted by a determined adversary, and the output of JavaScript operations should not be trusted by the server. Some implications:\nWeb site authors cannot perfectly conceal how their JavaScript operates, because the code is sent to the client, and obfuscated code can be reverse engineered.\nJavaScript form validation only provides convenience for users, not security. If a site verifies that the user agreed to its terms of service, or filters invalid characters out of fields that should only contain numbers, it must do so on the server, not only the client.\nIt would be extremely bad practice to embed a password in JavaScript (where it can be extracted by an attacker), then have JavaScript verify a user''s password and pass "password_ok=1" back to the server (since the "password_ok=1" response is easy to forge).[15]\nIt also does not make sense to rely on JavaScript to prevent user interface operations (such as "view source" or "save image"). This is because a client could simply ignore such scripting. [16]\nBrowser and plugin coding errors\nJavaScript provides an interface to a wide range of browser capabilities, some of which may have flaws such as buffer overflows. These flaws can allow attackers to write scripts which would run any code they wish on the user''s system.\nThese flaws have affected major browsers including Firefox[17], Internet Explorer[18], and Safari.[19]\nPlugins, such as video players, Macromedia Flash, and the wide range of ActiveX controls enabled by default in Microsoft Internet Explorer, may also have flaws exploitable via JavaScript, and such flaws have been exploited in the past.[20][21] In Windows Vista, Microsoft has attempted to contain the risks of bugs such as buffer overflows by running the Internet Explorer process with limited privileges.[22]\nSandbox implementation errors\nWeb browsers are capable of running JavaScript outside of the sandbox, with the privileges necessary to, for example, create or delete files. Of course, such privileges aren''t meant to be granted to code from the web.\nIncorrectly granting privileges to JavaScript from the web has played a role in vulnerabilities in both Internet Explorer[23] and Firefox[24]. In Windows XP Service Pack 2, Microsoft demoted JScript''s privileges in Internet Explorer.[25]\nSome versions of Microsoft Windows allow JavaScript stored on a computer''s hard drive to run as a general-purpose, non-sandboxed program. This makes JavaScript (like VBScript) a theoretically viable vector for a Trojan horse, although JavaScript Trojan horses are uncommon in practice.[26] (See Windows Script Host.)\nUses outside web pages\nOutside the web, JavaScript interpreters are embedded in a number of tools. Each of these applications provides its own object model which provides access to the host environment, with the core JavaScript language remaining mostly the same in each application.\nActionScript, the programming language used in Adobe Flash, is another implementation of the ECMAScript standard.\nApple''s Dashboard Widgets, Microsoft''s Gadgets, Yahoo! Widgets, Google Desktop Gadgets are implemented using JavaScript.\nThe Mozilla platform, which underlies Firefox and some other web browsers, uses JavaScript to implement the graphical user interface (GUI) of its various products.\nAdobe''s Acrobat and Adobe Reader (formerly Acrobat Reader) support JavaScript in PDF files.\nTools in the Adobe Creative Suite, including Photoshop, Illustrator, Dreamweaver and InDesign, allow scripting through JavaScript.\nMicrosoft''s Active Scripting technology supports the JavaScript-compatible JScript as an operating system scripting language.\nThe Java programming language, in version SE 6 (JDK 1.6), introduced the javax.script package, including a JavaScript implementation based on Mozilla Rhino. Thus, Java applications can host scripts that access the application''s variables and objects, much like web browsers host scripts that access the browser''s Document Object Model (DOM) for a webpage.[27][28]\nApplications on the social network platform OpenSocial are implemented in JavaScript.\nNewer versions of the Qt C++ toolkit include a QtScript module to interpret JavaScript, analogous to javax.script.[29]\nThe interactive music signal processing software Max/MSP released by Cycling ''74, offers a JavaScript model of its environment for use by developers. It allows much more precise control than the default GUI-centric programming model.\nLate Night Software''s JavaScript OSA (aka JavaScript for OSA, or JSOSA), is a freeware alternative to AppleScript for Mac OS X. It is based on the Mozilla 1.5 JavaScript implementation, with the addition of a MacOS object for interaction with the operating system and third-party applications.[30]\nECMAScript was included in the VRML97 standard for scripting nodes of VRML scene description files.\nSome high-end Philips universal remote panels, including TSU9600 and TSU9400, can be scripted using JavaScript.[31]\nSphere is an open source and cross platform computer program designed primarily to make role-playing games that uses JavaScript as scripting language.\nAdobe Integrated Runtime is a JavaScript runtime that allows developers to create desktop applications.\nOpenOffice.org office application suite has provision for JavaScript as one of scripting languages.\nMirth HL7 interface suite uses JavaScript to allow scripting certain actions.\nDebugging\nWithin JavaScript, access to a debugger becomes invaluable when developing large, non-trivial programs. Because there can be implementation differences between the various browsers (particularly within the Document Object Model) it is useful to have access to a debugger for each of the browsers a web application is being targeted at.\nCurrently, Internet Explorer, Firefox, Safari, and Opera all have third-party script debuggers available for them.\nInternet Explorer has three debuggers available for it: Microsoft Visual Studio is the richest of the three, closely followed by Microsoft Script Editor (a component of Microsoft Office[32]), and finally the free Microsoft Script Debugger which is far more basic than the other two. The free Microsoft Visual Web Developer Express provides a limited version of the JavaScript debugging functionality in Microsoft Visual Studio.\nWeb applications within Firefox can be debugged using the Firebug plug-in, or the older Venkman debugger, which also works with the Mozilla browser. Firefox also has a simpler built-in Error Console, which logs and evaluates JavaScript. It also logs CSS errors and warnings.\nDrosera is a debugger for the WebKit engine[33] on Macintosh and Windows[34] powering Apple''s Safari.\nThere are also some free tools such as JSLint, a code quality tool that will scan JavaScript code looking for problems[35], as well as a non-free tool called SplineTech JavaScript HTML Debugger.[36]\nSince JavaScript is interpreted, loosely-typed, and may be hosted in varying environments, each with their own compatibility differences, a programmer has to take extra care to make sure the code executes as expected in as wide a range of circumstances as possible, and that functionality degrades gracefully when it does not.\nVersions\nVersion\nRelease date\nEquivalent to\nNetscape\nNavigator\nMozilla\nFirefox\nInternet\nExplorer\nOpera\nSafari\n1.0\nMarch 1996\n2.0\n3.0\n1.1\nAugust 1996\n3.0\n1.2\nJune 1997\n4.0-4.05\n1.3\nOctober 1998\nECMA-262 1st edition / ECMA-262 2nd edition\n4.06-4.7x\n4.0\n1.4\nNetscape\nServer\n1.5\nNovember 2000\nECMA-262 3rd edition\n6.0\n1.0\n5.5 (JScript 5.5),\n6 (JScript 5.6),\n7 (JScript 5.7),\n8 (JScript 6)\n6.0,\n7.0,\n8.0,\n9.0\n1.6\nNovember 2005\n1.5 + Array extras + Array and String generics + E4X\n1.5\n1.7\nOctober 2006\n1.6 + Pythonic generators + Iterators + let\n2.0\n3.x\n1.8\nJune 2008\n1.7 + Generator expressions + Expression closures\n3.0\n1.9\n1.8 + New Features\n3.1\nThe next major version of JavaScript, 2.0, will conform to ECMA-262 4th edition.[37]\nRelated languages\nThere is not a particularly close genealogical relationship between Java and JavaScript; their similarities are mostly in basic syntax because both are ultimately derived from C. Their semantics are quite different and their object models are unrelated and largely incompatible. In Java, as in C and C++, all data is statically typed, whereas JavaScript variables, properties, and array elements may hold values of any type.\nThe standardization effort for JavaScript also needed to avoid trademark issues, so the ECMA 262 standard calls the language ECMAScript, three editions of which have been published since the work started in November 1996.\nMicrosoft''s VBScript, like JavaScript, can be run client-side in web pages. VBScript has syntax derived from Visual Basic and is only supported by Microsoft''s Internet Explorer.\nJSON, or JavaScript Object Notation, is a general-purpose data interchange format that is defined as a subset of JavaScript.\nJavaScript is also considered a functional programming language like Scheme and OCaml because it has closures and supports higher-order functions.[38]\nAlthough JavaScript and Lua are not genealogically related, the two are semantically very similar despite apparent syntactical and implementational differences.\nMozilla browsers currently support LiveConnect, a feature that allows JavaScript and Java to intercommunicate on the web. However, support for LiveConnect is scheduled to be phased out in the future.\nSee also\nWikibooks has a book on the topic of\nProgramming:JavaScript\nECMAScript\nJavaScript syntax\nClient-side JavaScript\nAJAX\nDynamic HTML\nServer-side JavaScript\nJSDoc\nJSON\nJSAN\nComparison of layout engines (ECMAScript)\nComparison of Javascript-based source code editors\nReferences\n^ TechVision: Innovators of the Net: Brendan Eich and JavaScript\n^ Brendan''s Roadmap Updates: Popularity\n^ "ECMAScript Language Overview" p.4 (2007-10-23).\n^ "Sun Trademarks".\nSun Microsystems. Retrieved on 2007-11-08.\n^ InfoWorld: JavaScript creator ponders past, future\n^ Programming languages used on the Internet and the World Wide Web (WWW)\n^ O''Reilly - Safari Books Online - 0596101996 - JavaScript: The Definitive Guide, 5th Edition\n^ Netscape Press Release\n^ "Javascript Programmers Trends". Retrieved on 2008-12-11.\n^ Flanagan, David (2006). JavaScript: The Definitive Guide. O''Reilly Media. pp. 176–178. ISBN 0596101996.\n^ Peter-Paul Koch, Object detection\n^ Peter-Paul Koch, Mission Impossible - mouse position\n^ Peter-Paul Koch, Browser detect\n^ MozillaZine, Mozilla Cross-Site Scripting Vulnerability Reported and Fixed\n^ For an example of this bad practice, see http://javascript.internet.com/passwords/\n^ "Right-click “protection”? Forget about it". Blog.anta.net. 2008-06-17. ISSN 1797-1993. http://blog.anta.net/2008/06/17/right-click-%e2%80%9cprotection%e2%80%9d-forget-about-it/. Retrieved on 17 June 2008.\n^ Mozilla Corporation, Buffer overflow in crypto.signText()\n^ Paul Festa, CNet, Buffer-overflow bug in IE\n^ SecurityTracker.com, Apple Safari JavaScript Buffer Overflow Lets Remote Users Execute Arbitrary Code and HTTP Redirect Bug Lets Remote Users Access Files\n^ SecurityFocus, Microsoft WebViewFolderIcon ActiveX Control Buffer Overflow Vulnerability\n^ Fusion Authority, Macromedia Flash ActiveX Buffer Overflow\n^ Mike Friedman, Protected Mode in Vista IE7\n^ US CERT, Vulnerability Note VU#713878: Microsoft Internet Explorer does not properly validate source of redirected frame\n^ Mozilla Foundation, Mozilla Foundation Security Advisory 2005-41: Privilege escalation via DOM property overrides\n^ Microsoft Corporation, Changes to Functionality in Microsoft Windows XP Service Pack 2: Part 5: Enhanced Browsing Security\n^ For one example of a rare JavaScript Trojan Horse, see Symantec Corporation, JS.Seeker.K\n^ http://java.sun.com/javase/6/webnotes/index.html#scripting javax.script release notes\n^ Flanagan 5th Edition, Pp 214 et seq\n^ Trolltech ASA, QtScript Module\n^ AppleScript#Open_Scripting_Architecture\n^ Koninklijke Philips Electronics NV, [1]\n^ JScript development in Microsoft Office 11 (MS InfoPath 2003)\n^ Introducing Drosera - Surfin'' Safari\n^ Bug tracker discussion on Drosera Windows support\n^ JSLint help page\n^ SplineTech JavaScript HTML Debugger\n^ Versions of JavaScript\n^ The Little JavaScripter shows the relationship with Scheme in more detail.\nBibliography\nMcDuffie, Tina Spain (2003). JavaScript Concepts & Techniques: Programming Interactive Web Sites. Franklin, Beedle & Associates. ISBN 1-887-90269-4.\nMcFarlane, Nigel (2003). Rapid Application Development with Mozilla. Prentice Hall Professional Technical References. ISBN 0-13-142343-6.\nFlanagan, David; Ferguson, Paula (2002). JavaScript: The Definitive Guide (4th Edition ed.). O''Reilly & Associates. ISBN 0-596-00048-0.\nFlanagan, David (2006). JavaScript: The Definitive Guide (5th Edition ed.). O''Reilly & Associates. ISBN 0-596-10199-6.\nGoodman, Danny; Markel, Scott (2003). JavaScript and DHTML Cookbook. O''Reilly & Associates. ISBN 0-596-00467-2.\nGoodman, Danny; Eich, Brendan (2001). JavaScript Bible. John Wiley & Sons. ISBN ISBN 0-7645-3342-8.\nWatt, Andrew H.; Watt, Jonathan A.; Simon, Jinjer L. (2002). Teach Yourself JavaScript in 21 Days. Pearson Education. ISBN 0-672-32297-8.\nDuffy, Scott (2003). How to do Everything with JavaScript. Osborne. ISBN 0-07-222887-3.\nHarris, Andy (2001). JavaScript Programming for the Absolute Beginner. Premier Press. ISBN 0-7615-3410-5.\nBurns, Joe; Growney, Andree S. (2001). JavaScript Goodies. Pearson Education. ISBN 0-7897-2612-2.\nShelly, Gary B.; Cashman, Thomas J.; Dorin, William J.; Quasney, Jeffrey J. (2000). JavaScript: Complete Concepts and Techniques. Cambridge: Course Technology. ISBN 0-7895-6233-2.\nHeinle, Nick; Koman, Richard (1997). Designing with JavaScript. O''Reilly & Associates. ISBN 1-56592-300-6.\nBhangal, Sham; Jankowski, Tomasz (2003). Foundation Web Design: Essential HTML, JavaScript, CSS, PhotoShop, Fireworks, and Flash. APress L. P.. ISBN 1-59059-152-6.\nVander Veer, Emily A. (2004). JavaScript For Dummies (4th Edition ed.). Wiley Pub.. ISBN 0-7645-7659-3.\nPowell, Thomas A.; Schneider, Fritz (2001). JavaScript: The Complete Reference. McGraw-Hill Companies. ISBN 0-07-219127-9.\nMozilla Developer Center\nMozilla''s Official Documentation on JavaScript\nReferences for Core JavaScript versions: 1.5\nNew in JavaScript: 1.6, 1.7, 1.8\nList of JavaScript releases: versions 1.5 - 1.8\nRe-Introduction to JavaScript\nJavaScript at the Open Directory Project\nComputerworld Interview with Brendan Eich on JavaScript\nv • d • e\nECMAScript (comparison)\nDialects\nActionScript · Caja · JavaScript / LiveScript · JScript · JavaScript OSA · JScript .NET · QtScript\nECMAScript engines\nInScript · JavaScriptCore · JScript · KJS · futhark · linear_b · Narcissus · QtScript · Rhino · SpiderMonkey · SunSpider · Tamarin · TraceMonkey · V8 · SquirrelFish\nOther\nBrendan Eich · Ecma International\n"http://en.wikipedia.org/wiki/JavaScript"\nCategories: Curly bracket programming languages | Domain-specific programming languages | JavaScript programming language | Prototype-based programming languages | Object-based programming languages | Scripting languages','\n',char(10)));
INSERT INTO pages VALUES('Coq','http://web.archive.org/web/20090713042410/http://en.wikipedia.org:80/wiki/Coq','en','2009-07-13 00:00:00',replace('An example of proof written as a functional program: the proof of commutativity of addition on natural numbers in the proof assistant Coq\nIn computer science, Coq is a proof assistant application. It allows the expression of mathematical assertions, mechanically checks proofs of these assertions, helps to find formal proofs, and extracts a certified program from the constructive proof of its formal specification. Coq works within the theory of the calculus of inductive constructions, a derivative of the calculus of constructions. Coq is not an automated theorem prover but includes automatic theorem proving tactics and various decision procedures.\nIt is developed in France, in the TypiCal (ex-LogiCal) project, jointly operated by INRIA, École Polytechnique, Paris-Sud 11 University and CNRS. There was also formerly a group at École Normale Supérieure de Lyon. The team leader is Senior Scientist Benjamin Werner. Coq is implemented in Objective Caml.\nThe word coq means "cock" (rooster) in French, and stems from a tradition of naming French research development tools with animal names. It is also a reference to Thierry Coquand, who developed the aforementioned calculus of constructions along with Gérard Huet. Also, at first it was simply called Coc, the acronym of calculus of construction.\n1 Four color theorem and ssreflect extension\n2 See also\n3 References\n4\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nFour color theorem and ssreflect extension\nGeorges Gonthier (of Microsoft Research, in Cambridge, England) and Benjamin Werner (of INRIA) used Coq to create a surveyable proof of the four color theorem, which was completed in September 2004.[1]\nBased on this work, a significant extension to Coq was developed called Ssreflect (which stands for "small scale reflection"). Despite the name, most of the new features added to Coq by Ssreflect are general purpose features, useful not merely for the computational reflection style of proof. These include:\nAdditional convenient notations for irrefutable and refutable pattern matching, on inductive types with one or two constructors\nImplicit arguments for functions applied to zero arguments - which is useful when programming with higher-order functions\nConcise anonymous arguments\nAn improved set tactic with more powerful matching\nSupport for reflection\nSsreflect 1.1 is freely available under the open source CeCill-B license, and is compatible with Coq 8.1 (patch levels 2 and 3).[2]\nSee also\nCurry-Howard\nIntuitionistic type theory\nReferences\n^ Development of theories and tactics: Four Color Theorem\n^ Announcing Ssreflect version 1.1\nThe Coq proof assistant - the official English website\nCocorico!, the Coq Wiki\nMSR Inria math components - hosts the Ssreflect extension\nThe Coq''Art - A book on Coq by Yves Bertot and Pierre Castéran\nCertified Programming with Dependent Types -- online draft textbook by Adam Chlipala\nThis logic-related article is a stub. You can help Wikipedia by expanding it.\n"http://en.wikipedia.org/wiki/Coq"\nCategories: Logic stubs | Interactive theorem proving software | Free theorem provers | Dependently-typed formal languages | OCaml software','\n',char(10)));
INSERT INTO pages VALUES('Caml','http://web.archive.org/web/20090416213114/http://en.wikipedia.org:80/wiki/Caml','en','2009-04-16 00:00:00',replace('This article is about the programming language.\nFor the markup language, see CAML.\nCaml\nParadigm\nmulti-paradigm: functional, imperative; object-oriented in OCaml\nAppeared in\n1985\nDesigned by\nGérard Huet, Guy Cousineau, Ascánder Suárez, Pierre Weis, Michel Mauny (Heavy Caml), Xavier Leroy (Caml Light, Objective Caml)\nTyping discipline\nstrong, static\nMajor implementations\nOCaml, Caml Light\nInfluenced by\nML\nInfluenced\nF#\nWebsite\nhttp://caml.inria.fr\nCaml (originally an acronym for Categorical Abstract Machine Language) is a dialect of the ML programming language family, developed at INRIA and formerly at ENS.\nLike all descendants of ML, Caml is statically typed, strictly evaluated, and uses automatic memory management.\nThe first Caml implementation in Lisp was nicknamed "Heavy CAML" because of its memory and CPU requirements relative to its successor Caml Light which was implemented in C by Xavier Leroy and Damien Doligez. In addition to a complete rewriting, CAML Special Light added a powerful (applicative) module system to the core language.\nCurrently, the main implementation of Caml is Objective Caml, which adds many new features to the language including an object layer.\n1 Examples\n1.1 Hello World\n1.2 Factorial function (recursion and purely functional programming)\n1.3 Numerical derivative (higher-order functions)\n1.4 Discrete Wavelet Transform (pattern matching)\n2 See also\n3\n3.1 Books\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nExamples\nIn the following, # represents the OCaml prompt.\nHello World\nprint_endline "Hello world!";;\nFactorial function (recursion and purely functional programming)\nMany mathematical functions, such as factorial, are most naturally represented in a purely functional form. The following recursive, purely-functional Caml function implements factorial:\nlet rec fact n = if n=0 then 1 else n * fact(n-1);;\nThe function can be written equivalently using pattern matching:\nlet rec fact = function\n| 0 -> 1\n| n -> n * fact(n-1);;\nThis latter form is the mathematical definition of factorial as a recurrence relation.\nNote that the compiler inferred the type of this function to be "int -> int", meaning that this function maps ints onto ints. For example, 12! is:\n# fact 12;;\n- : int = 479001600\nNumerical derivative (higher-order functions)\nAs a functional programming language, it is easy to create and pass around functions in OCaml programs. This capability has an enormous number of applications. Calculating the numerical derivative of a function is one such application. The following Caml function "d" computes the numerical derivative of a given function "f" at a given point "x":\nlet d delta f x =\n(f (x +. delta) -. f (x -. delta)) /. (2. *. delta);;\nThis function requires a small value "delta". A good choice for delta is the cube root of the machine epsilon.\nThe type of the function "d" indicates that it maps a "float" onto another function with the type "(float -> float) -> float -> float". This allows us to partially apply arguments. This functional style is known as currying. In this case, it is useful to partially apply the first argument "delta" to "d", to obtain a more specialised function:\n# let d = d (sqrt epsilon_float);;\nval d : (float -> float) -> float -> float = <fun>\nNote that the inferred type indicates that the replacement "d" is expecting a function with the type "float -> float" as its first argument. We can compute a numerical approximation to the derivative of x^3-x-1 at x=3 with:\n# d (fun x -> x *. x *. x -. x -. 1.) 3.;;\n- : float = 26.\nThe correct answer is f''(x) = 3x^2-1 => f''(3) = 27-1 = 26.\nThe function "d" is called a "higher-order function" because it accepts another function ("f") as an argument.\nThe concepts of curried and higher-order functions are clearly useful in mathematical programs. In fact, these concepts are equally applicable to most other forms of programming and can be used to factor code much more aggressively, resulting in shorter programs and fewer bugs.\nDiscrete Wavelet Transform (pattern matching)\nThe 1D Haar wavelet transform of an integer-power-of-two-length list of numbers can be implemented very succinctly in Caml and is an excellent example of the use of pattern matching over lists, taking pairs of elements ("h1" and "h2") off the front and storing their sums and differences on the lists "s" and "d", respectively:\n# let haar l =\nlet rec aux l s d = match l, s, d with\n[s], [], d -> s :: d\n| [], s, d -> aux s [] d\n| h1 :: h2 :: t, s, d -> aux t (h1 + h2 :: s) (h1 - h2 :: d)\n| _ -> invalid_arg "haar" in\naux l [] [];;\nval haar : int list -> int list = <fun>\nFor example:\n# haar [1; 2; 3; 4; -4; -3; -2; -1];;\n- : int list = [0; 20; 4; 4; -1; -1; -1; -1]\nPattern matching allows complicated transformations to be represented clearly and succinctly. Moreover, the OCaml compiler turns pattern matches into very efficient code, at times resulting in programs that are shorter and faster than equivalent code written with a case statement.\nSee also\nStandard ML\nF#, an OCaml-like language for Microsoft .NET\nObjective Caml\nCategorical abstract machine\nCaml language family official website\nBooks\nThe Functional Approach to Programming with Caml by Guy Cousineau and Michel Mauny.\n"http://en.wikipedia.org/wiki/Caml"\nCategories: ML programming language family | Programming languages created in 1985Hidden categories: All articles with unsourced statements | Articles with unsourced statements since May 2008 | Articles with unsourced statements since February 2007','\n',char(10)));
INSERT INTO pages VALUES('OCaml','http://web.archive.org/web/20081227125521/http://en.wikipedia.org:80/wiki/Ocaml','en','2008-12-27 00:00:00',replace('( Ocaml)\012Objective Caml\012Paradigm\012multi-paradigm: imperative, functional, object-oriented\012Developer\012INRIA\012Latest release\0123.11.0/ 04 December 2008; 23 days ago\012Dialects\012F#, JoCaml, MetaOCaml, OcamlP3l\012Influenced by\012Caml Light, Standard ML\012Influenced\012Scala\012OS\012Cross-platform\012License\012Q Public License (compiler)\012LGPL (library)\012Website\012http://caml.inria.fr/\012Objective Caml, or OCaml (pronounced /oʊˈkæməl/ oh-KAM-əl) is the main implementation of the Caml programming language, created by Xavier Leroy, Jérôme Vouillon, Damien Doligez, Didier Rémy and others in 1996. OCaml is an open source project managed and principally maintained by INRIA.\012OCaml extends the core Caml language with object-oriented constructs.\012OCaml''s toolset includes an interactive toplevel interpreter, a bytecode compiler, and an optimizing native code compiler. It has a large standard library that makes it useful for many of the same applications as Python or Perl, as well as robust modular and object-oriented programming constructs that make it applicable for large-scale software engineering.\012OCaml is the successor to Caml Light. The acronym CAML originally stood for Categorical Abstract Machine Language, although OCaml abandons this abstract machine.\0121 Philosophy\0122 Features\0123 Code examples\0123.1 Hello World\0123.2 Summing a list of integers\0123.3 Quicksort\0123.4 Birthday paradox\0123.5 Church numerals\0123.6 Arbitrary-precision factorial function (libraries)\0123.7 Triangle (graphics)\0124 Derived languages\0124.1 MetaOCaml\0124.2 Other derived languages\0125 See also\0126\0126.1 References\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012Philosophy\012ML-derived languages are best known for their static type systems and type-inferring compilers. OCaml unifies functional, imperative, and object-oriented programming under an ML-like type system.\012OCaml''s static type system eliminates a large class of programmer errors that may cause problems at runtime. However, it also forces the programmer to conform to the constraints of the type system, which can require careful thought and close attention. A type-inferring compiler greatly reduces the need for manual type annotations (for example, the data type of variables and the signature of functions usually do not need to be explicitly declared, as they do in Java). Nonetheless, effective use of OCaml''s type system can require some sophistication on the part of the programmer.\012OCaml is perhaps most distinguished from other languages with origins in academia by its emphasis on performance. Firstly, its static type system renders runtime type mismatches impossible, and thus obviates runtime type and safety checks that burden the performance of dynamically typed languages, while still guaranteeing runtime safety (except when array bounds checking is turned off, or when certain type-unsafe features like serialization are used; these are rare enough that avoiding them is practically possible).\012Aside from type-checking overhead, functional programming languages are, in general, challenging to compile to efficient machine language code, due to issues such as the funarg problem. In addition to standard loop, register, and instruction optimizations, OCaml''s optimizing compiler employs static program analysis techniques to optimize value boxing and closure allocation, helping to maximize the performance of the resulting code even if it makes extensive use of functional programming constructs.\012Xavier Leroy has cautiously stated that "OCaml delivers at least 50% of the performance of a decent C compiler"[1], and benchmarks have shown that this is generally the case[2]. Some functions in the OCaml standard library are implemented with faster algorithms than equivalent functions in the standard libraries of other languages. For example, the implementation of set union in the OCaml standard library is asymptotically faster than the equivalent function in the standard libraries of imperative languages (e.g. C++, Java) because the OCaml implementation exploits the immutability of sets in order to reuse parts of input sets in the output (persistence).\012Features\012OCaml features: a static type system, type inference, parametric polymorphism, tail recursion, pattern matching, first class lexical closures, functors (parametric modules), exception handling, and incremental generational automatic garbage collection.\012OCaml is particularly notable for extending ML-style type inference to an object system in a general purpose language. This permits structural subtyping, where object types are compatible if their method signatures are compatible, regardless of their declared inheritance; an unusual feature in statically-typed languages.\012A foreign function interface for linking to C primitives is provided, including language support for efficient numerical arrays in formats compatible with both C and FORTRAN. OCaml also supports the creation of libraries of OCaml functions that can be linked to a "main" program in C, so that one could distribute an OCaml library to C programmers who have no knowledge nor installation of OCaml.\012The OCaml distribution contains:\012An extensible parser and macro language named Camlp4, which permits the syntax of OCaml to be extended or even replaced\012Lexer and parser tools called ocamllex and ocamlyacc\012Debugger which supports stepping backwards to investigate errors\012Documentation generator\012Profiler — for measuring performance\012Numerous general purpose libraries\012The native code compiler is available for many platforms, including Unix, Microsoft Windows, and Apple Mac OS X. Excellent portability is ensured through native code generation support for major architectures: IA-32, IA-64, AMD64, HP/PA; PowerPC, SPARC, Alpha, MIPS, and StrongARM.\012OCaml bytecode and native code programs can be written in a multithreaded style, with preemptive context switching. However, because the garbage collector is not designed for concurrency, symmetric multiprocessing is not supported[3]. OCaml threads in the same process execute by time sharing only.\012Code examples\012Snippets of OCaml code are most easily studied by entering them into the "top-level". This is an interactive OCaml session that prints the inferred types of resulting or defined expressions. The OCaml top-level is started by simply executing the "ocaml" program:\012$ ocaml\012Objective Caml version 3.09.0\012#\012Code can then be entered at the "#" prompt. For example, to calculate 1+2*3:\012# 1 + 2 * 3;;\012- : int = 7\012OCaml infers the type of the expression to be "int" (a machine-precision integer) and gives the result "7".\012Hello World\012The following program "hello.ml":\012print_endline "Hello world!";;\012can be compiled to bytecode:\012$ ocamlc hello.ml -o hello\012and executed:\012$ ./hello\012Hello world!\012$\012Summing a list of integers\012Lists are one of the most fundamental datatypes in OCaml. The following code example sums a list of integers.\012let rec sum xs =\012match xs with\012| [] -> 0\012| x :: xs'' -> x + sum xs''\012# sum [1;2;3;4;5];;\012- : int = 15\012Quicksort\012Ocaml lends itself to the concise expression of recursive algorithms. The following code example implements the quicksort algorithm to sort a list into increasing order.\012let rec quicksort = function\012| [] -> []\012| pivot :: rest ->\012let is_less x = x < pivot in\012let left, right = List.partition is_less rest in\012quicksort left @ [pivot] @ quicksort right\012Birthday paradox\012The following program calculates the smallest number of people in a room for whom the probability of completely unique birthdays is less than 50% (the so-called birthday paradox, where for 1 person the probability is obviously 100%, for 2 it is 364/365, etc.) (answer = 23).\012let year_size = 365.;;\012let rec birthday_paradox prob people =\012let prob'' = (year_size -. float people) /. year_size *. prob\012in\012if prob'' < 0.5 then\012Printf.printf "answer = %d\n" (people+1)\012else\012birthday_paradox prob'' (people+1) ;;\012birthday_paradox 1.0 1;;\012Church numerals\012The following code defines a Church encoding of natural numbers, with successor (succ) and addition (add). A Church numeral n is a higher-order function that accepts a function f and a value x and applies f to x exactly n times. To convert a Church numeral from a functional value to a string, we pass it a function which prepends the string "S" to its input and the constant string "0".\012let zero f x = x\012let succ n f x = f (n f x)\012let one = succ zero\012let two = succ (succ zero)\012let add n1 n2 f x = n1 f (n2 f x)\012let to_string n = n (fun k -> "S" ^ k) "0"\012let _ = print (add (succ two) two)\012Arbitrary-precision factorial function (libraries)\012A variety of libraries are directly accessible from OCaml. For example, OCaml has a built-in library for arbitrary precision arithmetic. As the factorial function grows very rapidly, it quickly overflows machine-precision numbers (typically 32- or 64-bits). Thus, factorial is a suitable candidate for arbitrary-precision arithmetic.\012In OCaml, the Num module provides arbitrary-precision arithmetic and can be loaded into a running top-level using:\012# #load "nums.cma";;\012# open Num;;\012The factorial function may then be written using the arbitrary-precision numeric operators =/, */ and -/ :\012# let rec fact n =\012if n =/ Int 0 then Int 1 else n */ fact(n -/ Int 1);;\012val fact : Num.num -> Num.num = <fun>\012This function can compute much larger factorials, such as 120!:\012# string_of_num (fact (Int 120));;\012- : string =\012"6689502913449127057588118054090372586752746333138029810295671352301633\01255724496298936687416527198498130815763789321409055253440858940812185989\0128481114389650005964960521256960000000000000000000000000000"\012Triangle (graphics)\012The following program "simple.ml" renders a rotating triangle in 2D using OpenGL:\012let _ =\012ignore( Glut.init Sys.argv );\012Glut.initDisplayMode ~double_buffer:true ();\012ignore (Glut.createWindow ~title:"OpenGL Demo");\012let angle t = 10. *. t *. t in\012let render () =\012GlClear.clear [ `color ];\012GlMat.load_identity ();\012GlMat.rotate ~angle: (angle (Sys.time ())) ~z:1. ();\012GlDraw.begins `triangles;\012List.iter GlDraw.vertex2 [-1., -1.; 0., 1.; 1., -1.];\012GlDraw.ends ();\012Glut.swapBuffers () in\012GlMat.mode `modelview;\012Glut.displayFunc ~cb:render;\012Glut.idleFunc ~cb:(Some Glut.postRedisplay);\012Glut.mainLoop ()\012The LablGL bindings to OpenGL are required. The program may then be compiled to bytecode with:\012$ ocamlc -I +lablGL lablglut.cma lablgl.cma simple.ml -o simple\012or to nativecode with:\012$ ocamlopt -I +lablGL lablglut.cmxa lablgl.cmxa simple.ml -o simple\012and run:\012$ ./simple\012Far more sophisticated, high-performance 2D and 3D graphical programs are easily developed in OCaml. Thanks to the use of OpenGL, the resulting programs are not only succinct and efficient but also cross-platform, compiling without any changes on all major platforms.\012Derived languages\012MetaOCaml\012MetaOCaml[4] is a multi-stage programming extension of OCaml enabling incremental compiling of new machine code during runtime. Under certain circumstances, significant speedups are possible using multi-stage programming, because more detailed information about the data to process is available at runtime than at the regular compile time, so the incremental compiler can optimize away many cases of condition checking etc.\012As an example: if at compile time it is known that a certain power function x -> x^n is needed very frequently, but the value of n is known only at runtime, you can use a two-stage power function in MetaOCaml:\012let rec power n x =\012if n = 0\012then .<1>.\012else\012if even n\012then sqr (power (n/2) x)\012else .<.~x *. ~(power (n-1) x)>.;;\012As soon as you know n at runtime, you can create a specialized and very fast power function:\012.<fun x -> .~(power 5 .<x>.)>.;;\012The result is:\012fun x_1 -> (x_1 *\012let y_3 =\012let y_2 = (x_1 * 1)\012in (y_2 * y_2)\012in (y_3 * y_3))\012The new function is automatically compiled.\012Other derived languages\012AtomCaml provides a synchronization primitive for atomic (transactional) execution of code.\012F# is a Microsoft .NET language based on OCaml.\012Fresh OCaml facilitates the manipulation of names and binders.\012GCaml adds extensional polymorphism to OCaml, thus allowing overloading and type-safe marshalling.\012JoCaml integrates constructions for developing concurrent and distributed programs.\012OCamlDuce extends OCaml with features such as XML expressions and regular-expression types.\012OCamlP3l is a parallel programming system based on OCaml and the P3L language\012See also\012Caml and Caml Light, languages from which OCaml evolved\012Standard ML, another popular dialect of ML\012Extensible ML, another object-oriented dialect of ML\012O''Haskell, an object-oriented extension to the functional language Haskell\012Caml language family official website\012OCaml libraries\012OCaml tutorial for C, C++, Java and Perl programmers\012A basic OCaml tutorial\012A Tutorial with a practical approach.\012OCaml-Java, OCaml for Java\012OCamIL, an OCaml compiler for Microsoft .NET\012Comparison of the speed of various languages including Ocaml\012LablGL and LablGTK OpenGL+ bindings (LablGL) and GTK+ bindings (LablGTK)\012Newest Ocaml Projects on Sourceforge\012MetaOCaml home page\012OCamlcore Planet\012OCamlForge\012References\012^ Linux Weekly News.\012^ The Computer Language Benchmarks Game.\012^ Xavier Leroy''s "standard lecture" on threads\012^ MetaOCaml.\012"http://en.wikipedia.org/wiki/Objective_Caml"\012Categories: ML programming language family | Functional languages | Object-oriented programming languages | Extensible syntax programming languages | Cross-platform software | OCaml software','\012',char(10)));
INSERT INTO pages VALUES('SPSS','http://web.archive.org/web/20081218234138/http://en.wikipedia.org:80/wiki/SPSS','en','2008-12-18 00:00:00',replace('This article is about the computer software.\nFor solar-powered satellite system, see Solar Power Satellite.\nFor Self-Propelled Semi-Submersible (SPSS), see Narco sub.\nSPSS\nDeveloped by\nSPSS Inc.\nLatest release\n17.0 (Win / Mac / Linux) / 2008\nOS\nWindows, Linux / UNIX & Mac\nType\nStatistical analysis\nLicense\nProprietary software\nWebsite\nwww.spss.com\nSPSS is a computer program used for statistical analysis.\n1 Statistics program\n2 Versions\n3 Release History\n4 See also\n5 Notes\n6 References\n7\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nStatistics program\nSPSS (originally, Statistical Package for the Social Sciences) was released in its first version in 1968 after being founded by Norman Nie and C. Hadlai Hull. Nie was then a political science postgraduate at Stanford University,[1] and now Research Professor in the Department of Political Science at Stanford and Professor Emeritus of Political Science at the University of Chicago.[2] SPSS is among the most widely used programs for statistical analysis in social science. It is used by market researchers, health researchers, survey companies, government, education researchers, marketing organizations and others. The original SPSS manual (Nie, Bent & Hull, 1970) has been described as ''Sociology''s most influential book''.[3] In addition to statistical analysis, data management (case selection, file reshaping, creating derived data) and data documentation (a metadata dictionary is stored with the data) are features of the base software.\nStatistics included in the base software:\nDescriptive statistics: Cross tabulation, Frequencies, Descriptives, Explore, Descriptive Ratio Statistics\nBivariate statistics: Means, t-test, ANOVA, Correlation (bivariate, partial, distances), Nonparametric tests\nPrediction for numerical outcomes: Linear regression\nPrediction for identifying groups: Factor analysis, cluster analysis (two-step, K-means, hierarchical), Discriminant\nThe many features of SPSS are accessible via pull-down menus or can be programmed with a proprietary 4GL command syntax language. Command syntax programming has the benefits of reproducibility and handling complex data manipulations and analyses. The pull-down menu interface also generates command syntax, though the default settings have to be changed to make the syntax visible to the user. Programs can be run interactively, or unattended using the supplied Production Job Facility. Additionally a "macro" language can be used to write command language subroutines and a Python programmability extension can access the information in the data dictionary and data and dynamically build command syntax programs. The Python programmability extension, introduced in SPSS 14, replaced the less functional SAX Basic "scripts" for most purposes, although SaxBasic remains available. In addition, the Python extension allows SPSS to run any of the statistics in the free software package R. From version 14 onwards SPSS can be driven externally by a Python or a VB.NET program using supplied "plug-ins".\nSPSS places constraints on internal file structure, data types, data processing and matching files, which together considerably simplify programming. SPSS datasets have a 2-dimensional table structure where the rows typically represent cases (such as individuals or households) and the columns represent measurements (such as age, sex or household income). Only 2 data types are defined: numeric and text (or "string"). All data processing occurs sequentially case-by-case through the file. Files can be matched one-to-one and one-to-many, but not many-to-many.\nThe graphical user interface has two views which can be toggled by clicking on one of the two tabs in the bottom left of the SPSS window. The ''Data View'' shows a spreadsheet view of the cases (rows) and variables (columns). Unlike spreadsheets, the data cells can only contain numbers or text and formulas cannot be stored in these cells. The ''Variable View'' displays the metadata dictionary where each row represents a variable and shows the variable name, variable label, value label(s), print width, measurement type and a variety of other characteristics. Cells in both views can be manually edited, defining the file structure and allowing data entry without using command syntax. This may be sufficient for small datasets. Larger datasets such as statistical surveys are more often created in data entry software, or entered during computer-assisted personal interviewing, by scanning and using optical character recognition and optical mark recognition software, or by direct capture from online questionnaires. These datasets are then read into SPSS.\nSPSS can read and write data from ASCII text files (including hierarchical files), other statistics packages, spreadsheets and databases. SPSS can read and write to external relational database tables via ODBC and SQL.\nStatistical output is to a proprietary file format (*.spv file, supporting pivot tables) for which, in addition to the in-package viewer, a stand-alone reader can be downloaded. The proprietary output can be exported to text or Microsoft Word. Alternatively, output can be captured as data (using the OMS command), as text, tab-delimited text, PDF, XLS, HTML, XML, SPSS dataset or a variety of graphic image formats (JPEG, PNG, BMP and EMF).\nAdd-on modules provide additional capabilities. The available modules are:\nSPSS Programmability Extension (added in version 14). Allows Python programming control of SPSS.\nSPSS Data Validation (added in version 14). Allows programming of logical checks and reporting of suspicious values.\nSPSS Regression Models - Logistic regression, ordinal regression, multinomial logistic regression, and mixed models.\nSPSS Advanced Models - Multivariate GLM and repeated measures ANOVA (removed from base system in version 14).\nSPSS Classification Trees. Creates classification and decision trees for identifying groups and predicting behaviour.\nSPSS Tables. Allows user-defined control of output for reports.\nSPSS Exact Tests. Allows statistical testing on small samples.\nSPSS Categories\nSPSS Trends\nSPSS Conjoint\nSPSS Missing Value Analysis. Simple regression-based imputation.\nSPSS Map\nSPSS Complex Samples (added in Version 12). Adjusts for stratification and clustering and other sample selection biases.\nSPSS Server is a version of SPSS with a client/server architecture. It has some features not available in the desktop version, such as scoring functions.\nVersions\nEarly versions of SPSS were designed for batch processing on mainframes, including for example IBM and ICL versions, originally using punched cards for input. A processing run read a command file of SPSS commands and either a raw input file of fixed format data with a single record type, or a ''getfile'' of data saved by a previous run. To save precious computer time an ''edit'' run could be done to check command syntax without analysing the data. From version 10 (SPSS-X) in 1983, data files could contain multiple record types.\nSPSS version 16.0 runs under Windows, Mac OS 10.5 and earlier, and Linux. The graphical user interface is written in Java. The Mac OS version is provided as a Universal binary, making it fully compatible with both PowerPC and Intel-based Mac hardware.\nPrior to SPSS 16.0, different versions of SPSS were available for Windows, Mac OS X and Unix. The Windows version was updated more frequently, and had more features, than the versions for other operating systems.\nSPSS version 13.0 for Mac OS X was not compatible with Intel-based Macintosh computers, due to the Rosetta emulation software causing errors in calculations. SPSS 15.0 for Windows needed a downloadable hotfix to be installed in order to be compatible with Windows Vista.\nRelease History\nSPSS 15.0.0 - September 2006\nSPSS 16.0.1 - November 2007\nSPSS 17.0.0 - August 2008\nSee also\nAt Wikiversity, you can learn about: SPSS\nList of statistical packages\nComparison of statistical packages\nPSPP -- an open source alternative to SPSS\nRcmdr -- an open source R-based alternative to SPSS\nNotes\n^ "SPSS company profile".\nSPSS. Retrieved on 2008-03-22.\n^ "Norman Nie".\nStanford University Department of Political Science. Retrieved on 2008-03-22.\n^ Wellman, B. Doing it ourselves, Pp 71-78 in Required Reading: Sociology''s Most Influential Books. Edited by Dan Clawson, University of Massachusetts Press, 1998, ISBN 9781558491533\nReferences\nSPSS 15.0 Command Syntax Reference 2006, SPSS Inc., Chicago Ill.\nRaynald Levesque, SPSS Programming and Data Management: A Guide for SPSS and SAS Users, Fourth Edition (2007), SPSS Inc., Chicago Ill. PDF ISBN 1568273908\nGeorge Argyrous, Statistics for Research: With a Guide to SPSS, Second Edition (2005), SAGE UK, London. ISBN 1412919487.\nSPSS Inc Homepage - support page includes a searchable database of solutions\nRaynald Levesque''s SPSS Tools - library of worked solutions for SPSS programmers (FAQ, command syntax; macros; scripts; python)\nArchives of SPSSX-L Discussion - SPSS Listserv active since 1996. Discusses programming, statistics and analysis\nUCLA ATS Resources to help you learn SPSS - Resources for learning SPSS\nUCLA ATS Technical Reports - Report 1 compares Stata, SAS and SPSS against R (R is a language and environment for statistical computing and graphics).\nUsing SPSS For Data Analysis - SPSS Tutorial from Harvard\nSPSS Developer Central - Support for developers of applications using SPSS, including materials and examples of the Python programmability feature\nSPSS Log - A blog posting answers on SPSS questions (since March 2006)\nSPSS Experts - Profiles of six SPSS experts around the world\ncomp.soft-sys.stat.spss - SPSS Usenet newsgroup via Google Groups\nSPSS Forum - A forum for SPSS users (since June 2007)\nGNU PSPP - PSPP is a free SPSS replacement.\nViewSav - ViewSav is intended as a Real-Time Codebook for SPSS data files.\nv • d • e\nStatistical software\nPublic domain\nDataplot · Epi Info · CSPro · X-12-ARIMA\nOpen source\ngretl · JMulTi · OpenBUGS · PSPP · R · XLispStat · DAP\nFreeware\nADMB · BV4.1\nRetail\nBMDP · EViews · GAUSS · GenStat · JMP · Mathematica · MedCalc · Minitab · NCSS · OxMetrics · RATS · SAS · SigmaStat · SPSS · Stata · STATISTICA · StatXact · SUDAAN · SYSTAT · S-PLUS\nCategory\n• Comparison\n"http://en.wikipedia.org/wiki/SPSS"\nCategories: Statistical software | Statistical programming languages','\n',char(10)));
INSERT INTO pages VALUES('Prolog','http://web.archive.org/web/20081221010318/http://en.wikipedia.org:80/wiki/Prolog','en','2008-12-21 00:00:00',replace('This article is about the programming language.\nFor the sense of an introduction, see prologue.\nFor other uses of "Prologue", see Prologue (disambiguation).\nFor the company, see Cyan Worlds.\nProlog\nParadigm\nLogic programming\nAppeared in\n1972\nDesigned by\nAlain Colmerauer\nMajor implementations\nBProlog, ECLiPSe, Ciao Prolog, GNU Prolog, Quintus, SICStus, Strawberry, SWI-Prolog, YAP-Prolog, tuProlog, P#\nDialects\nISO Prolog, Edinburgh Prolog\nInfluenced\nVisual Prolog, Mercury, Oz, Erlang, Strand, KL0, KL1\nProlog is a logic programming language. It is a general purpose language often associated with artificial intelligence and computational linguistics. It has a purely logical subset, called "pure Prolog", as well as a number of extralogical features.\nHaving its roots in formal logic, and unlike many other programming languages, Prolog is declarative: The program logic is expressed in terms of relations, and execution is triggered by running queries over these relations. Relations and queries are constructed using Prolog''s single data type, the term. Relations are defined by clauses. Given a query, the Prolog engine attempts to find a resolution refutation of the negated query. If the negated query can be refuted, i.e., an instantiation for all free variables is found that makes the union of clauses and the singleton set consisting of the negated query false, it follows that the original query, with the found instantiation applied, is a logical consequence of the program. This makes Prolog (and other logic programming languages) particularly useful for database, symbolic mathematics, and language parsing applications. Because Prolog allows impure predicates, checking the truth value of certain special predicates may have some deliberate side effect, such as printing a value to the screen. This permits the programmer to use some amount of conventional imperative programming when the logical paradigm is inconvenient.\nThe language was first conceived by a group around Alain Colmerauer in Marseille, France, in the early 1970s, while the first compiler was written by David H. D. Warren in Edinburgh, Scotland. Prolog was one of the first logic programming languages, and remains among the most popular such languages today, with many free and commercial implementations available. While initially aimed at natural language processing, the language has since then stretched far into other areas like theorem proving, expert systems, games, automated answering systems, ontologies and sophisticated control systems, and modern Prolog environments support the creation of graphical user interfaces, as well as administrative and networked applications.\n1 History\n2 Data types\n3 Programming in Prolog\n4 Evaluation\n5 Loops and recursion\n6 Negation\n7 Operational considerations\n8 DCGs and parsing\n8.1 Parser example\n9 Higher-order programming\n10 Meta-interpreters and reflection\n11 Implementation techniques\n12 Examples\n12.1 QuickSort\n12.2 Turing machine\n12.3 Dynamic programming\n13 Extensions\n14 Related languages\n15 See also\n16 References\n17\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nThe name Prolog was chosen by Philippe Roussel as an abbreviation for programmation en logique (French for programming in logic). It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski''s procedural interpretation of Horn clauses. It was motivated in part by the desire to reconcile the use of logic as a declarative knowledge representation language with the procedural representation of knowledge that was popular in North America in the late 1960s and early 1970s.\nMuch of the modern development of Prolog came from the impetus of the fifth generation computer systems project (FGCS), which developed a variant of Prolog named Kernel Language for its first operating system.\nPure Prolog was originally restricted to the use of a resolution theorem prover with Horn clauses of the form:\nH :- B1, …, Bn..\nThe application of the theorem-prover treats such clauses as procedures:\nto show/solve H, show/solve B1 and … and Bn.\nPure Prolog was soon extended, however, to include negation as failure, in which negative conditions of the form not(Bi) are shown by trying and failing to solve the corresponding positive conditions Bi.\nData types\nProlog''s single data type is the term. Terms are either atoms, numbers, variables or compound terms.\nAn atom is a general-purpose name with no inherent meaning. It is composed of a sequence of characters that is parsed by the Prolog reader as a single unit. Atoms are usually bare words in Prolog code, written with no special syntax. However, atoms containing spaces or certain other special characters must be surrounded by single quotes. Atoms beginning with a capital letter must also be quoted, to distinguish them from variables. The empty list, written [], is also an atom. Other examples of atoms include x, blue, ''Taco'', and ''some atom''.\nNumbers can be floats or integers. Many Prolog implementations also provide unbounded integers and rational numbers.\nVariables are denoted by a string consisting of letters, numbers and underscore characters, and beginning with an upper-case letter or underscore. Variables closely resemble variables in logic in that they are placeholders for arbitrary terms. A variable can become instantiated (bound to equal a specific term) via unification. A single underscore (_) denotes an anonymous variable and means "any term". Unlike other variables, the underscore does not represent the same value everywhere it occurs within a predicate definition.\nA compound term is composed of an atom called a "functor" and a number of "arguments", which are again terms. Compound terms are ordinarily written as a functor followed by a comma-separated list of argument terms, which is contained in parentheses. The number of arguments is called the term''s arity. An atom can be regarded as a compound term with arity zero.\nExamples of compound terms are truck_year(''Mazda'', 1986) and ''Person_Friends''(zelda,[tom,jim]). Compound terms with functors that are declared as operators can be written in prefix or infix notation. For example, the terms -(z), +(a,b) and =(X,Y) can also be written as -z, a+b and X=Y, respectively. Users can declare arbitrary functors as operators with different precedences to allow for domain-specific notations. The notation f/n is commonly used to denote a term with functor f and arity n.\nSpecial cases of compound terms:\nLists are defined inductively: The atom [] is a list. A compound term with functor . (dot) and arity 2, whose second argument is a list, is itself a list. There exists special syntax for denoting lists: .(A, B) is equivalent to [A|B]. For example, the list .(1, .(2, .(3, []))) can also be written as [1 | [2 | [3 | []]]], or even more compactly as [1,2,3].\nStrings: A sequence of characters surrounded by quotes is equivalent to a list of (numeric) character codes, generally in the local character encoding or Unicode if the system supports Unicode.\nProgramming in Prolog\nProlog programs describe relations, defined by means of clauses. Pure Prolog is restricted to Horn clauses, a Turing-complete subset of first-order predicate logic. There are two types of clauses: Facts and rules. A rule is of the form\nHead :- Body.\nand is read as "Head is true if Body is true". A rule''s body consists of calls to predicates, which are called the rule''s goals. The built-in predicate ,/2 (meaning a 2-arity operator with name ,) denotes conjunction of goals, and ;/2 denotes disjunction. Conjunctions and disjunctions can only appear in the body, not in the head of a rule.\nClauses with empty bodies are called facts. An example of a fact is:\ncat(tom).\nwhich is equivalent to the rule:\ncat(tom) :- true.\nThe built-in predicate true/0 is always true.\nGiven above fact, one can ask:\nis tom a cat?\n?- cat(tom).\nYes\nwhat things are cats?\n?- cat(X).\nX = tom\nDue to the relational nature of many built-in predicates, they can typically be used in several directions. For example, length/2 can be used to determine the length of a list (length(List, L), given a list List) as well as to generate a list skeleton of a given length (length(X, 5)), and also to generate both list skeletons and their lengths together (length(X, L)). Similarly, append/3 can be used both to append two lists (append(ListA, ListB, X) given lists ListA and ListB) as well as to split a given list into parts (append(X, Y, List), given a list List). For this reason, a comparatively small set of library predicates suffices for many Prolog programs. All predicates can also be used to perform unit tests: Queries can be embedded in programs and allow for automatic compile-time regression testing.\nAs a general purpose language, Prolog also provides various built-in predicates to perform routine activities like input/output, using graphics and otherwise communicating with the operating system. These predicates are not given a relational meaning and are only useful for the side-effects they exhibit on the system. For example, the predicate write/1 displays a term on the screen.\nEvaluation\nExecution of a Prolog program is initiated by the user''s posting of a single goal, called the query. Logically, the Prolog engine tries to find a resolution refutation of the negated query. The resolution method used by Prolog is called SLD resolution. If the negated query can be refuted, it follows that the query, with the appropriate variable bindings in place, is a logical consequence of the program. In that case, all generated variable bindings are reported to the user, and the query is said to have succeeded. Operationally, Prolog''s execution strategy can be thought of as a generalization of function calls in other languages, one difference being that multiple clause heads can match a given call. In that case, the system creates a choice-point, unifies the goal with the clause head of the first alternative, and continues with the goals of that first alternative. If any goal fails in the course of executing the program, all variable bindings that were made since the most recent choice-point was created are undone, and execution continues with the next alternative of that choice-point. This execution strategy is called chronological backtracking. For example:\nsibling(X, Y)\n:- parent_child(Z, X), parent_child(Z, Y).\nparent_child(X, Y) :- father_child(X, Y).\nparent_child(X, Y) :- mother_child(X, Y).\nmother_child(trude, sally).\nfather_child(tom, sally).\nfather_child(tom, erica).\nfather_child(mike, tom).\nThis results in the following query being evaluated as true:\n?- sibling(sally, erica).\nYes\nThis is obtained as follows: Initially, the only matching clause-head for the query sibling(sally, erica) is the first one, so proving the query is equivalent to proving the body of that clause with the appropriate variable bindings in place, i.e., the conjunction (parent_child(Z,sally), parent_child(Z,erica)). The next goal to be proved is the leftmost one of this conjunction, i.e., parent_child(Z, sally). Two clause heads match this goal. The system creates a choice-point and tries the first alternative, whose body is father_child(Z, sally). This goal can be proved using the fact father_child(tom, sally), so the binding Z = tom is generated, and the next goal to be proved is the second part of the above conjunction: parent_child(tom, erica). Again, this can be proved by the corresponding fact. Since all goals could be proved, the query succeeds. Since the query contained no variables, no bindings are reported to the user. A query with variables, like:\n?- father_child(Father, Child).\nenumerates all valid answers on backtracking.\nNotice that with the code as stated above, the query "?- sibling(sally, sally)." also succeeds. One would insert additional goals to describe the relevant restrictions, if desired.\nLoops and recursion\nIterative algorithms can be implemented by means of recursive predicates. Prolog systems typically implement a well-known optimization technique called tail call optimization (TCO) for deterministic predicates exhibiting tail recursion or, more generally, tail calls: A clause''s stack frame is discarded before performing a call in a tail position. Therefore, deterministic tail-recursive predicates are executed with constant stack space, like loops in other languages.\nNegation\nThe built-in Prolog predicate \+/1 provides negation as failure, which allows for non-monotonic reasoning. The goal "\+ illegal(X)" in the rule\nlegal(X) :- \+ illegal(X).\nis evaluated as follows: Prolog attempts to prove illegal(X). If a proof for that goal can be found, the original goal (i.e., \+ illegal(X)) fails. If no proof can be found, the original goal succeeds. Therefore, the \+/1 prefix operator is called the "not provable" operator, since the query "?- \+ Goal" succeeds if Goal is not provable. This kind of negation is sound if its argument is ground. Soundness is lost if the argument contains variables. In particular, the query "?- legal(X)." can now not be used to enumerate all things that are legal.\nOperational considerations\nUnder a declarative reading, the order of rules, and of goals within rules, is irrelevant since logical disjunction and conjunction are commutative. Procedurally, however, it is often important to take into account Prolog''s execution strategy, either for efficiency reasons, or due to the semantics of impure built-in predicates for which the order of evaluation matters.\nDCGs and parsing\nThere is a special notation called definite clause grammars (DCGs). A rule defined via -->/2 instead of :-/2 is expanded by the preprocessor (expand_term/2, a facility analogous to macros in other languages) according to a few straight-forward rewriting rules, resulting in ordinary Prolog clauses. Most notably, the rewriting equips the predicate with two additional arguments, which can be used to implicitly thread state around, analogous to monads in other languages. DCGs are often used to write parsers or list generators, as they also provide a convenient interface to list differences.\nParser example\nA larger example will show the potential of using Prolog in parsing.\nGiven the sentence expressed in BNF:\n<sentence>\n::=\n<stat_part>\n<stat_part>\n::=\n<statement> | <stat_part> <statement>\n<statement>\n::=\n<id> = <expression> ;\n<expression>\n::=\n<operand> | <expression> <operator> <operand>\n<operand>\n::=\n<id> | <digit>\n<id>\n::=\na | b\n<digit>\n::=\n0..9\n<operator>\n::=\n+ | - | *\nThis can be written in Prolog using DCGs, corresponding to a predictive parser with one token look-ahead:\nsentence(S)\n--> statement(S0), sentence_r(S0, S).\nsentence_r(S, S)\n--> [].\nsentence_r(S0, seq(S0, S)) --> statement(S1), sentence_r(S1, S).\nstatement(assign(Id,E)) --> id(Id), [=], expression(E), [;].\nexpression(E) --> term(T), expression_r(T, E).\nexpression_r(E, E)\n--> [].\nexpression_r(E0, E) --> [+], term(T), expression_r(plus(E0,T), E).\nexpression_r(E0, E) --> [-], term(T), expression_r(minus(E0, T), E).\nterm(T)\n--> factor(F), term_r(F, T).\nterm_r(T, T)\n--> [].\nterm_r(T0, T) --> [*], factor(F), term_r(times(T0, F), T).\nfactor(id(ID))\n--> id(ID).\nfactor(digit(D)) --> [D], { (number(D) ; var(D)), between(0, 9, D)}.\nid(a) --> [a].\nid(b) --> [b].\nThis code defines a relation between a sentence (given as a list of tokens) and its abstract syntax tree (AST). Example query:\n?- phrase(sentence(AST), [a,=,1,+,3,*,b,;,b,=,0,;]).\nAST = seq(assign(a, plus(digit(1), times(digit(3), id(b)))), assign(b, digit(0))) ;\nThe AST is represented using Prolog terms and can be used to apply optimizations, to compile such expressions to machine-code, or to directly interpret such statements. As is typical for the relational nature of predicates, these definitions can be used both to parse and generate sentences, and also to check whether a given tree corresponds to a given list of tokens. Using iterative deepening for fair enumeration, each arbitrary but fixed sentence and its corresponding AST will be generated eventually:\n?- length(Tokens, _), phrase(sentence(AST), Tokens).\nTokens = [a, =, a, (;)], AST = assign(a, id(a)) ;\nTokens = [a, =, b, (;)], AST = assign(a, id(b))\netc.\nHigher-order programming\nSince arbitrary Prolog goals can be constructed and evaluated at run-time, it is easy to write higher-order predicates like maplist/2, which applies an arbitrary predicate to each member of a given list, and sublist/3, which filters elements that satisfy a given predicate, also allowing for currying.\nTo convert solutions from temporal representation (answer substitutions on backtracking) to spatial representation (terms), Prolog has various all-solutions predicates that collect all answer substitutions of a given query in a list. This can be used for list comprehension. For example, perfect numbers equal the sum of their proper divisors:\nperfect(N) :-\nbetween(1, inf, N), U is N // 2,\nfindall(D, (between(1,U,D), N mod D =:= 0), Ds),\nsumlist(Ds, N).\nThis can be used to enumerate perfect numbers, and also to check whether a number is perfect.\nMeta-interpreters and reflection\nProlog is a homoiconic language and provides many facilities for reflection. Its implicit execution strategy makes it possible to write a concise meta-circular evaluator (also called meta-interpreter) for pure Prolog code. Since Prolog programs are themselves sequences of Prolog terms (:-/2 is an infix operator) that are easily read and inspected using built-in mechanisms (like read/1), it is easy to write customized interpreters that augment Prolog with domain-specific features.\nImplementation techniques\nFor efficiency, Prolog code is typically compiled to abstract machine code, often influenced by the register-based Warren Abstract Machine (WAM) instruction set. Some implementations employ abstract interpretation to derive type and mode information of predicates at compile time, or compile to real machine code for high performance. Devising efficient implementation techniques for Prolog code is a field of active research in the logic programming community, and various other execution techniques are employed in some implementations. These include clause binarization and stack-based virtual machines.\nSome Prolog systems, like BProlog and XSB, implement an extension called tabling, which frees the user from manually storing intermediate results.\nExamples\nHere follow some example programs written in Prolog.\nQuickSort\nThe QuickSort sorting algorithm, relating a list to its sorted version:\npartition([], _, [], []).\npartition([X|Xs], Pivot, Smalls, Bigs) :-\n(\nX @< Pivot ->\nSmalls = [X|Rest],\npartition(Xs, Pivot, Rest, Bigs)\n;\nBigs = [X|Rest],\npartition(Xs, Pivot, Smalls, Rest)\n).\nquicksort([])\n--> [].\nquicksort([X|Xs]) -->\n{ partition(Xs, X, Smaller, Bigger) },\nquicksort(Smaller), [X], quicksort(Bigger).\nTuring machine\nTuring completeness of Prolog can be shown by using it to simulate a Turing machine:\nturing(Tape0, Tape) :-\nperform(q0, [], Ls, Tape0, Rs),\nreverse(Ls, Ls1),\nappend(Ls1, Rs, Tape).\nperform(qf, Ls, Ls, Rs, Rs) :- !.\nperform(Q0, Ls0, Ls, Rs0, Rs) :-\nsymbol(Rs0, Sym, RsRest),\nonce(rule(Q0, Sym, Q1, NewSym, Action)),\naction(Action, Ls0, Ls1, [NewSym|RsRest], Rs1),\nperform(Q1, Ls1, Ls, Rs1, Rs).\nsymbol([], b, []).\nsymbol([Sym|Rs], Sym, Rs).\naction(left, Ls0, Ls, Rs0, Rs) :- left(Ls0, Ls, Rs0, Rs).\naction(stay, Ls, Ls, Rs, Rs).\naction(right, Ls0, [Sym|Ls0], [Sym|Rs], Rs).\nleft([], [], Rs0, [b|Rs0]).\nleft([L|Ls], Ls, Rs, [L|Rs]).\nA simple example Turing machine is specified by the facts:\nrule(q0, 1, q0, 1, right).\nrule(q0, b, qf, 1, stay).\nThis machine performs incrementation by one of a number in unary encoding: It loops over any number of "1" cells and appends an additional "1" at the end. Example query and result:\n?- turing([1,1,1], Ts).\nTs = [1, 1, 1, 1] ;\nThis example illustrates how any computation can be expressed declaratively as a sequence of state transitions, implemented in Prolog as a relation between successive states of interest. As another example for this, an optimizing compiler with three optimization passes could be implemented as a relation between an initial program and its optimized form:\nprogram_optimized(Prog0, Prog) :-\noptimization_pass_1(Prog0, Prog1),\noptimization_pass_2(Prog1, Prog2),\noptimization_pass_3(Prog2, Prog).\nor equivalently using DCG notation:\nprogram_optimized --> optimization_pass_1, optimization_pass_2, optimization_pass_3.\nDynamic programming\nThe following Prolog program uses dynamic programming to find the longest common subsequence of two lists in polynomial time. The clause database is used for memoization:\n:- dynamic(stored/1).\nmemo(Goal) :- ( stored(Goal) -> true ; Goal, assertz(stored(Goal)) ).\nlcs([], _, []) :- !.\nlcs(_, [], []) :- !.\nlcs([X|Xs], [X|Ys], [X|Ls]) :- !, memo(lcs(Xs, Ys, Ls)).\nlcs([X|Xs], [Y|Ys], Ls) :-\nmemo(lcs([X|Xs], Ys, Ls1)), memo(lcs(Xs, [Y|Ys], Ls2)),\nlength(Ls1, L1), length(Ls2, L2),\n(\nL1 >= L2 -> Ls = Ls1 ; Ls = Ls2 ).\nExample query:\n?- lcs([x,m,j,y,a,u,z], [m,z,j,a,w,x,u], Ls).\nLs = [m, j, a, u]\nExtensions\nConstraint logic programming is important for many Prolog applications in industrial settings, like time tabling and other scheduling tasks. Most Prolog systems ship with at least one constraint solver for finite domains, and often also with solvers for other domains like rational numbers.\nHiLog and λProlog extend Prolog with higher-order programming features.\nF-logic extends Prolog with frames/objects for knowledge representation.\nOW Prolog has been created in order to answer Prolog''s lack of graphics and interface.\nLogtalk is an open source object-oriented extension to the Prolog programming language. Integrating logic programming with object-oriented and event-driven programming, it is compatible with most Prolog compilers. It supports both prototypes and classes. In addition, it supports component-based programming through category-based composition.\nProlog-MPI is an open-source SWI-Prolog extension for distributed computing over the Message Passing Interface.\nOblog is a small, portable, Object-oriented extension to Prolog by Margaret McDougall of EdCAAD, University of Edinburgh.\nRelated languages\nVisual Prolog, also formerly known as PDC Prolog and Turbo Prolog. Visual Prolog is a strongly typed object-oriented dialect of Prolog, which is considerably different from standard Prolog. As Turbo Prolog it was marketed by Borland, but it is now developed and marketed by the Danish firm PDC (Prolog Development Center) that originally produced it.\nDatalog is actually a subset of Prolog. It is limited to relationships that may be stratified and does not allow compound terms. In contrast to Prolog, Datalog is not Turing-complete.\nIn some ways Prolog is a subset of Planner. The ideas in Planner were later further developed in the Scientific Community Metaphor.\nFrameworks also exist which can provide a bridge between Prolog and the Java programming language:\nJPL is a bi-directional Java Prolog bridge which ships with SWI-Prolog by default, allowing Java and Prolog to call each other respectively. It is known to have good concurrency support and is under active development.\nInterProlog, a programming library bridge between Java and Prolog, implementing bi-directional predicate/method calling between both languages. Java objects can be mapped into Prolog terms and vice-versa. Allows the development of GUIs and other functionality in Java while leaving logic processing in the Prolog layer. Supports XSB, SWI-Prolog and YAP.\nProva provides native syntax integration with Java, agent messaging and reaction rules. Prova positions itself as a rule-based scripting (RBS) system for middleware. The language breaks new ground in combining imperative and declarative programming.\nSee also\nComparison of Prolog implementations\nProlog standards compliance\nReferences\nWilliam F. Clocksin, Christopher S. Mellish: Programming in Prolog: Using the ISO Standard. Springer, 5th ed., 2003, ISBN 978-3540006787. (This edition is updated for ISO Prolog. Previous editions described Edinburgh Prolog.)\nWilliam F. Clocksin: Clause and Effect. Prolog Programming for the Working Programmer. Springer, 2003, ISBN 978-3540629719.\nMichael A. Covington, Donald Nute, Andre Vellino, Prolog Programming in Depth, 1996, ISBN 0-13-138645-X.\nMichael A. Covington, Natural Language Processing for Prolog Programmers, 1994, ISBN 0-13-629213-5.\nLeon Sterling and Ehud Shapiro, The Art of Prolog: Advanced Programming Techniques, 1994, ISBN 0-262-19338-8.\nIvan Bratko, PROLOG Programming for Artificial Intelligence, 2000, ISBN 0-201-40375-7.\nRobert Kowalski, The Early Years of Logic Programming, CACM January 1988.\nISO/IEC 13211: Information technology — Programming languages — Prolog. International Organization for Standardization, Geneva.\nAlain Colmerauer and Philippe Roussel, The birth of Prolog, in The second ACM SIGPLAN conference on History of programming languages, p. 37-52, 1992.\nRichard O''Keefe, The Craft of Prolog, ISBN 0-262-15039-5.\nPatrick Blackburn, Johan Bos, Kristina Striegnitz, Learn Prolog Now!, 2006, ISBN 1-904987-17-6.\nWikibooks has more on the topic of\nProlog\ncomp.lang.prolog FAQ\nProlog: The ISO standard\nDECsystem-10 Prolog User’s Manual (plain text) describes a typical Edinburgh Prolog\nProlog Tutorial by J.R.Fisher\nRunnable examples by Lloyd Allison\nOn-line guide to Prolog Programming by Roman Bartak\nLearn Prolog Now! by Patrick Blackburn, Johan Bos and Kristina Striegnitz\nProlog and Logic Programming by Dr Peter Hancox\nBuilding Expert Systems in Prolog, online book by Amzi! Inc.\nLiterate programming in Prolog\n"http://en.wikipedia.org/wiki/Prolog"\nCategories: Prolog programming language family | Computer and telecommunication standards | Declarative programming languages','\n',char(10)));
INSERT INTO pages VALUES('C++','http://web.archive.org/web/20081217050014/http://en.wikipedia.org:80/wiki/C++','en','2008-12-17 00:00:00',replace('C++\012Paradigm\012Multi-paradigm\012Appeared in\0121983\012Designed by\012Bjarne Stroustrup\012Typing discipline\012Static, unsafe, nominative\012Major implementations\012Microsoft Visual C++, GCC, Borland C++ Builder, Intel C++ Compiler\012Dialects\012ISO/IEC C++ 1998, ISO/IEC C++ 2003\012Influenced by\012C, Simula, Ada 83, ALGOL 68, CLU, ML\012Influenced\012Ada 95, C#, Java, PHP, Perl, D, Aikido, Dao\012C++ ("C Plus Plus", pronounced /ˌsiːˌplʌsˈplʌs/) is a general-purpose programming language. It is regarded as a middle-level language, as it comprises a combination of both high-level and low-level language features.[1] It was developed by Bjarne Stroustrup in 1979 at Bell Labs as an enhancement to the C programming language and originally named "C with Classes". It was renamed to C++ in 1983.\012C++ enjoys wide use in the software industry. Some of its application domains include systems software, device drivers, embedded software, high-performance server and client applications, and entertainment software such as video games. Several groups provide both free and commercial C++ compiler software, including the GNU Project, Microsoft, Intel, Borland and others.\012The language began as enhancements to C, first adding classes, then virtual functions, operator overloading, multiple inheritance, templates, and exception handling among other features. After years of development, the C++ programming language standard was ratified in 1998 as ISO/IEC 14882:1998. The current standard is the 2003 version, ISO/IEC 14882:2003. The next standard version (known informally as C++0x) is in development.\012C++ is a statically typed, free-form, multi-paradigm, compiled language where compilation creates machine code for a target machine hardware. It supports procedural programming, data abstraction, object-oriented programming, and generic programming.\0121 History\0121.1 Language standard\0121.2 Etymology\0122 Philosophy\0123 Standard library\0124 Language features\0124.1 Operators and operator overloading\0124.2 Templates\0124.3 Objects\0124.3.1 Encapsulation\0124.3.2 Inheritance\0124.4 Polymorphism\0124.4.1 Static polymorphism\0124.4.2 Dynamic polymorphism\0124.4.2.1 Inheritance\0124.4.2.2 Virtual member functions\0125 Parsing and processing C++ source code\0126 Compatibility\0126.1 With C\0127 Adoption and reception\0128 Criticism\0129 See also\01210 References\01211 Further reading\01212\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012History\012Bjarne Stroustrup, creator of C++\012Stroustrup began work on C with Classes in 1979. The idea of creating a new language originated from Stroustrup''s experience in programming for his Ph.D. thesis. Stroustrup found that Simula had features that were very helpful for large software development, but the language was too slow for practical use, while BCPL was fast but too low-level to be suitable for large software development. When Stroustrup started working in AT&T Bell Labs, he had the problem of analyzing the UNIX kernel with respect to distributed computing. Remembering his Ph.D. experience, Stroustrup set out to enhance the C language with Simula-like features. C was chosen because it was general-purpose, fast, portable and widely used. Besides C and Simula, some other languages that inspired him were ALGOL 68, Ada, CLU and ML. At first, the class, derived class, strong type checking, inlining, and default argument features were added to C via Cfront. The first commercial release occurred in October 1985.[2]\012In 1983, the name of the language was changed from C with Classes to C++ (++ being the increment operator in C and C++). New features were added including virtual functions, function name and operator overloading, references, constants, user-controlled free-store memory control, improved type checking, and BCPL style single-line comments with two forward slashes (//). In 1985, the first edition of The C++ Programming Language was released, providing an important reference to the language, since there was not yet an official standard. In 1989, Release 2.0 of C++ was released. New features included multiple inheritance, abstract classes, static member functions, const member functions, and protected members. In 1990, The Annotated C++ Reference Manual was published. This work became the basis for the future standard. Late addition of features included templates, exceptions, namespaces, new casts, and a Boolean type.\012As the C++ language evolved, a standard library also evolved with it. The first addition to the C++ standard library was the stream I/O library which provided facilities to replace the traditional C functions such as printf and scanf. Later, among the most significant additions to the standard library, was the Standard Template Library.\012C++ continues to be used and is still one of the preferred programming languages to develop professional applications. The language has gone from being mostly Western, to attracting programmers from all over the world.[3]\012Language standard\012After years of work, a joint ANSI–ISO committee standardized C++ in 1998 (ISO/IEC 14882:1998). For some years after the official release of the standard, the committee processed defect reports, and published a corrected version of the C++ standard in 2003. In 2005, a technical report, called the "Library Technical Report 1" (often known as TR1 for short) was released. While not an official part of the standard, it gives a number of extensions to the standard library, which are expected to be included in the next version of C++. Support for TR1 is growing in almost all currently maintained C++ compilers.\012While the C++ language is royalty-free, the standard document itself is not freely available.\012Etymology\012According to Stroustrup: "the name signifies the evolutionary nature of the changes from C".[4] During C++''s development period, the language had been referred to as "new C", then "C with Classes". The final name is credited to Rick Mascitti (mid-1983) and was first used in December 1983. When Mascitti was questioned informally in 1992 about the naming, he indicated that it was given in a tongue-in-cheek spirit. It stems from C''s "++" operator (which increments the value of a variable) and a common naming convention of using "+" to indicate an enhanced computer program. There is no language called "C plus". ABCL/c+ was the name of an earlier, unrelated programming language.\012Philosophy\012In The Design and Evolution of C++ (1994), Bjarne Stroustrup describes some rules that he uses for the design of C++:\012C++ is designed to be a statically typed, general-purpose language that is as efficient and portable as C\012C++ is designed to directly and comprehensively support multiple programming styles (procedural programming, data abstraction, object-oriented programming, and generic programming)\012C++ is designed to give the programmer choice, even if this makes it possible for the programmer to choose incorrectly\012C++ is designed to be as compatible with C as possible, therefore providing a smooth transition from C\012C++ avoids features that are platform specific or not general purpose\012C++ does not incur overhead for features that are not used (the "zero-overhead principle")\012C++ is designed to function without a sophisticated programming environment\012Inside the C++ Object Model (Lippman, 1996) describes how compilers may convert C++ program statements into an in-memory layout. Compiler authors are, however, free to implement the standard in their own manner.\012Standard library\012The 1998 ANSI/ISO C++ standard consists of two parts: the core language and the C++ standard library; the latter includes most of the Standard Template Library (STL) and a slightly modified version of the C standard library. Many C++ libraries exist which are not part of the standard, and, using linkage specification, libraries can even be written in languages such as C, Fortran, Pascal, or BASIC. Which of these are supported is compiler dependent.\012The C++ standard library incorporates the C standard library with some small modifications to make it work better with the C++ language. Another large part of the C++ library is based on the STL. This provides such useful tools as containers (for example vectors and lists), iterators to provide these containers with array-like access and algorithms to perform operations such as searching and sorting. Furthermore (multi)maps (associative arrays) and (multi)sets are provided, all of which export compatible interfaces. Therefore it is possible, using templates, to write generic algorithms that work with any container or on any sequence defined by iterators. As in C, the features of the library are accessed by using the #include directive to include a standard header. C++ provides 69 standard headers, of which 19 are deprecated.\012The STL was originally a third-party library from HP and later SGI, before its incorporation into the C++ standard. The standard does not refer to it as "STL", as it is merely a part of the standard library, but many people still use that term to distinguish it from the rest of the library (input/output streams, internationalization, diagnostics, the C library subset, etc.).\012Most C++ compilers provide an implementation of the C++ standard library, including the STL. Compiler-independent implementations of the STL, such as STLPort, also exist. Other projects also produce various custom implementations of the C++ standard library and the STL with various design goals.\012Language features\012C++ inherits most of C''s syntax and the C preprocessor. The following is a Hello world program which uses the C++ standard library stream facility to write a message to standard output:[5][6]\012#include <iostream>\012// provides std::cout\012int main()\012{\012std::cout << "Hello, world!\n";\012}\012Operators and operator overloading\012C++ provides more than 30 operators, covering basic arithmetic, bit manipulation, indirection, comparisons, logical operations and more. Almost all operators can be overloaded for user-defined types, with a few notable exceptions such as member access (. and .*). The rich set of overloadable operators is central to using C++ as a domain specific language. The overloadable operators are also an essential part of many advanced C++ programming techniques, such as smart pointers. Overloading an operator does not change the precedence of calculations involving the operator, nor does it change the number of operands that the operator uses (any operand may however be ignored).\012Templates\012generic programming and template metaprogramming\012C++ templates enable generic programming. C++ supports both function and class templates. Templates may be parameterized by types, compile-time constants, and other templates. C++ templates are implemented by instantiation at compile-time. To instantiate a template, compilers substitute specific arguments for a template''s parameters to generate a concrete function or class instance. Templates are a powerful tool that can be used for generic programming, template metaprogramming, and code optimization, but this power implies a cost. Template use may increase code size, since each template instantiation produces a copy of the template code: one for each set of template arguments. This is in contrast to run-time generics seen in other languages (e.g. Java) where at compile-time the type is erased and a single template body is preserved.\012Templates are different from macros: while both of these compile-time language features enable conditional compilation, templates are not restricted to lexical substitution. Templates are aware of the semantics and type system of their companion language, as well as all compile-time type definitions, and can perform high-level operations including programmatic flow control based on evaluation of strictly type-checked parameters. Macros are capable of conditional control over compilation based on predetermined criteria, but cannot instantiate new types, recurse, or perform type evaluation and in effect are limited to pre-compilation text-substitution and text-inclusion/exclusion. In other words, macros can control compilation flow based on pre-defined symbols but cannot, unlike templates, independently instantiate new symbols. Templates are a tool for static polymorphism (see below) and generic programming.\012In addition, templates are a compile time mechanism in C++ which is Turing-complete, meaning that any computation expressible by a computer program can be computed, in some form, by a template metaprogram prior to runtime.\012In summary, a template is a compile-time parameterized function or class written without knowledge of the specific arguments used to instantiate it. After instantiation the resulting code is equivalent to code written specifically for the passed arguments. In this manner, templates provide a way to decouple generic, broadly-applicable aspects of functions and classes (encoded in templates) from specific aspects (encoded in template parameters) without sacrificing performance due to abstraction.\012Objects\012Main article: C++ structures and classes\012C++ introduces object-oriented (OO) features to C. It offers classes, which provide the four features commonly present in OO (and some non-OO) languages: abstraction, encapsulation, inheritance, and polymorphism. Objects are instances of classes created at runtime. The class can be thought of as a template from which many different individual objects may be generated as a program runs.\012Encapsulation\012Encapsulation is the hiding of information. C++ implements encapsulation by allowing all members of a class to be declared as either public, private, or protected. A public member of the class is accessible to any function. A private member is accessible only to functions that are members of that class and to functions and classes explicitly granted access permission by the class ("friends"). A protected member is accessible to members of classes that inherit from the class in addition to the class itself and any friends.\012The OO principle is that all of the functions (and only the functions) that access the internal representation of a type should be encapsulated within the type definition. C++ supports this (via member functions and friend functions), but does not enforce it: the programmer can declare parts or all of the representation of a type to be public, and is allowed to make public entities that are not part of the representation of the type. Because of this, C++ supports not just OO programming, but other weaker decomposition paradigms, like modular programming.\012It is generally considered good practice to make all data private or protected, and to make public only those functions that are part of a minimal interface for users of the class. This hides all the details of data implementation, allowing the designer to later fundamentally change the implementation without changing the interface in any way.\012Inheritance\012Inheritance allows one data type to acquire properties of other data types. Inheritance from a base class may be declared as public, protected, or private. This access specifier determines whether unrelated and derived classes can access the inherited public and protected members of the base class. Only public inheritance corresponds to what is usually meant by "inheritance". The other two forms are much less frequently used. If the access specifier is omitted, a "class" inherits privately, while a "struct" inherits publicly. Base classes may be declared as virtual; this is called virtual inheritance. Virtual inheritance ensures that only one instance of a base class exists in the inheritance graph, avoiding some of the ambiguity problems of multiple inheritance.\012Multiple inheritance is a C++ feature sometimes considered controversial. Multiple inheritance allows a class to be derived from more than one base class; this can result in a complicated graph of inheritance relationships. For example, a "Flying Cat" class can inherit from both "Cat" and "Flying Mammal". Some other languages, such as Java or C#, accomplish something similar (although more limited) by allowing inheritance of multiple interfaces while restricting the number of base classes to one (interfaces, unlike classes, provide only declarations of member functions, no implementation or member data).\012Polymorphism\012Polymorphism in object-oriented programming\012Polymorphism enables one common interface for many implementations, and for objects to act differently under different circumstances.\012C++ supports several kinds of static (compile-time) and dynamic (run-time) polymorphisms. Compile-time polymorphism does not allow for certain run-time decisions, while run-time polymorphism typically incurs a performance penalty.\012Static polymorphism\012Function overloading allows programs to declare multiple functions having the same name (but with different arguments). The functions are distinguished by the number and/or types of their formal parameters. Thus, the same function name can refer to different functions depending on the context in which it is used. The type returned by the function is not used to distinguish overloaded functions.\012When declaring a function, a programmer can specify default arguments for one or more parameters. Doing so allows the parameters with defaults to optionally be omitted when the function is called, in which case the default arguments will be used. When a function is called with fewer arguments than there are declared parameters, explicit arguments are matched to parameters in left-to-right order, with any unmatched parameters at the end of the parameter list being assigned their default arguments. In many cases, specifying default arguments in a single function declaration is preferable to providing overloaded function definitions with different numbers of parameters.\012Templates in C++ provide a sophisticated mechanism for writing generic, polymorphic code. In particular, through the Curiously Recurring Template Pattern it''s possible to implement a form of static polymorphism that closely mimics the syntax for overriding virtual functions. Since C++ templates are type-aware and Turing-complete they can also be used to let the compiler resolve recursive conditionals and generate substantial programs through template metaprogramming.\012Dynamic polymorphism\012Inheritance\012Variable pointers (and references) to a base class type in C++ can refer to objects of any derived classes of that type in addition to objects exactly matching the variable type. This allows arrays and other kinds of containers to hold pointers to objects of differing types. Because assignment of values to variables usually occurs at run-time, this is necessarily a run-time phenomenon.\012C++ also provides a dynamic_cast operator, which allows the program to safely attempt conversion of an object into an object of a more specific object type (as opposed to conversion to a more general type, which is always allowed). This feature relies on run-time type information (RTTI). Objects known to be of a certain specific type can also be cast to that type with static_cast, a purely compile-time construct which is faster and does not require RTTI.\012Virtual member functions\012Ordinarily when a function in a derived class overrides a function in a base class, the function to call is determined by the type of the object. A given function is overridden when there exists no difference, in the number or type of parameters, between two or more definitions of that function. Hence, at compile time it may not be possible to determine the type of the object and therefore the correct function to call, given only a base class pointer; the decision is therefore put off until runtime. This is called dynamic dispatch. Virtual member functions or methods[7] allow the most specific implementation of the function to be called, according to the actual run-time type of the object. In C++, this is commonly done using virtual function tables. If the object type is known, this may be bypassed by prepending a fully qualified class name before the function call, but in general calls to virtual functions are resolved at run time.\012In addition to standard member functions, operator overloads and destructors can be virtual. A general rule of thumb is that if any functions in the class are virtual, the destructor should be as well. As the type of an object at its creation is known at compile time, constructors, and by extension copy constructors, cannot be virtual. Nonetheless a situation may arise where a copy of an object needs to be created when a pointer to a derived object is passed as a pointer to a base object. In such a case a common solution is to create a clone() (or similar) function and declare that as virtual. The clone() method creates and returns a copy of the derived class when called.\012A member function can also be made "pure virtual" by appending it with = 0 after the closing parenthesis and before the semicolon. Objects cannot be created of a class with a pure virtual function and are called abstract data types. Such abstract data types can only be derived from. Any derived class inherits the virtual function as pure and must provide a non-pure definition of it (and all other pure virtual functions) before objects of the derived class can be created. An attempt to create an object from a class with a pure virtual function or inherited pure virtual function will be flagged as a compile-time error.\012Parsing and processing C++ source code\012It is relatively difficult to write a good C++ parser with classic parsing algorithms such as LALR(1).[8] This is partly because the C++ grammar is not LALR. Because of this, there are very few tools for analyzing or performing non-trivial transformations (e.g., refactoring) of existing code. One way to handle this difficulty is to choose a different syntax, such as Significantly Prettier and Easier C++ Syntax, which is LALR(1) parsable. More powerful parsers, such as GLR parsers, can be substantially simpler (though slower).\012Parsing (in the literal sense of producing a syntax tree) is not the most difficult problem in building a C++ processing tool. Such tools must also have the same understanding of the meaning of the identifiers in the program as a compiler might have. Practical systems for processing C++ must then not only parse the source text, but be able to resolve for each identifier precisely which definition applies (e.g. they must correctly handle C++''s complex scoping rules) and what its type is, as well as the types of larger expressions.\012Finally, a practical C++ processing tool must be able to handle the variety of C++ dialects used in practice (such as that supported by the GNU Compiler Collection and that of Microsoft''s Visual C++) and implement appropriate analyzers, source code transformers, and regenerate source text. Combining advanced parsing algorithms such as GLR with symbol table construction and program transformation machinery can enable the construction of arbitrary C++ tools.\012Compatibility\012Producing a reasonably standards-compliant C++ compiler has proven to be a difficult task for compiler vendors in general. For many years, different C++ compilers implemented the C++ language to different levels of compliance to the standard, and their implementations varied widely in some areas such as partial template specialization. Recent releases of most popular C++ compilers support almost all of the C++ 1998 standard.[9]\012One particular point of contention is the export keyword, intended to allow template definitions to be separated from their declarations. The first compiler to implement export was Comeau C/C++, in early 2003 (5 years after the release of the standard); in 2004, the beta compiler of Borland C++ Builder X was also released with export. Both of these compilers are based on the EDG C++ front end. It should also be noted that many C++ books provide example code using the keyword export (for example, Beginning ANSI C++ by Ivor Horton) which will not compile in most compilers, but there is no reference to the problem with the keyword export mentioned. Other compilers such as GCC do not support it at all. Herb Sutter, secretary of the C++ standards committee, recommended that export be removed from future versions of the C++ standard, [10] but finally the decision was made to retain it.[11]\012In order to give compiler vendors greater freedom, the C++ standards committee decided not to dictate the implementation of name mangling, exception handling, and other implementation-specific features. The downside of this decision is that object code produced by different compilers is expected to be incompatible. There are, however, third party standards for particular machines or operating systems which attempt to standardize compilers on those platforms (for example C++ ABI[12]); some compilers adopt a secondary standard for these items.\012With C\012For more details on this topic, see Compatibility of C and C++.\012C++ is often considered to be a superset of C, but this is not strictly true.[13] Most C code can easily be made to compile correctly in C++, but there are a few differences that cause some valid C code to be invalid in C++, or to behave differently in C++.\012One commonly encountered difference is that C allows implicit conversion from void* to other pointer types, but C++ does not. Another common portability issue is that C++ defines many new keywords, such as new and class, that may be used as identifiers (e.g. variable names) in a C program.\012Some incompatibilities have been removed by the latest (C99) C standard, which now supports C++ features such as // comments and mixed declarations and code. However, C99 introduced a number of new features that C++ does not support (such as variable-length arrays, native complex-number types, and compound literals), so the languages may be diverging more than they are converging. However, at least some of the new C99 features will likely be included in the next version of the C++ standard, C++0x.\012In order to intermix C and C++ code, any function declaration or definition that is to be called from/used both in C and C++ must be declared with C linkage by placing it within an extern "C" { ... } block. Such a function may not rely on features depending on name mangling (i.e., function overloading).\012Adoption and reception\012Please help improve this section by expanding it. Further information might be found on the talk page. (October 2008)\012Criticism\012It has been suggested that it may be better to integrate the information in this article''s Criticism or Controversy section(s) into the article as a whole to achieve a more neutral presentation. (Discuss)\012Modern critics of the language raise several points. First, since C++ is based on and largely compatible with C, it inherits most of the criticisms leveled at that language. Taken as a whole, C++ has a large feature set, including all of C, plus a large set of its own additions, in part leading to criticisms of being a "bloated" and complicated language. Bjarne Stroustrup points out that resultant executables don''t support these claims of bloat: "I have even seen the C++ version of the ''hello world'' program smaller than the C version."[14] The Embedded C++ standard was specified to deal with part of this, but it received criticism for leaving out useful parts of the language that incur no runtime penalty.[15] Because of its large feature set, it is difficult to fully master C++.\012While C++ is more complex than some other programming languages, Bjarne Stroustrup points out that "The programming world is far more complex today than it was 30 years ago, and modern programming languages reflect that."[16] The ISO standard of the C++ language is about 310 pages (excluding library). For comparison, the C programming language''s is about 160 pages, even though it was designed more than 15 years prior and doesn''t consider object-oriented programming.\012This article needs additional citations for verification. Please help improve this article by adding reliable references. Unsourced material may be challenged and removed. (December 2008)\012Other criticism stems from what is missing from C++. For example, the current version of Standard C++ provides no language features to create multi-threaded software other than the volatile keyword. (The next version of C++ will introduce the thread_local keyword.) These facilities are present in some other languages including Java, Ada, and C# (see also Lock). It is possible to use operating system calls or third party libraries to do multi-threaded programming, but both approaches may create portability concerns.\012This article or section contains weasel words, vague phrasing that often accompanies biased or unverifiable information. Such statements should be clarified or removed. (December 2008)\012C++ is also sometimes compared unfavorably with single-paradigm object-oriented languages such as Smalltalk, Java or Eiffel on the basis that it allows programmers to "mix and match" object-oriented and procedural programming, rather than strictly enforcing a single paradigm. This is part of a wider debate on the relative merits of the two programming styles.\012Comparison of Java and C++\012See also\012Comparison of programming languages\012List of C++ compilers\012Comparison of integrated development environments for C/C++\012List of C++ template libraries\012C++0x, the planned new standard for C++\012References\012^ C++ The Complete Reference Third Edition, Herbert Schildt, Publisher: Osborne McGraw-Hill.\012^ "Bjarne Stroustrup''s FAQ - When was C++ invented?". Retrieved on 2006-05-30.\012^ "Trends on C++ Programmers, Developers & Engineers". Retrieved on 2008-12-01.\012^ "Bjarne Stroustrup''s FAQ - Where did the name "C++" come from?". Retrieved on 2008-01-16.\012^ Stroustrup, Bjarne (2000). The C++ Programming Language (Special Edition ed.). Addison-Wesley. pp. 46. ISBN 0-201-70073-5.\012^ Open issues for The C++ Programming Language (3rd Edition) - This code is copied directly from Bjarne Stroustrup''s errata page (p. 633). He addresses the use of ''\n'' rather than std::endl. Also see www.research.att.com and www.delorie.com/djgpp/ for an explanation of the implicit return 0; in the main function. This implicit return is not available in other functions.\012^ Stroustrup, Bjarne (2000). The C++ Programming Language (Special Edition ed.). Addison-Wesley. pp. 310. ISBN 0-201-70073-5.\012"A virtual member function is sometimes called a method.".\012^ Parsing C++ at nobugs.org\012^ Herb Sutter (2003-04-15). "C++ Conformance Roundup". Dr. Dobb''s Journal. Retrieved on 2006-05-30.\012^ Why We Can’t Afford ExportPDF (266 KiB)\012^ "Minutes of J16 Meeting No. 36/WG21 Meeting No. 31, April 7-11, 2003" (2003-04-25). Retrieved on 2006-09-04.\012^ "C++ ABI". Retrieved on 2006-05-30.\012^ "Bjarne Stroustrup''s FAQ - Is C a subset of C++?". Retrieved on 2008-01-18.\012^ Why is the code generated for the "Hello world" program ten times larger for C++ than for C?\012^ What do you think of EC++?\012^ Why is C++ so BIG?\012Further reading\012Abrahams, David; Aleksey Gurtovoy. C++ Template Metaprogramming: Concepts, Tools, and Techniques from Boost and Beyond. Addison-Wesley. ISBN 0-321-22725-5.\012Alexandrescu, Andrei (2001). Modern C++ Design: Generic Programming and Design Patterns Applied. Addison-Wesley. ISBN 0-201-70431-5.\012Becker, Pete (2006). The C++ Standard Library Extensions : A Tutorial and Reference. Addison-Wesley. ISBN 0-321-41299-0.\012Alexandrescu, Andrei; Herb Sutter (2004). C++ Design and Coding Standards: Rules and Guidelines for Writing Programs. Addison-Wesley. ISBN 0-321-11358-6.\012Coplien, James O. (1992, reprinted with corrections 1994). Advanced C++: Programming Styles and Idioms. ISBN 0-201-54855-0.\012Dewhurst, Stephen C. (2005). C++ Common Knowledge: Essential Intermediate Programming. Addison-Wesley. ISBN 0-321-32192-8.\012Information Technology Industry Council (2003-10-15). Programming languages — C++ (Second edition ed.). Geneva: ISO/IEC. 14882:2003(E).\012Josuttis, Nicolai M. The C++ Standard Library. Addison-Wesley. ISBN 0-201-37926-0.\012Koenig, Andrew; Barbara E. Moo (2000). Accelerated C++ - Practical Programming by Example. Addison-Wesley. ISBN 0-201-70353-X.\012Lippman, Stanley B.; Josée Lajoie, Barbara E. Moo (2005). C++ Primer. Addison-Wesley. ISBN 0-201-72148-1.\012Lippman, Stanley B. (1996). Inside the C++ Object Model. Addison-Wesley. ISBN 0-201-83454-5.\012Stroustrup, Bjarne (2000). The C++ Programming Language (Special Edition ed.). Addison-Wesley. ISBN 0-201-70073-5.\012Stroustrup, Bjarne (1994). The Design and Evolution of C++. Addison-Wesley. ISBN 0-201-54330-3.\012Sutter, Herb (2001). More Exceptional C++: 40 New Engineering Puzzles, Programming Problems, and Solutions. Addison-Wesley. ISBN 0-201-70434-X.\012Sutter, Herb (2004). Exceptional C++ Style. Addison-Wesley. ISBN 0-201-76042-8.\012Vandevoorde, David; Nicolai M. Josuttis (2003). C++ Templates: The complete Guide. Addison-Wesley. ISBN 0-201-73484-2.\012Scott Meyers (2005). Effective C++. Third Edition. Addison-Wesley. ISBN 0-321-33487-6\012Wikibooks has a book on the topic of\012C++\012Look up C++ in\012Wiktionary, the free dictionary.\012A paper by Stroustrup showing the timeline of C++ evolution (1979-1991)\012Apache C++ Standard Library Documentation\012Standards Committee Page: JTC1/SC22/WG21 - C++\012C++ FAQ Lite by Marshall Cline\012Computer World interview with Bjarne Stroustrup\012CrazyEngineers.com interview with Bjarne Stroustrup\012The State of the Language: An Interview with Bjarne Stroustrup (August 15, 2008)\012v • d • e\012Integrated development environments for C/C++\012Open source\012Anjuta · Code::Blocks · Codelite · Dev-C++ · Eclipse · GNAT Programming Studio · KDevelop · MonoDevelop · wxDev-C++\012Freeware\012Visual Studio Express · Pelles C · Sun Studio · Turbo C++ Explorer · Xcode\012Retail\012C++ Builder · Visual Studio · Turbo C++ Professional\012Category\012• Comparison\012"http://en.wikipedia.org/wiki/C%2B%2B"\012Categories: Integrated development environments | C++ | Curly bracket programming languagesHidden categories: Articles to be expanded since October 2008 | All articles to be expanded | Cleanup from section | All articles with unsourced statements | Articles with unsourced statements since September 2007 | Articles needing additional references from December 2008 | Articles with weasel words','\012',char(10)));
INSERT INTO pages VALUES('ActionScript','http://web.archive.org/web/20090107131058/http://en.wikipedia.org:80/wiki/Actionscript','en','2009-01-07 00:00:00',replace('( Actionscript)\nThis article or section recently underwent a major revision or rewrite and needs further review. You can help Wikipedia by assisting in the revision.\nActionScript\nParadigm\nMulti-paradigm\nAppeared in\n1998\nDesigned by\nGary Grossman\nDeveloper\nMacromedia (now Adobe Systems)\nLatest release\n3.0/ 27 June 2006; 924 days ago\nTyping discipline\nstrong, static, safe\nMajor implementations\nAdobe Flash, Adobe Flex\nInfluenced by\nJavaScript, Java\nOS\nCross-platform\nActionScript\nFilename extension\n.as\nInternet media type\napplication/actionscript[1]\nActionScript is a scripting language based on ECMAScript. ActionScript is used primarily for the development of websites and software using the Adobe Flash Player platform (in the form of SWF files embedded into Web pages), but is also used in some database applications (such as Alpha Five), and in basic robotics, as with the Make Controller Kit. Originally developed by Macromedia, the language is now owned by Adobe (which acquired Macromedia in 2005). ActionScript was initially designed for controlling simple 2D vector animations made in Adobe Flash (formerly Macromedia Flash). Later versions added functionality allowing for the creation of Web-based games and rich Internet applications with streaming media (such as video and audio).\n1 History\n1.1 Timeline by player\n1.2 Timeline by ActionScript version\n1.3 Flash Lite\n2 Syntax\n2.1 ActionScript 2.0\n2.2 ActionScript 3.0\n3 Data structures\n3.1 Data types\n3.2 Using data types\n4 References\n5 See also\n6\n6.1 Adobe documentation and references\n6.2 Tutorials / Resource Sites\n6.3 Tools and scripts\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nActionScript started as a scripting language for Macromedia''s Shockwave Flash authoring tool, now developed by Adobe as Adobe Flash. The first three versions of the Flash authoring tool provided limited interactivity features. Early Flash developers could attach a simple command, called an "action", to a button or a frame. The set of actions was basic navigation controls, with commands such as "play", "stop", "getURL", and "gotoAndPlay".\nWith the release of Flash 4 in 1999, this simple set of actions became a small scripting language. New capabilities introduced for Flash 4 included variables, expressions, operators, if statements, and loops. Although referred to internally as "ActionScript", the Flash 4 user manual and marketing documents continued to use the term "actions" to describe this set of commands .\nTimeline by player\nFlash Player 2: The first version with scripting support. Actions included gotoAndPlay, gotoAndStop, nextFrame and nextScene for timeline control.\nFlash Player 3: Expanded basic scripting support with the ability to load external SWFs (loadMovie).\nFlash Player 4: First player with a full scripting implementation (called Actions). The scripting was a flash based syntax and contained support for loops, conditionals, variables and other basic language constructs.\nFlash Player 5: Included the first version of ActionScript. Used prototype-based programming based on ECMAScript, and allowed full procedural programming and object-oriented programming.\nFlash Player 6: Added an event handling model, accessibility controls and support for switch. The first version with support for the AMF and RTMP protocols which allowed for ondemand audio/video streaming.\nFlash Player 7: Additions include CSS styling for text and support for ActionScript 2.0, a programming language based on the ECMAScript 4 Netscape Proposal with class-based inheritance. However, ActionScript 2.0 can cross compile to ActionScript 1.0 byte-code, so that it can run in Flash Player 6.\nFlash Player 8: Further extended ActionScript 1/ActionScript 2 by adding new class libraries with APIs for controlling bitmap data at run-time, file uploads and live filters for blur and dropshadow.\nExample of ActionScript 2.0 running on Macromedia Flash 8.\nFlash Player 9 (initially called 8.5): Added ActionScript 3.0 with the advent of a new virtual machine, called AVM2 (ActionScript Virtual Machine 2), which coexists with the previous AVM1 needed to support legacy content. Performance increases were a major objective for this release of the player including a new JIT compiler. Support for binary sockets, E4X XML parsing, full-screen mode and Regular Expressions were added. This is the first release of the player to be titled Adobe Flash Player.\nFlash Player 10 (initially called Astro): Added basic 3D manipulation, such as rotating on the X, Y, and Z axis, and a 3D drawing API. Ability to create custom filters using Adobe Pixel Bender. Graphic processing is now offloaded to the GPU which gives a noticeable decrease to rendering time for each frame, basically higher Frame rate. There is a new sound API which allows for custom creation of audio in flash, something that has never been possible before. [2]\nTimeline by ActionScript version\n2000–2003: ActionScript "1.0" With the release of Flash 5 in September 2000, the "actions" from Flash 4 were enhanced once more and named "ActionScript" for the first time.[3] This was the first version of ActionScript with influences from JavaScript and the ECMA-262 (Third Edition) standard, supporting the said standard''s object model and many of its core data types. Local variables may be declared with the var statement, and user-defined functions with parameter passing and return values can also be created. Notably, ActionScript could now also be typed with a text editor rather than being assembled by choosing actions from drop-down lists and dialog box controls. With the next release of its authoring tool, Flash MX, and its corresponding player, Flash Player 6, the language remained essentially unchanged; there were only minor changes, such as the addition of the switch statement and the "strict equality" (===) operator, which brought it closer to being ECMA-262-compliant. Two important features of ActionScript that distinguish it from later versions are its loose type system and its reliance on prototype-based inheritance. Loose typing refers to the ability of a variable to hold any type of data. This allows for rapid script development and is particularly well-suited for small-scale scripting projects. Prototype-based inheritance is the ActionScript 1.0 mechanism for code reuse and object-oriented programming. Instead of a class keyword that defines common characteristics of a class, ActionScript 1.0 uses a special object that serves as a "prototype" for a class of objects. All common characteristics of a class are defined in the class''s prototype object and every instance of that class contains a link to that prototype object.\n2003–2006: ActionScript 2.0 The next major revision of the language, ActionScript 2.0, was introduced in September 2003 with the release of Flash MX 2004 and its corresponding player, Flash Player 7. In response to user demand for a language better equipped for larger and more complex applications, ActionScript 2.0 featured compile-time type checking and class-based syntax, such as the keywords class and extends. (While this allowed for a more flexible object-oriented programming approach, the code would still be compiled to ActionScript 1.0 bytecode, allowing it to be used on the preceding Flash Player 6 as well. In other words, the class-based inheritance syntax was a layer on top of the existing prototype-based system.) With ActionScript 2.0, developers could constrain variables to a specific type by adding a type annotation so that type mismatch errors could be found at compile-time. ActionScript 2.0 also introduced class-based inheritance syntax so that developers could create classes and interfaces, much as they would in class-based languages such as Java and C++. This version conformed partially to the ECMAScript Fourth Edition draft specification.\n2006–today: ActionScript 3.0 In June 2006, ActionScript 3.0 debuted with Adobe Flex 2.0 and its corresponding player, Flash Player 9. ActionScript 3.0 was a fundamental restructuring of the language, so much so that it uses an entirely different virtual machine. Flash Player 9 contains two virtual machines, AVM1 for code written in ActionScript 1.0 and 2.0, and AVM2 for content written in ActionScript 3.0. ActionScript 3.0 is faster than its previous versions but still not fast enough for fullscreen applications with many objects active. Actionscript 3.0 has limited support for hardware acceleration ( DirectX, OpenGL ).\nThe update to the language introduced several new features:\nCompile-time and runtime type checking—type information exists at both compile-time and runtime.\nImproved performance from a class-based inheritance system separate from the prototype-based inheritance system.\nSupport for packages, namespaces, and regular expressions.\nCompiles to an entirely new type of bytecode, incompatible with ActionScript 1.0 and 2.0 bytecode.\nRevised Flash Player API, organized into packages.\nUnified event handling system based on the DOM event handling standard.\nIntegration of ECMAScript for XML (E4X) for purposes of XML processing.\nDirect access to the Flash runtime display list for complete control of what gets displayed at runtime.\nCompletely conforming implementation of the ECMAScript fourth edition draft specification.\nFlash Lite\nFlash Lite 1.0: Flash Lite is the Flash technology specifically developed for mobile phones and consumer electronics devices. Supports Flash 4 ActionScript.\nFlash Lite 1.1: Flash 4 ActionScript support and additional device APIs added.\nFlash Lite 2.0 and 2.1: Added support for Flash 7 ActionScript 2.0 and some additional fscommand2 API.\nFlash Lite 3: Added support for Flash 8 ActionScript 2.0 and also FLV video playback.\nSyntax\nActionScript code is free form and thus may be created with whichever amount or style of whitespace that the author desires. The basic syntax is derived from ECMAScript.\nActionScript 2.0\nThe following code, which works in any compliant player, creates a text field at depth 0, at position (0, 0) on the screen (measured in pixels), that is 100 pixels wide and high. Then the text parameter is set to the "Hello, world!" string, and it is automatically displayed in the player:\ncreateTextField("greet", 0, 0, 0, 100, 100);\ngreet.text = "Hello, world";\nWhen writing external ActionScript 2.0 class files the above example could be written in a file named Greeter.as as following.\nclass com.example.Greeter extends MovieClip\n{\npublic function Greeter() {}\npublic function onLoad() :Void\n{\nvar txtHello:TextField = this.createTextField("txtHello", 0, 0, 0, 100, 100.);\ntxtHello.text = "Hello, world";\n}\n}\nActionScript 3.0\nActionScript 3.0 has a similar syntax to ActionScript 2.0 but a different set of APIs for creating objects. Compare the below to the previous ActionScript 2.0 version:\nvar greet:TextField = new TextField();\ngreet.text = "Hello World";\nthis.addChild(greet);\nMinimal ActionScript 3.0 programs may be somewhat larger and more complicated due to the increased separation of the programming language and the Flash IDE.\nPresume the following file to be Greeter.as:\npackage com.example\n{\nimport flash.text.TextField;\nimport flash.display.Sprite;\npublic class Greeter extends Sprite\n{\npublic function Greeter()\n{\nvar txtHello:TextField = new TextField();\ntxtHello.text = "Hello World";\naddChild(txtHello);\n}\n}\n}\nFinally, an example of using ActionScript when developing Flex applications, again presuming the following content to be in a file named Greeter.as:\npackage\n{\npublic class Greeter\n{\npublic static function sayHello():String\n{\nvar greet:String = "Hello, world!";\nreturn greet;\n}\n}\n}\nThis code will work with the following MXML application file:\n<?xml version="1.0" encoding="utf-8"?>\n<mx:Application xmlns:mx="http://www.adobe.com/2006/mxml" xmlns="*" layout="vertical" creationComplete="initApp()">\n<mx:Script>\n<![CDATA[\npublic function initApp():void\n{\n// Prints our "Hello, world!" message into "mainTxt".\nmainTxt.text = Greeter.sayHello();\n}\n]]>\n</mx:Script>\n<mx:Label id="title" fontSize="24" fontStyle="bold" text=''"Hello, world!" Example''/>\n<mx:TextArea id="mainTxt" width="250"/>\n</mx:Application>\nData structures\nData types\nActionScript primarily consists of "fundamental" or "simple" data types which are used to create other data types. These data types are very similar to Java data types. Since ActionScript 3 was a complete rewrite of ActionScript 2, the data types and their inheritances have changed.\nActionScript 2 top level data types\nString - A list of characters such as "Hello World"\nNumber - Any Numeric value\nBoolean - A simple binary storage that can only be "true" or "false".\nObject - Object is the data type all complex data types inherit from. It allows for the grouping of methods, functions, parameters, and other objects.\nActionScript 2 complex data types\nThere are additional "complex" data types. These are more processor and memory intensive and consist of many "simple" data types. For AS2, some of these data types are:\nMovieClip - An ActionScript creation that allows easy usage of visible objects.\nTextField - A simple dynamic or input text field. Inherits the Movieclip type.\nButton - A simple button with 4 frames (states): Up, Over, Down and Hit. Inherits the MovieClip type.\nDate - Allows access to information about a specific point in time.\nArray - Allows linear storage of data.\nXML - An XML object\nXMLNode - An XML node\nLoadVars - A Load Variables object allows for the storing and send of HTTP POST and HTTP GET variables\nSound\nNetStream\nNetConnection\nMovieClipLoader\nEventListener\nActionScript 3 top level data types (see Data type descriptions)\nBoolean - The Boolean data type has only two possible values: true and false or 1 and 0. No other values are valid.\nint - The int data type is a 32-bit integer between -2,147,483,648 and 2,147,483,647.\nNull - The Null data type contains only one value, null. This is the default value for the String data type and all classes that define complex data types, including the Object class.\nNumber - The Number data type can represent integers, unsigned integers, and floating-point numbers. The Number data type uses the 64-bit double-precision format as specified by the IEEE Standard for Binary Floating-Point Arithmetic (IEEE-754).\nString - The String data type represents a sequence of 16-bit characters. Strings are stored internally as Unicode characters, using the UTF-16 format. Previous versions of flash used the UTF-8 format.\nuint - The uint (Unsigned Integer) data type is a 32-bit unsigned integer between 0 and 4,294,967,295.\nvoid - The void data type contains only one value, undefined. In previous versions of ActionScript, undefined was the default value for instances of the Object class. In ActionScript 3.0, the default value for Object instances is null.\nActionScript 3 complex data types (see Data type descriptions)\nObject - The Object data type is defined by the Object class. The Object class serves as the base class for all class definitions in ActionScript. Objects in their basic form can be used as associative arrays that contain key-value pairs, where keys are Strings and values may be any type.\nArray - Contains a list of data. Though ActionScript 3 is a strongly-typed language, the contents of an Array may be of any type and values must be cast back to their original type after retrieval. (Support for typed Arrays has recently been added with the Vector class.)\nVector - A variant on Array supported only when publishing for Flash Player 10 or above. Vectors are typed, dense Arrays (values must be defined or null) which may be fixed-length, and are bounds-checked during retrieval. Vectors are not just more typesafe than Arrays but also perform faster.\nDictionary - Dictionaries are a variant of Object that may contain keys of any data type (whereas Object always uses strings for its keys).\nMovieClip - Animated movie clip display object; a descendant (with minor modifications) of the main Flash timeline.\nBitmap - A non-animated bitmap display object.\nShape - A non-animated vector shape object.\nByteArray - Contains an array of binary byte data.\nTextField - A dynamic, optionally interactive text field object.\nSimpleButton - A simple interactive button type supporting "up","over", and "down" states with an arbitrary hit area.\nDate - A date object containing the current system date/time.\nError - A generic error object that allows runtime error reporting when thrown as an exception.\nFunction - The core class for all Flash method definitions.\nRegExp - A regular expression object for strings.\nVideo - A video playback object supporting direct (progressive download) or streaming (RTMP) transports. As of Flash Player version 9.0.115.0, the open h.264/MP4 high-definition video format is also supported along side standard Flash video (FLV) content.\nXML - A revised XML object based on the E4C standard; nodes and attributes are accessed differently than ActionScript 2.0 object (a legacy class named XMLDocument is provided for backwards compatibility).\nXMLList - An Array-based object for various content lookups in the XML class.\nUsing data types\nThe basic syntax is:\nvar yourVariableName:YourVariableType = new YourVariableType(Param1, Param2, ..., ParamN);\nSo in order to make an empty Object:\nvar myObject:Object = new Object();\nSome types are automatically put in place:\nvar myString:String = "Hello Wikipedia!"; // This would automatically set the variable as a string.\nvar myNumber:Number = 5; // This would do the same for a number.\nvar myObject:Object = {Param1:"Hi!", Param2:76}; //This creates an object with two variables.\n// Param1 is a string with the data of "Hi!",\n// and Param2 is a number with the data of 76.\nvar myArray:Array = [5,"Hello!",{a:5, b:7}] //This is the syntax for automatically creating an Array.\n//It creates an Array with 3 variables.\n//The first (0) is a number with the value of 5,\n//the second (1) is a string with the value of "Hello!",\n//and the third (2) is an object with {a:5, b:7}.\nUnlike most object-oriented languages, ActionScript makes no distinction between primitive types and reference types. In ActionScript, all variables are reference types.[4]\nSome data types can be assigned values with literals:\nvar item1:String="ABC";\nvar item2:Boolean=true;\nvar item3:Number=12\nvar item4:Array=["a","b","c"];\nvar item5:XML = <node><child/></node>; //Note that the primitive XML is not quoted\nA reference in ActionScript is a pointer to an instance of a class. This does not create a copy but accesses the same memory space. All objects in ActionScript are accessed as references instead of being copied.\nvar item1:XML=new XML("<node><child/></node>");\nvar item2:XML=item1;\nitem2.firstChild.attributes.value=13;\n//item1 now equals item2 since item2 simply points to what item1 points to.\n//Both are now:\n//<node><child value="13"/></node>\nOnly references to an object may be removed by using the "delete" keyword. Removal of actual objects and data is done by the Flash Player garbage collector which checks for any existing references in the Flash memory space. If none are found (no other reference is made to the orphaned object), it is removed from memory. For this reason, memory management in ActionScript requires careful application development planning.\nvar item1:XML=new XML("<node><child/></node>");\ndelete item1;\n//If no other reference to item1 is present anywhere else in the application,\n//it will be removed on the garbage collector''s next pass\nReferences\n^ RFC 4329\n^ http://labs.adobe.com/technologies/flashplayer10/\n^ Note that the name "ActionScript 1.0" is a retronym, coined after the release of ActionScript 2.0.\n^ http://livedocs.adobe.com/flex/3/html/03_Language_and_Syntax_19.html\nSee also\nECMAScript — The standardized scripting language upon which ActionScript is based.\nAdobe Flash — The program in which ActionScript debuted.\nAdobe Flash Player — The official and most widely used SWF player.\nAdobe Flash Lite — A miniature version of the Flash Player for mobile devices.\nAdobe AIR - Runtime for ActionScript/Flex\nAdobe Flex - SDK and IDE which uses ActionScript\nSWF File Format\nTamarin (JIT)\nMacromedia\nAdobe Systems\nGnash, a free Flash viewer\nSwfdec\nAdobe Flex Builder - IDE by Adobe to author ActionScript\nWikibooks has a book on the topic of\nActionScript Programming\nAt Wikiversity, you can learn about: ActionScript:Introduction\nAdobe documentation and references\nActionScript Technology Center\nActionScript 2.0 Language Reference\nActionScript 3.0 Language & Component Reference\nFlex 3 LiveDocs: Programming ActionScript 3.0\nTutorials / Resource Sites\nVideo Tutorials from Lee Brimelow\nAdobe - Flash Developer Center\nFlashkit.com - Community Resource / Tutorials\nKirupa.com - Community Resource / Tutorials\nActionscript.org - Community Resource / Tutorials\nTools and scripts\nFlashDevelop - Popular open-source ActionScript IDE\nAdobe\nAdobe Flash Professional (ie. the Flash IDE)\nAdobe Flex SDK (ie. the free SDK)\nhaxe.org - The HaXe compiler, the AS 3 successor to MTASC\nMotion Twin ActionScript Compiler - MTASC is an Open-source ActionScript 2 compiler\nActionScript Cheatsheet - Free, printable quick reference cards for ActionScript 1.0, ActionScript 2.0, ActionScript 3.0, Papervision 3D and Adobe AIR.\nv • d • e\nAdobe Flash\nFlash-specific file formats\n.swf (Shockwave Flash) · .as (ActionScript) · .flv (Flash Video) · .amf (Action Message Format)\nOther versions\nAdobe Flash Lite · FutureSplash Animator (Flash 1.0)\nRelated topics\nActionScript · Adobe Flash Player · Local Shared Object · Flash animation\n· .spl (historical Flash 1.0 file format) · Criticism\nv • d • e\nECMAScript (comparison)\nDialects\nActionScript · Caja · JavaScript / LiveScript · JScript · JavaScript OSA · JScript .NET · QtScript\nECMAScript engines\nInScript · JavaScriptCore · JScript · KJS · futhark · linear_b · Narcissus · QtScript · Rhino · SpiderMonkey · SunSpider · Tamarin · TraceMonkey · V8 · SquirrelFish\nOther\nBrendan Eich · Ecma International\n"http://en.wikipedia.org/wiki/ActionScript"\nCategories: Recently revised | Adobe Flash | Domain-specific programming languages | Scripting languages | JavaScript programming language family | Prototype-based programming languages | Curly bracket programming languagesHidden categories: All articles with unsourced statements | Articles with unsourced statements since April 2008','\n',char(10)));
INSERT INTO pages VALUES('AWK','http://web.archive.org/web/20090107190613/http://en.wikipedia.org:80/wiki/Awk','en','2009-01-07 00:00:00',replace('( Awk)\012This article is about the programming language.\012For other uses, see AWK (disambiguation).\012AWK\012Paradigm\012scripting language, procedural, event-driven\012Appeared in\0121977, last revised 1985, current POSIX edition is IEEE Std 1003.1-2004\012Designed by\012Alfred Aho, Peter Weinberger, and Brian Kernighan\012Typing discipline\012none; can handle strings, integers and floating point numbers; regular expressions\012Major implementations\012awk, GNU Awk, mawk, nawk, MKS AWK, Thompson AWK (compiler), Awka (compiler)\012Dialects\012old awk oawk 1977, new awk nawk 1985, GNU Awk\012Influenced by\012C, SNOBOL4, Bourne shell\012Influenced\012Perl, Korn Shell (ksh93, dtksh, tksh), Lua\012OS\012Cross-platform\012Website\012cm.bell-labs.com/cm/cs/awkbook/index.html\012AWK is a general purpose programming language that is designed for processing text-based data, either in files or data streams, and was created at Bell Labs in the 1970s[1]. The name AWK is derived from the family names of its authors — Alfred Aho, Peter Weinberger, and Brian Kernighan; however, it is not commonly pronounced as a string of separate letters but rather to sound the same as the name of the bird, auk (which acts as an emblem of the language such as on The AWK Programming Language book cover). awk, when written in all lowercase letters, refers to the Unix or Plan 9 program that runs other programs written in the AWK programming language.\012"AWK is a language for processing files of text. A file is treated as a sequence of records, and by default each line is a record. Each line is broken up into a sequence of fields, so we can think of the first word in a line as the first field, the second word as the second field, and so on. An AWK program is of a sequence of pattern-action statements. AWK reads the input a line at a time. A line is scanned for each pattern in the program, and for each pattern that matches, the associated action is executed." - Alfred V. Aho[2]\012AWK is an example of a programming language that extensively uses the string datatype, associative arrays (that is, arrays indexed by key strings), and regular expressions. The power, terseness, and limitations of AWK programs and sed scripts inspired Larry Wall to write Perl. Because of their dense notation, all these languages are often used for writing one-liner programs.\012AWK is one of the early tools to appear in Version 7 Unix and gained popularity as a way to add computational features to a Unix pipeline. A version of the AWK language is a standard feature of nearly every modern Unix-like operating system available today. AWK is mentioned in the Single UNIX Specification as one of the mandatory utilities of a Unix operating system. Besides the Bourne shell, AWK is the only other scripting language available in a standard Unix environment[3]. Implementations of AWK exist as installed software for almost all other operating systems.\0121 Structure of AWK programs\0122 AWK commands\0122.1 The print command\0122.2 Variables and Syntax\0122.3 User-defined functions\0123 Sample applications\0123.1 Hello World\0123.2 Print lines longer than 80 characters\0123.3 Print a count of words\0123.4 Sum last word\0123.5 Match a range of input lines\0123.6 Calculate word frequencies\0123.7 Match pattern from command line\0124 Self-contained AWK scripts\0125 AWK versions and implementations\0126 Books\0127 References\0128 See also\0129\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012Structure of AWK programs\012An AWK program is a series of pattern action pairs, written as:\012pattern { action }\012where pattern is typically an expression and action is a series of commands. Each line of input is tested against all the patterns in turn and the action is executed for each expression that is true. Either the pattern or the action may be omitted. The pattern defaults to matching every line of input. The default action is to print the line of input.\012In addition to a simple AWK expression, the pattern can be BEGIN or END causing the action to be executed before or after all lines of input have been read, or pattern1, pattern2 which matches the range of lines of input starting with a line that matches pattern1 up to and including the line that matches pattern2 before again trying to match against pattern1 on future lines.\012In addition to normal arithmetic and logical operators, AWK expressions include the tilde operator, ~, which matches a regular expression against a string. As handy syntactic sugar, /regexp/ without using the tilde operator matches against the current line of input.\012AWK commands\012AWK commands are the statement that is substituted for action in the examples above. AWK commands can include function calls, variable assignments, calculations, or any combination thereof. AWK contains built-in support for many functions; many more are provided by the various flavors of AWK. Also, some flavors support the inclusion of dynamically linked libraries, which can also provide more functions.\012For brevity, the enclosing curly braces ( { } ) will be omitted from these examples.\012The print command\012The print command is used to output text. The output text is always terminated with a predefined string called the output record separator (ORS) whose default value is a newline. The simplest form of this command is:\012print\012This displays the contents of the current line. In AWK, lines are broken down into fields, and these can be displayed separately:\012print $1\012Displays the first field of the current line\012print $1, $3\012Displays the first and third fields of the current line, separated by a predefined string called the output field separator (OFS) whose default value is a single space character\012Although these fields ($X) may bear resemblance to variables (the $ symbol indicates variables in perl), they actually refer to the fields of the current line. A special case, $0, refers to the entire line. In fact, the commands "print" and "print $0" are identical in functionality.\012The print command can also display the results of calculations and/or function calls:\012print 3+2\012print foobar(3)\012print foobar(variable)\012print sin(3-2)\012Output may be sent to a file:\012print "expression" > "file name"\012or through a pipe:\012print "expression" | "command"\012example\012awk ''{ print }'' /etc/passwd\012Variables and Syntax\012Variable names can use any of the characters [A-Za-z0-9_], with the exception of language keywords. The operators + - * / represent addition, subtraction, multiplication, and division, respectively. For string concatenation, simply place two variables (or string constants) next to each other. It is optional to use a space in between if string constants are involved. But you can''t place two variable names adjacent to each other without having a space in between. String constants are delimited by double quotes. Statements need not end with semicolons. Finally, comments can be added to programs by using # as the first character on a line.\012User-defined functions\012In a format similar to C, function definitions consist of the keyword function, the function name, argument names and the function body. Here is an example of a function.\012function add_three (number, temp) {\012temp = number + 3\012return temp\012}\012This statement can be invoked as follows:\012print add_three(36)\012# Outputs 39\012Functions can have variables that are in the local scope. The names of these are added to the end of the argument list, though values for these should be omitted when calling the function. It is convention to add some whitespace in the argument list before the local variables, in order to indicate where the parameters end and the local variables begin.\012Sample applications\012Hello World\012Here is the ubiquitous "Hello world program" program written in AWK:\012BEGIN { print "Hello, world!" }\012Note that you do not need an explicit exit statement, since the only pattern is BEGIN, no command-line arguments are processed.\012Print lines longer than 80 characters\012Print all lines longer than 80 characters. Note that the default action is to print the current line.\012length($0) > 80\012Print a count of words\012Count words in the input, and print lines, words, and characters (like wc)\012{\012w += NF\012c += length + 1\012}\012END { print NR, w, c }\012As there is no pattern for the first line of the program, every line of input matches by default so the increment actions are executed for every line. Note that w += NF is shorthand for w = w + NF.\012Sum last word\012{ s += $NF }\012END { print s + 0 }\012s is incremented by the numeric value of $NF which is the last word on the line as defined by AWK''s field separator, by default white-space. NF is the number of fields in the current line, e.g. 4. Since $4 is the value of the fourth field, $NF is the value of the last field in the line regardless of how many fields this line has, or whether it has more or fewer fields than surrounding lines. $ is actually a unary operator with the highest operator precedence. (If the line has no fields then NF is 0, $0 is the whole line, which in this case is empty apart from possible white-space, and so has the numeric value 0.)\012At the end of the input the END pattern matches so s is printed. However, since there may have been no lines of input at all, in which case no value has ever been assigned to s, it will by default be an empty string. Adding zero to a variable is an AWK idiom for coercing it from a string to a numeric value. (Concatenating an empty string is to coerce from a number to a string, e.g. s "". Note, there''s no operator to concatenate strings, they''re just placed adjacently.) With the coercion the program prints 0 on an empty input, without it an empty line is printed.\012Match a range of input lines\012$ yes Wikipedia | awk ''NR % 4 == 1, NR % 4 == 3 { printf "%6d\012%s\n", NR, $0 }'' | sed 7q\0121\012Wikipedia\0122\012Wikipedia\0123\012Wikipedia\0125\012Wikipedia\0126\012Wikipedia\0127\012Wikipedia\0129\012Wikipedia\012$\012The yes command repeatedly prints its argument (by default the letter "y") on a line. In this case, we tell the command to print the word "Wikipedia". The action statement prints each line numbered. The printf function emulates the standard C printf, and works similarly to the print command described above. The pattern to match, however, works as follows: NR is the number of records, typically lines of input, AWK has so far read, i.e. the current line number, starting at 1 for the first line of input. % is the modulo operator. NR % 4 == 1 is true for the first, fifth, ninth, etc., lines of input. Likewise, NR % 4 == 3 is true for the third, seventh, eleventh, etc., lines of input. The range pattern is false until the first part matches, on line 1, and then remains true up to and including when the second part matches, on line 3. It then stays false until the first part matches again on line 5. The sed command is used to print the first 7 lines, to prevent yes running forever. It is equivalent to head -7 if the head command is available.\012The first part of a range pattern being constantly true, e.g. 1, can be used to start the range at the beginning of input. Similarly, if the second part is constantly false, e.g. 0, the range continues until the end of input:\012/^--cut here--$/, 0\012prints lines of input from the first line matching the regular expression ^--cut here--$, that is, a line containing only the phrase "--cut here--", to the end.\012Calculate word frequencies\012Word frequency, uses associative arrays:\012BEGIN { FS="[^a-zA-Z]+" }\012{ for (i=1; i<=NF; i++)\012words[tolower($i)]++\012}\012END { for (i in words)\012print i, words[i]\012}\012The BEGIN block sets the field separator to any sequence of non-alphabetic characters. Note that separators can be regular expressions. After that, we get to a bare action, which performs the action on every input line. In this case, for every field on the line, we add one to the number of times that word, first converted to lowercase, appears. Finally, in the END block, we print the words with their frequencies. The line\012for (i in words)\012creates a loop that goes through the array words, setting i to each subscript of the array. This is different from most languages, where such a loop goes through each value in the array. This means that you print the word with each count in a simple way. tolower was an addition to the One True awk (see below) made after the book was published.\012Match pattern from command line\012This program can be represented in several ways. The first one uses the Bourne shell to make a shell script that does everything. It is the shortest of these methods:\012$ cat grepinawk\012pattern=$1\012shift\012awk ''/''$pattern''/ { print FILENAME ":" $0 }'' $*\012$\012The $pattern in the awk command is not protected by quotes. A pattern by itself in the usual way checks to see if the whole line ($0) matches. FILENAME contains the current filename. awk has no explicit concatenation operator; two adjacent strings concatenate them. $0 expands to the original unchanged input line.\012There are alternate ways of writing this. This shell script accesses the environment directly from within awk:\012$ cat grepinawk\012pattern=$1\012shift\012awk ''$0 ~ ENVIRON["pattern"] { print FILENAME ":" $0 }'' $*\012$\012This is a shell script that uses ENVIRON, an array introduced in a newer version of the One True awk after the book was published. The subscript of ENVIRON is the name of an environment variable; its result is the variable''s value. This is like the getenv function in various standard libraries and POSIX. The shell script makes an environment variable pattern containing the first argument, then drops that argument and has awk look for the pattern in each file.\012~ checks to see if its left operand matches its right operand; !~ is its inverse. Note that a regular expression is just a string and can be stored in variables.\012The next way uses command-line variable assignment, in which an argument to awk can be seen as an assignment to a variable:\012$ cat grepinawk\012pattern=$1\012shift\012awk ''$0 ~ pattern { print FILENAME ":" $0 }'' "pattern=$pattern" $*\012$\012Finally, this is written in pure awk, without help from a shell or without the need to know too much about the implementation of the awk script (as the variable assignment on command line one does), but is a bit lengthy:\012BEGIN {\012pattern = ARGV[1]\012for (i = 1; i < ARGC; i++) # remove first argument\012ARGV[i] = ARGV[i + 1]\012ARGC--\012if (ARGC == 1) { # the pattern was the only thing, so force read from standard input (used by book)\012ARGC = 2\012ARGV[1] = "-"\012}\012}\012$0 ~ pattern { print FILENAME ":" $0 }\012The BEGIN is necessary not only to extract the first argument, but also to prevent it from being interpreted as a filename after the BEGIN block ends. ARGC, the number of arguments, is always guaranteed to be ≥1, as ARGV[0] is the name of the command that executed the script, most often the string "awk". Also note that ARGV[ARGC] is the empty string, "". # initiates a comment that expands to the end of the line.\012Note the if block. awk only checks to see if it should read from standard input before it runs the command. This means that\012awk ''prog''\012only works because the fact that there are no filenames is only checked before prog is run! If you explicitly set ARGC to 1 so that there are no arguments, awk will simply quit because it feels there are no more input files. Therefore, you need to explicitly say to read from standard input with the special filename -.\012Self-contained AWK scripts\012As with many other programming languages, self-contained AWK script can be constructed using the so-called "shebang" syntax.\012For example, a UNIX command called hello.awk that prints the string "Hello, world!" may be built by creating a file named hello.awk containing the following lines:\012#!/usr/bin/awk -f\012BEGIN { print "Hello, world!" }\012The -f tells awk that the argument that follows is the file to read the awk program from, which is placed there by the shell when running.\012AWK versions and implementations\012AWK was originally written in 1977, and distributed with Version 7 Unix.\012In 1985 its authors started expanding the language, most significantly by adding user-defined functions. The language is described in the book The AWK Programming Language, published 1988, and its implementation was made available in releases of UNIX System V. To avoid confusion with the incompatible older version, this version was sometimes known as "new awk" or nawk. This implementation was released under a free software license in 1996, and is still maintained by Brian Kernighan. (see external links below)\012BWK awk refers to the version by Brian W. Kernighan. It has been dubbed the "One True AWK" because of the use of the term in association with the book[4] that originally described the language, and the fact that Kernighan was one of the original authors of awk. FreeBSD refers to this version as one-true-awk[5]. This version also has features not in the book, such as tolower and ENVIRON that are explained above; see the FIXES file in the source archive for details.\012gawk (GNU awk) is another free software implementation and the only implementation that made serious attempts at implementing i18n. It also allows the user to extend the functionality of the program via user-written shared libraries. It was written before the original implementation became freely available, and is still widely used. Many Linux distributions come with a recent version of gawk and gawk is widely recognized as the de-facto standard implementation in the Linux world; gawk version 3.0 was included as awk in FreeBSD prior to version 5.0. Subsequent versions of FreeBSD use BWK awk in order to avoid[6] the GPL, a more restrictive (in the sense that GPL licensed code cannot be modified to become proprietary software) license than the BSD license. [7]\012xgawk is a SourceForge project[8] based on gawk. It extends gawk with dynamically loadable libraries.\012mawk is a very fast AWK implementation by Mike Brennan based on a byte code interpreter.\012Old versions of Unix, such as UNIX/32V, included awkcc, which converted AWK to C. Kernighan wrote a program to turn awk into C++; its state is not known. [9]\012awka (whose front end is written on top of the mawk program) is another translator of awk scripts into C code. When compiled, statically including the author''s libawka.a, the resulting executables are considerably sped up and according to the author''s tests compare very well with other versions of awk, perl or tcl. Small scripts will turn into programs of 160-170 kB. http://awka.sourceforge.net\012Downloads and further information about these versions are available from the sites listed below.\012Thompson AWK or TAWK is an AWK compiler for Solaris (operating system), DOS, OS/2, and Windows, previously sold by Thompson Automation Software (which has ceased its activities).\012Jawk is a SourceForge project[10] to implement AWK in Java. Extensions to the language are added to provide access to Java features within AWK scripts (i.e., Java threads, sockets, Collections, etc).\012BusyBox includes a sparsely documented AWK implementation that appears to be complete, written by Dmitry Zakharov. This is a very small implementation suitable for embedded systems.\012Books\012Alfred V. Aho, Brian W. Kernighan, and Peter J. Weinberger (1988). The AWK Programming Language. Addison-Wesley. ISBN 0-201-07981-X. http://cm.bell-labs.com/cm/cs/awkbook/.\012The book''s webpage includes downloads of the current implementation of Awk and links to others.\012Arnold Robbins. Effective awk Programming (Edition 3 ed.). http://www.oreilly.com/catalog/awkprog3/index.html.\012Arnold Robbins maintained the GNU Awk implementation of AWK for more than 10 years. The free GNU Awk manual was also published by O''Reilly in May 2001. Free download of this manual is possible through the following book references.\012Arnold Robbins. GAWK: Effective AWK Programming: A User''s Guide for GNU Awk (Edition 3 ed.). http://www.gnu.org/software/gawk/manual/html_node/index.html.\012Dale Dougherty, Arnold Robbins (March 1997). sed & awk, Second Edition (Second Edition ed.). O''Reilly Media. ISBN 1-56592-225-5. http://www.oreilly.com/catalog/sed2/.\012References\012^ The A-Z of Programming Languages: AWK\012^ http://www.computerworld.com.au/index.php/id;1726534212;pp;2 The A-Z of Programming Languages: AWK\012^ The Single UNIX Specification, Version 3, Utilities Interface Table\012^ The AWK Programming Language, ISBN 0-201-07981-X.\012^ FreeBSD''s work log for importing BWK awk into FreeBSD''s core, dated 2005-05-16, downloaded 2006-09-20\012^ FreeBSD''s view of GPL Advantages and Disadvantages\012^ FreeBSD 5.0 release notes with notice of BWK awk in the base distribution\012^ xgawk at SourceForge\012^ An AWK to C++ Translator\012^ Jawk at SourceForge\012See also\012sed\012List of Unix programs\012AWK -- Become an expert in 60 minutes\012Awk by example - developerWorks. Retrieved on 2008-07-15\012awk: pattern scanning and processing language – Commands & Utilities Reference, The Single UNIX® Specification, Issue 6 from The Open Group\012The AWK Programming Language home page.\012The new home of the One True AWK, maintained by Brian Kernighan, now at Princeton University after technical difficulties with the above link\012comp.lang.awk is a USENET newsgroup dedicated to AWK.\012GAWK (GNU awk) webpage\012mawk download site\012DJGPP port of Gawk 3.11b as a downloadable 768KB zipfile\012xgawk download site\012Awka Open Source, AWK to C Conversion Tool\012TAWK Compiler\012Jawk Open Source, an implementation of AWK in Java with extensions\012gnulamp awk tutorial\012Computerworld Interview with Alfred V. Aho on AWK\012aaa - the Amazing Awk Assembler by Henry Spencer - A legendary AWK program.\012The GAWK Man Page\012v • d • e\012Unix command line programs and builtins (more)\012File system\012cat · cd · chmod · chown · chgrp · cksum · cmp · cp · du · df · file · fsck · fuser · ln · ls · lsattr · lsof · mkdir · mount · mv · pwd · rm · rmdir · split · touch\012Processes\012at · chroot · cron · exit · kill · killall · nice · pgrep · pidof · pkill · ps · pstree · sleep · time · top · wait · watch\012User environment\012env · finger · id · logname · mesg · passwd · su · sudo · uname · uptime · w · wall · who · whoami · write\012Text processing\012awk · comm · cut · ed · ex · fmt · head · iconv · join · less · more · paste · sed · sort · tac · tail · tr · uniq · vi · wc · xargs\012Shell programming\012alias · basename · dirname · echo · expr · false · printf · test · true · unset\012Networking\012inetd · netstat · ping · rlogin · netcat · traceroute\012Searching\012find · grep · strings\012Miscellaneous\012banner · bc · cal · clear · date · dd · lp · man · size · tee · tput · yes · umask\012"http://en.wikipedia.org/wiki/AWK"\012Categories: Curly bracket programming languages | Domain-specific programming languages | Text-oriented programming languages | Scripting languages | Unix software | Free compilers and interpreters | Standard Unix programs | Cross-platform software','\012',char(10)));
INSERT INTO pages VALUES('ColdFusion','http://web.archive.org/web/20090111235212/http://en.wikipedia.org:80/wiki/Coldfusion','en','2009-01-11 00:00:00',replace('( Coldfusion)\nThis article needs additional citations for verification. Please help improve this article by adding reliable references. Unsourced material may be challenged and removed. (February 2008)\nThis article may require cleanup to meet Wikipedia''s quality standards.\nPlease improve this article if you can. (May 2008)\nThis article is about the computer programming language.\nFor other uses, see Cold Fusion (disambiguation).\nAdobe ColdFusion 8\nDeveloped by\nAdobe Systems Incorporated\nInitial release\n1995\nLatest release\n8.0.1 / 04 April 2008; 282 days ago\nOS\nWindows, Linux, UNIX, Macintosh\nAvailable in\nEnglish\nType\nApplication server\nLicense\nProprietary\nWebsite\nColdFusion Homepage\nColdFusion is an application server and software language used for Internet application development[1] such as for dynamic web sites. In this regard, ColdFusion is a similar product to Microsoft ASP.NET, JavaServer Pages or PHP. ColdFusion was the first amongst these technologies to provide the developer the capability of creating dynamic websites that were attached to a backend database.\n1 Overview\n1.1 Main Features\n2 History\n2.1 Early versions\n2.2 Releases\n2.3 ColdFusion MX\n2.4 ColdFusion MX 7\n2.5 Adobe ColdFusion 8\n2.6 Adobe ColdFusion 9\n3 Features\n3.1 Rich forms\n3.2 PDF and FlashPaper generation\n3.3 ColdFusion Components (Objects)\n3.3.1 Remoting\n3.4 Custom tags\n3.5 Alternative server environments\n4 Interactions with other programming languages\n4.1 ColdFusion and Java\n4.2 ColdFusion and .NET\n5 Acronyms\n6 Technical commentary\n7 Notes and references\n8 See also\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nOverview\nThe primary distinguishing feature of ColdFusion is its associated scripting language, ColdFusion Markup Language (CFML), which compares to JSP, ASP.NET, or PHP and resembles HTML in syntax. "ColdFusion" is often used synonymously with "CFML", but there are additional CFML application servers besides ColdFusion, and ColdFusion supports programming languages other than CFML, such as server-side Actionscript and embedded scripts that can be written in a JavaScript-like language known as CFScript.\nOriginally a product of Allaire, and released in July 1995, ColdFusion was originally developed by brothers JJ and Jeremy Allaire. In 2001 Allaire was acquired by Macromedia, which was in turn acquired by Adobe Systems in 2005.\nColdFusion is most often used for data-driven web sites or intranets, but can also be used to generate remote services such as SOAP web services or Flash remoting. It is especially well-suited as the server-side technology to the client-side Flex.\nColdFusion can also handle asynchronous events such as SMS and instant messaging via its gateway interface, available in ColdFusion MX 7 Enterprise Edition.\nMain Features\nColdFusion provides a number of additional features out of the box. Among them:\nSimplified database access (the native language syntax for querying databases, creating parameterized statements and working with the result set via the native "query" data type is generally considered to be much simpler than working with result sets in other languages such as Java in spite of the fact that JDBC is the underlying technology - use of ODBC databases is possible via a bridge driver)\nClient and server cache management\nClient-side code generation, especially for form widgets and validation\nConversion from HTML to PDF and FlashPaper\nData retrieval from common enterprise systems such as Active Directory, LDAP, SMTP, POP, HTTP, FTP, Microsoft Exchange Server and common data formats such as RSS and Atom\nFile indexing and searching service based on Verity K2\nGUI administration\nServer, application, client, session, and request scopes\nXML parsing, querying (XPath), validation and transformation (XSLT)\nServer clustering\nTask scheduling\nGraphing and reporting\nSimplified file manipulation including raster graphics (and CAPTCHA) and zip archives (introduction of video manipulation is planned in a future release)\nSimplified web service implementation (with automated WSDL generation / transparent SOAP handling for both creating and consuming services - as an example, ASP.NET[1] has no native equivalent for <CFINVOKE WEBSERVICE="http://host/tempconf.cfc?wsdl" METHOD="Celsius2Fahrenheit" TEMP="#tempc#" RETURNVARIABLE="tempf>[2])\nOther implementations of CFML offer similar or enhanced functionality, such as running in a .NET environment or image manipulation.\nHistory\nEarly versions\nThe first version of ColdFusion (then called Cold Fusion) was released on July 10, 1995. This first version was written almost entirely by one person, JJ Allaire. Primitive by modern standards, early versions of ColdFusion did little more than database access.[2]\nAll versions of ColdFusion prior to 6.0 were written using Microsoft Visual C++. This meant that ColdFusion was largely limited to running on Microsoft Windows, although Allaire did successfully port ColdFusion to Sun Solaris starting with version 3.1.\nReleases\n1995 : Allaire Cold Fusion version 1.0\n1996 : Allaire Cold Fusion version 1.5\n1996 : Allaire Cold Fusion version 2.0\n1997-Jun : Allaire Cold Fusion version 3.0\n1998-Jan : Allaire Cold Fusion version 3.1\n1998-Nov : Allaire ColdFusion version 4.0 (space eliminated between Cold and Fusion to make it ColdFusion)\n1999-Nov : Allaire ColdFusion version 4.5\n2001-Jun : Macromedia ColdFusion version 5.0\n2002-May : Macromedia ColdFusion MX version 6.0 (build 6,0,0,48097), Updater 1 (build 6,0,0,52311), Updater 2 (build 6,0,0,55693), Updater 3 (build 6,0,0,58500)\n2003-Oct : Macromedia ColdFusion MX version 6.1 (build 6,1,0,63958), Updater 1 (build 6,1,0,83762)\n2005 : Macromedia ColdFusion MX 7 (build 7,0,0,91690), 7.0.1 (build 7,0,1,116466), 7.0.2 (build 7,0,2,142559)\n2007-Jul-30 : Adobe ColdFusion 8 (build 8,0,0,176276)\n2008-Apr-04 : Adobe ColdFusion 8.0.1 (build 8,0,1,195765)\nColdFusion MX\nPrior to 2000, Allaire began a project codenamed "Neo", that would rewrite the basis of ColdFusion using Java, which would allow for greater portability among different platforms.\nOn January 16, 2001, Allaire announced that it would be merging with Macromedia. Shortly after the merger, Macromedia continued with the incremental release of ColdFusion 5.00 and in June 2002, Macromedia released Macromedia ColdFusion MX (6.0), extending the naming convention of Macromedia''s line of products. ColdFusion MX was completely rebuilt from the ground up and was based on the Java 2 Enterprise Edition (J2EE) platform. ColdFusion MX was also designed to integrate well with Macromedia Flash using Flash Remoting.\nStarting from the MX (6.0) release, ColdFusion is compiled to bytecode, like JSP and ASP.NET. The compiled .class files are readily accessible, and are cached until their source changes, like JSPs.\nWith the release of ColdFusion MX, the CFML language was also extended to support basic OOP.\nColdFusion MX 7\nWith the release of ColdFusion 7.0, the naming convention was amended, rendering the product name "Macromedia ColdFusion MX 7". CFMX 7 added Flash-based, and XForms-based, web forms and a report builder that output in Adobe PDF as well as FlashPaper, RTF and Excel. The Adobe PDF output is also available as a wrapper to any HTML page, converting that page to a quality printable document. The enterprise edition also added Gateways. These provide interaction with non-HTTP request services such as IM Services, SMS, Directory Watchers, and an asynchronous execution. XML support was boosted in this version to include native schema checking.\nColdFusion MX 7.0.2, codenamed "Mystic" includes advanced features for working with Adobe Flex 2.\nAdobe ColdFusion 8\nOn July 30, 2007, Adobe Systems released ColdFusion 8, dropping "MX" from its name. During beta testing the codename used was "Scorpio". More than 14,000 developers worldwide were active in the beta process - many more testers than the 5,000 Adobe Systems originally expected. The ColdFusion development team consisted of developers based in Newton/Boston, Massachusetts and Bangalore, India.\nSome of the new features are the CFPDFFORM tag, which enables integration with Adobe Acrobat forms, some image manipulation functions, Microsoft .NET integration, and the CFPRESENTATION tag, which allows the creation of dynamic presentations using Adobe Acrobat Connect, the Web-based collaboration solution formerly known as Macromedia Breeze. In addition, the ColdFusion Administrator for the Enterprise version ships with built-in server monitoring. ColdFusion 8 is available on several operating systems including Linux, Mac OS X and Windows Server 2003.\nOther additions to ColdFusion 8 are built-in AJAX widgets, file archive manipulation (CFZIP), Microsoft Exchange server integration (CFEXCHANGE), image manipulation including automatic captcha generation (CFIMAGE), multi-threading, per-application settings, Atom and RSS feeds, reporting enhancements, stronger encryption libraries, array and structure improvements, improved database interaction, extensive performance improvements, PDF manipulation and merging capabilities (CFPDF), interactive debugging, embedded database support with Apache Derby, and a more ECMAScript compliant CFSCRIPT.\nFor development of ColdFusion applications, several tools are available: Adobe Dreamweaver CS3, Macromedia HomeSite, CFEclipse, Eclipse and others. "Tag updates" are available for these applications to update their support for the new ColdFusion 8 features.\nAdobe ColdFusion 9\nAdobe is currently working on ColdFusion 9 (Codename: Centaur). There is no release date set, but the list of potential new features include [3]:\nAbility to code User Defined Functions (UDFs) and ColdFusion Components (CFC''s) entirely in CFScript.\nAn explicit "local" scope that does not require local variables to be declared at the top of the function.\nImplicit getters/setters for CFC.\nImplicit constructors via method called "init" or method with same name as CFC.\nNew CFFinally tag for Exception handling syntax and CFContinue tag for Control flow.\nObject-relational mapping (ORM) Database integration through Hibernate (Java).\nServer.cfc file with onServerStart and onServerEnd methods.\nTighter integration with Adobe AIR.\nFeatures\nIt has been suggested that this article or section be merged into ColdFusion Markup Language. (Discuss)\nRich forms\nColdFusion Server includes a subset of its Macromedia Flex 1.5 technology. Its stated purpose is to allow for rich forms in HTML pages using CFML to generate Flash movies. These Flash forms can be used to implement rich internet applications, but with limited efficiency due to the ActionScript restrictions in place on Flash forms by Macromedia.\nFlash forms also provide additional widgets for data input, such as date pickers and data grids.\nIn previous versions of ColdFusion, some form validation and additional widgets were available using a combination of Java applets and JavaScript. This option persists for those who do not wish to use Flash, however not all features are supported.\nAn example:\n<cfform format="flash" method="post" width="400" height="400">\n<cfinput type="text" name="username" label="Username" required="yes" >\n<cfinput type="password" name="password" label="Password" required="yes" >\n<cfinput type="submit" name="submit" value="Sign In" >\n</cfform>\nColdFusion also includes some XForms capability, and the ability to "skin" forms using XSLT.\nPDF and FlashPaper generation\nColdFusion can generate PDF or FlashPaper documents using standard HTML (i.e. no additional coding is needed to generate documents for print). CFML authors simply place HTML and CSS within a pair of cfdocument tags and specify the desired format (FlashPaper or PDF). The generated document can then either be saved to disk or sent to the client''s browser. ColdFusion 8 has now introduced the cfpdf tag which allows for unprecedented control over PDF documents including PDF forms, and merging of PDFs.\nColdFusion Components (Objects)\nColdFusion was originally not an object-oriented programming language, and even today lacks some OO features. ColdFusion falls into the category of OO languages that do not support multiple inheritance (along with Java, Smalltalk etc.)[4]. With the MX release (6+), ColdFusion introduced the component language construct which resembles classes in OO languages. Each component may contain any number of properties and methods. One component may also extend another (Inheritance). Components only support single inheritance. With the release of ColdFusion 8, Java-style interfaces are supported. ColdFusion components use the file extension cfc to differentiate them from ColdFusion templates (.cfm).\nRemoting\nComponent methods may be made available as web services with no additional coding and configuration. All that is required is for a method''s access to be declared ''remote''. ColdFusion automatically generates a WSDL at the URL for the component thusly: http://path/to/components/Component.cfc?wsdl. Aside from SOAP, the services are offered in Flash Remoting binary format.\nMethods which are declared remote may also be invoked via an HTTP GET or POST request. Consider the GET request as shown.\nhttp://path/to/components/Component.cfc?method=search&query=your+query&mode=strict\nThis will invoke the component''s search function, passing "your query" and "strict" as arguments.\nThis type of invocation is well-suited for AJAX-enabled applications. ColdFusion 8 introduced the ability to serialize ColdFusion data structures to JSON for consumption on the client.\nThe ColdFusion server will automatically generate documentation for a component if you navigate to its URL and insert the appropriate code within the component''s declarations. This is an application of component introspection, available to developers of ColdFusion components. Access to a component''s documentation requires a password. A developer can view the documentation for all components known to the ColdFusion server by navigating to the ColdFusion URL. This interface resembles the Javadoc HTML documentation for Java classes.\nCustom tags\nColdFusion provides several ways to implement custom tags, i.e. those not included in the core ColdFusion language. The traditional and most common way is using CFML. A standard CFML page can be interpreted as a tag, with the tag name corresponding to the file name prefixed with "cf_". For example, the file IMAP.cfm can be used as the tag "cf_imap". Attributes used within the tag are available in the ATTRIBUTES scope of the tag implementation page. CFML pages are accessible in the same directory as the calling page, via a special directory in the ColdFusion web application, or via a CFIMPORT tag in the calling page. The latter method does not necessarily require the "cf_" prefix for the tag name.\nA second way is the development of CFX tags using Java or C++. CFX tags are prefixed with "cfx_", for example "cfx_imap". Tags are added to the ColdFusion runtime environment using the ColdFusion administrator, where JAR or DLL files are registered as custom tags.\nFinally, ColdFusion supports JSP tag libraries from the JSP 2.0 language specification. JSP tags are included in CFML pages using the CFIMPORT tag.\nAlternative server environments\nColdFusion originated as proprietary technology based on Web technology industry standards. However, it is becoming a less closed technology through the availability of competing products. Products include Railo, BlueDragon, IgniteFusion, SmithProject and Coral Web Builder.\nThe argument can be made that ColdFusion is even less platform-bound than raw J2EE or .NET, simply because ColdFusion will run on top of a .NET app server (New Atlanta), or on top of any servlet container or J2EE application server (JRun, WebSphere, JBoss, Geronimo, Tomcat, Resin Server, Jetty (web server), etc.). In theory, a ColdFusion application could be moved unchanged from a J2EE application server to a .NET application server.\nCurrently, alternative server platforms generally support ColdFusion MX 6.1 functionality, with minor changes or feature enhancements.\nInteractions with other programming languages\nColdFusion and Java\nThe standard ColdFusion installation allows the deployment of ColdFusion as a WAR file or EAR file for deployment to standalone application servers, such as Macromedia JRun, and IBM WebSphere. ColdFusion can also be deployed to servlet containers such as Apache Tomcat and Mortbay Jetty, but because these platforms do not officially support ColdFusion, they leave many of its features inaccessible.\nBecause ColdFusion is a Java EE application, ColdFusion code can be mixed with Java classes to create a variety of applications and utilize existing Java libraries. ColdFusion has access to all underlying Java classes, supports JSP custom tag libraries, and can access JSP functions after retrieving the JSP page context (GetPageContext()).\nPrior to ColdFusion 7.0.1, ColdFusion components could only be used by Java or .NET by declaring them as web services. However, beginning in ColdFusion MX 7.0.1, ColdFusion components can now be utilized directly within Java classes using the CFCProxy class.[5]\nRecently, there has been much interest in Java development using alternate languages such as Jython, Groovy and JRuby. ColdFusion was one of the first scripting platforms to allow this style of Java development. There are, however, some limitations to ColdFusion''s ability to offer Java scripting:\nColdFusion MX 6.1 did not support usage of null value method parameters\nLack of Bean Scripting Framework plugin support\none cannot extend Java classes in ColdFusion\nColdFusion and .NET\nColdFusion 8 natively supports .NET within the CFML syntax. ColdFusion developers can simply call any .NET assembly without needing to recompile or alter the assemblies in any way. Data types are automatically translated between ColdFusion and .NET (example: .NET DataTable → ColdFusion Query).\nA unique feature for a J2EE vendor, ColdFusion 8 offers the ability to access .NET assemblies remotely through proxy (without the use of .NET Remoting). This allows ColdFusion users to leverage .NET without having to be installed on a Windows operating system.\nThe move to include .NET support in addition to the existing support for Java, CORBA and COM is a continuation of Adobe ColdFusion''s agnostic approach to the technology stack. ColdFusion can not only bring together disparate technologies within the enterprise, but can make those technologies available to a number of clients beyond the web browser including, but not limited to, the Flash Player, Adobe Integrated Runtime (AIR), Mobile devices (SMS), Acrobat Reader (PDF) and IM gateways.\nAcronyms\nThe acronym for the ColdFusion Markup Language is CFML. When ColdFusion templates are saved to disk, they are traditionally given the extension .cfm or .cfml. The .cfc extension is used for ColdFusion Components. The original extension was DBM or DBML, which stood for Database Markup Language. When talking about ColdFusion, most users use the acronym CF and this is used for numerous ColdFusion resources such as user groups (CFUGs) and sites.\nCFMX is the common abbreviation for ColdFusion versions 6 and 7 (aka ColdFusion MX).\nTechnical commentary\nIT commentators have offered various critiques of ColdFusion, discussing both the potential advantages and disadvantages of this technology relative to other alternatives.\nBootstrapping: ColdFusion is not a general purpose programming language. It cannot be used to create certain kinds of programs or software. For example, ColdFusion was written in Java and it would be impossible to write ColdFusion in ColdFusion itself (a technique known as Bootstrapping). Extending ColdFusion therefore frequently relies on also using other general purpose programming languages.\nCost: Adobe ColdFusion is expensive compared to some of its competitors, which are almost always free. Even Microsoft-based solutions such as ASP.NET are technically free if you own a PC or server running some version of Windows. For developers who do not wish to host their own site (and personally purchase ColdFusion Server), shared hosting accounts are readily available at comparable prices to PHP or ASP.NET hosting. Note, ColdFusion is free for Academic use.\nExtensions: ColdFusion libraries and extensions are not always free, although there are sites dedicated to open-source ColdFusion code and several open-source frameworks have emerged in recent years in active development. ColdFusion can call Java libraries which alleviates this issue.\nOOP: ColdFusion lacks advanced object-oriented features [6] such as providing little distinction between instance and class (virtual and static) properties and methods. ColdFusion doesn''t offer constructor syntax per se, but rather forces an object factory pattern to return object instances. A common idiom is to use init to indicate a method which is the constructor for each component. Methods are implicitly virtual if they reference the THIS scope. There are several techniques available to provide mixin functionality.\nOpen Source: Some competing scripting languages such as PHP, Ruby, Perl and Python are open-source. Although the language of CFML itself is documented, Adobe ColdFusion''s server code is not viewable or modifiable. However, SmithProject and the J2EE version of BlueDragon (OpenBD) are open-source CFML parsing engines.\nShared hosting: Certain features of ColdFusion such as event gateways, creation of datasources, caching settings and classpath additions are not readily configurable for usage in a shared hosting environment.[7] ColdFusion 7 introduced the Admin API which allows hosting providers to automate things such as datasource creation for their customers.\nScripting: CFScript is similar to but incompatible with the ECMAScript specification. ColdFusion does include some server-side Actionscript functionality, however ColdFusion''s server-side Actionscript has significantly fewer features than CFML. Note: The release of CF 8 brought CFscript closer to ECMA by introducing == for equals, < for less than, and ++ etc.\nSyntax: CFML syntax is very different from traditional programming languages, which use a C-style syntax, although this is a key reason for its success.\nNotes and references\n^ Adobe - ColdFusion\n^ Web Hosting Resource and Directory since 1997 - Tophosts.com\n^ Potential New Features for CF9\n^ nictunney.com - Coldfusion MoFo\n^ Using the CFC Proxy\n^ The release of CF 8 has included a cfinterface tag to define interfaces similarly to OOP languages like Java.\n^ The release of CF 8 has allowed hosting providers to provide application specific settings and administrator accounts, which should help to bring more functionality to shared hosting customers. Also, features like Event Gateways are included in the standard version now.\n"Adobe Ships ColdFusion 8". Adobe Systems Incorporated (2007-07-30).\nSee also\n4GL\nBlueDragon - Proprietary, Open Source alternative CFML Engine\nColdFusion Markup Language\nComparison of programming languages\nRailo - Proprietary alternative CFML Engine\nSmithProject - Free, Open Source alternative CFML Engine\nWikibooks has a book on the topic of\nProgramming:ColdFusion\nOfficial ColdFusion site\nColdFusion at the Open Directory Project\nThe ColdFusion section of Rosetta Code\nColdFusion Examples\nColdFusion Resource Center\nv • d • e\nAdobe Systems\nDesktop software\nCreative Suite · Technical Communication Suite · Acrobat · Audition · Digital Editions · Director · GoLive · PageMaker · Photoshop Lightroom · more\nReaders and players\nAdobe Reader · Flash Player · AIR · Adobe Media Player · Shockwave Player\nServer software\nColdFusion · LiveCycle · Flash Media Server · JRun · Premiere Express · Photoshop Express\nTechnology\nPostScript · PDF · FlashPaper · Authorware · Flash · Font Folio · DNG · Flex · AIR\n· BlazeDS\nServices\nAdobe Solutions Network\nBoard of directors\nBruce Chizen · Charles Geschke · Shantanu Narayen · John Warnock · Del Yocam\nAcquisitions\nMergers and acquisitions · Aldus · Macromedia · Scene7\n"http://en.wikipedia.org/wiki/ColdFusion"\nCategories: Adobe software | Domain-specific programming languages | Macromedia software | Web development software | CFML compilers | CFML programming language | JVM programming languagesHidden categories: Articles needing additional references from February 2008 | Cleanup from May 2008 | All pages needing cleanup | All articles to be merged | Articles to be merged since July 2008','\n',char(10)));
INSERT INTO pages VALUES('COBOL','http://web.archive.org/web/20090108085047/http://en.wikipedia.org:80/wiki/COBOL','en','2009-01-08 00:00:00',replace('For other uses, see COBOL (disambiguation).\nCOBOL\nParadigm\nprocedural,\nobject-oriented\nAppeared in\n1959 (1959)\nDesigned by\nGrace Hopper, William Selden, Gertrude Tierney, Howard Bromberg, Howard Discount, Vernon Reeves, Jean E. Sammet\nTyping discipline\nstrong, static\nMajor implementations\nOpenCobol.org, MicroFocus.com\nDialects\nHP3000 COBOL/II, COBOL/2, IBM OS/VS COBOL, IBM COBOL/II, IBM COBOL SAA, IBM Enterprise COBOL, IBM COBOL/400, IBM ILE COBOL, Unix COBOL X/Open, Micro Focus COBOL, Microsoft COBOL, Ryan McFarland RM/COBOL, Ryan McFarland RM/COBOL-85, DOSVS COBOL, UNIVAC COBOL, Realia COBOL, Fujitsu COBOL, ACUCOBOL-GT, DEC VAX COBOL, Wang VS COBOL, Visual COBOL\nInfluenced by\nFLOW-MATIC, COMTRAN, FACT\nInfluenced\nPL/I, CobolScript, ABAP\nCOBOL (pronounced /ˈkoʊbɒl/) is one of the oldest programming languages still in active use. Its name is an acronym for COmmon Business-Oriented Language, defining its primary domain in business, finance, and administrative systems for companies and governments.\nThe COBOL 2002 standard includes support for object-oriented programming and other modern language features.[1]\n1 History and specification\n1.1 History of COBOL standards\n1.2 Legacy\n1.3 COBOL 2002 and object-oriented COBOL\n2 Features\n2.1 Syntactic features\n2.2 Data types\n2.3 Hello, world\n3 Criticism\n4 Defense\n5 Aphorisms and humor about COBOL\n6 See also\n6.1 Other third-generation programming languages\n7 References\n8 Sources\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory and specification\nA specification of COBOL was initially created during the second half of 1959. The scene was set on April 8 at a meeting of computer manufacturers, users and university people at the University of Pennsylvania Computing Center and subsequently the United States Department of Defense agreed to sponsor and oversee the next activities. A meeting was held at the Pentagon on May 28 and 29 (exactly one year after the Zürich ALGOL 58 meeting), chaired by Charles A. Phillips. There it was decided to set up three committees, short, intermediate and long range (the last one was actually never formed). It was the Short Range Committee, chaired by Joseph Wegstein of the US National Bureau of Standards, that during the next months would create a description of the first version of COBOL.[2] The committee was formed to recommend a short range approach to a common business language. The committee was made up of members representing six computer manufacturers and three government agencies. The six computer manufacturers were Burroughs Corporation, IBM, Minneapolis-Honeywell (Honeywell Labs), RCA, Sperry Rand, and Sylvania Electric Products. The three government agencies were the US Air Force, the David Taylor Model Basin, and the National Bureau of Standards (now National Institute of Standards and Technology). The intermediate-range committee was formed but never became operational. In the end a sub-committee of the Short Range Committee developed the specifications of the COBOL language. This sub-committee was made up of six individuals:\nWilliam Selden and Gertrude Tierney of IBM\nHoward Bromberg and Howard Discount of RCA\nVernon Reeves and Jean E. Sammet of Sylvania Electric Products[3]\nThis subcommittee completed the specifications for COBOL in December 1959. The specifications were to a great extent inspired by the FLOW-MATIC language invented by Grace Hopper, commonly referred to as "the mother of the COBOL language", the IBM COMTRAN language invented by Bob Bemer, and the FACT language from Honeywell.\nThe name COBOL was decided upon at a meeting of the committee held on 18 Sept. 1959.\nThe first compilers for COBOL were subsequently implemented during the year 1960 and on 6 and 7 Dec. essentially the same COBOL program was run on two different makes of computers, an RCA computer and a Remington-Rand Univac computer, demonstrating that compatibility could be achieved.\nSince 1959 COBOL has undergone several modifications and improvements. In an attempt to overcome the problem of incompatibility between different versions of COBOL, the American National Standards Institute (ANSI) developed a standard form of the language in 1968. This version was known as American National Standard (ANS) COBOL. In 1974, ANSI published a revised version of (ANS) COBOL, containing a number of features that were not in the 1968 version. In 1985, ANSI published still another revised version that had new features not in the 1974 standard. The language continues to evolve today. In the early 1990''s it was decided to add object-orientation in the next full revision of COBOL. The initial estimate was to have this revision completed by 1997 and an ISO CD (Committee Draft) was available by 1997. Some implementers (including Micro Focus, Fujitsu, and IBM) introduced object-oriented syntax based on the 1997 or other drafts of the full revision. The final approved ISO Standard (adopted as an ANSI standard by INCITS) was approved and made available in 2002.\nLike the C++ programming language, object-oriented COBOL compilers are available even as the language moves toward standardization.\nThe 2002 (4th revision) of COBOL included many other features beyond object-orientation. These included (but are not limited to):\nNational Language support (including but not limited to Unicode support)\nLocale-based processing\nUser-defined functions\nCALL (and function) proto-types (for compile-time parameter checking)\nPointers and syntax for getting and freeing storage\nBit and Boolean support\n“True” binary support (up until this enhancement, binary items were truncated based on the (base-10) specification within the Data Division)\nFloating-point support\nStandard (or portable) arithmetic results\nHistory of COBOL standards\nThe specifications approved by the full Short Range Committee were approved by the Executive Committee on January 3, 1960, and sent to the government printing office, which edited and printed these specifications as Cobol 60.\nThe American National Standards Institute (ANSI) produced several revisions of the COBOL standard, including:\nCOBOL-68\nCOBOL-74\nCOBOL-85\nIntrinsic Functions Amendment - 1989\nCorrections Amendment - 1991\nAfter the Amendments to the 1985 ANSI Standard (which were adopted by ISO), primary development and ownership was taken over by ISO. The following editions and TRs (Technical Reports) have been issued by ISO (and adopted as ANSI) Standards:\nCOBOL 2002\nFinalizer Technical Report - 2003\nNative XML syntax Technical Report - 2006l\nObject Oriented Collection Class Libraries - pending final approval\nFrom 2002, the ISO standard is also available to the public coded as ISO/IEC 1989.\nWork is progressing on the next full revision of the COBOL Standard. It is expected to be approved and available in the early 2010s. For information on this revision, to see the latest draft of this revision, or to see what other works is happening with the COBOL Standard, see the COBOL Standards Website.\nLegacy\nCOBOL programs are in use globally in governmental and military agencies, in commercial enterprises, and on operating systems such as IBM''s z/OS, Microsoft''s Windows, and the POSIX families (Unix/Linux etc.). In 1997, the Gartner Group reported that 80% of the world''s business ran on COBOL with over 200 billion lines of code in existence and with an estimated 5 billion lines of new code annually.[4]\nNear the end of the twentieth century the year 2000 problem was the focus of significant COBOL programming effort, sometimes by the same programmers who had designed the systems decades before. The particular level of effort required for COBOL code has been attributed both to the large amount of business-oriented COBOL, as COBOL is by design a business language and business applications use dates heavily, and to constructs of the COBOL language such as the PICTURE clause, which can be used to define fixed-length numeric fields, including two-digit fields for years.\nCOBOL 2002 and object-oriented COBOL\nThe COBOL2002 standard supports Unicode, XML generation and parsing, calling conventions to and from non-COBOL languages such as C, and support for execution within framework environments such as Microsoft''s .NET and Java (including COBOL instantiated as Enterprise JavaBeans). Fujitsu and Micro Focus currently supports object oriented COBOL compilers targeting the .NET framework.[5]\nFeatures\nCOBOL as defined in the original specification included a PICTURE clause for detailed field specification. It did not support local variables, recursion, dynamic memory allocation, or structured programming constructs. Support for some or all of these features has been added in later editions of the COBOL standard.\nCOBOL has many reserved words (over 400), called keywords. The original COBOL specification supported self-modifying code via the infamous "ALTER X TO PROCEED TO Y" statement. This capability has since been removed.\nSyntactic features\nCOBOL provides an update-in-place syntax, for example\nADD YEARS TO AGE.\nThe equivalent construct in many procedural languages would be\nage = age + years\nThis syntax is similar to the compound assignment operator later adopted by C:\nage += years\nThe abbreviated conditional expression\nIF SALARY > 9000 OR SUPERVISOR-SALARY OR = PREV-SALARY\nis equivalent to\nIF SALARY > 9000\nOR SALARY > SUPERVISOR-SALARY\nOR SALARY = PREV-SALARY\nCOBOL provides "named conditions" (so-called 88-levels). These are declared as sub-items of another item (the conditional variable). The named condition can be used in an IF statement, and tests whether the conditional variable is equal to any of the values given in the named condition''s VALUE clause. The SET statement can be used to make a named condition TRUE (by assigning the first of its values to the conditional variable).\nCOBOL allows identifiers to be up to 30 characters long. When COBOL was introduced, much shorter lengths (e.g., 6 characters for FORTRAN) were prevalent.\nThe concept of copybooks was introduced by COBOL; these are chunks of text which can be inserted into a program''s code. This is done with the COPY statement, which also allows parts of the copybook''s text to be replaced with other text (using the REPLACING ... BY ... clause).\nData types\nStandard COBOL provides the following data types:\nData type\nSample declaration\nNotes\nCharacter\nPIC X(20)\nPIC A(4)9(5)X(7)\nAlphanumeric and alphabetic-only\nSingle-byte character set (SBCS)\nEdited character\nPIC X99BAXX\nFormatted and inserted characters\nNumeric fixed-point binary\nPIC S999V99\nUSAGE COMPUTATIONAL\nor\nBINARY\nBinary 16, 32, or 64 bits (2, 4, or 8 bytes)\nSigned or unsigned. Conforming compilers limit the maximum value of variables based on the picture clause and not the number of bits reserved for storage.\nNumeric fixed-point packed decimal\nPIC S999V99\nUSAGE PACKED-DECIMAL\n1 to 18 decimal digits (1 to 10 bytes)\nSigned or unsigned\nNumeric fixed-point zoned decimal\nPIC S999V99\n[USAGE DISPLAY]\n1 to 18 decimal digits (1 to 18 bytes)\nSigned or unsigned\nNumeric floating-point\nPIC S9V999ES99\nBinary floating-point\nEdited numeric\nPIC +Z,ZZ9.99\nPIC $***,**9.99CR\nFormatted characters and digits\nGroup (record)\n01 CUST-NAME.\n05 CUST-LAST PIC X(20).\n05 CUST-FIRST PIC X(20).\nAggregated elements\nTable (array)\nOCCURS 12 TIMES\nFixed-size array, row-major order\nUp to 7 dimensions\nVariable-length table\nOCCURS 0 to 12 TIMES\nDEPENDING ON CUST-COUNT\nVariable-sized array, row-major order\nUp to 7 dimensions\nRenames (variant or union data)\n66 RAW-RECORD\nRENAMES CUST-RECORD\nCharacter data overlaying other variables\nCondition name\n88 IS-RETIRED-AGE\nVALUES 65 THRU 150\nBoolean value\ndependent upon another variable\nArray index\nUSAGE INDEX\nArray subscript\nMost vendors provide additional types, such as:\nData type\nSample declaration\nNotes\nNumeric fixed-point binary\nin native byte order\nPIC S999V99\nUSAGE COMPUTATIONAL-4\nBinary 16, 32, or 64 bits (2, 4, or 8 bytes)\nSigned or unsigned\nNumeric fixed-point binary\nin big-endian byte order\nPIC S999V99\nUSAGE COMPUTATIONAL-5\nBinary 16, 32, or 64 bits (2, 4, or 8 bytes)\nSigned or unsigned\nWide character\nPIC G(20)\nAlphanumeric\nDouble-byte character set (DBCS)\nEdited wide character\nPIC G99BGGG\nFormatted and inserted wide characters\nEdited floating-point\nPIC +9.9(6)E+99\nFormatted characters and decimal digits\nData pointer\nUSAGE POINTER\nData memory address\nCode pointer\nUSAGE PROCEDURE-POINTER\nCode memory address\nHello, world\nAn example of the "Hello, world" program in COBOL:\nIDENTIFICATION DIVISION.\nPROGRAM-ID. HELLO-WORLD.\nPROCEDURE DIVISION.\nMAIN.\nDISPLAY ''Hello, world.''.\nSTOP RUN.\nCriticism\nCritics have argued that COBOL''s syntax serves mainly to increase the size of programs, at the expense of developing the thinking process needed for software development. In his letter to an editor in 1975 titled "How do we tell truths that might hurt?", computer scientist and Turing Award recipient Edsger Dijkstra remarked that "The use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offense."[6]\nCOBOL 85 was not compatible with earlier versions, resulting in the "cesarean birth of COBOL 85". Joseph T. Brophy, CIO, Travelers Insurance, spearheaded an effort to inform users of COBOL of the heavy reprogramming costs of implementing the new standard. As a result the ANSI COBOL Committee received more than 3,200 letters from the public, mostly negative, requiring the committee to make changes.[7]\nOlder versions of COBOL lack local variables and so cannot truly support structured programming.\nOthers[who?] criticize the ad hoc incorporation of features on a language that was meant to be a short term solution to interoperability in 1959. Coupled with the perceived archaic syntax, they argue that it tries to fill a niche for which better tools have already been designed and developed.\nDefense\nThe COBOL specification has also been revised over the years to incorporate developments in computing theory and practice .\nAs with any language, COBOL code can be made more verbose than necessary. For example, one of the roots of the quadratic equation ax2 + bx + c = 0, which are:\ncan be coded in COBOL using the "compute" verb as:\nCOMPUTE X = (-B + SQRT(B ** 2 - (4 * A * C))) / (2 * A)\nThe same formula could also be written less concisely as:\nMULTIPLY B BY B GIVING B-SQUARED.\nMULTIPLY 4 BY A GIVING FOUR-A.\nMULTIPLY FOUR-A BY C GIVING FOUR-A-C.\nSUBTRACT FOUR-A-C FROM B-SQUARED GIVING RESULT-1.\nCOMPUTE RESULT-2 = RESULT-1 ** .5.\nSUBTRACT B FROM RESULT-2 GIVING NUMERATOR.\nMULTIPLY 2 BY A GIVING DENOMINATOR.\nDIVIDE NUMERATOR BY DENOMINATOR GIVING X.\nWhich form to use is a matter of style. In some cases the less concise form may be easier to read. For example:\nADD YEARS TO AGE.\nMULTIPLY PRICE BY QUANTITY GIVING COST.\nSUBTRACT DISCOUNT FROM COST GIVING FINAL-COST.\nOlder versions of COBOL supported local variables via embedded programs (scope-delimited by the keywords PROGRAM-ID and END-PROGRAM). Variables declared within the embedded program are invisible outside its scope. Also, local variables could be accomplished via separately compiled sub-programs. Newer COBOL compilers support the LOCAL-STORAGE section for local variables.\nAphorisms and humor about COBOL\nIt has been said of languages like C, C++, and Java that the only way to modify legacy code is to rewrite it - write once and write once again; or write once and throw away. On the other hand, it has been said of COBOL that there actually is one original COBOL program, and it has only been copied and modified millions of times.\nThe name "ADD 1 TO COBOL GIVING COBOL" has been suggested for a hypothetical object-oriented dialect of COBOL, as a play on the name C++. While this is meant to suggest that COBOL is inherently verbose, the form given is more verbose than COBOL actually requires; the succinct form would be "ADD 1 TO COBOL".\nAnother suggested name is "POSTINCREMENT COBOL BY 1", which not only reflects the verbose nature of COBOL statements, but also highlights the tendency for COBOL features to require their own dedicated reserved keywords (standard COBOL employs over 400 reserved words), this example being the case for a hypothetical new POSTINCREMENT operator.\nSee also\nAlphabetical list of programming languages\nBurroughs B2000\nCODASYL\nComparison of programming languages\nOther third-generation programming languages\nAda\nALGOL\nAPL\nBASIC\nC\nC++\nC#\nFORTRAN\nJava\nLisp - ISO/IEC 13816\nPascal, Object Pascal, Extended Pascal\nPL/I\nRPG\nReferences\n^ Oliveira, Rui (2006). The Power of Cobol. City: BookSurge Publishing. ISBN 0620346523.\n^ Garfunkel, Jerome (1987). The Cobol 85 Example Book. New York: Wiley. ISBN 0471804614.\n^ Wexelblat, Richard (1981). History of Programming Languages. Boston: Academic Press. ISBN 0127450408.\n^ "Future of COBOL" (PDF) 5.\nLegacyJ Corporation (2003). Retrieved on 2006-11-08.\n^ NetCOBOL for .NET supports COBOL migration and software development in the .NET environment\n^ Dijkstra (2006). "E. W. Dijkstra Archive: How do we tell truths that might hurt? (EWD498)".\nUniversity of Texas at Austin. Retrieved on August 29, 2007.\n^ (The COBOL 85 Example Book)\nSources\nEbbinkhuijsen, Wim B.C., COBOL Alphen aan den Rijn/Diegem: Samson Bedrijfsinformatie bv, 1990. ISBN 90-14-04560-3. (Dutch)\nWikibooks has more on the topic of\nCOBOL\nCOBOL-Standard Committee\nCOBOLware\nCOBOL Tutorial\nCOBOL Virtual Machine\nIBM COBOL compilers\nIBM Enterprise COBOL for z/OS V4R1 Bookshelf\nIBM VS COBOL II V1R4.0 Bookshelf\nIBM COBOL documentation (iSeries Information Center)\nIBM ILE COBOL reference manualPDF (3.9 MB)\nMainframe COBOL Community\nOpenCOBOL: Open-source COBOL compiler\nAdd1tocobol: COBOL advocacy project\nMicro Focus COBOL\nWildcat Cobol - Open-source .NET compiler\nDescription from another wiki\nSolution for COBOL to serialize and de-serialize XML\nCobol User''s Group has an extensive collection of links\nArticle "Cobol: Not Dead Yet" by Robert Mitchell\nArticle "Cobol Coders: Going, Going, Gone?" by Gary Anthes\n"http://en.wikipedia.org/wiki/COBOL"\nCategories: COBOL | Object-oriented programming languages | .NET programming languagesHidden category: Articles with specifically-marked weasel-worded phrases','\n',char(10)));
INSERT INTO pages VALUES('Clojure','http://web.archive.org/web/20081227074722/http://en.wikipedia.org:80/wiki/Clojure','en','2008-12-27 00:00:00',replace('Clojure\nParadigm\nfunctional, multiparadigm\nAppeared in\n2007\nDesigned by\nRich Hickey\nDeveloper\nRich Hickey\nLatest release\n20081217/ 2008-12-17\nTyping discipline\ndynamic, strong\nInfluenced by\nLisp, ML, Haskell, Erlang\nOS\nCross-platform\nLicense\nEclipse Public License\nWebsite\nhttp://clojure.org\nClojure is a modern dialect of Lisp. It is a general-purpose language sporting interactive development, and it encourages a functional programming style that enables simplified multithreaded programming. Clojure runs on the Java Virtual Machine. Clojure honors the code-as-data philosophy and has a sophisticated Lisp macro system.\n1 Philosophy\n2 Syntax\n3 Macros\n4 Language features\n5\n6 References\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nPhilosophy\nRich Hickey developed Clojure because he wanted a modern Lisp for functional programming, symbiotic with an established platform, designed for concurrency.\nSyntax\nLike any other Lisp, Clojure''s syntax is built on S-expressions that are first parsed into data structures by a reader before being compiled. Clojure''s reader supports literal syntax for maps, sets and vectors in addition to lists, and these are given to the compiler as they are. In other words, the Clojure compiler does not compile only list data structures, but supports all of the mentioned types directly. Clojure is a Lisp-1, and is not intended to be code-compatible with other dialects of Lisp.\nMacros\nClojure''s macro system is very similar to that in Common Lisp with the exception that Clojure''s version of the backquote (called "syntax quote") qualifies symbols with their namespace, this helps prevent unintended name capture as binding to namespace-qualified names is forbidden. It is possible to force a capturing macro expansion, but this must be done explicitly. Clojure also disallows rebinding global names in other namespaces that have been imported into the current namespace.\nLanguage features\nDynamic development with a read-eval-print loop\nFunctions as first-class objects with an emphasis on recursion instead of side-effect-based looping\nProvides a rich set of immutable, persistent data structures\nConcurrent programming through software transactional memory, an agent system, and a dynamic var system\nCompatibility with Java: Clojure can natively call methods and create objects from any Java library, and Java programs can call Clojure functions\nClojure is a compiled language producing JVM bytecode\nWikibooks has a book on the topic of\nClojure Programming\nClojure home page\nGoogle Group\nGoogle Code page for Clojure\nReferences\n"Rationale". Rich Hickey. clojure.org. http://clojure.org/rationale. Retrieved on 2008-10-17.\n"http://en.wikipedia.org/wiki/Clojure"\nCategories: Functional languages | JVM programming languages | Dynamic programming languages | Lisp programming language family','\n',char(10)));
INSERT INTO pages VALUES('PL/SQL','http://web.archive.org/web/20090201182036/http://en.wikipedia.org:80/wiki/PL/SQL','en','2009-02-01 00:00:00',replace('Paradigm\nImperative (procedural)\nDeveloper\nOracle\nInfluenced by\nAda\nWebsite\nOfficial site\nPL/SQL (Procedural Language/Structured Query Language) is Oracle Corporation''s proprietary procedural extension to the SQL database language, used in the Oracle database. Some other SQL database management systems offer similar extensions to the SQL language. PL/SQL''s syntax strongly resembles that of Ada, and just like Ada compilers of the 1980s the PL/SQL runtime system uses Diana as intermediate representation.\nThe key strength of PL/SQL is its tight integration with the Oracle database.\nPL/SQL is one of three languages embedded in the Oracle Database, the other two being SQL and Java.\n1 History\n2 Functionality\n3 Basic code structure\n3.1 Functions\n3.2 Procedures\n3.3 Anonymous Blocks\n3.4 Packages\n3.5 Numeric variables\n3.6 Character variables\n3.7 Date variables\n3.8 Datatypes for specific columns\n4 Conditional Statements\n5 Array handling\n6 Looping\n6.1 LOOP statements\n6.2 FOR loops\n6.3 Cursor FOR loops\n6.3.1 Example\n7 Similar languages\n8 References\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nPL/SQL made its first appearance in Oracle Forms v3. A few years later, it was included in the Oracle Database server v7 (as database procedures, functions, packages, triggers and anonymous blocks) followed by Oracle Reports v2.\nFunctionality\nPL/SQL supports the following: variables, conditions, arrays, and exceptions. Implementations from version 8 of Oracle Database onwards have included features associated with object-orientation.\nThe underlying SQL functions as a declarative language. Standard SQL—unlike some functional programming languages—does not require implementations to convert tail calls to jumps. The open standard SQL does not readily provide "first row" and "rest of table" accessors, and it cannot easily perform some constructs such as loops. PL/SQL, however, as a Turing-complete procedural language that fills in these gaps, allows Oracle database developers to interface with the underlying relational database in an imperative manner. SQL statements can make explicit in-line calls to PL/SQL functions, or can cause PL/SQL triggers to fire upon pre-defined Data Manipulation Language (DML) events.\nPL/SQL stored procedures (functions, procedures, packages, and triggers) performing DML will get compiled into an Oracle database: to this extent, their SQL code can undergo syntax-checking. Programmers working in an Oracle database environment can construct PL/SQL blocks of functionality to serve as procedures, functions; or they can write in-line segments of PL/SQL within SQL*Plus scripts.\nWhile programmers can readily incorporate SQL DML statements into PL/SQL (as cursor definitions, for example, or using the SELECT ... INTO syntax), Data Definition Language (DDL) statements such as CREATE TABLE/DROP INDEX etc. require the use of "Dynamic SQL". Earlier versions of Oracle Database required the use of a complex built-in DBMS_SQL package for Dynamic SQL where the system needed to explicitly parse and execute an SQL statement. Later versions have included an EXECUTE IMMEDIATE syntax called "Native Dynamic SQL" which considerably simplifies matters. Any use of DDL in an Oracle database will result in an implicit COMMIT. Programmers can also use Dynamic SQL to execute DML where they do not know the exact content of the statement in advance.\nPL/SQL offers several pre-defined packages for specific purposes. Such PL/SQL packages include:\nDBMS_OUTPUT - for output operations to non-database destinations\nDBMS_JOB - for running specific procedures/functions at a particular time (i.e. scheduling)\nDBMS_XPLAN - for formatting Explain Plan output\nDBMS_SESSION - provides access to SQL ALTER SESSION and SET ROLE statements, and other session information.\nDBMS_METADATA - for extracting meta data from the data dictionary (such as DDL statements)\nUTL_FILE - for reading and writing files on disk\nUTL_HTTP - for making requests to web servers from the database\nUTL_SMTP - for sending mail from the database (via an SMTP server)\nOracle Corporation customarily adds more packages and/or extends package functionality with each successive release of Oracle Database.\nBasic code structure\nDECLARE\n-- Declaration block (optional)\nBEGIN\n-- Program proper\nEXCEPTION\n-- Exception-handling (optional)\nEND\n/* Sample comment spanning\nmultiple lines... */\nNote that blocks can be nested within blocks.\nThe DECLARE section specifies the datatypes of variables, constants, collections, and user-defined types.\nThe block between BEGIN and END specifies executable procedural code.\nExceptions, errors which arise during the execution of the code, have one of two types:\npre-defined exceptions\nuser-defined exceptions.\nUser-defined exceptions are always raised explicitly by the programmers, using the RAISE command, in any situation where they have determined that it is impossible for normal execution to continue. This command has the syntax:\nRAISE <exception name>\nOracle Corporation has pre-defined several exceptions like NO_DATA_FOUND, TOO_MANY_ROWS, etc. Each exception has a SQL Error Number and SQL Error Message associated with it. Programmers can access these by using the SQLCODE and SQLERRM functions.\nThe DECLARE section defines and (optionally) initialises variables. If not initialised specifically, they default to NULL.\nFor example:\nDECLARE\nnumber1 NUMBER(2);\nnumber2 NUMBER(2)\n:= 17;\ntext1\nVARCHAR2(12) := ''Hello world'';\ntext2\nDATE\n:= SYSDATE;\n-- current date and time\nBEGIN\nSELECT street_number\nINTO\nnumber1\nFROM\naddress\nWHERE\nname = ''Billa'';\nEND;\nThe symbol := functions as an assignment operator to store a value in a variable.\nThe major datatypes in PL/SQL include NUMBER, INTEGER, CHAR, VARCHAR2, DATE, TIMESTAMP, TEXT etc.\nFunctions\nFunctions in PL/SQL are a collection of SQL and PL/SQL statements that perform a task and should return a value to the calling environment.\nCREATE OR REPLACE FUNCTION <function_name>\nIS/AS\n{Variable declaration}\n{CONSTANT declaration}\nRETURN return_type\nBEGIN\nPl/SQL Block;\nEXCEPTION\nEXCEPTION Block;\nEND;\nProcedures\nProcedures are the same as Functions, in that they are also used to perform some task with the difference being that procedures cannot be used in a SQL statement and although they can have multiple out parameters they do not return a value.\nAnonymous Blocks\nAnonymous PL/SQL blocks can be embedded in an Oracle Precompiler or OCI program. At run time, the program, lacking a local PL/SQL engine, sends these blocks to the Oracle server, where they are compiled and executed. Likewise, interactive tools such as SQL*Plus and Enterprise Manager, lacking a local PL/SQL engine, must send anonymous blocks to Oracle.\nPackages\nPackages are the combination of Functions, Procedures,Variable,Constants & Cursors...etc.Which is used to group the related things make for reusable purpose.\nNumeric variables\nvariable_name number(P[,S]) := value;\nTo define a numeric variable, the programmer appends the variable type NUMBER to the name definition. To specify the (optional) precision(P) and the (optional) scale (S), one can further append these in round brackets, separated by a comma. ("Precision" in this context refers to the number of digits which the variable can hold, "scale" refers to the number of digits which can follow the decimal point.)\nA selection of other datatypes for numeric variables would include:\nbinary_float, binary_double, dec, decimal, double precision, float, integer, int, numeric, real, smallint, binary_integer\nCharacter variables\nvariable_name varchar2(L) := ''Text'';\nTo define a character variable, the programmer normally appends the variable type VARCHAR2 to the name definition. There follows in brackets the maximum number of characters which the variable can store.\nOther datatypes for character variables include:\nvarchar, char, long, raw, long raw, nchar, nchar2, clob, blob, bfile\nDate variables\nvariable_name date := ''01-Jan-2005'';\nOracle provides a number of data types that can store dates (DATE, DATETIME, TIMESTAMP etc.), however DATE is most commonly used.\nProgrammers define date variables by appending the datatype code "DATE" to a variable name. The TO_DATE function can be used to convert strings to date values. The function converts the first quoted string into a date, using as a definition the second quoted string, for example:\nTO_DATE(''31-12-2004'',''dd-mm-yyyy'')\nor\nTO_DATE (''31-Dec-2004'',''dd-mon-yyyy'', ''NLS_DATE_LANGUAGE = American'')\nTo convert the dates to strings one uses the function TO_CHAR (date_string, format_string).\nDatatypes for specific columns\nVariable_name Table_name.Column_name%type;\nThis syntax defines a variable of the type of the referenced column on the referenced tables.\nProgrammers specify user-defined datatypes with the syntax:\ntype data_type is record (field_1 type_1 :=xyz, field_2 type_2 :=xyz, ..., field_n type_n :=xyz);\nFor example:\nDECLARE\nTYPE t_address IS\nRECORD (\nname address.name%TYPE,\nstreet address.street%TYPE,\nstreet_number address.street_number%TYPE,\npostcode address.postcode%TYPE);\nv_address t_address;\nBEGIN\nSELECT name, street, street_number, postcode INTO v_address FROM address WHERE ROWNUM = 1;\nEND;\nThis sample program defines its own datatype, called t_address, which contains the fields name, street, street_number and postcode.\nso according the example we are able to copy the data from database to the fields in program. Using this datatype the programmer has defined a variable called v_address and loaded it with data from the ADDRESS table.\nProgrammers can address individual attributes in such a structure by means of the dot-notation, thus: "v_address.street := ''High Street'';"\nConditional Statements\nThe following code segment shows the IF-THEN-ELSIF construct. The ELSIF and ELSE parts are optional so it is possible to create simpler IF-THEN or, IF-THEN-ELSE constructs.\nIF x = 1 THEN\nsequence_of_statements_1;\nELSIF x = 2 THEN\nsequence_of_statements_2;\nELSIF x = 3 THEN\nsequence_of_statements_3;\nELSIF x = 4 THEN\nsequence_of_statements_4;\nELSIF x = 5 THEN\nsequence_of_statements_5;\nELSE\nsequence_of_statements_N;\nEND IF;\nThe CASE statement simplifies some large IF-THEN-ELSE structures.\nCASE\nWHEN x = 1 THEN sequence_of_statements_1;\nWHEN x = 2 THEN sequence_of_statements_2;\nWHEN x = 3 THEN sequence_of_statements_3;\nWHEN x = 4 THEN sequence_of_statements_4;\nWHEN x = 5 THEN sequence_of_statements_5;\nELSE sequence_of_statements_N;\nEND CASE;\nCASE statement can be used with predefined selector:\nCASE x\nWHEN 1 THEN sequence_of_statements_1;\nWHEN 2 THEN sequence_of_statements_2;\nWHEN 3 THEN sequence_of_statements_3;\nWHEN 4 THEN sequence_of_statements_4;\nWHEN 5 THEN sequence_of_statements_5;\nELSE sequence_of_statements_N;\nEND CASE;\nArray handling\nPL/SQL refers to arrays as "collections". The language offers three types of collections:\nIndex-by tables (associative arrays)\nNested tables\nVarrays (variable-size arrays)\nProgrammers must specify an upper limit for varrays, but need not for index-by tables or for nested tables. The language includes several collection methods used to manipulate collection elements: for example FIRST, LAST, NEXT, PRIOR, EXTEND, TRIM, DELETE, etc. Index-by tables can be used to simulate associative arrays, as in this example of a memo function for Ackermann''s function in PL/SQL.\nLooping\nAs a procedural language by definition, PL/SQL provides several iteration constructs, including basic LOOP statements, WHILE loops, FOR loops, and Cursor FOR loops.\nLOOP statements\nSyntax:\nLOOP\nstatement1;\nstatement2;\nEND LOOP;\nLoops can be terminated by using the EXIT keyword, or by raising an exception.\nFOR loops\nCursor FOR loops\nFOR RecordIndex IN (SELECT person_code FROM people_table)\nLOOP\nDBMS_OUTPUT.PUT_LINE(RecordIndex.person_code);\nEND LOOP;\nCursor-for loops automatically open a cursor, read in their data and close the cursor again\nAs an alternative, the PL/SQL programmer can pre-define the cursor''s SELECT-statement in advance in order (for example) to allow re-use or to make the code more understandable (especially useful in the case of long or complex queries).\nDECLARE\nCURSOR cursor_person IS\nSELECT person_code FROM people_table;\nBEGIN\nFOR RecordIndex IN cursor_person\nLOOP\nDBMS_OUTPUT.PUT_LINE(RecordIndex.person_code);\nEND LOOP;\nEND;\nThe concept of the person_code within the FOR-loop gets expressed with dot-notation ("."):\nRecordIndex.person_code\nExample\nDECLARE\nvar NUMBER; /* this "var" is not in the same scope as the for loop "var"\na reference to "var" after the "end loop;" would find its\nvalue to be null */\nBEGIN\n/*N.B. for loop variables in pl/sql are new declarations, with scope only inside the loop */\nFOR var IN 0 ..10 LOOP\nDBMS_OUTPUT.put_line(var);\nEND LOOP;\nEND;\nOutput:\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSimilar languages\nPL/SQL functions analogously to the embedded procedural languages associated with other relational databases. Sybase ASE and Microsoft SQL Server have Transact-SQL, PostgreSQL has PL/pgSQL (which tries to emulate PL/SQL to an extent), and IBM DB2 includes SQL Procedural Language,[1] which conforms to the ISO SQL’s SQL/PSM standard.\nThe designers of PL/SQL modelled its syntax on that of Ada. Both Ada and PL/SQL have Pascal as a common ancestor, and so PL/SQL also resembles Pascal in numerous aspects. The structure of a PL/SQL package closely resembles the basic Pascal''s program structure, or a Borland Delphi unit. Programmers can define global data-types, constants and static variables, public and private, in a PL/SQL package.\nPL/SQL also allows for the definition of classes and instantiating these as objects in PL/SQL code. This resembles usages in object-oriented programming languages like Object Pascal, C++ and Java. PL/SQL refers to a class as an "Advanced Data Type" (ADT), and defines it as an Oracle SQL data-type as opposed to a PL/SQL user-defined type, allowing its use in both the Oracle SQL Engine and the Oracle PL/SQL engine. The constructor and methods of an Advanced Data Type are written in PL/SQL. The resulting Advanced Data Type can operate as an object class in PL/SQL. Such objects can also persist as column values in Oracle database tables.\nPL/SQL does not resemble Transact-SQL, despite superficial similarities. Porting code from one to the other usually involves non-trivial work, not only due to the differences in the feature sets of the two languages, but also due to the very significant differences in the way Oracle and SQL Server deal with concurrency and locking.\nThe Fyracle project aims to enable the execution of PL/SQL code in the open-source Firebird database.\nReferences\n^ SQL PL\nThis article includes a list of references or external links, but its sources remain unclear because it lacks inline citations. Please improve this article by introducing more precise citations where appropriate. (February 2008)\nThis article needs additional citations for verification. Please help improve this article by adding reliable references. Unsourced material may be challenged and removed. (January 2008)\nWikibooks has a book on the topic of\nProgramming:Oracle PL/SQL Cheatsheet\nFeuerstein, Steven; with Bill Pribyl (2005). Oracle PL/SQL Programming (4th ed. ed.). O''Reilly & Associates. ISBN 0-596-00977-1.\nNaudé, Frank (June 9, 2005). "Oracle PL/SQL FAQ rev 2.08". http://www.orafaq.com/faqplsql.htm.\nOracle FAQ: PL/SQL\nOracle Technology Center\n"http://en.wikipedia.org/wiki/PL/SQL"\nCategories: Oracle software | SQL | Ada programming language family | Data-centric programming languagesHidden categories: Articles lacking in-text citations | Articles needing additional references from January 2008','\n',char(10)));
INSERT INTO pages VALUES('Verilog','http://web.archive.org/web/20090125044559/http://en.wikipedia.org:80/wiki/Verilog','en','2009-01-25 00:00:00',replace('In the semiconductor and electronic design industry, Verilog is a hardware description language (HDL) used to model electronic systems. Verilog HDL, not to be confused with VHDL, is most commonly used in the design, verification, and implementation of digital logic chips at the Register transfer level (RTL) level of abstraction. It is also used in the verification of analog and mixed-signal circuits.\n1 About Verilog\n2 History\n2.1 Beginning\n2.2 Verilog-95\n2.3 Verilog 2001\n2.4 Verilog 2005\n2.5 SystemVerilog\n3 Example\n4 Definition of Constants\n5 Synthesizeable constructs\n6 Initial and Always\n7 Fork/Join\n8 Race Conditions\n9 Operators\n10 System tasks\n11 Program Language Interface (PLI)\n12 Simulation software\n13 See also\n13.1 Additional material\n13.2 Related languages\n14\n14.1 Verilog Resources\n14.2 Standards Development\n14.3 Verilog Tools\n14.4 Open Source Verilog Tools\n14.5 References\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nAbout Verilog\nHardware description languages, such as Verilog, differ from software programming languages in several fundamental ways. HDLs add the concept of concurrency, which is parallel execution of multiple statements in explicitly specified threads, propagation of time, and signal dependency (sensitivity). There are two assignment operators, a blocking assignment (=), and a non-blocking (<=) assignment. The non-blocking assignment allows designers to describe a state-machine update without needing to declare and use temporary storage variables. Since these concepts are part of the Verilog''s language semantics, designers could quickly write descriptions of large circuits, in a relatively compact and concise form. At the time of Verilog''s introduction (1984), Verilog represented a tremendous productivity improvement for circuit designers who were already using graphical schematic-capture, and specially-written software programs to document and simulate electronic circuits.\nThe designers of Verilog wanted a language with syntax similar to the C programming language, which was already widely used in engineering software development. Verilog is case-sensitive, has a basic preprocessor (though less sophisticated than ANSI C/C++), and equivalent control flow keywords (if/else, for, while, case, etc.), and compatible language operators precedence. Syntactic differences include variable declaration (Verilog requires bit-widths on net/reg types), demarcation of procedural-blocks (begin/end instead of curly braces {}), though there are many other minor differences.\nA Verilog design consists of a hierarchy of modules. Modules encapsulate design hierarchy, and communicate with other modules through a set of declared input, output, and bidirectional ports. Internally, a module can contain any combination of the following: net/variable declarations (wire, reg, integer, etc.), concurrent and sequential statement blocks and instances of other modules (sub-hierarchies). Sequential statements are placed inside a begin/end block and executed in sequential order within the block. But the blocks themselves are executed concurrently, qualifying Verilog as a Dataflow language.\nVerilog''s concept of ''wire'' consists of both signal values (4-state: "1, 0, floating, undefined"), and strengths (strong, weak, etc.) This system allows abstract modeling of shared signal-lines, where multiple sources drive a common net. When a wire has multiple drivers, the wire''s (readable) value is resolved by a function of the source drivers and their strengths.\nA subset of statements in the Verilog language is synthesizable. Verilog modules that conform to a synthsizeable coding-style, known as RTL (register transfer level), can be physically realized by synthesis software. Synthesis-software algorithmically transforms the (abstract) Verilog source into a netlist, a logically-equivalent description consisting only of elementary logic primitives (AND, OR, NOT, flipflops, etc.) Further manipulations to the netlist ultimately lead to a circuit fabrication blueprint (such as a photo mask-set for an ASIC), or a bitstream-file for an FPGA)\nHistory\nBeginning\nVerilog was invented by Phil Moorby and Prabhu Goel during the winter of 1983/1984 at Automated Integrated Design Systems (later renamed to Gateway Design Automation in 1985) as a hardware modeling language. Gateway Design Automation was later purchased by Cadence Design Systems in 1990. Cadence now has full proprietary rights to Gateway''s Verilog and the Verilog-XL simulator logic simulators.\nVerilog-95\nWith the increasing success of VHDL at the time, Cadence decided to make the language available for open standardization. Cadence transferred Verilog into the public domain under the Open Verilog International (OVI) (now known as Accellera) organization. Verilog was later submitted to IEEE and became IEEE Standard 1364-1995, commonly referred to as Verilog-95.\nIn the same time frame Cadence initiated the creation of Verilog-A to put standards support behind its analog simulator Spectre. Verilog-A was never intended to be a standalone language and is a subset of Verilog-AMS which encompassed Verilog-95.\nVerilog 2001\nExtensions to Verilog-95 were submitted back to IEEE to cover the deficiencies that users had found in the original Verilog standard. These extensions became IEEE Standard 1364-2001 known as Verilog-2001.\nVerilog-2001 is a significant upgrade from Verilog-95. First, it adds explicit support for (2''s complement) signed nets and variables. Previously, code authors had to perform signed-operations using awkward bit-level manipulations (for example, the carry-out bit of a simple 8-bit addition required an explicit description of the boolean-algebra to determine its correct value.) The same function under Verilog-2001 can be more succinctly described by one of the built-in operators: +, -, /, *, >>>. A generate/endgenerate construct (similar to VHDL''s generate/endgenerate) allows Verilog-2001 to control instance and statement instantiation through normal decision-operators (case/if/else). Using generate/endgenerate, Verilog-2001 can instantiate an array of instances, with control over the connectivity of the individual instances. File I/O has been improved by several new system-tasks. And finally, a few syntax additions were introduced to improve code-readability (eg. always @*, named-parameter override, C-style function/task/module header declaration.)\nVerilog-2001 is the dominant flavor of Verilog supported by the majority of commercial EDA software packages.\nVerilog 2005\nNot to be confused with SystemVerilog, Verilog 2005 (IEEE Standard 1364-2005) consists of minor corrections, spec clarifications, and a few new language features (such as the uwire keyword.)\nA separate part of the Verilog standard , Verilog-AMS, attempts to integrate analog and mixed signal modelling with traditional Verilog.\nSystemVerilog\nMain article: SystemVerilog\nSystemVerilog is a superset of Verilog-2005, with many new features and capabilities to aid design-verification and design-modeling.\nThe advent of High Level Verification languages such as OpenVera, and Verisity''s E language encouraged the development of Superlog by Co-Design Automation Inc. Co-Design Automation Inc was later purchased by Synopsys. The foundations of Superlog and Vera were donated to Accellera, which later became the IEEE standard P1800-2005: SystemVerilog.\nExample\nA hello world program looks like this:\nmodule main;\ninitial\nbegin\n$display("Hello world!");\n$finish;\nend\nendmodule\nA simple example of two flip-flops follows:\nmodule toplevel(clock,reset);\ninput clock;\ninput reset;\nreg flop1;\nreg flop2;\nalways @ (posedge reset or posedge clock)\nif (reset)\nbegin\nflop1 <= 0;\nflop2 <= 1;\nend\nelse\nbegin\nflop1 <= flop2;\nflop2 <= flop1;\nend\nendmodule\nThe "<=" operator in verilog is another aspect of its being a hardware description language as opposed to a normal procedural language. This is known as a "non-blocking" assignment. When the simulation runs, all of the signals assigned with a "<=" operator have their assignment scheduled to occur after all statements occurring during the same point in time have executed. After all the statements have been executed for one event, the scheduled assignments are performed. This makes it easier to code behaviours that happen simultaneously.\nIn the above example, flop1 is assigned flop2, and flop2 is assigned flop1. These statements are executed during the same time event. Since the assignments are coded with the "<=" non-blocking operator, the assignments are scheduled to occur at the end of the event. Until then, all reads to flop1 and flop2 will use the values they had at the beginning of the time event.\nThis means that the order of the assignments are irrelevant and will produce the same result. flop1 and flop2 will swap values every clock.\nThe other choice for assignment is an "=" operator and this is known as a blocking assignment. When the "=" operator is used, things occur in the sequence they occur much like a procedural language.\nIn the above example, if the statements had used the "=" blocking operator instead of "<=", the order of the statements would affect the behaviour: the reset would set flop2 to a 1, and flop1 to a 0. A clock event would then set flop1 to flop2, which is a 1 after the reset. The next statement would be executed subsequently and would set flop2 to flop1, which is now a 1. Rather than swap values every clock, flop1 and flop2 would both become 1 and remain that way.\nAn example counter circuit follows:\nmodule Div20x (rst, clk, cet, cep, count,tc);\n// TITLE ''Divide-by-20 Counter with enables''\n// enable CEP is a clock enable only\n// enable CET is a clock enable and\n// enables the TC output\n// a counter using the Verilog language\nparameter size = 5;\nparameter length = 20;\ninput rst; // These inputs/outputs represent\ninput clk; // connections to the module.\ninput cet;\ninput cep;\noutput [size-1:0] count;\noutput tc;\nreg [size-1:0] count; // Signals assigned\n// within an always\n// (or initial)block\n// must be of type reg\nwire tc; // Other signals are of type wire\n// The always statement below is a parallel\n// execution statement that\n// executes any time the signals\n// rst or clk transition from low to high\nalways @ (posedge clk or posedge rst)\nif (rst) // This causes reset of the cntr\ncount <= 5''b0;\nelse\nif (cet && cep) // Enables both\ntrue\nbegin\nif (count == length-1)\ncount <= 5''b0;\nelse\ncount <= count + 5''b1; // 5''b1 is 5 bits\nend\n// wide and equal\n// to the value 1.\n// the value of tc is continuously assigned\n// the value of the expression\nassign tc = (cet && (count == length-1));\nendmodule\nAn example of delays:\n...\nreg a, b, c, d;\nwire e;\n...\nalways @(b or e)\nbegin\na = b & e;\nb = a | b;\n#5 c = b;\nd = #6 c ^ e;\nend\nThe always clause above illustrates the other type of method of use, i.e. the always clause executes any time any of the entities in the list change, i.e. the b or e change. When one of these changes, immediately a and b are assigned new values. After a delay of 5 time units, c is assigned the value of b and the value of c ^ e is tucked away in an invisible store. Then after 6 more time units, d is assigned the value that was tucked away.\nSignals that are driven from within a process (an initial or always block) must be of type reg. Signals that are driven from outside a process must be of type wire. The keyword reg does not necessarily imply a hardware register.\nDefinition of Constants\nThe definition of constants in Verilog supports the addition of a width parameter. The basic syntax is:\n<Width in bits>''<base letter><number>\nExamples:\n12''h123 - Hexadecimal 123 (using 12 bits)\n20''d44 - Decimal 44 (using 20 bits - 0 extension is automatic)\n4''b1010 - Binary 1010 (using 4 bits)\n6''o77 - Octal 77 (using 6 bits)\nSynthesizeable constructs\nAs mentioned previously, there are several basic templates that can be used to represent hardware.\n// Mux examples - Three ways to do the same thing.\n// The first example uses continuous assignment\nwire out ;\nassign out = sel ? a : b;\n// the second example uses a procedure\n// to accomplish the same thing.\nreg out;\nalways @(a or b or sel)\nbegin\ncase(sel)\n1''b0: out = b;\n1''b1: out = a;\nendcase\nend\n// Finally - you can use if/else in a\n// procedural structure.\nreg out;\nalways @(a or b or sel)\nif (sel)\nout = a;\nelse\nout = b;\nThe next interesting structure is a transparent latch; it will pass the input to the output when the gate signal is set for "pass-through", and captures the input and store it upon transition of the gate signal to "hold". The output will remain stable regardless of the input signal while the gate is set to "hold". In the example below the "pass-through" level of the gate would be when the value of the if clause is true, i.e. gate = 1. This is read "if gate is true, the din is fed to latch_out continuously." Once the if clause is false, the last value at latch_out will remain and is independent of the value of din.\n// Transparent latch example\nreg out;\nalways @(gate or din)\nif(gate)\nout = din; // Pass through state\n// Note that the else isn''t required here. The variable\n// out will follow the value of din while gate is high.\n// When gate goes low, out will remain constant.\nThe flip-flop is the next significant template; in verilog, the D-flop is the simplest, and it can be modeled as:\nreg q;\nalways @(posedge clk)\nq <= d;\nThe significant thing to notice in the example is the use of the non-blocking assignment. A basic rule of thumb is to use <= when there is a posedge or negedge statement within the always clause.\nA variant of the D-flop is one with an asynchronous reset; there is a convention that the reset state will be the first if clause within the statement.\nreg q;\nalways @(posedge clk or posedge reset)\nif(reset)\nq <= 0;\nelse\nq <= d;\nThe next variant is including both an asynchronous reset and asynchronous set condition; again the convention comes into play, i.e. the reset term is followed by the set term.\nreg q;\nalways @(posedge clk or posedge reset or posedge set)\nif(reset)\nq <= 0;\nelse if(set)\nq <= 1;\nelse\nq <= d;\nThe final basic variant is one that implements a D-flop with a mux feeding its input. The mux has a d-input and feedback from the flop itself. This allows a gated load function.\n// Basic structure with an EXPLICIT feedback path\nalways @(posedge clk)\nif(gate)\nq <= d;\nelse\nq <= q; // explicit feedback path\n// The more common structure ASSUMES the feedback is present\n// This is a safe assumption since this is how the\n// hardware compiler will interpret it. This structure\n// looks much like a Latch. The differences are the\n// ''''''@(posedge clk)'''''' and the non-blocking ''''''<=''''''\n//\nalways @(posedge clk)\nif(gate)\nq <= d; // the "else" mux is "implied"\nLooking at the original counter example you can see a combination of the basic asynchronous reset flop and Gated input flop used. The register variable count is set to zero on the rising edge or rst. When rst is 0, the variable count will load new data when cet && cep is true.\nInitial and Always\nThere are two separate ways of declaring a verilog process. These are the always and the initial keywords. The always keyword indicates a free-running process that triggers on the accompanying event-control (@) clause. The initial keyword indicates a process executes exactly once. Both constructs begin execution at simulator time 0, and both execute until the end of the block. Once an always block has reached its end, it is rescheduled (again). It is a common misconception to believe that an initial block will execute before an always block. In fact, it is better to think of the initial-block as a special-case of the always-block, one which terminates after it completes for the first time.\n//Examples:\ninitial\nbegin\na = 1; // Assign a value to reg a at time 0\n#1; // Wait 1 time unit\nb = a; // Assign the value of reg a to reg b\nend\nalways @(a or b) // Anytime a or b CHANGE, run the process\nbegin\nif (a)\nc = b;\nelse\nd = ~b;\nend // Done with this block, now return to the top (i.e. the @ event-control)\nalways @(posedge a)// Run whenever reg a has a low to high change\na <= b;\nThese are the classic uses for these two keywords, but there are two significant additional uses. The most common of these is an always keyword without the @() sensitivity list. It is possible to use always as shown below:\nalways\nbegin // Always begins executing at time 0 and NEVER stops\nclk = 0; // Set clk to 0\n#1; // Wait for 1 time unit\nclk = 1; // Set clk to 1\n#1; // Wait 1 time unit\nend // Keeps executing - so continue back at the top of the begin\nThe always keyword acts similar to the "C" construct while(1) {..} in the sense that it will execute forever.\nThe other interesting exception is the use of the initial keyword with the addition of the forever keyword.\nThe example below is functionally identical to the always example above.\ninitial forever // Start at time 0 and repeat the begin/end forever\nbegin\nclk = 0; // Set clk to 0\n#1; // Wait for 1 time unit\nclk = 1; // Set clk to 1\n#1; // Wait 1 time unit\nend\nFork/Join\nThe fork/join pair are used by Verilog to create parallel processes. All statements (or blocks) between a fork/join pair begin execution simultaneously upon execution flow hitting the fork. Execution continues after the join upon completion of the longest running statement or block between the fork and join.\ninitial\nfork\n$write("A"); // Print Char A\n$write("B"); // Print Char B\nbegin\n#1; // Wait 1 time unit\n$write("C");// Print Char C\nend\njoin\nThe way the above is written, it is possible to have either the sequences "ABC" or "BAC" print out. The order of simulation between the first $write and the second $write depends on the simulator implementation. This illustrates one of the biggest issues with Verilog. You can have race conditions where the language execution order doesn''t guarantee the results.\nRace Conditions\nThe order of execution isn''t always guaranteed within verilog. This can best be illustrated by a classic example. Consider the code snippet below:\ninitial\na = 0;\ninitial\nb = a;\ninitial\nbegin\n#1;\n$display("Value a=%b Value of b=%b",a,b);\nend\nWhat will be printed out for the values of a and b? Well - it could be 0 and 0, or perhaps 0 and X! This all depends on the order of execution of the initial blocks. If the simulators scheduler works from the top of the file to the bottom, then you would get 0 and 0. If it begins from the bottom of the module and works up, then b will receive the initial value of a at the beginning of the simulation before it has been initialized to 0 (the value of any variable not set explicitily is set to X.) This is the way you can experience a race condition in a simulation. So be careful! Note that the 3rd initial block will execute as you expect because of the #1 there. That is a different point on the time wheel beyond time 0, consequently both of the earlier initial blocks have completed execution.\nOperators\nOperator type\nOperator symbols\nOperation performed\nBitwise\n~\n1''s complement\n&\nBitwise AND\n|\nBitwise OR\n^\nBitwise XOR\n~^ or ^~\nBitwise XNOR\nLogical\n!\nNOT\n&&\nAND\n||\nOR\nReduction\n&\nReduction AND\n~&\nReduction NAND\n|\nReduction OR\n~|\nReduction NOR\n^\nReduction XOR\n~^ or ^~\nReduction XNOR\nArithmetic\n+\nAddition\n-\nSubtraction\n-\n2''s complement\n*\nMultiplication\n/\nDivision\n**\nexponent (*Verilog-2001)\nRelational\n>\nGreater than\n<\nLess than\n>=\nGreater than or equal to\n<=\nLess than or equal to\n==\nlogical equality (bit-value 1''bX is removed from comparison)\n!=\nLogical inequality (bit-value 1''bX is removed from comparison)\n===\n4-state logical equality (bit-value 1''bX is taken as literal)\n!==\n4-state Logical inequality (bit-value 1''bX is taken as literal)\nShift\n>>\nLogical Right shift\n<<\nLogical Left shift\n>>>\nArithmetic Right shift (*Verilog-2001)\n<<<\nArithmetic Left shift (*Verilog-2001)\nConcatenation\n{ , }\nConcatenation\nReplication\n{{ }}\nReplication\nConditional\n? :\nConditional\nSystem tasks\nSystem tasks are available to handle simple I/O, and various design measurement functions. All system tasks are prefixed with $ to distinguish them from user tasks and functions. This section presents a short list of the most often used tasks. It is by no means a comprehensive list.\n$display - Print to screen a line followed by an automatic newline.\n$write - Print to screen a line without the newline.\n$swrite - Print to variable a line without the newline.\n$sscanf - Read from variable a format-specified string. (*Verilog-2001)\n$fopen - Open a handle to a file (read or write)\n$fdisplay - Write to file a line followed by an automatic newline.\n$fwrite - Write to file a line without the newline.\n$fscanf - Read from file a format-specified string. (*Verilog-2001)\n$fclose - Close and release an open file-handle.\n$readmemh - Read hex file content into a memory array.\n$readmemb - Read binary file content into a memory array.\n$monitor - Print out all the listed variables when any change value.\n$time - Value of current simulation time.\n$dumpfile - Declare the VCD (Value Change Dump) format output file name.\n$dumpvars - Turn on and dump the variables.\n$dumpports - Turn on and dump the variables in Extended-VCD format.\n$random - Return a random value.\nProgram Language Interface (PLI)\nProgram Language Interface provides a programmer with transferring control from Verilog to a program function written in C language. It is officially deprecated by IEEE Std 1364-2005 in favor of the newer Verilog Procedural Interface, which completely replaces the PLI.\nThe PLI enables Verilog to cooperate with other programs written in the C language such as test harness, Instruction Set Simulator of microcontroller, debugger, and so on. For example, it provides C functions named tf_putlongp() and tf_getlongp() which are used to write and read the argument of the current Verilog task or function, respectively.\nSimulation software\nFor information on Verilog simulators, see List of Verilog Simulators.\nSee also\nAdditional material\nList of Verilog simulators\nWaveform viewer\nSystemVerilog Direct Programming Interface (DPI)\nVerilog Procedural Interface (VPI)\nRelated languages\nVHDL\nSystemC\nSystemVerilog\nOpenVera\nSpecman E\nProperty Specification Language\nWikibooks has a book on the topic of\nProgrammable Logic/Verilog\nVerilog Resources\nwww.testbench.in – Verilog for Functional Verification - free online tutorial with many examples.\nverilog-ams – Accellera Verilog Analog Mixed-Signal Group website.\nAsic-World – Extensive free online tutorial with many examples.\nVerilog.net – Premiere List of Verilog Resources on the Internet.\nDigital Computer Courses ("Politehnica" University of Bucharest).\nQualis Design Corporation (2000-07-20). "Verilog HDL quick reference card".\n1.1. Qualis Design Corporation.\nA Verilog Designers Guide – Doulos. Good for beginners.\nLots of Verilog Examples – asic.co.in.\nOnline Verilog-1995 Quick Reference Guide – Stuart Sutherland of Sutherland HDL, Inc.\nPerl CPAN module for parsing $readmem files\nStandards Development\nIEEE Std 1364-2001 – The official standard for Verilog 2001 (not free).\nIEEE P1364 – Working group for Verilog (inactive).\nIEEE P1800 – Working group for SystemVerilog (replaces above).\nVerilog syntax – A description of the syntax in Backus-Naur form. This predates the IEEE-1364 standard.\nVerilog-AMS – Accellera mixed signal extensions to Verilog\nVerilog 2001 syntax – A heavily linked BNF syntax for Verilog 2001 (generated by EBNF tools).\nVerilog Tools\nNCSim\nNusym Technology\nVCS - A fast Verilog simulator, mainly UNIX-based.\nModelSim - A mixed-languages simulator, supporting Verilog-2001 and SystemVerilog.\nActive HDL - A mixed-languages simulator, supporting Verilog-2001 and SystemVerilog.\nLogicSim - A low-cost Windows-only Verilog simulator.\nVeriLogger Extreme - Verilog 2001 simulator for Windows and Unix\nC-to-Verilog - A tool for compiling C into Verilog.\nOpen Source Verilog Tools\nGPL Cver - An open-source Verilog simulator, supporting Verilog-2001 and the complete Verilog Procedural Interface.\nWave VCD a free vcd waveform viewer for verilog and vhdl. Works with GPL CVer.\nIcarus Verilog - An open-source Verilog simulator and synthesis tool, supporting Verilog-2001 and (partially) Verilog Procedural Interface.\nVerilog AUTOs - An open-source meta-comment system to simplify maintaining Verilog code.\nVerilator - Free Verilog to SystemC/C++ compiler and other utilities\nVeriwell an open source verilog simulation project.\nV-MS an open source verilog and verilog-ams (v* mixed-signal) parser/elaborator framework project.\nCovered - A Verilog code coverage analyzer.\nReferences\nThomas, Donald, Moorby, Phillip "The Verilog Hardware Description Language" Kluwer Academic Publishers, Norwell, MA. ISBN 0-7923-8166-1\n[1] Cornell ECE576 Course illustrating synthesis constructs\nJanick Bergerdon, "Writing Testbenches: Functional Verification of HDL Models", 2000, ISBN 0-7923-7766-4. (The HDL Testbench Bible)\n"http://en.wikipedia.org/wiki/Verilog"\nCategories: Hardware description languages | IEEE DASC standards','\n',char(10)));
INSERT INTO pages VALUES('Simula','http://web.archive.org/web/20090425231506/http://en.wikipedia.org:80/wiki/Simula','en','2009-04-25 00:00:00',replace('This article needs additional citations for verification. Please help improve this article by adding reliable references (ideally, using inline citations). Unsourced material may be challenged and removed. (January 2008)\nThis article includes a list of references or external links, but its sources remain unclear because it lacks inline citations. Please improve this article by introducing more precise citations where appropriate. (January 2008)\nSimula\nParadigm\nobject-oriented\nAppeared in\n1967\nDesigned by\nOle-Johan Dahl, Kristen Nygaard\nMajor implementations\nGNU Cim\nInfluenced by\nALGOL 60\nInfluenced\nObject-oriented programming languages\nSimula is a name for two programming languages, Simula I and Simula 67, developed in the 1960s at the Norwegian Computing Center in Oslo, by Ole-Johan Dahl and Kristen Nygaard. Syntactically, it is a fairly faithful superset of Algol 60. [1]\nSimula 67 introduced objects, classes, subclasses, virtual methods, coroutines, discrete event simulation, and features garbage collection.\nSimula is considered the first object-oriented programming language. As its name implies, Simula was designed for doing simulations, and the needs of that domain provided the framework for many of the features of object-oriented languages today.\nSimula has been used in a wide range of applications such as simulating VLSI designs, processes, protocols, algorithms, and other applications such as typesetting, computer graphics, and education. Since Simula-type objects are reimplemented in C++, Java and C# the influence of Simula is often understated. The creator of C++, Bjarne Stroustrup, has acknowledged that Simula 67 was the greatest influence on him to develop C++, to bring the kind of productivity enhancements offered by Simula to the raw computational speed offered by lower level languages like BCPL.\n1 History [2]\n2 Sample Code\n2.1 Minimal program\n2.2 Classic Hello world\n2.3 Classes, subclasses and virtual methods\n2.4 Call by name\n2.5 Simulation\n3 See also\n4 References\n5 Source\n6\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory [2]\nKristen Nygaard started writing computer simulation programs in 1957. Nygaard saw a need for a better way of describing the heterogeneity and the operation of a system. To go further with his ideas on a formal computer language for describing a system, Nygaard realized that he needed someone with more programming skills than he had. Ole-Johan Dahl joined him on his work January 1962. The decision of linking the language up to Algol 60 was made shortly after. By May 1962 the main concepts for a simulation language were set. "SIMULA I" was born, a special purpose programming language for simulating discrete event systems.\nKristen Nygaard was invited to Univac late May 1962 in connection with the marketing of their new UNIVAC 1107 computer. At that visit Nygaard presented the ideas of Simula to Robert Bemer, the director of systems programming at Univac. Bemer was a sworn ALGOL fan and found the Simula project compelling. Bemer was also chairing a session at the second international conference on information processing hosted by IFIP. He invited Nygaard, who presented the paper "SIMULA -- An Extension of ALGOL to the Description of Discrete-Event Networks".\nNorwegian Computing Center got a UNIVAC 1107 August 1963 at a considerable discount, on which Dahl implemented the SIMULA I under contract with Univac. The implementation was based on the UNIVAC Algol 60 compiler. SIMULA I was fully operational on UNIVAC 1107 January 1965. In the following couple of years Dahl and Nygaard spent a lot of time teaching Simula. Simula spread to several countries around the world and SIMULA I was later implemented on Burroughs B5500 computers and the Russian URAL-16 computer.\nIn 1966 C. A. R. Hoare introduced the concept of record class construct, which Dahl and Nygaard extended with the concept of prefixing and other features to meet their requirements for a generalized process concept. Dahl and Nygaard presented their paper on Class and Subclass Declarations at the IFIP Working Conference on simulation languages in Oslo, May 1967. This paper became the first formal definition of Simula 67. In June 1967 a conference was held to standardize the language and initiate a number of implementations. Dahl proposed to unify the Type and the Class concept. This led to serious discussions, and the proposal was rejected by the board. SIMULA 67 was formally standardized on the first meeting of the SIMULA Standards Group (SSG) in February 1968.\nSimula was influential in the development of Smalltalk and later object-oriented programming languages. It also helped inspire the Actor model of concurrent computation although Simula only supports co-routines and not true concurrency.\nIn the late sixties and the early seventies there were four main implementations of Simula:\nUNIVAC 1100 by NCC\nSystem/360 and System/370 by Swedish Research Institute for National Defence (FOA)\nCDC 3000 by University of Oslo''s Joint Computer Installation at Kjeller\nTOPS-10 by ENEA AB\nThese implementations were ported to a wide range of platforms. The TOPS-10 implemented the concept of public, protected, and private member variables and methods, that later was integrated into Simula 87. Simula 87 is the latest standard and is ported to a wide range of platforms. There are mainly three implementations:\nSimula AS\nLund Simula\nGNU Cim - Download from the University of Oslo ftp site\nIn November 2001 Dahl and Nygaard were awarded the IEEE John von Neumann Medal by the Institute of Electrical and Electronic Engineers "For the introduction of the concepts underlying object-oriented programming through the design and implementation of SIMULA 67". In February 2002 they received the 2001 A. M. Turing Award by the Association for Computing Machinery (ACM), with the citation: "For ideas fundamental to the emergence of object oriented programming, through their design of the programming languages Simula I and Simula 67." Unfortunately neither Dahl, nor Nygaard could make it to the ACM Turing Award Lecture, scheduled to be delivered at the OOPSLA 2002 conference in Seattle, as they both passed away within two months of each other in June and August, respectively.\nSimula Research Laboratory is a research institute named after the Simula language, and Nygaard held a part time position there from the opening in 2001.\nSample Code\nMinimal program\nThe empty computer file is the minimal program in Simula, measured by the size of the source code. It consists of one thing only; a dummy statement.\nHowever, the minimal program is more conveniently represented as an empty block:\nBegin\nEnd;\nIt begins executing and immediately terminates. The language does not have any return value from the program itself.\nClassic Hello world\nNote that Simula is case-insensitive. An example of a Hello world program in Simula:\nBegin\nOutText ("Hello World!");\nOutimage;\nEnd;\nClasses, subclasses and virtual methods\nA more realistic example with use of classes, subclasses and virtual methods:\nBegin\nClass Glyph;\nVirtual: Procedure print Is Procedure print;;\nBegin\nEnd;\nGlyph Class Char (c);\nCharacter c;\nBegin\nProcedure print;\nOutChar(c);\nEnd;\nGlyph Class Line (elements);\nRef (Glyph) Array elements;\nBegin\nProcedure print;\nBegin\nInteger i;\nFor i:= 1 Step 1 Until UpperBound (elements, 1) Do\nelements (i).print;\nOutImage;\nEnd;\nEnd;\nRef (Glyph) rg;\nRef (Glyph) Array rgs (1 : 4);\n! Main program;\nrgs (1):- New Char (''A'');\nrgs (2):- New Char (''b'');\nrgs (3):- New Char (''b'');\nrgs (4):- New Char (''a'');\nrg:- New Line (rgs);\nrg.print;\nEnd;\nThe above example has one super class (Glyph) with two subclasses (Char and Line). There is one virtual method with two implementations. The execution starts by executing the main program. Simula does not have the concept of abstract classes since classes with pure virtual methods can be instantiated. This means that in the above example all classes can be instantiated. Calling a pure virtual method will however produce a runtime error.\nCall by name\nSimula supports call by name so the Jensen''s Device can easily be implemented. However, the default transmission mode for simple parameter is call by name in ALGOL but call by value in Simula. The source code for the Jensen''s Device must therefore specify call by name for the parameters when compiled by a Simula compiler.\nAnother much simpler example is the summation function\nwhich can be implemented as follows:\nReal Procedure Sigma (l, m, n, u);\nName l, u;\nInteger l, m, n; Real u;\nBegin\nReal s;\nl:= m;\nWhile l <= n Do Begin s:= s + u; l:= l + 1; End;\nSigma:= s;\nEnd;\nThe above code uses call by name for the controlling variable (l) and the expression (u). This allows the controlling variable to be used in the expression. Note that the Simula standard allows for certain restrictions on the controlling variable in a for loop. The above code therefore uses a while loop for maximum portability.\nThe following:\ncan then be implemented as follows:\nZ:= Sigma (i, 1, 100, 1 / (i + a) ** 2);\nSimulation\nSimula includes a simulation package for doing discrete event simulations. This simulation package is based on Simulas object oriented features and its coroutine concept.\nSam, Sally, and Andy are shopping for clothes. They have to share one fitting room. Each one of them is browsing the store for about 12 minutes and then uses the fitting room exclusively for about three minutes, each following a normal distribution. A simulation of their fitting room experience is as follows:\nSimulation Begin\nClass FittingRoom; Begin\nRef (Head) door;\nBoolean inUse;\nProcedure request; Begin\nIf inUse Then Begin\nWait (door);\ndoor.First.Out;\nEnd;\ninUse:= True;\nEnd;\nProcedure leave; Begin\ninUse:= False;\nActivate door.First;\nEnd;\ndoor:- New Head;\nEnd;\nProcedure report (message); Text message; Begin\nOutFix (Time, 2, 0); OutText (": " & message); OutImage;\nEnd;\nProcess Class Person (pname); Text pname; Begin\nWhile True Do Begin\nHold (Normal (12, 4, u));\nreport\n(pname & " is requesting the fitting room");\nfittingroom1.request;\nreport (pname & " has entered the fitting room");\nHold (Normal (3, 1, u));\nfittingroom1.leave;\nreport (pname & " has left the fitting room");\nEnd;\nEnd;\nInteger u;\nRef (FittingRoom) fittingRoom1;\nfittingRoom1:- New FittingRoom;\nActivate New Person ("Sam");\nActivate New Person ("Sally");\nActivate New Person ("Andy");\nHold (100);\nEnd;\nThe main block is prefixed with Simulation for enabling simulation. The simulation package can be used on any block and simulations can even be nested when simulating someone doing simulations.\nThe fitting room object uses a queue (door) for getting access to the fitting room. When someone requests the fitting room and it''s in use they must wait in this queue (Wait (door)). When someone leaves the fitting room the first one (if any) is released from the queue (Activate door.first) and accordingly removed from the door queue (door.First.Out).\nPerson is a subclass of Process and its activity is described using hold (time for browsing the store and time spent in the fitting room) and calls methods in the fitting room object for requesting and leaving the fitting room.\nThe main program creates all the objects and activates all the person objects to put them into the event queue. The main program holds for 100 minutes of simulated time before the program terminates.\nSee also\nObject-oriented programming\nBETA programming language (a modern successor to Simula)\nSimulation language\nALGOL 60\nReferences\n^ Ole-Johan Dahl, Bjørm Myhrhaug, and Kristen Nygaard (1970), :[1], Common Base Language, Norwegian Computing Center, 1.3.1\n^ Jan Rune Holmevik (1995),:[2], Compiling Simula, Institute for Studies in Research and Higher Education, Oslo, Norway\nSource\nCompiling Simula Early history of the development of Simula by Jan Rune Holmevik\nIBM System 360/370 Compiler and Historical Documentation The Simula Standard and other historical documentation by Peter Sylvester\nIntroduction to OOP in Simula – By J.Sklenar, based on the 1997 seminar "30 Years of Object Oriented Programming (OOP)" at the University of Malta\nHow Object-Oriented Programming Started – By Dahl and Nygaard, abbrev. version of an encyclopedia article; on Nygaards home page\nSimula at the Université de Montréal Includes tutorials, documentation, and links in English and in French\nAn Introduction to Programming in Simula A textbook by Rob Pooley now available as HTML\n"http://en.wikipedia.org/wiki/Simula"\nCategories: ALGOL 60 dialects | Class-based programming languages | Simulation programming languagesHidden categories: Articles needing additional references from January 2008 | Articles lacking in-text citations from January 2008','\n',char(10)));
INSERT INTO pages VALUES('PL/I','http://web.archive.org/web/20081204151014/http://en.wikipedia.org./wiki/PL/I','en','2008-12-04 00:00:00',replace('PL/I\nParadigm\nimperative, structured\nAppeared in\n1964\nDesigned by\nHursley Laboratories\nDeveloper\nIBM\nDialects\nPL/M, XPL, PL/P, PL/C, PL/S, PL/AS, PL/X, PL/8, EPL\nInfluenced by\nCOBOL, Fortran, ALGOL,\nPL/I ("Programming Language One", pronounced /ˌpiːˌɛlˈwʌn/) is an imperative computer programming language designed for scientific, engineering, and business applications. It is one of the most feature-rich programming languages and one of the very first in the highly-feature-rich category. It has been used by various academic, commercial and industrial users since it was introduced in the early 1960s, and is still actively used today.\nPL/I''s principal domain is data processing; it supports recursion and structured programming. The language syntax is English-like and suited for describing complex data formats, with a wide set of functions available to verify and manipulate them.\nPL/I is considered by some to be a turning point where it was found that large languages with a lot of complexity that allow programmers to do almost anything (such as coerce types with no semantic relationship to one another) are burdensome and dangerous rather than "more powerful."\n1 History\n2 Retrospective\n2.1 Design and implementation issues\n2.2 Programmer preference issues\n2.3 Improved features\n3 Sample programs\n3.1 Hello world program\n3.2 Search for a string\n4 Variable Names\n5 Automatic storage\n6 Standards\n7 Notes\n8 See also\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nPL/I was developed by IBM, at its Hursley Laboratories in the United Kingdom, as part of the development of System/360. Prior to System/360, IBM made several different incompatible models of mainframes for different purposes: some were designed for business use, others for scientific use. The goal of the System/360 project was to develop one series of compatible models to replace all the previous models, and which could be used equally well for commercial or scientific use.\nNot only did business and scientific users use different machines; they also used different languages. Business users mainly used COBOL, while scientific users used Fortran. The goal of PL/I was to develop a single language usable for both business and scientific purposes. Another goal was to add structured programming constructs derived from ALGOL, which neither COBOL nor Fortran supported (at the time). PL/I was designed by a committee drawn from IBM programmers and users drawn from across the United States, working over several months. IBM originally wanted PL/I to be ready for use by the launch of System/360, but unfortunately this deadline could not be met.\nThe language was originally to be called NPL, for "New Programming Language"; but that abbreviation could not be used because it was the name of the National Physical Laboratory in the UK. The ''NPL'' name was in effect between March 1 and November 30 in 1964. MPL and MPPL were considered before settling on PL/1.[1] (This was a parallel to IBM''s forthcoming database access language, Data Language/1).\nCompilers were implemented by several groups in the early 1960s. The Multics project at MIT, one of the first to develop an operating system in a high level language, used Early PL/I (EPL), a subset dialect of PL/I, as their implementation language in 1964. EPL was developed at Bell Labs and MIT by Douglas McIlroy, Robert Morris, and others.\nAlthough PL/I did not have immense universal populari','\n',char(10)));
INSERT INTO pages VALUES('S-PLUS','http://web.archive.org/web/20090208111104/http://en.wikipedia.org:80/wiki/S-PLUS','en','2009-02-08 00:00:00',replace('S-PLUS\nDeveloped by\nTIBCO Software Inc.\nLatest release\n8.1.1 / 14 November 2008; 86 days ago\nOS\nWindows, Unix/Linux\nType\nstatistical package\nLicense\nproprietary\nWebsite\nS-PLUS\nS-PLUS is a commercial advanced statistics package sold by TIBCO Software Inc.. It is a commercial implementation of the S programming language.\nIt features object-oriented programming capabilities and advanced analytical algorithms.\nTIBCO announced in June 2008 that they had agreed to acquire Insightful Corporation,[1] and in September 2008 that the acquisition was complete.[2]\n1 Historical timeline\n2 Additional functionality\n3 See also\n4\n5 References\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistorical timeline\n1988: S-PLUS is first produced by a Seattle-based start-up company called Statistical Sciences, Inc. The founder and sole owner is R. Douglas Martin, professor of statistics at the University of Washington, Seattle.\n1993: Statistical Sciences acquires the exclusive license to distribute S and merges with MathSoft, becoming the firm''s Data Analysis Products Division (DAPD).\n1995: S-PLUS 3.3 for Windows 95/NT. Matrix library, command history, Trellis graphics\n1996: S-PLUS 3.4 for UNIX. Trellis graphics, nlme library, hexagonal binning, cluster methods.\n1997: S-PLUS 4 for Windows. New GUI, integration with Excel, editable graphics.\n1998: S-PLUS 4.5 for Windows. Scatterplot brushing, create S-PLUS graphs from within Excel & SPSS.\n1998: S-PLUS is available for Linux & Solaris.\n1999: S-PLUS 5 for Solaris, Linux, HP-UX, IBM AIX, SGI Irix, and DEC Alpha. S-PLUS 2000 for Windows. nlme 3.3, quality control charting, new commands for data manipulation.\n2000: S-PLUS 6 for Linux/UNIX. Java-based GUI, Graphlets, survival5, missing data library, robust library.\n2001: MathSoft sells its Cambridge-based Engineering and Education Products Division (EEPD), changes name to Insightful Corporation, and moves headquarters to Seattle. This move is basically an "Undo" of the previous merger between MathSoft and Statistical Sciences, Inc.\n2001: S-PLUS Analytic Server 2.0. S-PLUS 6 for Windows (Excel integration, C++ classes/libraries for connectivity, Graphlets, S version 4, missing data library, robust library).\n2002: StatServer 6. Student edition of S-PLUS now free.\n2003: S-PLUS 6.2 New reporting, database integration, improved Graphlets, ported to AIX, libraries for correlated data, Bayesian methods, multivariate regressions.\n2004: Insightful purchases the S language from Lucent Technologies for $2 million.\n2004: S+ArrayAnalyzer 2.0 released.\n2005: S-PLUS 7.0 released. BigData library for working with larger-than-memory data sets, S-PLUS Workbench (Eclipse development tool). Insightful Miner 7.0 released.\n2007: S-PLUS 8 released. New package system, language extensions for R package compatibility, Workbench debugger.\nAdditional functionality\nS-PLUS users can also install additional modules which extend the functionality of S-PLUS with regard to specific applications. These are code libraries which are also developed by the Insightful Corporation and which can be executed directly.\nS+ArrayAnalyzer: Microarray analysis\nS+FinMetrics: financial econometrics\nS+NuOPT: large-scale constrained optimization\nS+SeqTrial: Clinical trial design and analysis\nS+SpatialStats: analysis of spatial data\nS+Wavelets: wavelet and signal series analysis\nFAME S+Connector: integration module for S-PLUS and FAME\nS+EnvironmentalStats: environmental statistics\nSee also\nR programming language\nS-PLUS homepage\nReferences\n^ TIBCO announces agreement to acquire Insightful Corporation, press release, TIBCO Software Inc., June 19, 2008.\n^ TIBCO Completes Acquisition of Insightful Corporation, press release, TIBCO Software Inc., September 3, 2008.\nv • d • e\nStatistical software\nPublic domain\nDataplot · Epi Info · CSPro · X-12-ARIMA\nOpen source\ngretl · JMulTi · OpenBUGS · PSPP · R · Simfit\n· XLispStat · DAP\nFreeware\nADMB · BV4.1\nRetail\nBMDP · EViews · GAUSS · GenStat · JMP · Mathematica · MedCalc · Minitab · NCSS · OxMetrics · RATS · SAS · SigmaStat · SPSS · Stata · STATISTICA · StatXact · SUDAAN · SYSTAT · S-PLUS\n· The Unscrambler\nCategory\n• Comparison\n"http://en.wikipedia.org/wiki/S-PLUS"\nCategory: Statistical software','\n',char(10)));
INSERT INTO pages VALUES('Stata','http://web.archive.org/web/20090301110025/http://en.wikipedia.org:80/wiki/Stata','en','2009-03-01 00:00:00',replace('Stata\nStata 10.0 on Windows\nDeveloped by\nStataCorp\nLatest release\n10.1 / 2008-08-11; 202 days ago\nOS\nWindows, Mac OS X, Unix, Linux\nType\nstatistical analysis\nLicense\nproprietary\nWebsite\nwww.stata.com\nStata is a general-purpose statistical software package created in 1985 by StataCorp. It is used by many businesses and academic institutions around the world. Most of its users work in research, especially in the fields of economics, sociology, political science, and epidemiology.\nStata''s full range of capabilities includes:\nData management\nStatistical analysis\nGraphics\nSimulations\nCustom programming\nThe name "Stata" was formed by blending "statistics" and "data"; it is not an acronym and therefore should not appear with all letters capitalised (i.e. as STATA)[1]. There is no correct way to pronounce "Stata", any of "Stay-ta", "Sta-ta" or "Stah-ta" are considered acceptable[2].\n1 User interface\n2 Data structure and storage\n3 Extensibility\n4 User community\n5 Example Stata code\n6 Timeline of releases\n7 See also\n8 References\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nUser interface\nSince version 8.0, Stata has included a graphical user interface which uses menus and dialog boxes to give access to nearly all built-in commands. This generates code which is always displayed, easing the transition to the command line interface and more flexible scripting language. The dataset can be viewed or edited in spreadsheet format, but this must be closed before other commands are executed.\nData structure and storage\nStata can only open a single dataset at any one time. Stata holds the entire dataset in (random-access or virtual) memory, which limits its use with extremely large datasets. This is mitigated to some extent by efficient internal storage, as there are integer storage types which occupy only one or two bytes rather than four, and single-precision (4 bytes) rather than double-precision (8 bytes) is the default for floating-point numbers.\nThe dataset is always rectangular in format, that is, all variables hold the same number of observations (in more mathematical terms, all vectors have the same length, although some entries may be missing values).\nStata''s file formats are platform independent, so users of different operating systems can easily exchange datasets and programs. Additionally, in reference to Stata''s datasets, Stata 10 is backward compatible with regard to Stata 8 and Stata 9, but Stata 8 and Stata 9 are not, by default, forward compatible with regard to Stata 10. In other words, Stata 10 can open datasets that were created in Stata 8 and Stata 9, but Stata 8 and Stata 9 are unable to open datasets that were created in Stata 10, unless the Stata 10 user saves the file in the older format, by using the saveold command[3], or installs the use10 module[4].\nExtensibility\nStata is unusual among commercial statistics packages in allowing user-written commands, distributed as so called ado-files, to be straightforwardly downloaded from the internet which are then indistinguishable to the user from the built-in commands. In this respect, Stata combines the extensibility more often associated with open-source packages with features usually associated with commercial packages such as software verification, technical support and professional documentation. Some user-written commands have later been adopted by StataCorp to become part of a subsequent official release after appropriate checking, certification and documentation.\nUser community\nStata has an active email list (Statalist, over 1000 messages per month), to which StataCorp employees regularly contribute. Statalist is maintained by Marcello Pagano, Harvard School of Public Health not by StataCorp itself. Articles about the use of Stata and new user-written commands are published in the quarterly peer-reviewed Stata Journal. User group meetings are held annually in the USA, the UK, Germany and Italy, and less frequently in several other countries.\nExample Stata code\nTo perform logistic regression of y on x:\nlogistic y x\nTo display a scatter plot of y against x restricted to values of x below 10:\nscatter y x if x < 10\nTimeline of releases\nIn recent years, StataCorp have released a new major release of Stata (incrementing the integer part of the version number) roughly every two years. Users must pay a fee if they wish to upgrade to the latest major release. Minor releases (incrementing the decimal part of the version number) are sometimes made available in between major releases. These are available as free downloadable updates to those who have a licence for the previous major release. Dates of all releases are available on the Stata website[5]. Stata''s version control system is designed to give a very high degree of backward compatibility, ensuring that code written for previous releases continues to work.\nSee also\nList of statistical packages\nComparison of statistical packages\ngretl - an open source package for econometric analysis that can import Stata data files\nReferences\n^ What is the correct way to write ‘Stata’?\n^ What is the correct way to pronounce ‘Stata’?\n^ Stata''s ''help'' entry for the save command\n^ USE10: Stata module to use and describe version 10 datafiles in Stata 9.2\n^ History of Stata\nOfficial Stata website\nStata Journal\nExtensive Introduction to Stata - Kit Baum (Boston College)\nUCLA Stata Portal\nUCLA ATS Resources to help you learn Stata - Resources for learning Stata\nUCLA ATS Technical Reports - See Technical Report #1. Strategically using General Purpose Statistics Packages: A Look at Stata, SAS and SPSS\nStata Highlights Page - Demonstrates how Stata can be used for several basic and advanced statistical procedures\nIdeas Repec Statistical Software Components - The main archive of user-written add-on programs (ado-files) for Stata\nv • d • e\nStatistical software\nPublic domain\nDataplot · Epi Info · CSPro · X-12-ARIMA\nOpen source\nADMB · DAP · gretl · JMulTi · OpenBUGS · PSPP · R · Simfit\n· XLispStat · Yxilon\nFreeware\nBV4.1 · XploRe\nRetail\nCross-platform\nData Desk · GAUSS · GraphPad Prism · JMP · Mathematica · OxMetrics · RATS · SAS · SPSS · Stata · SUDAAN · S-PLUS\nWindows only\nBMDP · EViews · GenStat · MedCalc · Minitab · NCSS · SigmaStat · STATISTICA · StatXact · SYSTAT · The Unscrambler\nCategory\n• Comparison\n"http://en.wikipedia.org/wiki/Stata"\nCategory: Statistical software','\n',char(10)));
INSERT INTO pages VALUES('Smalltalk','http://web.archive.org/web/20081221010938/http://en.wikipedia.org:80/wiki/Smalltalk','en','2008-12-21 00:00:00',replace('This article is about the programming language.\nFor other uses, see Small talk.\nSmalltalk\nParadigm\nobject-oriented\nAppeared in\nDevelopment started in 1969\nPublicly available in 1980\nDesigned by\nAlan Kay, Dan Ingalls, Adele Goldberg\nDeveloper\nAlan Kay, Dan Ingalls, Adele Goldberg, Ted Kaehler, Scott Wallace, and Xerox PARC\nTyping discipline\ndynamic\nMajor implementations\nSqueak, VisualWorks\nInfluenced by\nLisp, Simula\nInfluenced\nObjective-C, Self, Java, Dylan, AppleScript, Lisaac, NewtonScript, Python, Ruby, Scala, Perl 6\nSmalltalk is an object-oriented, dynamically typed, reflective programming language. Smalltalk was created as the language to underpin the "new world" of computing exemplified by "human–computer symbiosis."[1] It was designed and created in part for educational use, more so for constructionist learning, at Xerox PARC by Alan Kay, Dan Ingalls, Adele Goldberg, Ted Kaehler, Scott Wallace, and others during the 1970s, influenced by Lisp, Logo, Sketchpad and Simula.\nThe language was first generally released as Smalltalk-80 and has been widely used since. Smalltalk-like languages are in continuing active development, and have gathered loyal communities of users around them. ANSI Smalltalk was ratified in 1998 and represents the standard version of Smalltalk.\n1 History\n2 Influences\n3 Object-oriented programming\n4 Reflection\n5 Syntax\n5.1 Literals\n5.2 Variable declarations\n5.3 Assignment\n5.4 Messages\n5.5 Expressions\n5.6 Code blocks\n6 Control structures\n7 Classes\n7.1 Methods\n7.2 Instantiating classes\n8 Hello World example\n9 Image-based persistence\n10 Level of access\n11 Just-in-time compilation\n12 List of implementations\n13 References\n14\n15 Books\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nThere are a large number of Smalltalk variants, as there are with many computer languages.[2] The unqualified word Smalltalk is often used to indicate the Smalltalk-80 language, the first version to be made publicly available and created in 1980.\nSmalltalk was the product of research by a group of researchers led by Alan Kay at Xerox Palo Alto Research Center (PARC); Alan Kay designed most of the early Smalltalk versions, which Dan Ingalls implemented. The first version, known as Smalltalk-71, was created in a few mornings on a bet that a programming language based on the idea of message passing inspired by Simula could be implemented in "a page of code."[1] A later variant actually used for research work is now known as Smalltalk-72 and influenced the development of the Actor model. Its syntax and execution model were very different from modern Smalltalk variants.\nAfter significant revisions which froze some aspects of execution semantics to gain performance (by adopting a Simula-like class inheritance model of execution), Smalltalk-76 was created. This system had a development environment featuring most of the tools now familiar including a class library code browser/editor. Smalltalk-80 added metaclasses, to help maintain the "everything is an object" (except variables) paradigm by associating properties and behavior with individual classes, and even primitives such as integer and boolean values (for example, to support different ways of creating instances).\nSmalltalk-80 was the first language variant made available outside of PARC, first as Smalltalk-80 Version 1, given to a small number of companies (Hewlett-Packard, Apple Computer, Tektronix, and DEC) and universities (UC Berkeley) for "peer review" and implementation on their platforms. Later (in 1983) a general availability implementation, known as Smalltalk-80 Version 2, was released as an image (platform-independent file with object definitions) and a virtual machine specification. ANSI Smalltalk has been the standard language reference since 1998.[3]\nTwo of the currently popular Smalltalk implementation variants are descendants of those original Smalltalk-80 images. Squeak is an open source implementation derived from Smalltalk-80 Version 1 by way of Apple Smalltalk. VisualWorks is derived from Smalltalk-80 version 2 by way of Smalltalk-80 2.5 and ObjectWorks (both products of ParcPlace Systems, a Xerox PARC spin-off company formed to bring Smalltalk to the market). As an interesting link between generations, in 2002 Vassili Bykov implemented Hobbes, a virtual machine running Smalltalk-80 inside VisualWorks.[4] (Dan Ingalls later ported Hobbes to Squeak).\nDuring the late 1980s to mid-1990s, Smalltalk environments — including support, training and add-ons — were sold by two competing organizations: ParcPlace Systems and Digitalk, both California based. ParcPlace Systems tended to focus on the Unix/Sun Microsystems market, while Digitalk emphasized Intel-based PCs that were running either Microsoft Windows or IBM''s OS/2. Both companies, however, struggled to take Smalltalk mainstream due to Smalltalk''s substantial memory footprint, limited run-time performance, and initially lack of supported connectivity to SQL-based relational database servers. While the high price point of the ParcPlace Smalltalk limited its market penetration to mid-sized and large commercial organizations, the Digitalk products initially tried to reach a wider audience with a lower price point. IBM having initially supported the Digitalk product entered the market with a Smalltalk product in 1995 called VisualAge/Smalltalk. Easel introduced Enfin at this time on Windows and OS/2. Enfin became much more popular in Europe, as IBM introduced it into IT shops prior to their development of IBM Smalltalk (later VisualAge). Enfin was later acquired by Cincom Systems, and is now sold under the name ObjectStudio, and is part of the Cincom Smalltalk product suite.\nIn 1995, ParcPlace and Digitalk merged into ParcPlace-Digitalk and then rebranded in 1997 as ObjectShare, located in Irvine, CA. ObjectShare (NASDAQ: OBJS) was traded publicly until 1999, when it was delisted and dissolved. The merged company never managed to find an effective response to Java in terms of market positions and by 1997 its owners were looking to sell the business. In 1999, Seagull Software acquired the Java development lab of ObjectShare (original Smalltalk/V, Visual Smalltalk development team), and still owns VisualSmalltalk, although worldwide distribution rights for the Smalltalk product remained with ObjectShare.[5] VisualWorks was sold to Cincom and is now part of Cincom Smalltalk. Cincom has backed Smalltalk quite strongly, putting out multiple new releases of VisualWorks and ObjectStudio each year since 1999.\nCincom, Gemstone and Object Arts, plus other vendors continue to sell Smalltalk environments, IBM has ''end of life''d VisualAge Smalltalk having in the late 1990s decided to back Java and it is, as of 2006, supported by Instantiations, Inc. which has renamed the product VASmalltalk and released a new version. The open Squeak implementation has an active community of developers, including many of the original Smalltalk community, and has recently been used to provide the Etoys environment on the OLPC project and the virtual worlds environment Croquet Project. GNU Smalltalk is a free software implementation of a derivative of Smalltalk-80 from the GNU project.\nA significant development, that has spread across all current Smalltalk environments, is the increasing usage of the Seaside and AIDA/Web web frameworks to simplify the building of complex web applications.\nInfluences\nPlease help improve this section by expanding it. Further information might be found on the talk page. (October 2007)\nSmalltalk has influenced the wider world of computer programming in four main areas. It inspired the syntax and semantics of other computer programming languages. Secondly, it was a prototype for a model of computation known as message passing. Thirdly, its WIMP GUI inspired the windowing environments of personal computers in the late twentieth and early twenty-first centuries, so much so that the windows of the first Macintosh desktop look almost identical to the MVC windows of Smalltalk-80. Finally, the integrated development environment was the model for a generation of visual programming tools that look like Smalltalk''s code browsers and debuggers.\nSmalltalk laid the groundwork and proved all the principles that led to the development and commercial success of Java.\nPython and Ruby have reimplemented some Smalltalk ideas with syntaxes similar to that of C or Java. The Smalltalk "metamodel" also serves as the inspiration for the object model design of Perl 6.\nThere is also a modular Smalltalk-like implementation designed for scripting called S# (S-Sharp). S# uses just-in-time compilation technology and supports an extended Smalltalk-like language written by David Simmons of Smallscript Corp.[6][7]\nObject-oriented programming\nMain article: Object-oriented programming\nAs in other object-oriented languages, the central concept in Smalltalk-80 (but not in Smalltalk-72) is that of an object. An object is always an instance of a class. Classes are "blueprints" that describe the properties and behavior of their instances. For example, a Window class would declare that windows have properties such as the label, the position and whether the window is visible or not. The class would also declare that instances support operations such as opening, closing, moving and hiding. Each particular Window object would have its own values of those properties, and each of them would be able to perform operations defined by its class.\nA Smalltalk object can do exactly three things:\nHold state (references to other objects).\nReceive a message from itself or another object.\nIn the course of processing a message, send messages to itself or another object.\nThe state an object holds is always private to that object. Other objects can query or change that state only by sending requests (messages) to the object to do so. Any message can be sent to any object: when a message is received, the receiver determines whether that message is appropriate. (Alan Kay has commented that despite the attention given to objects, messaging is the most important concept in Smalltalk.)\nSmalltalk is a ''pure'' OO language, meaning that, unlike Java and C++, there is no difference between values which are objects and values which are primitive types. In Smalltalk, primitive values such as integers, booleans and characters are also objects, in the sense that they are instances of corresponding classes, and operations on them are invoked by sending messages. A programmer can change the classes that implement primitive values, so that new behavior can be defined for their instances--for example, to implement new control structures--or even so that their existing behavior will be changed. This fact is summarised in the commonly heard phrase "In Smalltalk everything is an object" (which would more accurately be expressed as "all values are objects", as variables aren''t).\nSince all values are objects, classes themselves are also objects. Each class is an instance of the metaclass of that class. Metaclasses in turn are also objects, and are all instances of a class called Metaclass. Code blocks are also objects.\nReflection\nSmalltalk-80 is a totally reflective system, implemented in Smalltalk-80 itself. Smalltalk-80 provides both structural and computational reflection. Smalltalk is a structurally reflective system whose structure is defined by Smalltalk-80 objects. The classes and methods that define the system are themselves objects and fully part of the system that they help define. The Smalltalk compiler compiles textual source code into method objects, typically instances of CompiledMethod. These get added to classes by storing them in a class''s method dictionary. The part of the class hierarchy that defines classes can add new classes to the system. The system is extended by running Smalltalk-80 code that creates or defines classes and methods. In this way a Smalltalk-80 system is a "living" system, carrying around the ability to extend itself at run time.\nSince the classes are themselves objects, they can be asked questions such as "what methods do you implement?" or "what fields/slots/instance variables do you define?". So objects can easily be inspected, copied, (de)serialized and so on with generic code that applies to any object in the system.\nSmalltalk-80 also provides computational reflection, the ability to observe the computational state of the system. In languages derived from the original Smalltalk-80 the current activation of a method is accessible as an object named via a keyword, thisContext. By sending messages to thisContext a method activation can ask questions like "who sent this message to me". These facilities make it possible to implement co-routines or Prolog-like back-tracking without modifying the virtual machine. One of the more interesting uses of this is in the Seaside web framework which relieves the programmer of dealing with the complexity of a Web Browser''s back button by storing continuations for each edited page and switching between them as the user navigates a web site. Programming the web server using Seaside can then be done using a more conventional programming style.\nWhen an object is sent a message that it does not implement, the virtual machine sends the object the doesNotUnderstand: message with a reification of the message as an argument. The message (another object, an instance of Message) contains the selector of the message and an Array of its arguments. In an interactive Smalltalk system the default implementation of doesNotUnderstand: is one that opens an error window reporting the error to the user. Through this and the reflective facilities the user can examine the context in which the error occurred, redefine the offending code, and continue, all within the system, using Smalltalk-80''s reflective facilities.\nYet another important use of doesNotUnderstand: is intercession. One can create a class that does not define any methods other than doesNotUnderstand: and does not inherit from any other class. The instances of this class effectively understand no messages. So every time a message is sent to these instances they actually get sent doesNotUnderstand:, hence they intercede in the message sending process. Such objects are called proxies. By implementing doesNotUnderstand: appropriately, one can create distributed systems where proxies forward messages across a network to other Smalltalk systems (a facility common in systems like CORBA, COM+ and RMI but first pioneered in Smalltalk-80 in the 1980s), and persistent systems where changes in state are written to a database and the like. An example of this latter is Logic Arts'' VOSS (Virtual Object Storage System) available for VA Smalltalk under dual open source and commercial licensing.\nSyntax\nSmalltalk-80 syntax is rather minimalist, based on only a handful of declarations and reserved words. In fact, only six keywords are reserved in Smalltalk: true, false, nil, self, super and thisContext. (These are not actually keywords, but pseudo-variables. The true, false, and nil pseudo-variables are singleton instances. Smalltalk does not really define any keywords.) The only built-in language constructs are message sends, assignment, method return and literal syntax for some objects. From its origins as a teaching language, standard Smalltalk syntax uses punctuation in a manner more like English than mainstream coding languages. The remainder of the language, including control structures for conditional evaluation and iteration, is implemented on top of the built-in constructs by the standard Smalltalk class library. (For performance reasons implementations may recognize and treat as special some of those messages; however, this is only an optimization, not hardwired into the language syntax).\nLiterals\nThe following examples illustrate the most common objects which can be written as literal values in Smalltalk-80 methods.\nNumbers. The following list illustrates some of the possibilities.\n42\n-42\n123.45\n1.2345e2\n2r10010010\n16rA000\nThe last two entries are a binary and a hexadecimal number, respectively. The number before the ''r'' is the radix or base. The base does not have to be a power of two; for example 36rSMALLTALK is a valid number (for the curious, equal to 80738163270632 decimal).\nCharacters are written by preceding them with a dollar sign:\n$A\nStrings are sequences of characters enclosed in single quotes:\n''Hello, world!''\nTo include a quote in a string, escape it using a second quote:\n''I said, ''''Hello, world!'''' to them.''\nDouble quotes do not need escaping, since single quotes delimit a string:\n''I said, "Hello, world!" to them.''\nTwo equal strings (strings are equal if they contain all the same characters) can be different objects residing in different places in memory. In addition to strings, Smalltalk has a class of character sequence objects called Symbol. Symbols are guaranteed to be unique--there can be no two equal symbols which are different objects. Because of that, symbols are very cheap to compare and are often used for language artifacts such as message selectors (see below).\nSymbols are written as # followed by characters. For example:\n#foo\nArrays:\n#(1 2 3 4)\ndefines an array of four integers.\nAnd last but not least, blocks (anonymous function literals)\n[... Some smalltalk code...]\nBlocks are explained in detail further in the text.\nMany Smalltalk dialects implement additional syntaxes for other objects, but the ones above are the bread and butter supported by all.\nVariable declarations\nThe two kinds of variable commonly used in Smalltalk are instance variables and temporary variables. Other variables and related terminology depend on the particular implementation. For example, VisualWorks has class shared variables and namespace shared variables, while Squeak and many other implementations have class variables, pool variables and global variables.\nTemporary variable declarations in Smalltalk are variables declared inside a method (see below). They are declared at the top of the method as names separated by spaces and enclosed by vertical bars. For example:\n| index |\ndeclares a temporary variable named index. Multiple variables may be declared within one set of bars:\n| index vowels |\ndeclares two variables: index and vowels.\nAssignment\nA variable is assigned a value via the '':='' syntax. So:\nvowels := ''aeiou''\nAssigns the string ''aeiou'' to the previously declared vowels variable. The string is an object (a sequence of characters between single quotes is the syntax for literal strings), created by the compiler at compile time.\nIn the original Parc Place image, the glyph of the underscore character (_) appeared as a left-facing arrow. Smalltalk originally accepted this left-arrow as the only assignment operator. Some modern code still contains what appear to be underscores acting as assignments, harking back to this original usage. Most modern Smalltalk implementations accept either the underscore or the colon-equals syntax.\nMessages\nThe message is the most fundamental language construct in Smalltalk. Even control structures are implemented as message sends. Smalltalk adopts by default a synchronous, single dynamic message dispatch strategy (as contrasted to a synchronous, multiple dispatch strategy adopted by some other object-oriented languages).\nThe following example sends the message ''factorial'' to number 42:\n42 factorial\nIn this situation 42 is called the message receiver, while ''factorial'' is the message selector. The receiver responds to the message by returning a value (presumably in this case a factorial of 42). Among other things, the result of the message can be assigned to a variable:\naRatherBigNumber := 42 factorial\n"factorial" above is what is called a unary message because only one object, the receiver, is involved. Messages can carry additional objects as arguments, as follows:\n2 raisedTo: 4\nIn this expression two objects are involved: 2 as the receiver and 4 as the message argument. The message result, or in Smalltalk parlance, the answer is supposed to be 16. Such messages are called keyword messages. A message can have more arguments, using the following syntax:\n''hello world'' indexOf: $o startingAt: 6\nwhich answers the index of character ''o'' in the receiver string, starting the search from index 6. The selector of this message is "indexOf:startingAt:", consisting of two pieces, or keywords.\nSuch interleaving of keywords and arguments greatly improves readability of code, since arguments are explained by their preceding keywords. For example, an expression to create a rectangle using a C++ or Java-like syntax might be written as:\nnew Rectangle(100, 200);\nIt''s unclear which argument is which—is the argument order (width, height) or (height, width)? In Java, you have to look up the API online to find out that the class''s argument-order is, in fact, (width, height). By contrast, in Smalltalk, this code would be written unambiguously as:\nRectangle width: 100 height: 200\nThe receiver in this case is "Rectangle", a class, and the answer will be a new instance of the class with the specified width and height.\nFinally, most of the special (non-alphabetic) characters can be used as what are called binary messages. These allow mathematical and logical operators to be written in their traditional form:\n3 + 4\nwhich sends the message "+" to the receiver 3 with 4 passed as the argument (the answer of which will be 7). Similarly,\n3 > 4\nis the message ">" sent to 3 with argument 4 (the answer of which will be false).\nNotice, that the Smalltalk-80 language itself does not imply the meaning of those operators. The outcome of the above is only defined by how the receiver of the message (in this case a Number instance) responds to messages "+" and ">".\nA side effect of this mechanism is operator overloading. A message ">" can also be understood by other objects, allowing the use of expressions of the form "a > b" to compare them.\nExpressions\nAn expression can include multiple message sends. In this case expressions are parsed according to a simple order of precedence. Unary messages have the highest precedence, followed by binary messages, followed by keyword messages. For example:\n3 factorial + 4 factorial between: 10 and: 100\nis evaluated as follows:\n3 receives the message "factorial" and answers 6\n4 receives the message "factorial" and answers 24\n6 receives the message "+" with 24 as the argument and answers 30\n30 receives the message "between:and:" with 10 and 100 as arguments and answers true\nThe answer of the last message send is the result of the entire expression.\nParentheses can alter the order of evaluation when needed. For example,\n(3 factorial + 4) factorial between: 10 and: 100\nwill change the meaning so that the expression first computes "3 factorial + 4" yielding 10. That 10 then receives the second "factorial" message, yielding 3628800. 3628800 then receives "between:and:", answering false.\nNote that because the meaning of binary messages is not hardwired into Smalltalk-80 syntax, all of them are considered to have equal precedence and are evaluated simply from left to right. Because of this, the meaning of Smalltalk expressions using binary messages can be different from their "traditional" interpretation:\n3 + 4 * 5\nis evaluated as "(3 + 4) * 5", producing 35.\nUnary messages can be chained by writing them one after another:\n3 factorial factorial log\nwhich sends "factorial" to 3, then "factorial" to the result (6), then "log" to the result (720), producing the result 2.85733.\nA series of expressions can be written as in the following (hypothetical) example, each ending with a period. This example first creates a new instance of class Window, stores it in a variable, and then sends two messages to it.\n| window |\nwindow := Window new.\nwindow label: ''Hello''.\nwindow open.\nIf a series of messages are sent to the same receiver as in the example above, they can also be written as a cascade with individual messages separated by semicolons:\n(Window new)\nlabel: ''Hello'';\nopen\nThis rewrite of the earlier example as a single expression avoids the need to store the new window in a temporary variable. According to the usual precedence rules, the unary message "new" is sent first, and then "label:" and "open" are sent to the answer of "new".\nCode blocks\nA block of code (an anonymous function) can be expressed as a literal value (which is an object, since all values are objects.) This is achieved with square brackets:\n[ :params | <message-expressions> ]\nWhere :params is the list of parameters the code can take. This means that the Smalltalk code:\n[:x | x + 1]\ncan be understood as:\nf(x) = x + 1\n(or, expressed using lambda calculus):\nλx.(x+1)\nand\n[:x | x + 1] value: 3\ncan be evaluated as\nf(3) = 3 + 1\nThe resulting block object is a closure. It can (at any time) access the variables of its enclosing lexical scopes. Blocks are first class objects. That is, references to blocks can be passed as arguments, returned as values, or stored as a state, just like any other objects. Blocks can be asked to execute their code by sending them a "value"-message (with one argument for each parameter in the block).\nThe literal representation of blocks was an innovation which allowed certain code to be significantly more readable; it allowed algorithms involving iteration to be coded in a clear and concise way. Code that would typically be written with loops in some languages can be written concisely in Smalltalk using blocks, sometimes in a single line.\npositiveAmounts := allAmounts select: [:amt | amt isPositive]\nNote that this is related to functional programming, wherein patterns of computation (here selection) are abstracted into higher-order functions. For example, the message select: on a Collection is equivalent to the higher-order function filter on an appropriate functor.\nControl structures\nControl structures do not have special syntax in Smalltalk. They are instead implemented as messages sent to objects. For example, conditional execution is implemented by sending the message ifTrue: to a Boolean object, passing as an argument the block of code to be executed if and only if the Boolean receiver is true.\nThe following code demonstrates this:\nresult := a > b\nifTrue:[ ''greater'' ]\nifFalse:[ ''less'' ]\nBlocks are also used to implement user-defined control structures, enumerators, visitors, pluggable behavior and many other patterns. For example:\n| aString vowels |\naString := ''This is a string''.\nvowels := aString select: [:aCharacter | aCharacter isVowel].\nIn the last line, the string is sent the message select: with an argument that is a code block literal. The code block literal will be used as a predicate function that should answer true if and only if an element of the String should be included in the Collection of characters that satisfy the test represented by the code block that is the argument to the "select:" message.\nA String object responds to the "select:" message by iterating through its members (by sending itself the message "do:"), evaluating the selection block ("aBlock") once with each character it contains as the argument. When evaluated (by being sent the message "value: each"), the selection block (referenced by the parameter "aBlock", and defined by the block literal "[:aCharacter | aCharacter isVowel]"), answers a boolean, which is then sent "ifTrue:". If the boolean is the object true, the character is added to a string to be returned. Because the "select:" method is defined in the abstract class Collection, it can also be used like this:\n| rectangles aPoint|\nrectangles := OrderedCollection\nwith: (Rectangle left: 0 right: 10 top: 100 bottom: 200)\nwith: (Rectangle left: 10 right: 10 top: 110 bottom: 210).\naPoint := Point x: 20 y: 20.\ncollisions := rectangles select: [:aRect | aRect containsPoint: aPoint].\nClasses\nThis is a stock class definition:\nObject subclass: #MessagePublisher\ninstanceVariableNames: ''''\nclassVariableNames: ''''\npoolDictionaries: ''''\ncategory: ''Smalltalk Examples''\nOften, most of this definition will be filled in by the environment. Notice that this is actually a message to the "Object"-class to create a subclass called "MessagePublisher". In other words: classes are first-class objects in Smalltalk which can receive messages just like any other object and can be created dynamically at execution time.\nMethods\nWhen an object receives a message, a method matching the message name is invoked. The following code defines a method publish, and so defines what will happen when this object receives the ''publish'' message.\npublish\nTranscript show: ''Hello, World!''\nThe following method demonstrates receiving multiple arguments and returning a value:\nquadMultiply: i1 and: i2\n"This method multiplies the given numbers by each other and the result by 4."\n| mul |\nmul := i1 * i2.\n^mul * 4\nThe method''s name is #quadMultiply:and:. The documentation is represented by a string, making it accessible from the program. Return value is specified with the ^ operator.\nNote that objects are responsible for determining dynamically at runtime which method to execute in response to a message--while in many languages this may be (sometimes, or even always) determined statically at compile time.\nInstantiating classes\nThe following code:\nMessagePublisher new\ncreates (and returns) a new instance of the MessagePublisher class. This is typically assigned to a variable:\npublisher := MessagePublisher new\nHowever, it is also possible to send a message to a temporary, anonymous object:\nMessagePublisher new publish\nHello World example\nMain article: Hello world program\nIn the following code, the message "show:" is sent to the object "Transcript" with the String literal ''Hello, world!'' as its argument. Invocation of the "show:" method causes the characters of its argument (the String literal ''Hello, world!'') to be displayed in the transcript ("terminal") window.\nTranscript show: ''Hello, world!''.\nNote that a Transcript window would need to be open in order to see the results of this example.\nImage-based persistence\nMost popular programming systems separate program code (in the form of class definitions, functions or procedures) from program state (such as objects or other forms of application data). They load the program code when an application is started, and any previous application state has to be recreated explicitly from configuration files or other data sources. Any settings the application programmer doesn''t explicitly save, you have to set back up whenever you restart. A traditional application also throws away a lot of useful document information every time you save a file, quit and reload. You lose details such as undo history or cursor position. Image based systems don''t force you to scrap all that just because you need to turn off your computer, or update the OS.\nMany Smalltalk systems, however, do not differentiate between application data (objects) and code (classes). In fact, classes are objects themselves. Therefore most Smalltalk systems store the entire application state (including both Class and non-Class objects) in an image file. The image can then be loaded by the Smalltalk virtual machine to restore a Smalltalk-like system to a previous state. This was inspired by FLEX, a language created by Alan Kay and described in his M.Sc. thesis.\nOther languages that model application code as a form of data, such as Lisp, often use image-based persistence as well.\nSmalltalk images are similar to (restartable) core dumps and can provide the same functionality as core dumps, such as delayed or remote debugging with full access to the application state at the time of error.\nLevel of access\nEverything in Smalltalk-80 is available for modification from within a running program. This means that, for example, the IDE can be changed in a running system without restarting it. In some implementations, the syntax of the language or the garbage collection implementation can also be changed on the fly. Even the statement true become: false is valid in Smalltalk, although executing it is not recommended.\nJust-in-time compilation\nMain article: Just-in-time compilation\nSmalltalk programs are usually compiled to bytecode, which is then interpreted by a virtual machine or dynamically translated into machine-native code.\nList of implementations\n#Smalltalk [1]\nAmbrai Smalltalk\nAthena - a Smalltalk scripting engine for Java >=1.6\nBistro\nCincom Smalltalk, ObjectStudio and VisualWorks by Cincom (wiki, blog)\nDolphin Smalltalk [2]\nEclipse - IBM: Bringing Smalltalk to Eclipse\nF-Script\nGemStone/S [3]\nGNU Smalltalk\nIBM VisualAge Smalltalk [4]\nLittle Smalltalk\nLSW Vision-Smalltalk, including a .NET version\nOSVM small Smalltalk for embedded devices [5]\nPocket Smalltalk runs on Palm Pilot\nS# [6]\nSmalltalk MT compiled Smalltalk for Windows\nSmalltalk/X, an open source Smalltalk [7]\nSmalltalk YX [8]\nSport\nSqueak, an open source Smalltalk\nStepTalk (uses Smalltalk language atop an Objective-C runtime)\nStrongtalk [9] (for Windows, offers optional strong typing)\nSusie: Scripting Using a Smalltalk Interpreter Engine [10]\nBits of History a Smalltalk-76 implementation as a Java applet.\nVA Smalltalk follow-on to IBM VisualAge Smalltalk [11]\nVisual Smalltalk Enterprise and family, including Smalltalk/V.\nVista Smalltalk for IE7 and Windows Vista\nReferences\n^ a b Kay, Alan. "The Early History of Smalltalk". Retrieved on 2007-09-13.\n^ "Versions".\nSmalltalk.org. Retrieved on 2007-09-13.\n^ "ANSI Smalltalk Standard".\nSmalltalk.org. Retrieved on 2007-09-13.\n^ Hobbes\n^ "History".\nSeagull Software. Retrieved on 2007-09-13.\n^ S#\n^ Smallscript Corp.\nWikibooks has a book on the topic of\nProgramming:Smalltalk\nSmalltalk: Getting the Message (tutorial)\nDesign Principles Behind Smalltalk by Dan Ingalls from the BYTE August 1981 Special Issue on Smalltalk\nThe early history of Smalltalk, by Alan Kay (HTML and PDF)\nSmalltalk.org Smalltalk advocacy site.\nLittlesmalltalk.org New Little Smalltalk Version with an actively developed GUI.\nClubSmalltalk is a Latin American group with a website in English to promote the Smalltalk technology\nOpen Directory: Smalltalk\nFAQ - http://smalltalk.awardspace.com\nImplementation Section from Smalltalk-80: The Language and Its Implementation by Goldberg & Robson\nSmalltalk-72 Instruction Manual\nSmalltalk-80: The Language and its Implementation\nSmalltalk information visualization tool\nESUG (European Smalltalk Users Group): A non-profit organization which gathers both industrial and academics. Has various Smalltalk promotion activities including a yearly event since 1993.\nThe Smalltalk-76 Programming System: Design and Implementation by Dan Ingalls.\nDolphin Map - A wiki for Dolphin Smalltalk related information.\nSmalltalk web ring Smalltalk products and services.\nVOSS (Virtual Object Storage System) Database Management for Smalltalk.\nBooks\nSqueak by Example Free, printable PDF download or order a print-on-demand, softcover copy of the book about Squeak Smalltalk.\nDownloadable books about Smalltalk Permission obtained to make these books freely available. Over a dozen full texts scanned from print.\n"http://en.wikipedia.org/wiki/Smalltalk"\nCategories: Class-based programming languages | Dynamically-typed programming languages | Object-oriented programming languages | Smalltalk programming language familyHidden categories: Articles needing additional references from September 2007 | Articles to be expanded since October 2007 | All articles to be expanded','\n',char(10)));
INSERT INTO pages VALUES('ABAP','http://web.archive.org/web/20081220211158/http://en.wikipedia.org:80/wiki/ABAP','en','2008-12-20 00:00:00',replace('This article does not cite any references or sources. Please help improve this article by adding citations to reliable sources. Unverifiable material may be challenged and removed. (April 2008)\nABAP/4\nParadigm\nObject-oriented, structured, imperative\nAppeared in\n1980s\nDesigned by\nSAP AG\nTyping discipline\nStatic, strong, safe, nominative\nMajor implementations\nSAP R/2,SAP R/3\nInfluenced by\nObjective-C, COBOL\nOS\nCross-platform\nWebsite\nhttps://www.sdn.sap.com/irj/sdn/abap\nABAP (Advanced Business Application Programming, originally Allgemeiner Berichts-Aufbereitungs-Prozessor = general report creation processor) is a high level programming language created by the German software company SAP. It is currently positioned, alongside the more recently introduced Java, as the language for programming SAP''s Web Application Server, part of its NetWeaver platform for building business applications. Its syntax is somewhat similar to COBOL.\n1 Introduction\n1.1 Where does the ABAP program run?\n1.2 SAP Basis\n1.3 SAP systems and landscapes\n2 Transactions\n2.1 Dialog transaction\n2.2 Parameter transaction\n2.3 Variant transaction\n2.4 Report transaction\n2.5 OO transaction\n3 Types of ABAP programs\n3.1 Report programs\n3.2 Online programs\n3.3 Subroutine pools\n3.4 Function pools\n3.5 Type pools\n3.6 Class pools\n3.7 Interface pools\n4 ABAP workbench\n5 The ABAP dictionary\n6 ABAP syntax\n6.1 "Helloworld"\n6.2 Formatting rules\n6.2.1 White space significance\n6.2.2 Case sensitivity\n6.3 Chained statements\n6.4 Comments\n6.4.1 Example\n7 Naming notation\n8 DATA and TYPES\n9 ABAP Objects\n10 ABAP statements – an overview\n10.1 Declarative statements\n10.2 Modularization statements\n10.3 Control statements\n10.4 Call statements\n10.5 Operational statements\n11 Unique concept of internal table in ABAP\n12 Internal tables as data types\n12.1 Line type\n12.2 Key\n12.3 Table type\n12.4 Generic internal tables\n13 Internal tables as dynamic data objects\n14 Choosing a table type\n14.1 Standard tables\n14.2 Sorted tables\n14.3 Hashed tables:\n15 Advanced topics\n15.1 Batch input: concepts\n16 Other Features\n17 Example\n18 Example report(type - ALV(ABAP list viewer))\n19 See also\n20\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nIntroduction\nABAP is one of the many application-specific fourth-generation languages (4GLs) first developed in the 1980s. It was originally the report language for SAP R/2, a platform that enabled large corporations to build mainframe business applications for materials management and financial and management accounting.\nABAP used to be an abbreviation of Allgemeiner Berichtsaufbereitungsprozessor, the German meaning of "generic report preparation processor", but was later renamed to Advanced Business Application Programming. ABAP was one of the first languages to include the concept of Logical Databases (LDBs), which provides a high level of abstraction from the basic database level.\nThe ABAP programming language was originally used by developers to develop the SAP R/3 platform. It was also intended to be used by SAP customers to enhance SAP applications – customers can develop custom reports and interfaces with ABAP programming. The language is fairly easy to learn for programmers but it is not a tool for direct use by non-programmers. Good programming skills, including knowledge of relational database design and preferably also of object-oriented concepts, are required to create ABAP programs.\nABAP remains the language for creating programs for the client-server R/3 system, which SAP first released in 1992. As computer hardware evolved through the 1990s, more and more of SAP''s applications and systems were written in ABAP. By 2001, all but the most basic functions were written in ABAP. In 1999, SAP released an object-oriented extension to ABAP called ABAP Objects, along with R/3 release 4.6.\nSAP''s most recent development platform, NetWeaver, supports both ABAP and Java.\nWhere does the ABAP program run?\nAll ABAP programs reside inside the SAP database. They are not stored in separate external files like Java or C++ programs. In the database all ABAP code exists in two forms: source code, which can be viewed and edited with the ABAP Workbench tools, and generated code, a binary representation somewhat comparable with Java bytecode. ABAP programs execute under the control of the runtime system, which is part of the SAP kernel. The runtime system is responsible for processing ABAP statements, controlling the flow logic of screens and responding to events (such as a user clicking on a screen button). A key component of the ABAP runtime system is the Database Interface, which turns database-independent ABAP statements ("Open SQL") into statements understood by the underlying DBMS ("Native SQL"). The database interface handles all the communication with the relational database on behalf of ABAP programs; it also contains extra features such as buffering of frequently accessed data in the local memory of the application server.\nSAP has three different layers as presentation layer (GUI), application layer (programs run on this) and data base layer where all data is stored and retrieved from user driven conditions, commands given by end user programmer through presentation layer.\nSAP Basis\nThe ABAP language environment, including the syntax checking, code generation and runtime system, is part of the SAP Basis component. SAP Basis is the technological platform that supports the entire range of SAP applications, now typically implemented in the framework of the SAP Web Application Server. In that sense SAP Basis can be seen as the "operating system" on which SAP applications run. Like any operating system, SAP Basis contains both low-level services (for example memory management, database communication or servicing Web requests) and high-level tools for end users and administrators. These tools can be executables ("SAP kernel") running directly on the underlying operating system, transactions developed in ABAP, or Web-based interfaces.\nSAP Basis also provides a layer of abstraction between the business applications and the operating system and database. This ensures that applications do not depend directly upon a specific server or database platform and can easily be ported from one platform to another.\nSAP Basis currently runs on UNIX (AIX, HP-UX, Solaris, Linux), Microsoft Windows, i5/OS on IBM System i (formerly iSeries, AS/400) and z/OS on IBM System z (formerly zSeries, S/390). Supported databases are DB2, Informix, MaxDB, Oracle and Microsoft SQL Server (support for Informix was discontinued in SAP Basis release 7.00).\nSAP systems and landscapes\nAll SAP data exists and all SAP software runs in the context of an SAP system. A system consists of a central relational database and one or more application servers ("instances") accessing the data and programs in this database. An SAP system contains at least one instance but may contain more, mostly for reasons of sizing and performance. In a system with multiple instances, load balancing mechanisms ensure that the load is spread evenly over the available application servers.\nInstallations of the Web Application Server (landscapes) typically consist of three systems: one for development, one for testing and quality assurance, and one for production. The landscape may contain more systems, e.g. separate systems for unit testing and pre-production testing, or it may contain fewer, e.g. only development and production, without separate QA; nevertheless three is the most common configuration. ABAP programs are created and undergo first testing in the development system. Afterwards they are distributed to the other systems in the landscape. These actions take place under control of the Change and Transport System (CTS), which is responsible for concurrency control (e.g. preventing two developers from changing the same code at the same time), version management and deployment of programs on the QA and production systems.\nThe Web Application Server consists of three layers: the database layer, the application layer and the presentation layer. These layers may run on the same or on different physical machines. The database layer contains the relational database and the database software. The application layer contains the instance or instances of the system. All application processes, including the business transactions and the ABAP development, run on the application layer. The presentation layer handles the interaction with users of the system. Online access to ABAP application servers can go via a proprietary graphical interface, the SAPGUI, or via a Web browser.\nTransactions\nA transaction in SAP terminology is the execution of a program. The normal way of executing ABAP code in the SAP system is by entering a transaction code (for instance, SE80 is the code for the ABAP workbench). Transactions can be accessed via system-defined or user-specific, role-based menus. They can also be started by entering their transaction code (a mnemonic name of up to 20 characters) in the special command field, which is present in every SAP screen. Transactions can also be invoked programmatically by means of the ABAP statements CALL TRANSACTION and LEAVE TO TRANSACTION. Transaction codes can also be linked to screen elements or menu entries. Selecting such an element will start the transaction. The term "transaction" must not be misunderstood here: in the context just described, a transaction simply means calling and executing an ABAP program. In application programming, "transaction" often refers to an indivisible operation on data, which is either committed as a whole or undone (rolled back) as a whole. This concept exists in SAP but is there called a LUW (Logical Unit of Work). In the course of one transaction (program execution), there can be different LUWs.\nLet’s have a look at the different kind of transactions:\nDialog transaction\nThese are the most common kind of transactions. The transaction code of a dialog transaction is linked to a Dynpro of an ABAP program. When the transaction is called, the respective program is loaded and the Dynpro is called. Therefore, a dialog transaction calls a Dynpro sequence rather than a program. Only during the execution of the Dynpro flow logic are the dialog modules of the ABAP program itself are called. The program flow can differ from execution to execution. You can even assign different dialog transaction codes to one program.\nParameter transaction\nIn the definition of a parameter transaction code, a dialog transaction is linked with parameters. When you call a parameter transaction, the input fields of the initial Dynpro screen of the dialog transaction are filled with parameters. The display of the initial screen can be inhibited by specifying all mandatory input fields as parameters of the transaction.\nVariant transaction\nIn the definition of a variant transaction code, a dialog transaction is linked with a transaction variant. When a variant transaction is accessed, the dialog transaction is called and executed with the transaction variant. In transaction variants, you can assign default values to the input fields on several Dynpro screens in a transaction, change the attributes of screen elements, and hide entire screens. Transaction variants are maintained in transaction SHD0.\nReport transaction\nA report transaction is the transaction code wrapping for starting the reporting process. The transaction code of a report transaction must be linked with the selection screen of an executable program. When you execute a report transaction, the runtime environment internally executes the ABAP statement SUBMIT—more to come on that.\nOO transaction\nA new kind of transaction as of release 6.10. The transaction code of an OO transaction is linked with a method of a local or global class. When the transaction is called, the corresponding program is loaded, for instance methods an object of the class is generated and the method is executed.\nTypes of ABAP programs\nIn ABAP, there are two different types of programs:\nReport programs\nA Sample Report\nReport programs follow a relatively simple programming model whereby a user optionally enters a set of parameters (e.g. a selection over a subset of data) and the program then uses the input parameters to produce a report in the form of an interactive list. The output from the report program is interactive because it is not a passive display; instead it enables the user, through ABAP language constructs, to obtain a more detailed view on specific data records via drill-down functions, or to invoke further processing through menu commands, for instance to sort the data in a different way or to filter the data according to selection criteria. This method of presenting reports has great advantages for users who must deal with large quantities of information and must also have the ability to examine this information in highly flexible ways, without being constrained by the rigid formatting or unmanageable size of "listing-like" reports. The ease with which such interactive reports can be developed is one of the most striking features of the ABAP language.\nThe term "report" is somewhat misleading in the sense that it is also possible to create report programs that modify the data in the underlying database instead of simply reading it.\nA customized screen created using Screen Painter,which is one of the tools available in ABAP workbench(T-code = SE51).\nOnline programs\nOnline programs (also called module pools) do not produce lists. These programs define more complex patterns of user interaction using a collection of screens. The term “screen” refers to the actual, physical image that the users sees. Each screen also has a “flow logic”; this refers to the ABAP code invoked by the screens, i.e. the logic that initializes screens, responds to a user’s requests and controls the sequence between the screens of a module pool. Each screen has its own Flow Logic, which is divided into a "PBO" (Process Before Output) and "PAI" (Process After Input) section. In SAP documentation the term “dynpro” (dynamic program) refers to the combination of the screen and its Flow Logic.\nOnline programs are not invoked directly by their name, but are associated with a transaction code. Users can then invoke them through customizable, role-dependent, transaction menus.\nApart from reports and online programs, it is also possible to develop sharable code units such as class libraries, function libraries and subroutine pools.\nSubroutine pools\nSubroutine pools, as the name implies, were created to contain collections of subroutines that can be called externally from other programs. Before release 6.10, this was the only way subroutine pools could be used. But besides subroutines, subroutine pools can also contain local classes and interfaces. As of release 6.10, you can connect transaction codes to methods. Therefore, you can now also call subroutine pools via transaction codes. This is the closest to a Java program you can get in ABAP: a subroutine pool with a class containing a method – say – main connected to a transaction code!\nFunction pools\nFunction pools, more commonly known as "function groups", are libraries of functions developed in ABAP. Functions differ from subroutines in that they are self-contained and do not belong to a specific program. ABAP functions accept as input any number of input parameters, return as output any number of output parameters, and raise exceptions if an error condition occurs.\nFunctions are invoked in ABAP programs by means of the CALL FUNCTION statement. A very important feature of ABAP is the ability to call function modules in another SAP system or in an external application using the RFC (Remote Function Call) mechanism. It is also possible to call functions asynchronously; the ABAP program then does not wait for the function to return but instead continues immediately, while the function executes in a separate context.\nType pools\nType pools are the precursors to general type definitions in the ABAP Dictionary. Before release 4.0, only elementary data types and flat structures could be defined in the ABAP Dictionary. All other types that should’ve been generally available had to be defined with TYPES in type pools. As of release 4.0, type pools were only necessary for constants. As of release 6.40, constants can be declared in the public sections of global classes and type pools can be replaced by global classes.\nClass pools\nClass pools serve as containers for exactly one global class. Besides the global class, they can contain global types and local classes/interfaces to be used in the global class. A class pool is loaded into memory by using one of its components. For example, a public method can be called from any ABAP program or via a transaction code connected to the method. You maintain class pools in the class builder.\nInterface pools\nInterface pools serve as containers for exactly one global interface—nothing more and nothing less. You use an interface pool by implementing its interface in classes and by creating reference variables with the type of its interface. You maintain interface pools in the class builder.\nABAP workbench\nThe ABAP Workbench contains different tools for editing Repository objects. These tools provide you with a wide range of assistance that covers the entire software development cycle. The most important tools for creating and editing Repository objects are:\nABAP Editor for writing and editing program code\nABAP Dictionary for processing database table definitions and retrieving global types\nMenu Painter for designing the user interface (menu bar, standard toolbar, application toolbar, function key assignment)\nScreen Painter for designing screens (dynamic programs) for user dialogs\nFunction Builder for displaying and processing function modules (routines with defined interfaces that are available throughout the system)\nClass Builder for displaying and processing ABAP Objects classes\nThe ABAP dictionary\nThe ABAP Dictionary is a fully integrated data environment controlling facility. It contains all definitions for Domains, Data Elements, Structures, Tables, Views, Search Helps, Lock Objects, Matchcode Objects, The Table Maintenance Generator, and the Table Description Generator.\nWith these objects in its repository, the ABAP Dictionary:\nEnforces data integrity\nManages data definitions without redundancy\nIs tightly integrated with the rest of the ABAP/4 Development Workbench.\nEnforcing data integrity is the process of ensuring that data entered into the system is logical, complete, and consistent. When data integrity rules are defined in the ABAP/4 Dictionary, the system automatically prevents the entry of invalid data. Defining the data integrity rules at the dictionary level means they only have to be defined once, rather than in each program that accesses that data.\nThe following are examples of data lacking integrity:\nA date field with a month value of 13\nAn order assigned to a customer number that doesn’t exist\nAn order not assigned to a customer\nManaging data definitions without redundancy is the process of linking similar information to the same data definition. For example, a customer database is likely to contain a customer’s ID number in several places. The ABAP Dictionary provides the capability of defining the characteristics of a customer ID number in only one place. That central definition then can be used for each instance of a customer ID number.\nThe ABAP Dictionary’s integration with the rest of the development environment enables ABAP programs to automatically recognize the names and characteristics of dictionary objects.\nAdditionally, the system provides easy navigation between development objects and dictionary definitions. For example, as a programmer, you can double-click on the name of a dictionary object in your program code, and the system will take you directly to the definition of that object in the ABAP/4 Dictionary.\nWhen a dictionary object is changed, a program that references the changed object will automatically reference the new version the next time the program runs. Because ABAP is interpreted, it is not necessary to recompile programs that reference changed dictionary objects.\nABAP syntax\nThis brief description of the ABAP syntax begins inevitably with the ubiquitous "Hello World" program.\n"Helloworld"\nPROGRAM TEST.\nWRITE ''Hello World''.\nThis example contains two statements, one on each line. The keywords are PROGRAM and WRITE. The program displays a list on the screen. In this case, the list consists of the line "Hello World".\nFormatting rules\nWhite space significance\nABAP has no format restrictions. You can enter statements in any format, so a statement can be indented, you can write several statements on one line, or spread a single statement over several lines. The only requirement is that every statement ends in a period.\nYou must separate words within a statement with at least one space. The system also interprets the end of line marker as a space.\nThe two-line "Hello World" program from above could also be written as\nPROGRAM TEST. WRITE ''Hello World'' .\nor even as:\nPROGRAM\nTEST.\nWRITE\n''Hello World''.\nFree formatting is convenient, but with complex code, such as deeply nested IF/ELSE blocks, it can get tricky. The ABAP editor therefore offers a "Pretty Printer" function, which can take care of proper indentation.\nOne obvious exception to the free-formatting rule are text literals. A text literal is a sequence of alphanumeric characters in the program code enclosed in single quotes. If a text literal in an ABAP statement extends across more than one line, then a ‘&’ character must be used to combine a succession of text literals into a single one. Example:\nUSERPROMPT = ''Please double-click on a line in the output list '' &\n''to see the complete details of the transaction.''.\nCase sensitivity\nABAP statements are not case-sensitive. The following code is perfectly permissible:\nproGRAm TEsT.\nWriTe ''Hello World''.\nUsers can configure the way source text is presented (all upper case, all lower case, ABAP keywords in upper case and variable names in lower case, etc.) according to their own preference. Typically the keywords are in upper case and every thing else (variable, function, method, and class names) in lower case.\nChained statements\nThe ABAP programming language allows you to concatenate consecutive statements with an identical first part into a chain statement.\nTo concatenate a sequence of separate statements, write the identical part only once and place a colon (:) after it. After the colon, write the remaining parts of the individual statements, separating them with commas. Ensure that you place a period (.) after the last part to inform the system where the chain ends.\nChaining is very often used in WRITE statements. WRITE accepts just one argument, so if for instance you wanted to display three fields from a structure called FLIGHTINFO, you would have to code:\nWRITE FLIGHTINFO-CITYFROM.\nWRITE FLIGHTINFO-CITYTO.\nWRITE FLIGHTINFO-AIRPTO.\nChaining the statements results in a more readable and more intuitive form:\nWRITE: FLIGHTINFO-CITYFROM, FLIGHTINFO-CITYTO, FLIGHTINFO-AIRPTO.\nIn the chain, a colon separates the beginning of the statement from the variable parts. After the colon or commas, you can insert any number of spaces.\nYou could, for example, write the same statement like this:\nWRITE:\nFLIGHTINFO-CITYFROM,\nFLIGHTINFO-CITYTO,\nFLIGHTINFO-AIRPTO.\nIn a chain statement, the first part (before the colon) is not limited to the keyword of the statements. For example, the code\nSUM = SUM + 1.\nSUM = SUM + 2.\nSUM = SUM + 3.\nSUM = SUM + 4.\ncould be written in chained form:\nSUM = SUM + : 1, 2, 3, 4.\nComments\nABAP has 2 ways of defining text as a comment.\nAn asterisk (*) in the leftmost column of a line makes that line a comment. A double quotation mark (>>"<<) anywhere on a line makes the rest of that line a comment.\nExample\n***************************************\n** Program: BOOKINGS\n**\n** Author: Joe Byte, 07-Jul-2007\n**\n***************************************\nREPORT BOOKINGS.\n* Read flight bookings from the database\nSELECT * FROM FLIGHTINFO\nWHERE CLASS = ''Y''\n"Y = economy\nOR\nCLASS = ''C''.\n"C = business\n(...)\nNaming notation\nThis list is incomplete; you can help by expanding it.\nABAP has a large number of naming conventions for different language elements. These are conventions and not rules, so an ABAP programmer is free to abide by them or not. However ABAP code developed by SAP itself generally respects these naming rules. Below is a list.\nALV_* Advance list viewer\nAS_* Methods that perform type conversions\nCHECK_* Check Methods\nCH_* Changing Parameters\nCL_* Class name\nCO_*/C_* Constants\nDR_* Data reference\nG_* Global variables/data objects\nGT_* Global table\nGX_* Global boolean field (X or space)\nIF_* Interface\nINT_*/IT_ Internal Table\nIS_* Methods that return a Boolean value\nL_* Indicates the data object is local. Often, before underscore, put a ''type letter'' in case of simple type (LC_,LF etc.)\nLC_* Local Constant\nLR_* Local Range\nLT_* Local Table\nLVC_* List Viewer Control\nON_* Event handler\nPA_* Parameters\nPE_*/EX_* Export parameter\nPI_*/IM_* Input parameter\nRA_* Ranges/Type Range Of\nRE_* Result\nRF_* Reference Variable\nSET_* Accessors Methods\nSO_* Select-Options\nST_* Structure\nTA_* Internal Standard Table\nTC_* Table Control\nTH_* Internal Hashed Table\nTP_* Other Variables\nTS_* Internal Sorted Table\nTT_* Table type\nTY_* Types\nT_* Variable is a table (T_MY_TABLE_VARIABLE)\nX* Source/first data object (e.g. XVBAK)\nY* Destination/second data object (e.g. YVBAK)\nWA_* Working Area\n** Secondary working area (e.g. *VBAK in TABLES statement. Obsolete)\nDATA and TYPES\nIt is a special strength of ABAP that you can define a great variety of data types and objects that span the spectrum from very elementary data types to very complex and dynamic types. Consequently, the subject of ABAP declarations is quite extensive.\nABAP accepts all data types defined in the SAP dictionary or in Type Pools. Types can also be defined inside the program itself. Object numeric (I for integer, F for floating point), packed decimal (P), character (C or N, where the N type is used for numeric strings that can be used in computation) or hexadecimal (X). Date fields (type D) and time fields (type T) have a "dual" nature; in an input/output context they behave like strings, but in a computational context they are numeric integers. This makes date and time calculations extremely easy. For example:\nDATESENT = ''20070901''.\nVALIDTO = DATESENT + 60.\nWRITE: ''Offer is valid until'', VALIDTO DD/MM/YYYY.\nIn this example, a string literal representing September 1, 2007 is assigned to DATESENT. DATESENT is then used in a numeric calculation to produce another data field, VALIDTO. VALIDTO is then output as a string. The optional "DD/MM/YYYY" modifier displays the date in a predefined format, here "31/10/2007". Without the modifier the date would display as "20071031".\nData and Types\nAll ABAP variables must be explicitly declared in order to be used. The convention is for all declarations to be at the top of the program, or subroutine. The declaration consists of the name, type, length (where applicable), additional modifiers (e.g. the number of implied decimals for a packed decimal field) and optionally an initial value:\n* Primitive types:\nDATA: COUNTER\nTYPE I,\nVALIDITY\nTYPE I VALUE 60,\nTAXRATE(3)\nTYPE P DECIMALS 1,\nLASTNAME(20) TYPE C.\n* Dictionary types:\nDATA: ORIGIN\nTYPE COUNTRY.\n* Internal table:\nDATA: T_FLIGHTS\nTYPE TABLE OF FLIGHTINFO,\nT_LOOKUP\nTYPE HASHED TABLE OF FLT_LOOKUP.\n* Objects:\nDATA: BOOKING\nTYPE REF TO CL_FLT_BOOKING.\nNotice the use of the colon to chain together consecutive DATA statements.\nABAP Objects\nObject orientation in ABAP is an extension of the ABAP language that makes available the advantages of object-oriented programming, such as encapsulation, interfaces, and inheritance. This helps to simplify applications and make them more controllable.\nABAP Objects is fully compatible with the existing language, so you can use existing statements and modularization units in programs that use ABAP Objects, and can also use ABAP Objects in existing ABAP programs. Note, however, that syntax checking is stronger in ABAP Objects programs, and some syntactical forms (usually older ones) of certain statements are not permitted.\nABAP statements – an overview\nThe first element of an ABAP statement is the ABAP keyword. This determines the category of the statement. The different statement categories are as follows:\nDeclarative statements\nThese statements define data types or declare data objects which are used by the other statements in a program or routine. The collected declarative statements in a program or routine make up its declaration part.\nExamples of declarative keywords:\nTYPES, DATA, TABLES\nModularization statements\nThese statements define the processing blocks in an ABAP program.\nThe modularization keywords can be further divided into:\n· Event Keywords\nYou use statements containing these keywords to define event blocks. There are no special statements to conclude processing blocks - they end when the next processing block is introduced.\nExamples of event keywords are:\nAT SELECTION SCREEN, START-OF-SELECTION, AT USER-COMMAND\n· Defining keywords\nYou use statements containing these keywords to define subroutines, function modules, dialog modules and methods. You conclude these processing blocks using the END- statements.\nExamples of definitive keywords:\nFORM ..... ENDFORM, FUNCTION ... ENDFUNCTION, MODULE ... ENDMODULE.\nControl statements\nYou use these statements to control the flow of an ABAP program within a processing block according to certain conditions.\nExamples of control keywords:\nIF, WHILE, CASE\nCall statements\nYou use these statements to call processing blocks that you have already defined using modularization statements. The blocks you call can either be in the same ABAP program or in a different program.\nExamples of call keywords:\nCALL METHOD, CALL TRANSACTION, SUBMIT, LEAVE TO\nOperational statements\nThese keywords process the data that you have defined using declarative statements.\nExamples of operational keywords:\nMOVE, ADD\nUnique concept of internal table in ABAP\nInternal tables provide a means of taking data from a fixed structure and storing it in working memory in ABAP. The data is stored line by line in memory, and each line has the same structure. In ABAP, internal tables fulfill the function of arrays. Since they are dynamic data objects, the programmer is saved the task of dynamic memory management in his or her programs. Internal tables should be used whenever there is a need to process a dataset with a fixed structure within a program. A particularly important use for internal tables is for storing and formatting data from a database table within a program. They are also a good way of including very complicated data structures in an ABAP program.\nLike all elements in the ABAP type concept, internal tables can exist both as data types and as data objects. A data type is the abstract description of an internal table, either in a program or centrally in the ABAP Dictionary, that you use to create a concrete data object. The data type is also an attribute of an existing data object.\nInternal tables as data types\nInternal tables and structures are the two structured data types in ABAP. The data type of an internal table is fully specified by its line type, key, and table type.\nLine type\nThe line type of an internal table can be any data type. The data type of an internal table is normally a structure. Each component of the structure is a column in the internal table. However, the line type may also be elementary or another internal table.\nLine Type can also refer to an ABAP Object''s reference pointer value. If two ABAP Objects are not related, they do not have the same line type. The line type is stored in the value of the reference pointer and can be viewed in the debugger. If one object attempts to access another unrelated object''s components, you will receive an error specifying that the line types do not match.\nKey\nThe key identifies table rows. There are two kinds of key for internal tables - the standard key and a user-defined key. You can specify whether the key is UNIQUE or NON-UNIQUE. Internal tables with a unique key cannot contain duplicate entries with the same key. The uniqueness depends on the table access method.\nIf a table has a structured line type, its default key consists of all of its non-numerical columns that are not references or themselves internal tables. If a table has an elementary line type, the default key is the entire line. An internal table which has a line type that is itself an internal table, has an empty key.\nThe user-defined key can contain any columns of the internal table that are not references or themselves internal tables. Internal tables with a user-defined key are called key tables. When you define the key, the sequence of the key fields is significant. You should remember this, for example, if you intend to sort the table according to the key.\nLater versions of ABAP permit the definition of secondary keys.\nTable type\nThe table type determines how ABAP will access individual table entries. Internal tables can be divided into three types:\nStandard tables have an internal linear index. (Think of index as "record number". It is not to be confused with a database index, for example). From a particular size upwards, the indexes of internal tables are administered as trees. In this case, the index administration overhead increases in logarithmic and not linear relation to the number of lines. The system can access records either by using the table index or the key. The response time for key access is proportional to the number of entries in the table. The key of a standard table is always non-unique. You cannot specify a unique key. This means that standard tables can always be filled very quickly, since the system does not have to check whether there are already existing entries.\nSorted tables are always saved sorted by the key. They also have an internal index. The system can access records either by using the table index or the key. The response time for key access is logarithmically proportional to the number of table entries, since the system uses a binary search. The key of a sorted table can be either unique or non-unique. When you define the table, you must specify whether the key is to be unique or not. Standard tables and sorted tables are known generically as index tables.\nHashed tables have no linear index. You can only access a hashed table using its key. The response time is independent of the number of table entries, and is constant, since the system access the table entries using a hash algorithm. The key of a hashed table must be unique. When you define the table, you must specify the key as UNIQUE.\nGeneric internal tables\nUnlike other local data types in programs, you do not have to specify the data type of an internal table fully. Instead, you can specify a generic construction, that is, the key or key and line type of an internal table data type may remain unspecified. You can use generic internal tables to specify the types of field symbols and the interface parameters of procedures. You cannot use them to declare data objects.\nInternal tables as dynamic data objects\nData objects that are defined either with the data type of an internal table, or directly as an internal table, are always fully defined in respect of their line type, key and access method. However, the number of lines is not fixed. Thus internal tables are dynamic data objects, since they can contain any number of lines of a particular type. The only restriction on the number of lines an internal table may contain are the limits of your system installation. The maximum memory that can be occupied by an internal table (including its internal administration) is 2 gigabytes. A more realistic figure is up to 500 megabytes. An additional restriction for hashed tables is that they may not contain more than 2 million entries. The line types of internal tables can be any ABAP data types - elementary, structured, or internal tables. The individual lines of an internal table are called table lines or table entries. Each component of a structured line is called a column in the internal table.\nChoosing a table type\nThe table type (and particularly the access method) that you will use depends on how the typical internal table operations will be most frequently executed.\nStandard tables\nThis is the most appropriate type if you are going to address the individual table entries using the index. Index access is the quickest possible access. You should fill a standard table by appending lines (ABAP APPEND statement), and read, modify and delete entries by specifying the index (INDEX option with the relevant ABAP command). The access time for a standard table increases in a linear relationship with the number of table entries. If you need key access, standard tables are particularly useful if you can fill and process the table in separate steps. For example, you could fill the table by appending entries, and then sort it. If you use the binary search option with key access, the response time is logarithmically proportional to the number of table entries.\nSorted tables\nThis is the most appropriate type if you need a table which is sorted as you fill it. You fill sorted tables using the INSERT statement. Entries are inserted according to the sort sequence defined through the table key. Any illegal entries are recognized as soon as you try to add them to the table. The response time for key access is logarithmically proportional to the number of table entries, since the system always uses a binary search. Sorted tables are particularly useful for partially sequential processing in a LOOP if you specify the beginning of the table key in the WHERE condition.\nHashed tables:\nThis is the most appropriate type for any table where the main operation is key access. You cannot access a hashed table using its index. The response time for key access remains constant, regardless of the number of table entries. Like database tables, hashed tables always have a unique key. Hashed tables are useful if you want to construct and use an internal table which resembles a database table or for processing large amounts of data.\nAdvanced topics\nBatch input: concepts\nProcessing sessions\nThe above figure shows how a batch input session works.\nA batch input session is a set of one or more calls to transactions along with the data to be processed by the transactions. The system normally executes the transactions in a session non-interactively, allowing rapid entry of bulk data into an R/3 System.\nA session records transactions and data in a special format that can be interpreted by the R/3 System. When the System reads a session, it uses the data in the session to simulate on-line entry of transactions and data. The System can call transactions and enter data using most of the facilities that are available to interactive users.\nFor example, the data that a session enters into transaction screens is subject to the same consistency checking as in normal interactive operation. Further, batch input sessions are subject to the user-based authorization checking that is performed by the system.\nThere are three batch input methods:\n(1) In the Direct Input Method, the programs are provided by the SAP system. These programs are available for Standard Applications. Under this method, the data base is updated using a Function Module, which is responsible for executing the appropriate consistency checks.\n(2) In the Call Transaction Method, the ABAP Program reads the external data which is present on the Application or Presentation Server, and uses the ABAP Statement CALL TRANSACTION USING to run a SAP statement.\n(3) In the Session Method the program reads the data and the SAP system stores the data in a "Batch Input Session". The session records the actions that are required to transfer data into the system using normal SAP transactions.\nOther Features\nABAP Objects ABAP uses an object-oriented interfaces.\nSharing Data: With ABAP shared objects, you can aggregate data in memory once at a central location. Different users and programs can then access this data without the need for copying.\nException Handling: With the class-based exception concept of ABAP, you can define a special control flow for a specific error situation and provide the user with information about the error.\nDeveloping Persistency: For permanent storage of data in ABAP, you use relational database tables by means of database-independent Open SQL, which is integrated in ABAP. However, you can also store selected objects transparently or access the integrated database or other databases using proprietary SQL.\nConnectivity and Interoperability: The Exchange Infrastructure and Web services are the means by which developers can implement a service-oriented architecture. With Web services, you can provide and consume services independently of implementation or protocol. Furthermore, you can do so within NetWeaver and in the communication with other systems. With the features of the Exchange Infrastructure, you can enable, manage, and adapt integration scenarios between systems.\nMaking Enhancements: With the Enhancement Framework, you can enhance programs, function modules, and global classes without modification as well as replace existing code. The Switch Framework enables you activate only specific development objects or enhancements in a system.\nExample\nFrom SAP NetWeaver:\n*-----------------------------------------------------------------------\n* set an exclusive lock at level object-type & object-id\n*-----------------------------------------------------------------------\nIF NOT lf_bapi_error = true.\nIF ( NOT istourhd-doc_type IS INITIAL ) AND\n( NOT istourhd-doc_id IS INITIAL )\nCALL FUNCTION ''ENQUEUE_/DSD/E_HH_RAREF''\nEXPORTING\nobj_typ\n= istourhd-doc_type\nobj_id\n= istourhd-doc_id\nEXCEPTIONS\nforeign_lock\n= 1\nsystem_failure = 2\nOTHERS\n= 3.\nIF sy-subrc <> 0.\n*\nterminate processing...\nlf_bapi_error = true.—\n*\n...and add message to return table\nPERFORM set_msg_to_bapiret2\nUSING\nsy-msgid gc_abort sy-msgno\nsy-msgv1 sy-msgv2 sy-msgv3 sy-msgv4\ngc_istourhd gc_enqueue_refdoc space\nCHANGING lt_return.\nENDIF.\nENDIF.\nENDIF.\n" bapi error\nExample report(type - ALV(ABAP list viewer))\nREPORT Z_ALV_SIMPLE_EXAMPLE_WITH_ITAB .\n************************************************************************\n*Simple example to use ALV and to define the ALV data in an internal\n*table\n************************************************************************\n*data definition\ntables:\nmarav. "Table MARA and table MAKT\n*---------------------------------------------------------------------*\n* Data to be displayed in ALV\n* Using the following syntax, REUSE_ALV_FIELDCATALOG_MERGE can auto-\n* matically determine the fieldstructure from this source program\nData:\nbegin of imat occurs 100,\nmatnr like marav-matnr, "Material number\nmaktx like marav-maktx, "Material short text\nmatkl like marav-matkl, "Material group (so you can test to make\n" intermediate sums)\nntgew like marav-ntgew, "Net weight, numeric field (so you can test to\n"make sums)\ngewei like marav-gewei, "weight unit (just to be complete)\nend of imat.\n*---------------------------------------------------------------------*\n* Other data needed\n* field to store report name\ndata i_repid like sy-repid.\n* field to check table length\ndata i_lines like sy-tabix.\n*---------------------------------------------------------------------*\n* Data for ALV display\nTYPE-POOLS: SLIS.\ndata int_fcat type SLIS_T_FIELDCAT_ALV.\n*---------------------------------------------------------------------*\nselect-options:\ns_matnr for marav-matnr matchcode object MAT1.\n*---------------------------------------------------------------------*\nstart-of-selection.\n* read data into table imat\nselect * from marav\ninto corresponding fields of table imat\nwhere\nmatnr in s_matnr.\n* Check if material was found\nclear i_lines.\ndescribe table imat lines i_lines.\nif i_lines lt 1.\n*\nUsing hardcoded write here for easy upload\nwrite: /\n''No materials found.''.\nexit.\nendif.\nend-of-selection.\n* To use ALV, we need either a reference to a structure defined in\n* the SAP Data Dictionary (DDIC) or an in-program structure called\n* the Field Catalog.\n* The Field Catalog can be declared explicitly or generated by FUNCTION\n* ''REUSE_ALV_FIELDCATALOG_MERGE'' from an internal table from any\n* report source, including this report.\n*---------------------------------------------------------------------*\n* Store report name\ni_repid = sy-repid.\n* Create Fieldcatalogue from internal table\nCALL FUNCTION ''REUSE_ALV_FIELDCATALOG_MERGE''\nEXPORTING\nI_PROGRAM_NAME\n= i_repid\nI_INTERNAL_TABNAME\n= ''IMAT''\n"capital letters!\nI_INCLNAME\n= i_repid\nCHANGING\nCT_FIELDCAT\n= int_fcat\nEXCEPTIONS\nINCONSISTENT_INTERFACE = 1\nPROGRAM_ERROR\n= 2\nOTHERS\n= 3.\n*explanations:\n*\nI_PROGRAM_NAME is the program which calls this function\n*\n*\nI_INTERNAL_TABNAME is the name of the internal table which you want\n*\nto display in ALV\n*\n*\nI_INCLNAME is the ABAP-source where the internal table is defined\n*\n(DATA....)\n*\nCT_FIELDCAT contains the Fieldcatalouge that we need later for\n*\nALV display\nIF SY-SUBRC <> 0.\nwrite: /\n''Returncode'',\nsy-subrc,\n''from FUNCTION REUSE_ALV_FIELDCATALOG_MERGE''.\nENDIF.\n*This was the field catalog\n*---------------------------------------------------------------------*\n*\n* Call for ALV list display\nCALL FUNCTION ''REUSE_ALV_LIST_DISPLAY''\nEXPORTING\nI_CALLBACK_PROGRAM = i_repid\nIT_FIELDCAT\n= int_fcat\nTABLES\nT_OUTTAB\n= imat\nEXCEPTIONS\nPROGRAM_ERROR\n= 1\nOTHERS\n= 2.\n*explanations:\n*\nI_CALLBACK_PROGRAM is the program which calls this function\n*\n*\nIT_FIELDCAT (just made by REUSE_ALV_FIELDCATALOG_MERGE) contains\n*\nnow the data definition needed for display\n*\n*\nI_SAVE allows the user to save his own layouts\n*\n*\nT_OUTTAB contains the data to be displayed in ALV\nIF SY-SUBRC <> 0.\nwrite: /\n''Returncode'',\nsy-subrc,\n''from FUNCTION REUSE_ALV_LIST_DISPLAY''.\nENDIF.\nSee also\nERP software\nasXML\nSAP Help Portal\nABAP in the SAP Developer Network\nABAP eLearning\nABAP Objects\nABAP at the Open Directory Project\nThe ABAP Wiki Project\nThe SAP ABAP Help Forums\nCodeProfiler - the ABAP security scanner\nSAP ABAP Tutorials\nSAP Database\nSAP Learning\nSAP Documents\n"http://en.wikipedia.org/wiki/ABAP"\nCategories: Domain-specific programming languages | 4GL | SAP (company) | Cross-platform softwareHidden categories: Articles lacking sources from April 2008 | All articles lacking sources | Incomplete lists','\n',char(10)));
INSERT INTO pages VALUES('Objective-C','http://web.archive.org/web/20081218102909/http://en.wikipedia.org:80/wiki/Objective-C','en','2008-12-18 00:00:00',replace('This article may require copy-editing for grammar, style, cohesion, tone or spelling. You can assist by editing it now. A how-to guide is available. (August 2008)\012Objective-C\012Paradigm\012reflective, object oriented\012Appeared in\0121986\012Designed by\012Brad Cox and Tom Love\012Developer\012Apple Inc.\012Typing discipline\012duck, static, weak\012Major implementations\012gcc, Apple\012Influenced by\012Smalltalk, C\012Influenced\012TOM, Java\012Objective-C is a reflective, object-oriented programming language which adds Smalltalk-style messaging to C.\012Today it is used primarily on Mac OS X and GNUstep, two environments based on the OpenStep standard, and is the primary language used for the NeXTSTEP, OPENSTEP, and Cocoa application frameworks. Generic Objective-C programs which do not make use of these libraries can also be compiled for any system supported by gcc, which includes an Objective-C compiler.\0121 History\0121.1 Popularization through NeXT\0122 Syntax\0122.1 Messages\0122.2 Interfaces and implementations\0122.2.1 Interface\0122.2.2 Implementation\0122.2.3 Instantiation\0122.3 Protocols\0122.4 Dynamic typing\0122.5 Forwarding\0122.5.1 Example\0122.5.2 Notes\0122.6 Categories\0122.6.1 Example usage of categories\0122.6.2 Notes\0122.7 Posing\0122.8 #import\0123 Other features\0124 Language variants\0124.1 Objective-C++\0124.2 Objective-C 2.0\0124.2.1 Garbage collection\0124.2.2 Properties\0124.2.3 Fast enumeration\0124.2.4 Implications for Cocoa development\0125 Today\0125.1 Portable Object Compiler\0126 Analysis of the language\0126.1 Philosophical differences between Objective-C and C++\0127 See also\0128 Notes\0129 References\01210\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012History\012In the early 1980s, common software engineering practice was based on structured programming. Structured programming was implemented in order to help "break down" programs into smaller parts, primarily to make them easier to work on as they grew increasingly large. However, as the problems being solved grew in size, structured programming became less useful as more and more procedures had to be written, leading to complex control structures and a low level of code reuse.\012Many saw object-oriented programming as a potential solution to the problem. In fact, Smalltalk had already addressed many of these engineering issues: some of the most complex systems in the world were Smalltalk environments. On the downside, Smalltalk used a virtual machine. The virtual machine interpreted an object memory called an image, containing all development tools. The Smalltalk image was very large and tended to require huge amounts of memory for the time and ran very slowly, partly due to the lack of useful hardware VM/container support.\012Objective-C was created primarily by Brad Cox and Tom Love in the early 1980s at their company Stepstone. Both had been introduced to Smalltalk while at ITT’s Programming Technology Center in 1981. Cox had become interested in the problems of true reusability in software design and programming. He realized that a language like Smalltalk would be invaluable in building powerful development environments for system developers at ITT. Cox began by modifying the C compiler to add some of the capabilities of Smalltalk. He soon had a working implementation of an object-oriented extension to the C language which he called "OOPC" for Object-Oriented Programming in C. Love, meanwhile, was hired by Schlumberger Research in 1982 and had the opportunity to acquire the first commercial copy of Smalltalk-80, which further influenced development of their brainchild.\012In order to demonstrate that real progress could be made, Cox showed that making interchangeable software components really needed only a few practical changes to existing tools. Specifically, they needed to support objects in a flexible manner, come supplied with a usable set of libraries, and allow for the code (and any resources needed by the code) to be bundled into a single cross-platform format.\012Love and Cox eventually formed a new venture, Productivity Products International (PPI), to commercialize their product, which coupled an Objective-C compiler with powerful class libraries.\012In 1986, Cox published the main description of Objective-C in its original form in the book Object-Oriented Programming, An Evolutionary Approach. Although he was careful to point out that there is more to the problem of reusability than just the language, Objective-C often found itself compared feature for feature with other languages.\012Popularization through NeXT\012In 1988, NeXT, the company started by Steve Jobs after Apple, licensed Objective-C from StepStone (the owner of the Objective-C trademark) and released their own Objective-C compiler and libraries on which the NeXTstep user interface and interface builder were based. Although the NeXT workstations failed to make much of an impact in the marketplace, the tools were widely lauded in the industry. This led NeXT to drop hardware production and focus on software tools, selling NeXTstep (and OpenStep) as a platform for custom programming.\012The GNU project started work on their free clone of NeXTStep, named GNUstep, based on the OpenStep standard. Dennis Glatting wrote the first gnu-objc runtime in 1992. The GNU Objective-C runtime which has been in use since 1993 is the one developed by Kresten Krab Thorup when he was a university student in Denmark. Kresten also worked at NeXT from 1993 to 1996.\012After acquiring NeXT in 1996, Apple used OpenStep in its new operating system, Mac OS X. This included Objective-C and NeXT''s Objective-C based developer tool, Project Builder (later replaced by Xcode), as well as its interface design tool, Interface Builder. Most of Apple''s present-day Cocoa API is based on OpenStep interface objects, and is the most significant Objective-C environment being used for active development.\012Syntax\012Objective-C is a very thin layer on top of C. Objective-C is a strict superset of C. That is, it is possible to compile any C program with an Objective-C compiler. Objective-C derives its syntax from both C and Smalltalk. Most of the syntax (including preprocessing, expressions, function declarations, and function calls) is inherited from C, while the syntax for object-oriented features was created to enable Smalltalk-style messaging.\012Messages\012Objective-C syntax offers alternatives to a few "kludges" in C syntax but more importantly supports object-oriented programming. The Objective-C model of object-oriented programming is based on sending messages to sovereign (even self-correcting) objects. This is unlike the Simula-style programming model used by C++ and this distinction is semantically important. The basic difference is that in Objective-C one does not call a method; one sends a message. In Objective-C the "receiver" of a message can opt to refuse it. Both styles carry their own strengths and weaknesses. Simula-style OOP allows multiple inheritance and faster execution by using compile-time binding whenever possible but does not support dynamic binding by default. It also forces all methods to have a corresponding implementation unless they are virtual but still, cannot be called unless an implementation is given. Smalltalk-style OOP allows messages to go unimplemented and is dynamically bound but in some cases runs slower and some programmers (especially ones from simula based languages) feel that it is a hassle to debug. On that note, some Simula-style programmers hate Objective-C while Objective-C (Smalltalk-style) programmers hate Simula-style languages and feel that they are not "true" object-oriented languages or that they are severely flawed (notably, C++ is the most attacked; see C++ FQA Lite).\012An object obj with method method is said to "respond" to the message method. Sending the message method to obj would require the following code in C++:\012obj.method(parameter);\012which in Objective-C is written as follows:\012[obj method:parameter];\012This mechanism allows messages to be sent to an object defined first at runtime - something statically typed languages such as C++ are incapable of per the current standards for such languages. C++ will be able to support messaging per ANSI Standard if the Boost library is standardized. Qt provides this capability to C++ and other languages (but Objective-C is poorly supported) by adding the "connect" function as well as a large array of classes that afford and support this functionality. (See the dynamic typing section below for more advantages of dynamic (late) binding.)\012Objective-C has a few features in message-passing that relates to how it handles OO. Objective-C messages do not need to execute because they are dynamically bound. If a message is implemented by an object, it will execute, but if not, it will not execute, yet the code will still compile and run. So for example, every object is sent an "awakeFromNib" message, but those objects don''t necessarily have to implement "awakeFromNib" to compile – if an object does implement "awakeFromNib", then that code will be executed when the message is sent, otherwise the message is ignored. Messages can also be sent to the object that implements them or to the superclass that an object is derived from. These can be accessed using the "self" and "super" object pointers. Also, messages can be sent to Template:Nil objects.\012Interfaces and implementations\012Objective-C requires the interface and implementation of a class be in separately declared code blocks. By convention, the interface is put in a header file and the implementation in a code file; the header files, normally suffixed .h, are similar to C header files; the implementation (method) files, normally suffixed .m, can be very similar to C code files.\012Interface\012The interface of the class is usually defined in a header file. A common convention is to name the header file after the name of the class. The interface for class Class would thus be found in the file Class.h.\012The interface declaration of the form:\012@interface classname : superclassname {\012// instance variables\012}\012+classMethod1;\012+(return_type)classMethod2;\012+(return_type)classMethod3:(param1_type)parameter_varName;\012-(return_type)instanceMethod1:(param1_type)param1_varName :(param2_type)param2_varName;\012-(return_type)instanceMethod2WithParameter:(param1_type)param1_varName andOtherParameter:(param2_type)param2_varName;\012@end\012Plus signs denote class methods, minus signs denote instance methods. Class methods have no access to instance variables.\012Return types can be any standard C type, a pointer to a generic Objective-C object, or a pointer to a specific type of object such as NSArray *, NSImage *, or NSString *. The default return type is the generic Objective-C type id.\012Method arguments begin with a colon followed by the expected argument type in parentheses followed by the argument name. In some cases (e.g. when writing system APIs) it is useful to add descriptive text before each parameter.\012-(void) setRange:(int)start :(int)end;\012-(void) importDocumentWithName:(NSString *)name withSpecifiedPreferences:(Preferences *)prefs beforePage:(int)insertPage;\012Implementation\012The interface only declares the class interface and not the methods themselves; the actual code is written in the implementation. Implementation (method) files normally have the file extension .m.\012@implementation classname\012+classMethod {\012// implementation\012}\012-instanceMethod {\012// implementation\012}\012@end\012Methods are written as with their interface declarations. Comparing C and Objective-C:\012int function(int i) {\012return square_root(i);\012}\012-(int)method:(int)i {\012return [self square_root: i];\012}\012The syntax allows pseudo-naming of arguments.\012-(int)changeColorToRed:(float)red green:(float)green blue:(float)blue\012[myColor changeColorToRed:5.0 green:2.0 blue:6.0];\012Internal representations of this method vary between different implementations of Objective-C. If myColor is of the class Color, internally, instance method -changeColorWithRed:green:blue: might be labeled _i_Color_changeColorWithRed_green_blue. The i is to refer to an instance method, with the class and then method names appended, colons translated to underscores. As the order of parameters is part of the method name, it cannot be changed to suit coding style or expression as in true named parameters.\012However, internal names of the function are rarely used directly, and generally messages are converted to function calls defined in the Objective-C runtime library – it''s not necessarily known at link time which method will be called: the class of the receiver (the object being sent the message) need not be known until runtime.\012Instantiation\012Once an Objective-C class is written, it can be instantiated. This is done by first allocating the memory for a new object and then by initializing it. An object isn''t fully functional until both steps have been completed. These steps are typically accomplished with a single line of code:\012MyObject * o = [[MyObject alloc] init];\012The alloc call allocates enough memory to hold all the instance variables for an object, and the init call can be overridden to set instance variables to specific values on creation. The init method is often written as follows:\012-(id) init {\012self = [super init];\012if (self) {\012ivar1 = value1;\012ivar2 = value2;\012.\012.\012.\012}\012return self;\012}\012Protocols\012Objective-C was extended at NeXT to introduce the concept of multiple inheritance of specification, but not implementation, through the introduction of protocols. This is a pattern achievable either as an abstract multiply inherited base class in C++, or else, more popularly, adopted (e.g., in Java or C#) as an "interface". Objective-C makes use of both ad-hoc protocols, called informal protocols, and compiler enforced protocols called formal protocols.\012An informal protocol is a list of methods which a class can implement. It is specified in the documentation, since it has no presence in the language. Informal protocols often include optional methods, where implementing the method can change the behavior of a class. For example, a text field class might have a delegate which should implement an informal protocol with an optional autocomplete method. The text field discovers whether the delegate implements that method (via reflection), and, if so, calls it to support autocomplete.\012A formal protocol is similar to an interface in Java or C#. It is a list of methods which any class can declare itself to implement. Versions of Objective-C before 2.0 required that a class must implement all methods in a protocol it declares itself as adopting; the compiler will emit an error if the class does not implement every method of its declared protocols. However, Objective-C 2.0 added support for marking certain methods in a protocol optional; the compiler will not enforce that such methods are implemented.\012The Objective-C concept of protocols is different from the Java or C# concept of interfaces in that a class may implement a protocol without being declared to implement that protocol. The difference is not detectable from outside code. Formal protocols cannot provide any implementations, they simply assure callers that classes which conform to the protocol will provide implementations. In the NeXT/Apple library, protocols are frequently used by the Distributed Objects system to represent the capabilities of an object executing on a remote system.\012The syntax\012@protocol Locking\012- (void)lock;\012- (void)unlock;\012@end\012denotes that there is the abstract idea of locking which is useful, and when stated in a class definition\012@interface SomeClass : SomeSuperClass <Locking>\012@end\012denotes that instances of SomeClass will provide an implementation for the two instance methods using whatever means they want. This abstract specification is particularly useful to describe the desired behaviors of plug-ins for example, without constraining at all what the implementation hierarchy should be.\012Dynamic typing\012Objective-C, like Smalltalk, can use dynamic typing: an object can be sent a message that is not specified in its interface. This can allow for increased flexibility — in Objective-C an object can "capture" this message, and depending on the object, can send the message off again to a different object (who can respond to the message correctly and appropriately, or likewise send the message on again). This behavior is known as message forwarding or delegation (see below). Alternatively, an error handler can be used instead, in case the message cannot be forwarded. If the object does not forward the message, handle the error, or respond to it, a runtime error occurs.\012Static typing information may also optionally be added to variables. This information is then checked at compile time. In the following statements, increasingly specific type information is provided. The statements are equivalent at runtime, but the additional information allows the compiler to warn the programmer if the passed argument does not match the type specified. In the first statement, the object may be of any class. In the second statement, the object must conform to the aProtocol protocol, and in the third, it must be a member of the NSNumber class.\012- setMyValue:(id) foo;\012- setMyValue:(id <aProtocol>) foo;\012- setMyValue:(NSNumber*)foo;\012Dynamic typing can be a powerful feature. When implementing container classes using statically-typed languages without generics like pre-1.5 Java, the programmer is forced to write a container class for a generic type of object, and then cast back and forth between the abstract generic type and the real type. Casting however breaks the discipline of static typing – if you put in an Integer and read out a String, you get an error. One way of alleviating the problem is to resort to generic programming, but then container classes must be homogeneous in type. This need not be the case with dynamic typing.\012Forwarding\012Since Objective-C permits the sending of a message to an object which might not respond to it, the object has a number of things it can do with the message. One of these things could be to forward the message on to an object which can respond to it. Forwarding can be used to implement certain design patterns, such as the Observer pattern or the Proxy pattern very simply.\012The Objective-C runtime specifies a pair of methods in Object\012forwarding methods:\012- (retval_t) forward:(SEL) sel :(arglist_t) args; // with GCC\012- (id) forward:(SEL) sel :(marg_list) args; // with NeXT/Apple systems\012action methods:\012- (retval_t) performv:(SEL) sel :(arglist_t) args;\012// with GCC\012- (id) performv:(SEL) sel :(marg_list) args; // with NeXT/Apple systems\012and as such an object wishing to implement forwarding needs only to override the forwarding method to define the forwarding behaviour. The action methods performv:: need not be overridden as this method merely performs the method based on the selector and arguments.\012Example\012Here is an example of a program which demonstrates the basics of forwarding.\012Forwarder.h\012#import <objc/Object.h>\012@interface Forwarder : Object\012{\012id recipient; //The object we want to forward the message to.\012}\012//Accessor methods\012- (id) recipient;\012- (id) setRecipient:(id) _recipient;\012@end\012Forwarder.m\012#import "Forwarder.h"\012@implementation Forwarder\012- (retval_t) forward: (SEL) sel : (arglist_t) args\012{\012/*\012* Check whether the recipient actually responds to the message.\012* This may or may not be desirable, for example, if a recipient\012* in turn does not respond to the message, it might do forwarding\012* itself.\012*/\012if([recipient respondsTo:sel])\012return [recipient performv: sel : args];\012else\012return [self error:"Recipient does not respond"];\012}\012- (id) setRecipient: (id) _recipient\012{\012recipient = _recipient;\012return self;\012}\012- (id) recipient\012{\012return recipient;\012}\012@end\012Recipient.h\012#import <objc/Object.h>\012// A simple Recipient object.\012@interface Recipient : Object\012- (id) hello;\012@end\012Recipient.m\012#import "Recipient.h"\012@implementation Recipient\012- (id) hello\012{\012printf("Recipient says hello!\n");\012return self;\012}\012@end\012main.m\012#import "Forwarder.h"\012#import "Recipient.h"\012int\012main(void)\012{\012Forwarder *forwarder = [Forwarder new];\012Recipient *recipient = [Recipient new];\012[forwarder setRecipient:recipient]; //Set the recipient.\012/*\012* Observe forwarder does not respond to a hello message! It will\012* be forwarded. All unrecognized methods will be forwarded to\012* the recipient\012* (if the recipient responds to them, as written in the Forwarder)\012*/\012[forwarder hello];\012return 0;\012}\012Notes\012If we were to compile the program, the compiler would report\012$ gcc -x objective-c -Wno-import Forwarder.m Recipient.m main.m -lobjc\012main.m: In function `main'':\012main.m:12: warning: `Forwarder'' does not respond to `hello''\012$\012The compiler is reporting the point made earlier, that Forwarder does not respond to hello messages. In certain circumstances, such a warning can help us find errors, but in this circumstance, we can safely ignore this warning, since we have implemented forwarding. If we were to run the program\012$ ./a.out\012Recipient says hello!\012Categories\012Cox’s main concern was the maintainability of large code bases. Experience from the structured programming world had shown that one of the main ways to improve code was to break it down into smaller pieces. Objective-C borrowed and extended the concept of Categories to help with this process from Smalltalk implementations (e.g., see [1]).\012A category collects method implementations into separate files. The programmer can place groups of related methods into a category to make them more readable. For instance, one could create a "SpellChecking" category "on" the String object, collecting all of the methods related to spell checking into a single place.\012Furthermore, the methods within a category are added to a class at runtime. Thus, categories permit the programmer to add methods to an existing class without the need to recompile that class or even have access to its source code. For example, if the system you are supplied with does not contain a spell checker in its String implementation, you can add it without modifying the String source code.\012Methods within categories become indistinguishable from the methods in a class when the program is run. A category has full access to all of the instance variables within the class, including private variables.\012Categories provide an elegant solution to the fragile base class problem for methods.\012If you declare a method in a category with the same method signature as an existing method in a class, the category’s method is adopted. Thus categories can not only add methods to a class, but also replace existing methods. This feature can be used to fix bugs in other classes by rewriting their methods, or to cause a global change to a class’ behavior within a program. If two categories have methods with the same method signature, it is undefined which category’s method is adopted.\012Other languages have attempted to add this feature in a variety of ways. TOM took the Objective-C system a step further and allowed for the addition of variables as well. Other languages have instead used prototype oriented solutions, the most notable being Self.\012Example usage of categories\012This example builds up an Integer class, by defining first a basic class with only accessor methods implemented, and adding two categories, Arithmetic and Display, which extend the basic class. Whilst categories can access the base class’ private data members, it is often good practice to access these private data members through the accessor methods, which helps keep categories more independent from the base class. This is one typical usage of categories—the other is to use categories to add or replace certain methods in the base class (however it is not regarded as good practice to use categories for subclass overriding).\012Integer.h\012#import <objc/Object.h>\012@interface Integer : Object\012{\012int integer;\012}\012- (int) integer;\012- (id) integer: (int) _integer;\012@end\012Integer.m\012#import "Integer.h"\012@implementation Integer\012- (int) integer\012{\012return integer;\012}\012- (id) integer: (int) _integer\012{\012integer = _integer;\012return self;\012}\012@end\012Arithmetic.h\012#import "Integer.h"\012@interface Integer (Arithmetic)\012- (id) add: (Integer *) addend;\012- (id) sub: (Integer *) subtrahend;\012@end\012Arithmetic.m\012#import "Arithmetic.h"\012@implementation Integer (Arithmetic)\012- (id) add: (Integer *) addend\012{\012return [self integer: [self integer] + [addend integer]];\012}\012- (id) sub: (Integer *) subtrahend\012{\012return [self integer: [self integer] - [subtrahend integer]];\012}\012@end\012Display.h\012#import "Integer.h"\012@interface Integer (Display)\012- (id) showstars;\012- (id) showint;\012@end\012Display.m\012#import "Display.h"\012@implementation Integer (Display)\012- (id) showstars\012{\012int i, x = [self integer];\012for(i=0; i < x; i++)\012printf("*");\012printf("\n");\012return self;\012}\012- (id) showint\012{\012printf("%d\n", [self integer]);\012return self;\012}\012@end\012main.m\012#import "Integer.h"\012#import "Arithmetic.h"\012#import "Display.h"\012int\012main(void)\012{\012Integer *num1 = [Integer new], *num2 = [Integer new];\012int x;\012printf("Enter an integer: ");\012scanf("%d", &x);\012[num1 integer:x];\012[num1 showstars];\012printf("Enter an integer: ");\012scanf("%d", &x);\012[num2 integer:x];\012[num2 showstars];\012[num1 add:num2];\012[num1 showint];\012}\012Notes\012Compilation is performed, for example, by\012gcc -x objective-c main.m Integer.m Arithmetic.m Display.m -lobjc\012One can experiment by omitting the #import "Arithmetic.h" and [num1 add:num2] lines and omit Arithmetic.m in compilation. The program will still run. This means that it is possible to "mix-and-match" added categories if necessary – if one does not need to have some capability provided in a category, one can simply not compile it in.\012Posing\012Objective-C permits a class to wholly replace another class within a program. The replacing class is said to "pose as" the target class.\012Note: Class posing was declared deprecated with Mac OS X v10.5 and unavailable in the 64-bit runtime.\012For the versions still supporting posing: All messages sent to the target class are instead received by the posing class. There are several restrictions:\012A class may only pose as one of its direct or indirect superclasses\012The posing class must not define any new instance variables which are absent from the target class (though it may define or override methods).\012The target class may not have received any messages prior to the posing.\012Posing, similarly to categories, allows globally augmenting existing classes. Posing permits two features absent from categories:\012A posing class can call overridden methods through super, thus incorporating the implementation of the target class.\012A posing class can override methods defined in categories.\012For example,\012@interface CustomNSApplication : NSApplication\012@end\012@implementation CustomNSApplication\012- (void) setMainMenu: (NSMenu*) menu\012{\012// do something with menu\012}\012@end\012class_poseAs ([CustomNSApplication class], [NSApplication class]);\012This intercepts every invocation of setMainMenu to NSApplication.\012#import\012In the C language, the #include pre-compile directive allows for the insertion of entire files before any compilation actually begins. Objective-C adds the #import directive, which does the same thing, except that it knows not to insert a file which has already been inserted.\012For example, if file A includes files X and Y, but X and Y each include the file Q, then Q will be inserted twice into the resultant file, causing "duplicate definition" compile errors. But if file Q is included using the #import directive, only the first inclusion of Q will occur—all others will be ignored.\012A few compilers, including GCC, support #import for C programs too; its use is discouraged on the basis that the user of the header file has to distinguish headers which should be included only once, from headers designed to be used multiple times. It is argued that this burden should be placed on the implementor; to this end, the implementor may place the directive #pragma once in the header file, or use the traditional #include guard technique:\012#ifndef HEADER_H\012#define HEADER_H\012... contents of header.h ...\012#endif\012If a header file uses guards or #pragma once, it makes no difference whether it is #included or #imported. The same objection to #import actually applies to Objective-C as well, and many Objective-C programs also use guards in their headers.\012Other features\012Objective-C''s features often allow for flexible, and often easy, solutions to programming issues.\012Delegating methods to other objects and remote invocation can be easily implemented using categories and message forwarding.\012Swizzling of the isa pointer allows for classes to change at runtime. Typically used for debugging where freed objects are swizzled into zombie objects, whose only purpose is to report an error when someone calls them. Swizzling was also used in EOF to create database faults. Swizzling is used today by Apple’s Foundation Framework to implement Key-Value Observing.\012Serialization, commonly called archival in Objective-C, can be done by overriding write and read methods.\012Language variants\012Objective-C++\012Objective-C++ is a front-end to the GNU Compiler Collection which can compile source files which use a combination of C++ and Objective-C syntax. Objective-C++ adds to C++ the extensions Objective-C adds to C. As nothing is done to unify the semantics behind the various language features, certain restrictions apply:\012A C++ class cannot derive from an Objective-C class and vice versa.\012C++ namespaces cannot be declared inside an Objective-C declaration.\012Objective-C classes cannot have instance variables of C++ classes which do not have a default constructor or which have one or more virtual methods, but pointers to C++ objects can be used as instance variables without restriction (allocate them with new in the -init method).\012C++ "by value" semantics cannot be applied to Objective-C objects, which are only accessible through pointers.\012An Objective-C declaration cannot be within a C++ template declaration and vice versa. Objective-C types, (e.g., Classname *) can be used as C++ template parameters, however.\012Objective-C and C++ exception handling is distinct; the handlers of each cannot handle exceptions of the other type.\012Care must be taken since the destructor calling conventions of Objective-C and C++’s exception run-time models do not match (i.e., a C++ destructor will not be called when an Objective-C exception exits the C++ object’s scope).\012Objective-C 2.0\012At the 2006 Worldwide Developers Conference, Apple announced the forthcoming release of "Objective-C 2.0," a revision of the Objective-C language to include "modern garbage collection, syntax enhancements[2], runtime performance improvements[3], and 64-bit support". Mac OS X v10.5, released in October 2007, included an Objective-C 2.0 compiler. It is not yet known when these language improvements will be available in the GNU runtime.\012Garbage collection\012Objective-C 2.0 provides an optional conservative yet generational garbage collector. When run in backwards-compatible mode, the runtime turns reference counting operations such as "retain" and "release" into no-ops. All objects are subject to garbage collection when garbage collection is enabled. Regular C pointers may be qualified with "__strong" to also trigger the underlying write-barrier compiler intercepts and thus participate in garbage collection. A zero-ing weak subsystem is also provided such that pointers marked as "__weak" are set to zero when the object (or more simply GC memory) is collected.\012Properties\012Objective-C 2.0 introduces a new syntax to declare instance variables as properties, with optional attributes to configure the generation of accessor methods. A property may be declared as "readonly", and may be provided with storage semantics such as "assign", "copy" or "retain".\012@interface Person : NSObject {\012@public NSString *name;\012@private int age;\012}\012@property(copy) NSString *name;\012@property(readonly) int age;\012-(id)initWithAge:(int)age;\012@end\012Properties are implemented by way of the @synthesize keyword, which generates getter and setter methods according to the property declaration. Alternately, the @dynamic keyword can be used to indicate that accessor methods will be provided by other means.\012@implementation Person\012@synthesize name;\012@dynamic age;\012-(id)initWithAge:(int)initAge\012{\012age = initAge; // NOTE: direct instance variable assignment, not property setter\012return self;\012}\012-(int)age\012{\012return 29; // NOTE: lying about age\012}\012@end\012Properties can be accessed using the traditional message passing syntax, dot notation, or by name via the "valueForKey:"/"setValue:forKey:" methods.\012Person *aPerson = [[Person alloc] initWithAge: 53];\012aPerson.name = @"Steve"; // NOTE: dot notation, uses synthesized setter, equivalent to [aPerson setName: @"Steve"];\012NSLog(@"Access by message (%@), dot notation(%@), property name(%@) and direct instance variable access (%@)",\012[aPerson name], aPerson.name, [aPerson valueForKey:@"name"], aPerson->name);\012In order to use dot notation to invoke property accessors within an instance method, the "self" keyword should be used:\012-(void) introduceMyselfWithProperties:(BOOL)useGetter\012{\012NSLog(@"Hi, my name is %@.", (useGetter ? self.name : name)); // NOTE: getter vs. ivar access\012}\012A class or protocol''s properties may be dynamically introspected.\012int i, propertyCount = 0;\012objc_property_t *propertyList = class_copyPropertyList([aPerson class], &propertyCount);\012for (i=0; i<propertyCount; i++) {\012objc_property_t *thisProperty = propertyList + i;\012const char* propertyName = property_getName(*thisProperty);\012NSLog(@"Person has a property: ''%s''", propertyName);\012}\012Fast enumeration\012Instead of using an Enumerator object to iterate through a collection, Objective-C 2.0 offers the fast enumeration syntax. The following two loops are equivalent in Objective-C 2.0.\012for (int i=0; i<[thePeople count]; i++) {\012Person *p = [thePeople objectAtIndex:i];\012NSLog(@"%@ is %i years old.", [p getName], [p getAge]);\012}\012for (Person *p in thePeople)\012NSLog(@"%@ is %i years old.", [p getName], [p getAge]);\012Fast enumeration generates more efficient code than standard enumeration because methods calls to enumerate over objects are replaced by pointer arithmetic using the NSFastEnumeration protocol.[4]\012Implications for Cocoa development\012All Objective-C applications developed for Mac OS X that make use of the above improvements for Objective-C 2.0 are incompatible with all operating systems prior to 10.5 (Leopard). Even using fast enumeration, which one might expect to generate the exact same binaries as standard enumeration, will cause an application to crash on OS X version 10.4 or earlier.\012Today\012Objective-C today is often used in tandem with a fixed library of standard objects (often known as a "kit" or "framework"), such as Cocoa or GNUstep. These libraries often come with the operating system: the GNUstep libraries often come with Linux distributions and Cocoa comes with Mac OS X. The programmer is not forced to inherit functionality from the existing base class (NSObject). Objective-C allows for the declaration of new root classes which do not inherit any existing functionality. Originally, Objective-C based programming environments typically offered an Object class as the base class from which almost all other classes inherited. With the introduction of OpenStep, NeXT created a new base class named NSObject which offered additional features over Object (an emphasis on using object references and reference counting instead of raw pointers, for example). Almost all classes in Cocoa inherit from NSObject.\012Not only did the renaming serve to differentiate the new default behavior of classes within the OpenStep API, but it allowed code which used Object — the original base class used on NeXTSTEP (and, more or less, other Objective-C class libraries) — to co-exist in the same runtime with code which used NSObject (with some limitations). As well, the introduction of the two letter prefix became a sort of simplistic form of namespaces, which Objective-C lacks. Using a prefix to create an informal packaging identifier became an informal coding standard in the Objective-C community, and continues to this day.\012Portable Object Compiler\012Besides the GCC/NeXT/Apple implementation, which added several extensions to the original Stepstone implementation, there exists another free open-source Objective-C implementation, which implements a slightly different set of extensions: The Portable Object Compiler [5] implements, among other things, also Smalltalk-like blocks for Objective-C.\012Analysis of the language\012Objective-C implementations use a thin runtime written in C which adds little to the size of the application. In contrast, most OO systems at the time that it was created used large virtual machine runtimes. Programs written in Objective-C tend to be not much larger than the size of their code and that of the libraries (which generally do not need to be included in the software distribution), in contrast to Smalltalk systems where a large amount of memory was used just to open a window. Objective-C applications tend to be larger than similar C or C++ applications because Objective-C dynamic typing does not allow methods to be stripped or inlined.\012Likewise, the language can be implemented on top of existing C compilers (in GCC, first as a preprocessor, then as a module) rather than as a new compiler. This allows Objective-C to leverage the huge existing collection of C code, libraries, tools, and mindshare. Existing C libraries can be wrapped in Objective-C wrappers to provide an OO-style interface.\012All of these practical changes lowered the barrier to entry, likely the biggest problem for the widespread acceptance of Smalltalk in the 1980s.\012The first versions of Objective-C did not support garbage collection. At the time this decision was a matter of some debate, and many people considered long "dead times" (when Smalltalk did collection) to render the entire system unusable. Some 3rd party implementations have added this feature (most notably GNUstep) and Apple have implemented it as of Mac OS X v10.5.[6]\012Another common criticism is that Objective-C does not have language support for namespaces. Instead, programmers are forced to add prefixes to their class names, which are traditionally shorter than namespace names and thus more prone to collisions. As of 2007, all Mac OS X classes and functions in the Cocoa programming environment are prefixed with "NS" (e.g. NSObject, NSButton) to identify them as belonging to the Mac OS X core; the "NS" derives from the names of the classes as defined during the development of NeXTstep.\012Since Objective-C is a strict superset of C, it does not treat C primitive types as first-class objects either.\012Unlike C++, Objective-C does not support operator overloading. Also unlike C++, Objective-C allows an object only to directly inherit from one class (forbidding multiple inheritance). However, categories and protocols may be used as alternative functionality to multiple inheritance.\012Because Objective-C uses dynamic runtime typing and because all method calls are function calls (or, in some cases, syscalls), many common performance optimizations cannot be applied to Objective-C methods (for example: inlining, constant propagation, interprocedural optimizations, and scalar replacement of aggregates). This limits the performance of Objective-C abstractions relative to similar abstractions in languages such as C++. Proponents of Objective-C claim that it should not be used for low level abstraction in the way that C++ or Java are used, because Objective-C is known to have a high runtime cost.\012Philosophical differences between Objective-C and C++\012The design and implementation of C++ and Objective-C represent different approaches to extending C.\012In addition to C’s style of procedural programming, C++ directly supports object-oriented programming, generic programming, and metaprogramming. C++ also comes with a large standard library which includes several container classes. Objective-C, on the other hand, adds only object-oriented features to C. Objective-C in its purest fashion does not contain the same number of standard library features, but in most places where Objective-C is used, it is used with an OpenStep-like library such as OPENSTEP, Cocoa, or GNUstep which provide similar functionality to some of C++’s standard library.\012One notable difference is that Objective-C provides runtime support for some reflective features, whereas C++ adds only a small amount of runtime support to C. In Objective-C, an object can be queried about its own properties, for example whether it will respond to a certain message. In C++ this is not possible without the use of external libraries.\012The use of reflection is part of the wider distinction between dynamic (run-time) features versus static (compile-time) features of a language. Although Objective-C and C++ each employ a mix of both features, Objective-C is decidedly geared toward run-time decisions while C++ is geared toward compile-time decisions. The tension between dynamic and static programming involves many of the classic trade-offs in computer science.\012See also\012Comparison of programming languages\012Notes\012^ http://video.google.com/videoplay?docid=-7466310348707586940&ei=0dr7SIe6L46qrgLk7dHsDg&q=Smalltalk-80\012^ http://lists.apple.com/archives/Objc-language/2006/Aug/msg00039.html\012^ http://lists.apple.com/archives/Objc-language/2006/Aug/msg00018.html\012^ Apple, Inc. (2007). "Fast Enumeration". Retrieved on 2008-06-09.\012^ http://users.pandora.be/stes/compiler.html\012^ Apple, Inc. (August 22, 2006). "Mac OS X Leopard – Xcode 3.0". Retrieved on 2006-08-22.\012References\012Cox, Brad J. (1991). Object Oriented Programming: An Evolutionary Approach. Addison Wesley. ISBN 0-201-54834-8.\012Wikibooks has a book on the topic of\012Programming:Objective-C\012Introduction to The Objective-C Programming Language (Apple Developer Connection)\012The Objective-C 2.0 Programming Language, PDF download from Apple\012Object-Oriented Programming and The Objective-C Language\012Beginner’s Guide to Objective-C\012ObjectiveLib: variant of a Standard Template Library\012Objective-C by Brad Cox\012Object Oriented Programming in Objective-C\012Objective-C FAQ\012comp.lang.objective-C FAQ\012Objective-C: Links, Resources, Stuff\012Objective-C mailing list\012AST for Objective-C in C#\012v • d • e\012C programming language\012Libraries\012C standard library · glibc · Dietlibc · uClibc · Newlib\012Features\012String · Syntax · Preprocessor · Variable types and declarations · Functions\012Descendants\012C++ · Objective-C · D · C# · Cyclone · Java · Vala\012C and Other Languages\012C and C++ (Compatibility · Operators) · Comparison of Pascal and C · C to Java byte-code compiler\012Category\012"http://en.wikipedia.org/wiki/Objective-C"\012Categories: C programming language family | Object-oriented programming languages | Dynamically-typed programming languages | Class-based programming languages | NeXT | GNUstep | Curly bracket programming languagesHidden categories: Wikipedia articles needing copy edit from August 2008 | All articles needing copy edit | All articles with unsourced statements | Articles with unsourced statements since February 2007','\012',char(10)));
INSERT INTO pages VALUES('ChucK','http://web.archive.org/web/20081217072511/http://en.wikipedia.org:80/wiki/Chuck','en','2008-12-17 00:00:00',replace('1 People\n2 Fictional characters\n3 Other uses\n4 See also\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nChuck\nGiven Name\nGender\nMale\nRelated names\nCarl, Charles, Charlie\nWikipedia articles\nAll pages beginning with Chuck\nLook up Chuck in\nWiktionary, the free dictionary.\nChuck is a nickname for Charles.\nIt may also refer to:\nPeople\nChuck Berry, American musician\nChuck Schuldiner, American musician\nChuck Norris, American martial-artist and actor\nChuck Liddell, American mixed martial artist\nChuck Palahniuk, American author\nChuck Palumbo, American professional wrestler\nChuck Yeager, American test pilot\nChuck Todd, American journalist and author\nChuck Taylor, American basketball player\nFictional characters\nChuck Bartowski, the title character of the television series Chuck\nChuck Bass, one of the main characters from the television series Gossip Girl\nCharlotte "Chuck" Charles, one of the main characters from the television series Pushing Daisies\nCharlie Brown, called "Chuck" by Peppermint Patty\nChuck E. Cheese''s, a chain of restaurants\nChuck E. Cheese, the mascot for Chuck E. Cheese''s\nChuck Darling, one of the two main characters in the television situation comedy Back to You\nChuck the Plant, mascot of sorts in several of LucasArts adventure games\nChuck Rock, name of a video game\nCharles Schwab Corp. representative\nLeChuck, a pirate and the main villain appearing in the Monkey Island series of computer games\nUncle Chuck, a character in Sonic the Hedgehog\nChuck, a character in Stargate Atlantis\nChucky (Child''s Play) the doll from the Child''s Play movie series\nChuckie Finster, a character from Rugrats\nChuck the unofficial mascot of Incubus (band)\nChuck Manifold, character in the movie Cars\nOther uses\nChuck (TV series), an American TV series (2007-Present)\nChucK, a programming language for computer music\nChuck (album), an album by Sum 41\nChuck steak, a type of steak\nChuck Taylor All-Stars, the popular canvas shoe produced by Converse Shoes, also referred to as "Chucks"\nChucks is also a short form for nunchucks or nunchaku, a kind of martial arts weapon\nA chuck (engineering), a part of a machine tool such as a lathe that securely holds a removable part\nChuck, a popular but incorrect name for the BSD Daemon (FreeBSD mascot)\nSee also\nChucky (disambiguation)\nThis disambiguation page lists articles associated with the same title. If an internal link led you here, you may wish to change the link to point directly to the intended article.\nNote: This page may need to be cleaned up to meet Wikipedia''s quality standards. See WikiProject Disambiguation for more information.\n"http://en.wikipedia.org/wiki/Chuck"\nCategory: American given namesHidden categories: All disambiguation pages | All article disambiguation pages | Disambiguation pages in need of cleanup','\n',char(10)));
INSERT INTO pages VALUES('Perl','http://web.archive.org/web/20081217060939/http://en.wikipedia.org:80/wiki/Perl','en','2008-12-17 00:00:00',replace('For other uses, see Perl (disambiguation).\012Perl\012Paradigm\012multi-paradigm: functional, imperative, object-oriented (class-based)\012Appeared in\0121987\012Designed by\012Larry Wall\012Latest release\0125.10.0/ 18 December 2007; 365 days ago\012Typing discipline\012Dynamic\012Influenced by\012AWK, Smalltalk 80, C, C++, Pascal, sed, Unix shell\012Influenced\012Python, PHP, Ruby, ECMAScript, Dao, Windows PowerShell, JavaScript\012OS\012Cross-platform\012License\012GNU General Public License, Artistic License\012Website\012http://www.perl.org/\012In computer programming, Perl is a high-level, general-purpose, interpreted, dynamic programming language. Perl was originally developed by Larry Wall, a linguist working as a systems administrator for NASA, in 1987, as a general purpose Unix scripting language to make report processing easier.[1][2] Since then, it has undergone many changes and revisions and became widely popular among programmers. Larry Wall continues to oversee development of the core language, and its coming version, Perl 6.\012Perl borrows features from other programming languages including C, shell scripting (sh), AWK,and sed.[3] The language provides powerful text processing facilities without the arbitrary data length limits of many contemporary Unix tools,[4] facilitating easy manipulation of text files. It is also used for graphics programming, system administration, network programming, applications that require database access and CGI programming on the Web. Perl is nicknamed "the Swiss Army chainsaw of programming languages" due to its flexibility and adaptability.[5]\0121 History\0121.1 Name\0121.2 The camel symbol\0122 Overview\0122.1 Features\0122.2 Design\0122.3 Applications\0122.4 Implementation\0122.5 Availability\0122.5.1 Windows\0123 Language structure\0123.1 Data types\0123.2 Control structures\0123.3 Subroutines\0123.4 Regular expressions\0123.4.1 Uses\0123.4.2 Syntax\0124 Database interfaces\0125 Comparative performance\0125.1 Optimizing\0126 Future\0127 The Perl community\0127.1 State of the Onion\0127.2 Pastimes\0127.2.1 JAPHs\0127.2.2 Perl golf\0127.2.3 Obfuscation\0127.2.4 Poetry\0127.2.5 CPAN Acme\0128 Criticism\0129 Further reading\01210 See also\01211 References\01212\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012History\012Larry Wall began work on Perl in 1987, while working as a programmer at Unisys,[6] and released version 1.0 to the comp.sources.misc newsgroup on December 18, 1987.[7] The language expanded rapidly over the next few years. Perl 2, released in 1988, featured a better regular expression engine. Perl 3, released in 1989, added support for binary data streams.\012Originally the only documentation for Perl was a single (increasingly lengthy) man page. In 1991, Programming perl (known to many Perl programmers as the "Camel Book") was published, and became the de facto reference for the language. At the same time, the Perl version number was bumped to 4, not to mark a major change in the language, but to identify the version that was documented by the book.\012Perl 4 went through a series of maintenance releases, culminating in Perl 4.036 in 1993. At that point, Wall abandoned Perl 4 to begin work on Perl 5.\012Initial design of Perl 5 continued into 1994. The perl5-porters mailing list was established in May 1994 to coordinate work on porting Perl 5 to different platforms. It remains the primary forum for development, maintenance, and porting of Perl 5.[8]\012Perl 5 was released on October 17, 1994. It was a nearly complete rewrite of the interpreter, and added many new features to the language, including objects, references, lexical (my) variables, and modules. Importantly, modules provided a mechanism for extending the language without modifying the interpreter. This allowed the core interpreter to stabilize, even as it enabled ordinary Perl programmers to add new language features.\012As of 2008, Perl 5 is still being actively maintained. Important features and some essential new language constructs have been added along the way, including Unicode support, threads, improved support for object oriented programming and many other enhancements.\012On December 18, 2007, the 20th anniversary of Perl 1.0, Perl 5.10.0 was released. Perl 5.10.0 includes notable new features, which bring it closer to Perl 6, among them a new switch statement (called "given/when"), regular expressions updates, the "smart match operator" ~~, and more.[9]\012One of the most important events in Perl 5 history took place outside of the language proper, and was a consequence of its module support. On October 26, 1995, the Comprehensive Perl Archive Network (CPAN) was established as a repository for Perl modules and Perl itself. At the time of writing, it carries over 13,500 modules by over 6,500 authors. CPAN is widely regarded as one of the greatest strengths of Perl in practice.\012Name\012Perl was originally named "Pearl", after the Parable of the Pearl from the Gospel of Matthew. Larry Wall wanted to give the language a short name with positive connotations; he claims that he considered (and rejected) every three- and four-letter word in the dictionary. He also considered naming it after his wife Gloria. Wall discovered the existing PEARL programming language before Perl''s official release and changed the spelling of the name.\012The name is normally capitalized (Perl) when referring to the language and uncapitalized (perl) when referring to the interpreter program itself, since Unix-like file systems are case-sensitive. Before the release of the first edition of Programming Perl, it was common to refer to the language as perl; Randal L. Schwartz, however, capitalised the language''s name in the book to make it stand out better when typeset. This case distinction was subsequently documented as canonical.[10]\012There is contention about the all-caps spelling "PERL", which the documentation declares incorrect[10] and some core community members even consider a sign of outsiders.[11] While the name is occasionally taken as an acronym for Practical Extraction and Report Language (which appears at the top of the documentation[12]), this expansion actually came after the name; several others have been suggested as equally canonical, including Wall''s own humorous Pathologically Eclectic Rubbish Lister.[13] Indeed, Wall claims that the name was intended to inspire many different expansions.[14]\012The camel symbol\012Programming Perl, published by O''Reilly Media, features a picture of a camel on the cover, and is commonly referred to as The Camel Book.[6] This image of a camel has become a general symbol of Perl.\012It is also a hacker emblem, appearing on some T-shirts and other clothing items.\012O''Reilly owns the image as a trademark, but claims to use their legal rights only to protect the "integrity and impact of that symbol".[15] O''Reilly allows non-commercial use of the symbol, and provides Programming Republic of Perl logos and Powered by Perl buttons.[16] However the Camel has never been meant to be an official Perl symbol, and if one is to be considered instead, then it''s an onion.[17]\012Overview\012Perl is a general-purpose programming language originally developed for text manipulation and now used for a wide range of tasks including system administration, web development, network programming and GUI development.\012The language is intended to be practical (easy to use, efficient, complete) rather than beautiful (tiny, elegant, minimal).[18] Its major features include support for multiple programming paradigms (procedural, object-oriented, and functional styles), reference counting memory management (without a cycle-detecting garbage collector), built-in support for text processing, and a large collection of third-party modules.\012According to Larry Wall, Perl has two slogans. The first is "There''s more than one way to do it", commonly known as TMTOWTDI and the second is "Easy things should be easy and hard things should be possible".[19]\012Features\012The overall structure of Perl derives broadly from C. Perl is procedural in nature, with variables, expressions, assignment statements, brace-delimited code blocks, control structures, and subroutines.\012Perl also takes features from shell programming. All variables are marked with leading sigils, which unambiguously identify the data type (scalar, array, hash, etc.) of the variable in context. Importantly, sigils allow variables to be interpolated directly into strings. Perl has many built-in functions which provide tools often used in shell programming (though many of these tools are implemented by programs external to the shell) like sorting, and calling on system facilities.\012Perl takes lists from Lisp, associative arrays (hashes) from AWK, and regular expressions from sed. These simplify and facilitate many parsing, text handling, and data management tasks.\012In Perl 5, features were added that support complex data structures, first-class functions (i.e., closures as values), and an object-oriented programming model. These include references, packages, class-based method dispatch, and lexically scoped variables, along with compiler directives (for example, the strict pragma). A major additional feature introduced with Perl 5 was the ability to package code as reusable modules. Larry Wall later stated that "The whole intent of Perl 5''s module system was to encourage the growth of Perl culture rather than the Perl core."[20]\012All versions of Perl do automatic data typing and memory management. The interpreter knows the type and storage requirements of every data object in the program; it allocates and frees storage for them as necessary using reference counting (so it cannot deallocate circular data structures without manual intervention). Legal type conversions—for example, conversions from number to string—are done automatically at run time; illegal type conversions are fatal errors.\012Design\012The design of Perl can be understood as a response to three broad trends in the computer industry: falling hardware costs, rising labor costs, and improvements in compiler technology. Many earlier computer languages, such as Fortran and C, were designed to make efficient use of expensive computer hardware. In contrast, Perl is designed to make efficient use of expensive computer programmers.\012Perl has many features that ease the programmer''s task at the expense of greater CPU and memory requirements. These include automatic memory management; dynamic typing; strings, lists, and hashes; regular expressions; introspection and an eval() function.\012Wall was trained as a linguist, and the design of Perl is very much informed by linguistic principles. Examples include Huffman coding (common constructions should be short), good end-weighting (the important information should come first), and a large collection of language primitives. Perl favors language constructs that are concise and natural for humans to read and write, even where they complicate the Perl interpreter.\012Perl syntax reflects the idea that "things that are different should look different". For example, scalars, arrays, and hashes have different leading sigils. Array indices and hash keys use different kinds of braces. Strings and regular expressions have different standard delimiters. This approach can be contrasted with languages like Lisp, where the same S-expression construct and basic syntax is used for many different purposes.\012Perl does not enforce any particular programming paradigm (procedural, object-oriented, functional, etc.) or even require the programmer to choose among them.\012There is a broad practical bent to both the Perl language and the community and culture that surround it. The preface to Programming Perl begins, "Perl is a language for getting your job done." One consequence of this is that Perl is not a tidy language. It includes many features, tolerates exceptions to its rules, and employs heuristics to resolve syntactical ambiguities. Because of the forgiving nature of the compiler, bugs can sometimes be hard to find. Discussing the variant behaviour of built-in functions in list and scalar contexts, the perlfunc(1) manual page says "In general, they do what you want, unless you want consistency."\012In addition to Larry Wall''s two slogans mentioned above, Perl has several mottos that convey aspects of its design and use, including "Perl: the Swiss Army Chainsaw of Programming Languages" and "No unnecessary limits". Perl has also been called "The Duct Tape of the Internet".[21]\012There is no written specification or standard for the Perl language, and no plans to create one for the current version of Perl. There has only been one implementation of the interpreter. That interpreter, together with its functional tests, stands as a de facto specification of the language.\012Applications\012Perl has many and varied applications, compounded by the availability of many standard and third-party modules.\012Perl has been used since the early days of the Web to write CGI scripts. It is known as one of "the three Ps" (along with Python and PHP), the most popular dynamic languages for writing Web applications. It is also an integral component of the popular LAMP solution stack for web development. Large projects written in Perl include Slash, Bugzilla, RT, TWiki and Movable Type. Many high-traffic websites, such as bbc.co.uk, Amazon.com, LiveJournal, Ticketmaster, Slashdot, Craigslist and IMDb[22] use Perl extensively.\012Perl is often used as a glue language, tying together systems and interfaces that were not specifically designed to interoperate, and for "data munging", i.e., converting or processing large amounts of data for tasks like creating reports. In fact, these strengths are intimately linked. The combination makes Perl a popular all-purpose language for system administrators, particularly as short programs can be entered and run on a single command line.\012With a degree of care, Perl code can be made portable across Windows and Unix. Portable Perl code is often used by suppliers of software (both COTS and bespoke) to simplify packaging and maintenance of software build and deployment scripts.\012Graphical user interfaces (GUI''s) may be developed using Perl. In particular, Perl/Tk is commonly used to enable user interaction with Perl scripts. Such interaction may be synchronous or asynchronous using callbacks to update the GUI. For more information about the technologies involved see Tk,Tcl and WxPerl.\012Perl is also widely used in finance and bioinformatics, where it is valued for rapid application development and deployment, and the ability to handle large data sets.\012Implementation\012Perl is implemented as a core interpreter, written in C, together with a large collection of modules, written in Perl and C. The source distribution is, as of 2005[update], 12 MB when packaged in a tar file and compressed. The interpreter is 150,000 lines of C code and compiles to a 1 MB executable on typical machine architectures. Alternatively, the interpreter can be compiled to a link library and embedded in other programs. There are nearly 500 modules in the distribution, comprising 200,000 lines of Perl and an additional 350,000 lines of C code. (Much of the C code in the modules consists of character encoding tables.)\012The interpreter has an object-oriented architecture. All of the elements of the Perl language—scalars, arrays, hashes, coderefs, file handles—are represented in the interpreter by C structs. Operations on these structs are defined by a large collection of macros, typedefs and functions; these constitute the Perl C API. The Perl API can be bewildering to the uninitiated, but its entry points follow a consistent naming scheme, which provides guidance to those who use it.\012The execution of a Perl program divides broadly into two phases: compile-time and run-time.[23] At compile time, the interpreter parses the program text into a syntax tree. At run time, it executes the program by walking the tree. The text is parsed only once, and the syntax tree is subject to optimization before it is executed, so the execution phase is relatively efficient. Compile-time optimizations on the syntax tree include constant folding and context propagation, but peephole optimization is also performed. However, compile-time and run-time phases may nest: BEGIN code blocks execute at compile-time, while the eval function initiates compilation during runtime. Both operations are an implicit part of a number of others—most notably, the use clause that loads libraries, known in Perl as modules, implies a BEGIN block.\012Perl has a context-sensitive grammar which can be affected by code executed during an intermittent run-time phase.[24] Therefore Perl cannot be parsed by a straight Lex/Yacc lexer/parser combination. Instead, the interpreter implements its own lexer, which coordinates with a modified GNU bison parser to resolve ambiguities in the language. It is said that "only perl can parse Perl", meaning that only the Perl interpreter (perl) can parse the Perl language (Perl). The truth of this is attested to by the persistent imperfections of other programs that undertake to parse Perl, such as source code analyzers and auto-indenters, which have to contend not only with the many ways to express unambiguous syntactic constructs, but also the fact that Perl cannot be parsed in the general case without executing it. Though successful in creating a Perl parser for document-related purposes, the PPI project determined that parsing Perl code as a document (retaining its integrity) and as executable code simultaneously was, in fact, not possible. Specifically the author claimed that, "parsing Perl suffers from the ''Halting Problem.''"[25]\012Perl is distributed with some 120,000 functional tests. These run as part of the normal build process, and extensively exercise the interpreter and its core modules. Perl developers rely on the functional tests to ensure that changes to the interpreter do not introduce bugs; conversely, Perl users who see the interpreter pass its functional tests on their system can have a high degree of confidence that it is working properly.\012Maintenance of the Perl interpreter has become increasingly difficult over the years. The code base has been in continuous development since 1994. The code has been optimized for performance at the expense of simplicity, clarity, and strong internal interfaces. New features have been added, yet virtually complete backward compatibility with earlier versions is maintained. The size and complexity of the interpreter is a barrier to developers who wish to work on it.\012Availability\012Perl is free software, and is licensed under both the Artistic License and the GNU General Public License. Distributions are available for most operating systems. It is particularly prevalent on Unix and Unix-like systems, but it has been ported to most modern (and many obsolete) platforms. With only six reported exceptions, Perl can be compiled from source code on all Unix-like, POSIX-compliant or otherwise Unix-compatible platforms.[26] However, this is rarely necessary, as Perl is included in the default installation of many popular operating systems.\012Because of unusual changes required for the Mac OS Classic environment, a special port called MacPerl was shipped independently.[27]\012The CPAN carries a complete list of supported platforms with links to the distributions available on each.[28]\012Windows\012Users of Microsoft Windows typically install one of the native binary distributions of Perl for Win32[29], most commonly ActivePerl. Compiling Perl from source code under Windows is possible, but most installations lack the requisite C compiler and build tools. This also makes it hard to install modules from the CPAN, particularly those that are partially written in C.\012Users of the ActivePerl binary distribution are therefore dependent on the repackaged modules provided in ActiveState’s module repository, which are precompiled and can be installed with PPM. Limited resources to maintain this repository have been cause for various long-standing problems.[30][31]\012To address this and other problems of Perl on the Windows platform, win32.perl.org was launched by Adam Kennedy on behalf of The Perl Foundation in June 2006. This is a community website for "all things Windows and Perl." A major aim of this project is to provide production-quality alternative Perl distributions that include an embedded C compiler and build tools, so as to enable Windows users to install modules directly from the CPAN. The production distribution in the family is known as Strawberry Perl, with research and experimental work done in a related Vanilla Perl distribution.\012Another popular way of running Perl under Windows is provided by the Cygwin emulation layer. Cygwin provides a Unix-like environment on Windows and both perl and cpan are conveniently available as standard pre-compiled packages in the Cygwin setup program. Since Cygwin also includes the gcc, compiling Perl from source is also possible.\012Language structure\012In Perl, the minimal Hello world program may be written as follows:\012print "Hello, world!\n"\012This prints the string Hello, world! and a newline, symbolically expressed by an n character whose interpretation is altered by the preceding escape character (a backslash).\012The canonical form of the program is slightly more verbose:\012#!/usr/bin/perl\012print "Hello, world!\n";\012The hash mark character introduces a comment in Perl, which runs up to the end of the line of code and is ignored by the compiler. The comment used here is of a special kind: it’s called the shebang line. This tells Unix-like operating systems where to find the Perl interpreter, making it possible to invoke the program without explicitly mentioning perl. (Note that on Microsoft Windows systems, Perl programs are typically invoked by associating the .pl extension with the Perl interpreter. In order to deal with such circumstances, perl detects the shebang line and parses it for switches,[32] so it is not strictly true that the shebang line is ignored by the compiler.)\012The second line in the canonical form includes a semicolon, which is used to separate statements in Perl. With only a single statement in a block or file, a separator is unnecessary, so it can be omitted from the minimal form of the program—or more generally from the final statement in any block or file. The canonical form includes it because it is common to terminate every statement even when it is unnecessary to do so, as this makes editing easier: code can be added to or moved away from the end of a block or file without having to adjust semicolons.\012Version 5.10 of Perl introduces a say function that implicitly appends a newline character to its output, making the minimal "Hello world" program even shorter:\012say ''Hello, world!''\012Data types\012Perl has a number of fundamental data types, the most commonly used and discussed being: scalars, arrays, hashes, filehandles and subroutines:\012A scalar is a single value; it may be a number, a string or a reference\012An array is an ordered collection of scalars\012A hash, or associative array, is a map from strings to scalars; the strings are called keys and the scalars are called values.\012A file handle is a map to a file, device, or pipe which is open for reading, writing, or both.\012A subroutine is a piece of code that may be passed arguments, be executed, and return data\012Most variables are marked by a leading sigil, which identifies the data type being accessed (not the type of the variable itself), except filehandles, which don''t have a sigil. The same name may be used for variables of different data types, without conflict.\012$foo # a scalar\012@foo # an array\012%foo # a hash\012FOO # a file handle\012&foo # a subroutine (but the & is optional)\012File handles and constants need not be uppercase, but it is a common convention because there is no sigil to denote them. Both are global in scope, but file handles are interchangeable with references to file handles, which can be stored in scalars, which in turn permit lexical scoping. Doing so is encouraged in Damian Conway''s Perl Best Practices. As a convenience, the open function in Perl 5.6 and newer will autovivify undefined scalars to file handle references.\012Numbers are written in the bare form; strings are enclosed by quotes of various kinds.\012$name = "joe";\012$color = ''red'';\012$number1 = 42;\012$number2 = ''42'';\012# This evaluates to true\012if ($number1 == $number2) { print "Numbers and strings of numbers are the same!"; }\012$answer = "The answer is $number1"; # Variable interpolation: The answer is 42\012$price = ''This device costs $42''; # No interpolation in single quotes\012$album = "It''s David Bowie''s \"Heroes\""; # literal quotes inside a string;\012$album = Its David Bowies "Heroes" # same as above with single quotes;\012$album = q(It''s David Bowie''s "Heroes"); # the quote-like operators q() and qq() allow\012# almost any delimiter instead of quotes, to\012# avoid excessive backslashing\012$multilined_string =<<EOF;\012This is my multilined string\012note that I am terminating it with the "EOF" word.\012EOF\012Perl will convert strings into numbers and vice versa depending on the context in which they are used. In the following example the strings $n and $m are treated as numbers when they are the arguments to the addition operator. This code prints the number ''5'', discarding non numeric information for the operation, although the variable values remain the same. (The string concatenation operator is the period, not the + symbol.)\012$n = ''3 apples'';\012$m = ''2 oranges'';\012print $n + $m;\012Perl also has a boolean context that it uses in evaluating conditional statements. The following values all evaluate as false in Perl:\012$false = 0; # the number zero\012$false = 0.0; # the number zero as a float\012$false = 0b0; # the number zero in binary\012$false = 0x0; # the number zero in hexadecimal\012$false = ''0''; # the string zero\012$false = ""; # the empty string\012$false = undef; # the return value from undef\012All other values are evaluated to true. This includes the odd self-describing literal string of "0 but true", which in fact is 0 as a number, but true when used as a boolean. (Any non-numeric string would also have this property, but this particular string is ignored by Perl with respect to numeric warnings.) A less explicit but more conceptually portable version of this string is ''0E0'' or ''0e0'', which does not rely on characters being evaluated as 0, as ''0E0'' is literally "zero times ten to the zeroth power."\012Evaluated boolean expressions also return scalar values. Although the documentation does not promise which particular true or false is returned (and thus cannot be relied on), many boolean operators return 1 for true and the empty-string for false (which evaluates to zero in a numeric context). The defined() function tells if the variable has any value set. In the above examples defined($false) is true for every value except undef.\012If a specifically 1 or 0 result (as in C) is needed, an explicit conversion is thought by some authors to be required:\012my $real_result = $boolean_result ? 1 : 0;\012However, if it''s known that the value is either 1 or undef, an implicit conversion can be used instead:\012my $real_result = $boolean_result + 0;\012A list is written by listing its elements, separated by commas, and enclosed by parentheses where required by operator precedence.\012@scores = (32, 45, 16, 5);\012It can be written many other ways as well, some straightforward and some less so:\012# An explicit and straightforward way\012@scores = (''32'', ''45'', ''16'', ''5'');\012# Equivalent to the above, but the qw() quote-like operator saves typing of\012# quotes and commas and reduces visual clutter; almost any delimiter can be\012# used instead of parentheses\012@scores = qw(32 45 16 5);\012# The split function returns a list of strings, which are extracted\012# from the expression using a regex template.\012# This may be useful for reading from a file of comma-separated values (CSV)\012@scores = split /,/, ''32,45,16,5'';\012# It''s also possible to use a postfix for operator and aliasing of\012# the $_ magic variable to the next value of the list during each\012# iteration; this is pointless here, but similar idioms are widely used\012# in some circumstances.\012push @scores, $_ foreach 32, 45, 16, 5;\012A hash may be initialized from a list of key/value pairs:\012%favorite = (\012joe => ''red'',\012sam => ''blue''\012);\012The => operator is equivalent to a comma, except that it assumes quotes around the preceding token if it is a bare identifier: (joe => ''red'') is the same as (''joe'' => ''red''). It can therefore be used to elide quote marks, improving readability.\012Individual elements of a list are accessed by providing a numerical index, in square brackets. Individual values in a hash are accessed by providing the corresponding key, in curly braces. The $ sigil identifies the accessed element as a scalar.\012$scores[2] # an element of @scores\012$favorite{joe} # a value in %favorite\012Thus, a hash can also be specified by setting its keys individually:\012$favorite{joe} = ''red'';\012$favorite{sam} = ''blue'';\012Multiple elements may be accessed by using the @ sigil instead (identifying the result as a list).\012@scores[2, 3, 1] # three elements of @scores\012@favorite{''joe'', ''sam''} # two values in %favorite\012@favorite{qw(joe sam)} # same as above\012The number of elements in an array can be obtained by evaluating the array in scalar context or with the help of the $# sigil. The latter gives the index of the last element in the array, not the number of elements. Note: the syntax highlighting in Wikipedia''s software mistakenly considers some of the following code to be part of the comments.\012$count = @friends; # Assigning to a scalar forces scalar context\012$#friends; # The index of the last element in @friends\012$#friends+1; # Usually the number of elements in @friends is one more\012# than $#friends because the first element is at index 0,\012# not 1, unless the programmer reset this to a different\012# value, which most Perl manuals discourage.\012There are a few functions that operate on entire hashes.\012@names = keys %addressbook;\012@addresses = values %addressbook;\012# Every call to each returns the next key/value pair.\012# All values will be eventually returned, but their order\012# cannot be predicted.\012while (($name, $address) = each %addressbook) {\012print "$name lives at $address\n";\012}\012# Similar to the above, but sorted alphabetically\012foreach my $next_name (sort keys %addressbook) {\012print "$next_name lives at $addressbook{$next_name}\n";\012}\012Control structures\012Main article: Perl control structures\012Perl has several kinds of control structures.\012It has block-oriented control structures, similar to those in the C, Javascript, and Java programming languages. Conditions are surrounded by parentheses, and controlled blocks are surrounded by braces:\012label while ( cond ) { ... }\012label while ( cond ) { ... } continue { ... }\012label for ( init-expr ; cond-expr ; incr-expr ) { ... }\012label foreach var ( list ) { ... }\012label foreach var ( list ) { ... } continue { ... }\012if ( cond ) { ... }\012if ( cond ) { ... } else { ... }\012if ( cond ) { ... } elsif ( cond ) { ... } else { ... }\012Where only a single statement is being controlled, statement modifiers provide a more concise syntax:\012statement if cond ;\012statement unless cond ;\012statement while cond ;\012statement until cond ;\012statement foreach list ;\012Short-circuit logical operators are commonly used to affect control flow at the expression level:\012expr and expr\012expr && expr\012expr or expr\012expr || expr\012(The "and" and "or" operators are similar to && and || but have lower precedence, which makes it easier to use them to control entire statements.)\012The flow control keywords next (corresponding to C''s continue), last (corresponding to C''s break), return, and redo are expressions, so they can be used with short-circuit operators.\012Perl also has two implicit looping constructs, each of which has two forms:\012results = grep { ... } list\012results = grep expr, list\012results = map { ... } list\012results = map expr, list\012grep returns all elements of list for which the controlled block or expression evaluates to true. map evaluates the controlled block or expression for each element of list and returns a list of the resulting values. These constructs enable a simple functional programming style.\012Up until the 5.10.0 release, there was no switch statement in Perl 5. From 5.10.0 onwards, a multi-way branch statement called given/when is available, which takes the following form:\012given ( expr ) { when ( cond ) { ... } default { ... } }\012Syntactically, this structure behaves similarly to switch statements found in other languages, but with a few important differences. The largest is that unlike switch/case structures, given/when statements break execution after the first successful branch, rather than waiting for explicitly defined break commands. Conversely, explicit continues are instead necessary to emulate switch behavior.\012For those not using the 5.10.0 release, the Perl documentation describes a half-dozen ways to achieve the same effect by using other control structures. There is also a Switch module, which provides functionality modeled on the forthcoming Perl 6 re-design. It is implemented using a source filter, so its use is unofficially discouraged.[33]\012Perl includes a goto label statement, but it is rarely used. Situations where a goto is called for in other languages don''t occur as often in Perl due to its breadth of flow control options.\012There is also a goto &sub statement that performs a tail call. It terminates the current subroutine and immediately calls the specified sub. This is used in situations where a caller can perform more efficient stack management than Perl itself (typically because no change to the current stack is required), and in deep recursion tail calling can have substantial positive impact on performance because it avoids the overhead of scope/stack management on return.\012Subroutines\012Subroutines are defined with the sub keyword, and invoked simply by naming them. If the subroutine in question has not yet been declared, invocation requires either parentheses after the function name or an ampersand (&) before it. But using & without parentheses will also implicitly pass the arguments of the current subroutine to the one called, and using & with parentheses will bypass prototypes.\012# Calling a subroutine\012# Parentheses are required here if the subroutine is defined later in the code\012foo();\012&foo; # (this also works, but has other consequences regarding arguments passed to the subroutine)\012# Defining a subroutine\012sub foo { ... }\012foo; # Here parentheses are not required\012A list of arguments may be provided after the subroutine name. Arguments may be scalars, lists, or hashes.\012foo $x, @y, %z;\012The parameters to a subroutine do not need to be declared as to either number or type; in fact, they may vary from call to call. Any validation of parameters must be performed explicitly inside the subroutine.\012Arrays are expanded to their elements, hashes are expanded to a list of key/value pairs, and the whole lot is passed into the subroutine as one flat list of scalars.\012Whatever arguments are passed are available to the subroutine in the special array @_. The elements of @_ are aliased to the actual arguments; changing an element of @_ changes the corresponding argument.\012Elements of @_ may be accessed by subscripting it in the usual way.\012$_[0], $_[1]\012However, the resulting code can be difficult to read, and the parameters have pass-by-reference semantics, which may be undesirable.\012One common idiom is to assign @_ to a list of named variables.\012my ($x, $y, $z) = @_;\012This provides mnemonic parameter names and implements pass-by-value semantics. The my keyword indicates that the following variables are lexically scoped to the containing block.\012Another idiom is to shift parameters off of @_. This is especially common when the subroutine takes only one argument, or for handling the $self argument in object-oriented modules.\012my $x = shift;\012Subroutines may assign @_ to a hash to simulate named arguments; this is recommended in Perl Best Practices for subroutines that are likely ever to have more than three parameters.[34]\012sub function1 {\012my %args = @_;\012print "''x'' argument was ''$args{x}''\n";\012}\012function1( x => 23 );\012Subroutines may return values.\012return 42, $x, @y, %z;\012If the subroutine does not exit via a return statement, then it returns the last expression evaluated within the subroutine body. Arrays and hashes in the return value are expanded to lists of scalars, just as they are for arguments.\012The returned expression is evaluated in the calling context of the subroutine; this can surprise the unwary.\012sub list { (4, 5, 6) }\012sub array { @x = (4, 5, 6); @x }\012$x = list; # returns 6 - last element of list\012$x = array; # returns 3 - number of elements in list\012@x = list; # returns (4, 5, 6)\012@x = array; # returns (4, 5, 6)\012A subroutine can discover its calling context with the wantarray function.\012sub either {\012return wantarray ? (1, 2) : ''Oranges'';\012}\012$x = either; # returns "Oranges"\012@x = either; # returns (1, 2)\012Regular expressions\012The Perl language includes a specialized syntax for writing regular expressions (RE, or regexes), and the interpreter contains an engine for matching strings to regular expressions. The regular expression engine uses a backtracking algorithm, extending its capabilities from simple pattern matching to string capture and substitution. The regular expression engine is derived from regex written by Henry Spencer.\012The Perl regular expression syntax was originally taken from Unix Version 8 regular expressions. However, it diverged before the first release of Perl, and has since grown to include many more features. Other languages and applications are now adopting Perl compatible regular expressions over POSIX regular expressions including PHP, Ruby, Java, Microsoft''s .NET Framework[35], and the Apache HTTP server.\012Regular expression syntax is extremely compact, owing to history. The first regular expression dialects were only slightly more expressive than globs, and the syntax was designed so that an expression would resemble the text it matches. This meant using no more than a single punctuation character or a pair of delimiting characters to express the few supported assertions. Over time, the expressiveness of regular expressions grew tremendously, but the syntax design was never revised and continues to rely on punctuation. As a result, regular expressions can be cryptic and extremely dense.\012Uses\012The m// (match) operator introduces a regular expression match. (If it is delimited by slashes, as in all the examples here, then the leading m may be omitted for brevity. If the m is present, as in all the following examples, other delimiters can be used in place of slashes.) In the simplest case, an expression like\012$x =~ /abc/;\012evaluates to true if and only if the string $x matches the regular expression abc.\012The s/// (substitute) operator, on the other hand, specifies a search and replace operation:\012$x =~ s/abc/aBc/; # upcase the b\012Another use of regular expressions is to specify delimiters for the split function:\012@words = split /,/, $line;\012The split function creates a list of the parts of the string separated by matches of the regular expression. In this example, a line is divided into a list of its comma-separated parts, and this list is then assigned to the @words array.\012Syntax\012Portions of a regular expression may be enclosed in parentheses; corresponding portions of a matching string are captured. Captured strings are assigned to the sequential built-in variables $1, $2, $3, ..., and a list of captured strings is returned as the value of the match.\012$x =~ /a(.)c/; # capture the character between ''a'' and ''c''\012Perl regular expressions can take modifiers. These are single-letter suffixes that modify the meaning of the expression:\012$x =~ /abc/i; # case-insensitive pattern match\012$x =~ s/abc/aBc/g; # global search and replace\012Since regular expressions can be dense and cryptic because of their compact syntax, the /x modifier was added in Perl to help programmers write more legible regular expressions. It allows programmers to place whitespace and comments inside regular expressions:\012$x =~ /a # match ''a''\012. # followed by any character\012c # then followed by the ''c''character\012/x;\012Database interfaces\012Perl is widely favored for database applications. Its text handling facilities are useful for generating SQL queries; arrays, hashes and automatic memory management make it easy to collect and process the returned data.\012In early versions of Perl, database interfaces were created by relinking the interpreter with a client-side database library. This was sufficiently difficult that it was only done for a few of the most important and widely used databases, and restricted the resulting perl executable to using just one database interface at a time.\012In Perl 5, database interfaces are implemented by Perl DBI modules. The DBI (Database Interface) module presents a single, database-independent interface to Perl applications, while the DBD (Database Driver) modules handle the details of accessing some 50 different databases; there are DBD drivers for most ANSI SQL databases.\012DBI provides caching for database handles and queries, which can greatly improve performance in long-lived execution environments such as mod_perl[36], helping high-volume systems avert load spikes as in the Slashdot effect.\012Comparative performance\012The Computer Language Benchmarks Game[37] compares the performance of implementations of typical programming problems in several programming languages. The submitted Perl implementations were typically towards the high end of the memory usage spectrum, and had varied speed results. Perl''s performance in the benchmarks game is similar to other interpreted languages such as Python, faster than PHP, and significantly faster than Ruby, but slower than most compiled languages.\012Perl programs can start slower than similar programs in compiled languages because perl has to compile the source every time it runs. In a talk at the YAPC::Europe 2005 conference and subsequent article, "A Timely Start", Jean-Louis Leroy found that his Perl programs took much longer to run than he expected because the perl interpreter spent much of the time finding modules because of his over-large include path.[38] Because pre-compiling is still an experimental part of Perl[39]—unlike that of Java, Python, and Ruby—Perl programs pay this overhead penalty on every execution. When amortized over a long run phase, startup time is not typically substantial, but measurement of very short execution times can often be skewed as is often found in benchmarks.\012A number of tools have been introduced to improve this situation, the first of which was Apache''s mod_perl, which sought to address one of the most common reasons that small Perl programs were invoked rapidly: CGI Web development. ActivePerl, via Microsoft ISAPI provides similar performance improvements.\012Once Perl code is compiled, there is additional overhead during the execution phase that typically isn''t present for programs written in compiled languages like C or C++, including, among many other things, overhead due to bytecode interpretation, reference-counting memory management, and dynamic type checking.\012Optimizing\012Perl programs, like any code, can be tuned for performance using benchmarks and profiles after a readable and correct implementation is finished. In part because of Perl''s interpreted nature, writing more efficient Perl will not always be enough to meet one''s performance goals for a program.\012In such situations, the most critical routines of a Perl program can be written in other languages such as C or Assembler, which can be connected to Perl via simple Inline modules or the more complex but flexible XS mechanism.[40] Nicholas Clark, a Perl core developer, discusses some Perl design trade-offs and some solutions in When perl is not quite fast enough.[41]\012In extreme cases, optimizing Perl can require intimate knowledge of the interpreter''s workings rather than skill with algorithms, the Perl language, or general principles of optimization.\012Future\012Main article: Perl 6\012At the 2000 Perl Conference, Jon Orwant made a case for a major new language initiative.[42] This led to a decision to begin work on a redesign of the language, to be called Perl 6. Proposals for new language features were solicited from the Perl community at large, and over 300 RFCs were submitted.\012Larry Wall spent the next few years digesting the RFCs and synthesizing them into a coherent framework for Perl 6. He has presented his design for Perl 6 in a series of documents called "apocalypses", which are numbered to correspond to chapters in Programming Perl ("The Camel Book"). The current, not yet finalized specification of Perl 6 is encapsulated in design documents called Synopses, which are numbered to correspond to Apocalypses.\012Perl 6 is not intended to be backward compatible, though there will be a compatibility mode.\012Thesis work by Bradley M. Kuhn, overseen by Larry Wall, considered the possible use of the Java virtual machine as a runtime for Perl.[43] Kuhn''s thesis showed this approach to be problematic, and in 2001, it was decided that Perl 6 would run on a cross-language virtual machine called Parrot. This will mean that other languages targeting the Parrot will gain native access to CPAN, allowing some level of cross-language development.\012In 2005 Audrey Tang created the pugs project, an implementation of Perl 6 in Haskell. This was and continues to act as a test platform for the Perl 6 language (separate from the development of the actual implementation) allowing the language designers to explore. The pugs project spawned an active Perl/Haskell cross-language community centered around the freenode #perl6 irc channel.\012A number of features in the Perl 6 language now show similarities with Haskell, and Perl 6 has been embraced by the Haskell community as a potential scripting language.\012As of 2006[update], Perl 6, Parrot, and pugs are under active development, and a new module for Perl 5 called v6 allows some Perl 6 code to run directly on top of Perl 5.\012Development of Perl 5 is also continuing. Perl 5.10 was released in December of 2007, with some new features influenced by the design of Perl 6.\012The Perl community\012Perl''s culture and community has developed alongside the language itself. Usenet was the first public venue in which Perl was introduced, but over the course of its evolution, Perl''s community was shaped by the growth of broadening Internet-based services including the introduction of the World Wide Web. The community that surrounds Perl was, in fact, the topic of Larry Wall''s first "State of the Onion" talk.[44]\012State of the Onion\012State of the Onion is the name for Larry Wall’s yearly keynote-style summaries on the progress of Perl and its community. They are characterized by his hallmark humor, employing references to Perl’s and the wider hacker culture, as well as Wall’s linguistic and sometimes his Christian background.\012Each talk is first given at various Perl conferences and eventually also published online.\012Pastimes\012Perl''s pastimes have become a defining element of the community. Included among them are trivial and complex uses of the language.\012JAPHs\012In email, Usenet and message board postings, "Just another Perl hacker" (JAPH) programs have become a common trend, originated by Randal L. Schwartz, one of the earliest professional Perl trainers.[45]\012In the parlance of Perl culture, Perl programmers are known as Perl hackers, and from this derives the practice of writing short programs to print out the phrase "Just another Perl hacker,". In the spirit of the original concept, these programs are moderately obfuscated and short enough to fit into the signature of an email or Usenet message. The "canonical" JAPH includes the comma at the end, although this is often omitted.\012Perl golf\012Perl "golf" is the pastime of reducing the number of characters (key "strokes") used in a Perl program to the bare minimum, much as how golf players seek to take as few shots as possible in a round. This use of the word "golf" originally focused on the JAPHs used in signatures in Usenet postings and elsewhere, though the same stunts had been an unnamed pastime in the language APL in previous decades. The use of Perl to write a program which performed RSA encryption prompted a widespread and practical interest in this pastime.[46] In subsequent years, code golf has been taken up as a pastime in other languages besides Perl.[47]\012Obfuscation\012As with C, obfuscated code competitions are a well-known pastime. The annual Obfuscated Perl contest made an arch virtue of Perl''s syntactic flexibility.\012Poetry\012Similar to obfuscated code and golf, but with a different purpose, Perl poetry is the practice of writing poems that can actually be compiled as legal (although generally non-sensical) Perl code. This hobby is more or less unique to Perl due to the large number of regular English words used in the language. New poems are regularly published in the Perl Monks site''s Perl Poetry section.[48]\012CPAN Acme\012There are also many examples of code written purely for entertainment on the CPAN. Lingua::Romana::Perligata, for example, allows writing programs in Latin.[49] Upon execution of such a program, the module translates its source code into regular Perl and runs it.\012The Perl community has set aside the "Acme" namespace for modules that are fun in nature (but its scope has widened to include exploratory or experimental code or any other module that is not meant to ever be used in production). Some of the Acme modules are deliberately implemented in amusing ways. This includes Acme::Bleach, one of the first modules in the Acme:: namespace,[50] which allows the program''s source code to be "whitened" (i.e., all characters replaced with whitespace) and yet still work.\012Criticism\012Some common points of criticism:\012Perl code is often considered noisy because the language uses more punctuation than typical.\012Many behaviours are controlled by special global variables with single-character non-alphabetical names.\012Carelessly written Perl programs are hard to read because of prevalent punctuation and high syntactic flexibility. See also Write-only language.\012Object orientation support is restricted to a mechanism for invoking methods via a reference. There is no provision for instance data beyond the reference itself, and the usual way of storing instance data (using a hash reference as the object and storing instance data as keys in that hash) lacks protection against typos, requires knowledge of the superclass implementation in subclasses, and is vulnerable to name collisions.\012Perl OOP has no obvious mechanism for class-private methods.\012It''s a dynamic language, which leads to the usual dynamic-vs.-static arguments.\012Parameters are passed to subroutines in an array rather than via formal, named arguments. (The next major release, 5.12, will probably address this.)\012Nested lists flatten unless the structure is explicitly conserved with reference constructors. This is equivalent in expressiveness to the more common design of implicit references with explicit flattening, but is often mistaken for a lack of nested data structures.\012There is no proper specification for the language. The language is defined by the behaviour of its sole implementation.\012"...today a large number of people continue to use AWK, saying languages such as Perl have become too complicated. Some say Perl has become such a complex language that it''s become almost impossible to understand the programs once they''ve been written." - Alfred V. Aho [51]\012Further reading\012Learning Perl, Fifth Edition (the Llama book), ISBN 0-596-52010-6\012Perl Cookbook, ISBN 0-596-00313-7\012Programming Perl, (the Camel book), ISBN 0-596-00027-8\012See also\012Free software portal\012The Perl Foundation\012Perl instruction at Wikiversity—you can use the training and/or help add to it\012Perl Object Environment (POE)—a framework for writing persistent object-oriented environments with event loops.\012Perl Data Language (PDL)—a Perl module which allows extending Perl for higher-order scientific processing.\012Plain Old Documentation (POD)—a documentation tool for Perl.\012Just another Perl hacker (JAPH)\012Perl Monks\012Perl Mongers\012PerlScript\012Perl 6\012Comparison of programming languages\012Autovivification\012Common Gateway Interface (CGI)\012References\012^ What is Perl?\012^ perl.com: Beginner''s Introduction to Perl\012^ Ashton, Elaine (1999). "The Timeline of Perl and its Culture (v3.0_0505)".\012^ Wall, Larry, Tom Christiansen and Jon Orwant (July 2000). Programming Perl, Third Edition. O''Reilly. ISBN 0-596-00027-8.\012^ Sheppard, Doug (2000-10-16). "Beginner''s Introduction to Perl".\012O''Reilly Media. Retrieved on 2008-07-27.\012^ a b "Larry Wall". Retrieved on 2006-08-20.\012^ "Perl, a "replacement" for awk and sed". Retrieved on 2007-12-18.\012^ `perl5-porters'' Mailing List Archive\012^ perldelta—what is new for perl 5.10.0\012^ a b "perlfaq1: What''s the difference between "perl" and "Perl"?".\012^ Schwartz, Randal. "PERL as shibboleth and the Perl community". Retrieved on 2007-06-01.\012^ Wall, Larry. "Larry Wall". Retrieved on 2008-10-02.\012^ Wall, Larry. "BUGS". perl(1) man page. Retrieved on 2006-10-13.\012^ Wall, Larry. "Re^7: PERL as shibboleth and the Perl community". Retrieved on 2007-01-03.\012^ O''Reilly—The Perl Camel Usage and Trademark Information\012^ Index of /images/perl\012^ Perl Trademark, User Logos, Perl Marks and more\012^ perlintro(1) man page\012^ With Larry Wall, Creator Of Perl\012^ Usenet post, May 10th 1997, with ID 199705101952.MAA00756@wall.org.\012^ "The Importance of Perl".\012O''Reilly & Associates, Inc. (April 1998). "As Hassan Schroeder, Sun''s first webmaster, remarked: “Perl is the duct tape of the Internet.”"\012^ "IMDb Helpdesk: What software/hardware are you using to run the site?". Retrieved on 2007-09-01.\012^ A description of the Perl 5 interpreter can be found in Programming Perl, 3rd Ed., chapter 18\012^ Schwartz, Randal. "On Parsing Perl". Retrieved on 2007-01-03.\012^ Kennedy, Adam (2006). "PPI—Parse, Analyze and Manipulate Perl (without perl)".\012CPAN.\012^ Hietaniemi, Jarkko (1998). "Perl Ports (Binary Distributions)".\012CPAN.org.\012^ "The MacPerl Pages".\012Prime Time Freeware (1997).\012^ CPAN/ports\012^ "Win32 Distributions".\012Win32 Perl Wiki.\012^ Golden, David (2006). "Activestate and Scalar-List-Utils".\012^ Kennedy, Adam (2007). "ActivePerl PPM repository design flaw goes critical".\012^ "perlrun manpage".\012^ using switch\012^ Damian Conway, Perl Best Practices, p.182\012^ Microsoft Corp., ".NET Framework Regular Expressions", .NET Framework Developer''s Guide, [1]\012^ Bekman, Stas. "Efficient Work with Databases under mod_perl". Retrieved on 2007-09-01.\012^ The Computer Language Benchmarks Game\012^ Leroy, Jean-Louis (2005-12-01). "A Timely Start".\012Perl.com.\012^ Beattie, Malcolm and Enache Adrian (2003). "B::Bytecode Perl compiler''s bytecode backend".\012search.cpan.org.\012^ http://search.cpan.org/perldoc/Inline/\012^ When perl is not quite fast enough\012^ Transcription of Larry''s talk. Retrieved on 2006 September 28.\012^ Kuhn, Bradley (January 2001). "Considerations on Porting Perl to the Java Virtual Machine".\012University of Cincinnati. Retrieved on 2008-06-28.\012^ Wall, Larry (1997-08-20). "Perl Culture (AKA the first State of the Onion)".\012^ Randal L. Schwartz (1999-05-02). "Who is Just another Perl hacker?". comp.lang.perl.misc. (Web link). Retrieved on 2007-11-12.\012^ The quest for the most diminutive munitions program\012^ "Code Golf: What is Code Golf?".\01229degrees (2007).\012^ Perl Poetry section on Perl Monks\012^ Conway, Damian. "Lingua::Romana::Perligata -- Perl for the XXI-imum Century".\012^ Brocard, Leon (2001-05-23). "use Perl; Journal of acme".\012^ http://www.computerworld.com.au/index.php/id;1726534212;pp;3\012Wikibooks has a book on the topic of\012Perl Programming\012At Wikiversity you can learn about Perl at:\012Topic:Perl\012Perl.org—Official Perl website\012Perl documentation\012The Perl Foundation\012Official Perl 5 Wiki\012Perl at the Open Directory Project\012v • d • e\012Perl\012People\012Larry Wall · Randal L. Schwartz · Damian Conway · Allison Randal · Audrey Tang · Simon Cozens · Sean M. Burke\012Things\012The Perl Foundation (Perl Mongers · PerlMonks · archives) · module · Parrot · YAPC · Bioperl\012Frameworks\012Catalyst · Mason · Maypole\012v • d • e\012Free and open source software\012General\012Copyleft · Events and Awards · Free software · Free Software Definition · Gratis versus Libre · Open source software\012Free software\012portal\012Notable packages\012Apache · CUPS · Firefox · GNOME · KDE · OpenOffice.org · Thunderbird · X Window System\012Operating systems\012BSD · Darwin · FreeDOS · GNU · Haiku · Linux · Mach · MINIX · OpenSolaris · ReactOS\012Development\012GCC · LLVM · Java · Perl · PHP · Python · Lua · Ruby · Tcl\012History\012Linux · Mozilla (Application Suite · Firefox · Thunderbird)\012Organizations\012Apache Software Foundation · Blender Foundation · Eclipse Foundation · FLOSS Manuals · freedesktop.org · Free Software Foundation · GNOME Foundation · GNU Project · Google Code · Linux Foundation · Mozilla Foundation · Open Source Initiative · SourceForge · Xiph.Org Foundation · X.Org Foundation\012Licences\012Apache · BSD · GPL · LGPL · MIT · MPL · Creative Commons · Permissive · Microsoft Public License · Microsoft Reciprocal License · FSF approved licenses\012Challenges\012Binary blob · Digital rights management · License proliferation · Mozilla software rebranding · Proprietary software · SCO-Linux controversies · Security · Software patents · Tivoization · Trusted Computing\012Other topics\012Alternative terms · Community · Linux distribution · Forking · Movement · Microsoft Open Specification Promise · Revolution OS · Comparison with closed source\012List of open source software packages\012"http://en.wikipedia.org/wiki/Perl"\012Categories: Perl | Curly bracket programming languages | Dynamic programming languages | Dynamically-typed programming languages | Free compilers and interpreters | Procedural programming languages | Scripting languages | Text-oriented programming languages | Unix software | Cross-platform softwareHidden categories: Articles containing potentially dated statements from 2005 | All articles containing potentially dated statements | All articles with unsourced statements | Articles with unsourced statements since June 2007 | Articles with unsourced statements since July 2007 | Articles with unsourced statements since October 2007 | Articles containing potentially dated statements from 2006','\012',char(10)));
INSERT INTO pages VALUES('LiveScript','http://web.archive.org/web/20060913000000/http://en.wikipedia.org:80/wiki/Livescript','en','2006-09-13 00:00:00','');
INSERT INTO pages VALUES('Modula-3','http://web.archive.org/web/20080809084011/http://en.wikipedia.org:80/wiki/Modula-3','en','2008-08-09 00:00:00',replace('Modula-3\012Paradigm\012imperative, structured, modular\012Appeared in\0121980s\012Designed by\012DEC and Olivetti\012Typing discipline\012strong, static\012Major implementations\012CM3, PM3, EZM3, HM3\012Influenced by\012Modula-2+, Modula-2, Pascal, ALGOL\012Influenced\012Java, Python[1], Caml, C#\012Modula-3 is a programming language conceived as a successor to an upgraded version of Modula-2. While it has been influential in research circles (influencing the designs of languages such as Java and C#), it has not been adopted widely in industry. It was designed by Luca Cardelli, Jim Donahue, Mick Jordan, Bill Kalsow and Greg Nelson at the Digital Equipment Corporation (DEC) Systems Research Center (SRC) and Olivetti in the late 1980s. Its design was heavily influenced by work on the Modula-2+ language in use at SRC at the time, which was the language in which the operating system for the DEC Firefly multiprocessor VAX workstation was written. As the revised Modula-3 Report states, the language was also influenced by other languages such as Mesa, Cedar, Object Pascal, Oberon and Euclid.[2]\012Modula-3''s main features are simplicity and safety while preserving the power of a systems-programming language. Modula-3 aimed to continue the Pascal tradition of type safety, while introducing new constructs for practical real-world programming. In particular Modula-3 added support for generic programming (similar to templates), multithreading, exception handling, garbage collection, object-oriented programming, partial revelation and encapsulation of unsafe code. The design goal of Modula-3 was a language that implements the most important features of modern imperative languages in quite basic forms. Thus allegedly dangerous and complicating features like multiple inheritance and operator overloading were omitted.\0121 Historical development\0122 Language features\0123 Syntax\0124 Standard library features\0125 Implementations\0126 Books\0127 Projects using Modula-3\0128 References\0129\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012Historical development\012The Modula-3 project started in November 1986 when Maurice Wilkes wrote to Niklaus Wirth with some ideas for a new version of Modula. Wilkes had been working at DEC just prior to this point, and had returned to England and joined Olivetti''s Research Strategy Board. Wirth had already moved on to Oberon, but had no problems with Wilkes''s team continuing development under the Modula name. The language definition was completed in August 1988, and an updated version in January 1989. Compilers from DEC and Olivetti soon followed, and 3rd party implementations after that.\012During the 1990s, Modula-3 gained considerable currency as a teaching language, but it was never widely adopted for industrial use. Contributing to this may have been the demise of DEC, a key Modula-3 supporter. In any case, in spite of Modula-3''s simplicity and power, it appears that there was little demand for a procedural compiled language with restricted implementation of object-oriented programming. For a time, a commercial compiler called CM3 and integrated development environment called Reactor were offered by Critical Mass, Inc., but that company ceased active operations in 2000. Modula-3 is now taught in universities only in comparative programming language courses, and its textbooks are out of print. Essentially the only corporate supporter of Modula-3 is elego Software Solutions GmbH, which inherited the complete sources from Critical Mass and has since made several releases of the CM3 system in source and binary form. The Reactor IDE has been open source released after several years it had not, with the new name CM3-IDE. In March 2002 elego also took over the repository of the last other active Modula-3 distribution, PM3, till then maintained at the École Polytechnique de Montréal.\012Language features\012Exception handling is based on a TRY...EXCEPT block system, which has since become common. One feature that has not been adopted in other languages, with the notable exceptions of Delphi (programming language), Python[1], Scala[2] and Visual Basic.NET, is that the EXCEPT construct defined a pseudo-CASE with each possible exception as a case in one EXCEPT clause. Modula-3 also supports a LOOP...EXIT...END construct that loops until an EXIT occurs, a structure equivalent to a simple loop inside of a TRY...EXCEPT clause.\012Object support is intentionally kept to its simplest terms. An object type (class) is introduced with the OBJECT declaration, which has essentially the same syntax as a RECORD declaration, although the type so declared is a reference type, whereas RECORDs in Modula-3 are not (similar to structs in C). For instance:\012A\012= OBJECT a: INTEGER; METHODS p() := AP; END;\012defines a new object type A, which contains a single field a and method p. The procedure AP that implements p must be defined elsewhere:\012PROCEDURE AP(self: A) = BEGIN ... END;\012Method calls are accomplished with o.p();, where o is a variable of type A.\012Modula-3''s REVEAL construct provides a conceptually simple and clean yet very powerful mechanism for hiding implementation details from clients, with arbitrarily many levels of "friendliness."\012Modula-3 is one of the few programming languages that requires that external references from a module be strictly qualified. That is, a reference in module A to the object x exported from module B must take the form B.x. It is not possible in Modula-3 to import "all exported names" from a module. Modula-3 also requires the programmer to distinguish between declaring a method signature (METHODS) and a method override in a subtype (OVERRIDES). Because of the language''s requirements on name qualification and method overriding, it is impossible to break a working program simply by adding new declarations to an interface (any interface). This makes it possible for large programs to be edited concurrently by many programmers without any worries about naming conflicts; and it also makes it possible to edit core language libraries with the firm knowledge that no existing programs will be "broken" in the process.\012In summary, the language features:\012Modules and interfaces\012Explicit marking of unsafe code\012Automatic garbage collection\012Strong typing, structural equivalence of types\012Objects\012Exceptions\012Threads\012Generics\012Modula-3 is one of the rare languages whose evolution of features is documented.\012In Systems Programming with Modula-3 four essential points of the language design are intensively discussed. These topics are: Structural vs. name equivalence, subtyping rules, generic modules, parameter modes like READONLY.\012Syntax\012Please help improve this section by expanding it. Further information might be found on the talk page or at requests for expansion. (June 2008)\012A common example of a language''s syntax is the Hello world program.\012MODULE Main;\012IMPORT IO;\012BEGIN\012IO.Put ("Hello World\n")\012END Main.\012Standard library features\012Continuing a trend started with the C programming language, many of the features required to write real programs were left out of the language definition itself and instead provided via a number of standard libraries. Standard libraries provide the following features.\012Text: Operations on immutable string references, called TEXTs\012Thread: Operations relating to threading, including MUTEX, condition variable, and thread pausing. The threading library provides pre-emptive threadswitching.\012Word: Bitwise operations on unsigned integers (or machine words). Normally implemented directly by the compiler\012Floating-point interfaces\012Fmt: Formatting various datatypes for printing\012Pkl (or Pickle): Object serialization of any reference types reachable by the garbage collector\012Table: Generic modules for maps\012As in C, I/O is also provided via libraries, in Modula-3 called Rd and Wr. The object-oriented design of the Rd and Wr libraries is covered in detail in the book by Greg Nelson. An interesting aspect of Modula-3 is that it is one of few programming languages whose standard libraries have been formally verified not to contain various types of bugs, including locking bugs. This was done under the auspices of the Extended Static Checker project at DEC Systems Research Center.\012Implementations\012Several compilers are available, most of them open source.\012DEC-SRC M3, the original\012Critical Mass CM3, a different successor of DEC-SRC M3\012Polytechnique Montreal Modula-3 PM3, a successor of DEC-SRC M3, currently merging with CM3\012EzM3, an independent lightweight and easily portable implementation, developed in connection with CVSup\012HM3, a successor of the pm3-1.1.15 release of PM3, with support of native threading using NPTL\012Since the only aspect of C data structures that is missing from Modula-3 is the union type, all existing Modula-3 implementations are able to provide good binary compatibility with C language type declarations of arrays and structs.\012Books\012None of these books are still in print, although used copies are obtainable.\012Greg Nelson, ed. Systems Programming with Modula-3 The definitive reference on the Modula-3 language with interesting articles on object-oriented systems software construction and a documentation of the discussion leading to the final features of the language.\012Samuel P. Harbison, Modula-3 Easy to use class textbook.\012Robert Sedgewick, Algorithms in Modula-3\012Laszlo Boszormenyi & Carsten Weich, Programming in Modula-3: An Introduction in Programming with Style\012Projects using Modula-3\012The SPIN operating system was implemented using Modula-3 as its programming language.\012The CVSup repository synchronization program was implemented in Modula-3.\012The m3w collection of (mostly) free (GPL) software with various levels of dedication and usability for web application programming.\012References\012^ http://www.python.org/doc/essays/foreword/ Foreword for "Programming Python" (1st ed.)\012^ SRC-RR-52 Modula-3 report (revised). - Cardelli, Luca; Donahue, James; Glassman, Lucille\012Modula-3 Resource Page\012Modula-3 Home Page (now long dead, mirror)\012Modula-3: Language definition\012elego Software Solutions\012Modula-3 newsgroup\012Notes from Caltech''s CS2 class, taught in Modula-3 in 2002 and 2003.\012mirror Programming in Modula-3: program examples\012"Building Distributed OO Applications: Modula-3 Objects at Work", draft book version\012"Object-Oriented Data Abstraction in Modula-3" on-line book\012Computerworld Interview with Luca Cardelli on Modula-3\012"http://en.wikipedia.org/wiki/Modula-3"\012Categories: Modula programming language family | Object-oriented programming languages | Systems programming languagesHidden categories: Articles to be expanded since June 2008 | All articles to be expanded','\012',char(10)));
INSERT INTO pages VALUES('Modula-2','http://web.archive.org/web/20081203191158/http://en.wikipedia.org./wiki/Modula-2','en','2008-12-03 00:00:00',replace('Modula-2\nParadigm\nimperative, structured, modular, data and method hiding\nAppeared in\n1978\nDesigned by\nNiklaus Wirth\nTyping discipline\nstrong, static\nMajor implementations\nETH Zurich (originally written by Niklaus Wirth), Gardens Point, p1, Native XDS-x86, gm2 (GNU Modula-2)\nDialects\nPIM2, PIM3, PIM4, ISO\nInfluenced by\nPascal, Mesa, ALGOL, Simula-67\nInfluenced\nModula-3, Oberon, Ada, Fortran 90, Zonnon, Modula-GM\nModula-2 is a computer programming language invented by Niklaus Wirth at ETH, around 1978, as a successor to his intermediate language Modula. Modula-2 was implemented in 1980 for the Lilith computer, which was commercialized in 1982 by startup company DISER (Data Image Sound Processor and Emitter Receiver System) as MC1 and MC2. DISER sold 120 units worldwide. The Modula-2 language was understood by Niklaus Wirth as a successor to his first major programming language Pascal. The language design was also influenced by the Mesa programming language and the new programming possibilities of the early personal computer Xerox Alto, both from Xerox, that Wirth saw during his 1976 sabbatical year at Xerox PARC.\n1 Description\n2 Dialects\n3 Language elements\n3.1 Reserved words\n4 Related languages\n4.1 Modula-GM\n5 Current compilers\n6 Discontinued compilers\n7 Books\n8 References\n9\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nDescription\nModula-2 is a general purpose procedural language, sufficiently flexible to do systems programming, but with much broader application. In particular, it was designed to support separate compilation and data abstraction in a straightforward way. Much of the syntax is based on Wirth''s earlier and better-known language, Pascal. Modula-2 was designed to be broadly similar to Pascal, with some elements removed and the important addition of the module concept, and direct language support for multiprogramming.\nThe Modula-2 module may be used to encapsulate a set of related subprograms and data structures, and restrict their visibility from other portions of the program. The module design implemented the data abstraction feature of Modula-2 in a very clean way. Modula-2 programs are composed of modules, each of which is made up of two parts: a definition module, the interface portion, which contains only those parts of the subsystem that are exported (visible to other modules), and an implementation module, which contains the working code that is internal to the module.\nThe language has strict scope control. In particular the scope of a module can be considered as an impenetrable wall: Except for standard identifiers no object from the outer world is visible inside a module unless explicitly imported; no internal module object is visible from the outside unless explicitly exported.\nSuppose module M1 exports objects a, b, c, and P by enumerating its identifiers in an explicit export list\nDEFINITION MODULE M1;\nEXPORT QUALIFIED a, b, c, P;\n...\nThen the objects a, b,c, and P from module M1 become now known outside module M1 as M1.a','\n',char(10)));
INSERT INTO pages VALUES('SNOBOL','http://web.archive.org/web/20090519190950/http://en.wikipedia.org:80/wiki/Snobol','en','2009-05-19 00:00:00',replace('( Snobol)\nThis article is about the programming language.\nFor the cleaning product, see SnoBol (cleaner).\nSNOBOL\nParadigm\nmulti-paradigm: object-oriented, functional, logic\nAppeared in\n1962\nDesigned by\nDavid J. Farber, Ralph E. Griswold and Ivan P. Polonsky\nDeveloper\nDavid J. Farber, Ralph E. Griswold, Ivan P. Polonsky, and Bell Labs\nMajor implementations\nSNOBOL, SPITBOL\nInfluenced\nIcon, Lua\nSNOBOL (String Oriented Symbolic Language) is a computer programming language developed between 1962 and 1967 at AT&T Bell Laboratories by David J. Farber, Ralph E. Griswold and Ivan P. Polonsky. It was one of a number of text-string-oriented languages developed during the 1950s and 1960s, others included COMIT and TRAC.\nSNOBOL4 stands apart from most programming languages by having patterns as a first-class data type (i.e. a data type whose values can be manipulated in all ways permitted to any other data type in the programming language) and by providing operators for pattern concatenation and alternation. Strings generated during execution can be treated as programs and executed.\nSNOBOL was quite widely taught in larger US universities in the late 1960s and early 1970s and was widely used in the 1970s and 1980s as a text manipulation language in the humanities.\nIn recent years its use has faded as newer languages such as Awk and Perl have made string manipulation by means of regular expressions fashionable. SNOBOL4 patterns, however, subsume BNF grammars, which are equivalent to Context-free grammars and more powerful than regular expressions [1]\nOne of the designers of SNOBOL, Ralph Griswold, designed a successor to SNOBOL, called Icon, which combined the backtracking of SNOBOL pattern matching with more standard Algol-like structuring, as well as adding some features of its own.\n1 Features\n2 Implementations\n3 Naming\n4 See also\n5 References\n6 Further reading\n7\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nFeatures\nThe SNOBOL4 (StriNg Oriented symBOlic Language number 4) version is the fourth and latest incarnation of such a series of special purpose programming languages for character string manipulation.\nThe SNOBOL4 variant of the language supports a number of built-in data types, such as integers and limited precision real numbers, strings, patterns, arrays, and tables (associative arrays), and also allows the programmer to define additional data types and new functions. SNOBOL4''s programmer-defined data type facility was advanced at the time—it is similar to the earlier Cobol''s and the later Pascal''s records.\nAll SNOBOL command lines are of the form Label1 Subject Pattern = Object :(Goto Label2) Each of the five sections were optional. In general, the subject was matched against the pattern. If the object was present, any matched portion was replaced by the object via rules for replacement. The goto could be an absolute branch, or conditionally based on success or failure of the pattern match.\nA SNOBOL pattern can be very simple or extremely complex. A simple pattern is just a text string (e.g. "ABCD"), but a complex pattern may be a large structure describing, for example, the complete grammar of a computer language. It is possible to implement a language interpreter in SNOBOL almost directly from a Backus-Naur form expression of it, with few changes. Creating a macro assembler and an interpreter for a completely theoretical piece of hardware could take as little as a few hundred lines, with a new instruction being added with a single line.\nComplex SNOBOL patterns can do things that would be impractical or impossible using the more primitive regular expressions used in most other pattern matching languages. Some of this power derives from the so-called "SPITBOL extensions" (which have since been incorporated in basically all modern implementations of the original SNOBOL 4 language too), although it is possible to achieve the same power without them. Part of this power comes from the side effects that it is possible to produce during the pattern matching operation, including saving numerous intermediate/tentative matching results and the ability to invoke user-written functions during the pattern match which can perform nearly any desired processing, and then influence the ongoing direction the interrupted pattern match takes, or even to indeed change the pattern itself during the matching operation. Patterns can be saved like any other first-class data item, and can be concatenated, used within other patterns, and used to create very complex and sophisticated pattern expressions. It is possible to write, for example, a SNOBOL4 pattern which matches "a complete name and international postal mailing address", which is well beyond anything that is practical to even attempt using regular expressions.\nSNOBOL pattern-matching uses a backtracking algorithm similar to that used in the logic programming language Prolog, which provides pattern-like constructs via DCGs.\nSNOBOL stores strings in a garbage-collected heap.\nSNOBOL rivals APL for its distinctiveness in format and programming style, both being radically unlike more "standard" procedural languages such as BASIC, Fortran, or C.\nImplementations\nThe classic implementation was on the PDP-10; it has been used to study compilers, formal grammars, and artificial intelligence, especially machine translation and machine comprehension of natural languages. The original implementation was on an IBM 7090 at Bell Labs, Holmdel, N.J. SNOBOL4 was specifically designed for portability; the first implementation was on an IBM 7094 but it was rapidly ported to many other platforms.\nIt is normally implemented as an interpreter because of the difficulty in implementing some of its very high-level features, but there is a compiler, the SPITBOL compiler, which provides nearly all the facilities that the interpreter provides.\nThe Gnat Ada Compiler comes with a package (GNAT.Spitbol) which implements all of the Spitbol string manipulation semantics. This can be called from within an Ada program.\nSeveral implementations are currently available. Macro SNOBOL4 in C written by Phil Budne is a free, open source implementation, capable of running on almost any platform. It is available at http://www.snobol4.org/. Catspaw, Inc. at http://www.snobol4.com/, provides a commercial implementation of the SNOBOL4 language for many different computer platforms, including DOS, Macintosh, Sun, RS/6000, and others. An older version, SNOBOL4+, is now available free from Catspaw. Minnesota SNOBOL4, By Viktors Berstis, the closest PC implementation to the original IBM mainframe version (even including Fortran-like FORMAT statement support) is also free, and is at http://www.berstis.com/snobol4.htm.\nAlthough SNOBOL itself has almost a complete absence of traditional and familiar-looking structured programming features, a structured version of SNOBOL called Snostorm existed at University College London UCL between 1982 and 1984, and another by Andrew Koenig called Snocone. [1]\nThe SPITBOL implementation also introduced a number of features which, while not using traditional structured programming keywords, nevertheless can be used to provide many of the equivalent capabilities normally thought of as "structured programming", most notably nested if/then/else type constructs. These features have since been added to most recent SNOBOL4 implementations.\nNaming\nAccording to Dave Farber,[2] he, Griswold and Polonsky "finally arrived at the name Symbolic EXpression Interpreter SEXI."\nAll went well until one day I was submitting a batch job to assemble the system and as normal on my JOB card -- the first card in the deck, I , in BTL standards my job and my name -- Sexi Farber\nOne of the Comp Center girls looked at it and said "that is what you think" in a humorous way.\nThat made it clear that we needed another name!! We sat and talked and drank coffee and shot rubber bands and after much to much time someone said -- most likely Ralph "we don''t have a Snowball chance in hell of finding a name". All of us yelled at once "WE GOT IT -- SNOBOL" in the spirit of all the BOL languages. We then stretched our mind to find what it stood for.\nDespite the naming, SNOBOL has no other connection to COBOL or ALGOL and no notable similarities.\nSee also\nSPITBOL\nIcon programming language\nUnicon programming language\nReferences\n^ Gimpel, J. F. 1973. A theory of discrete patterns and their implementation in SNOBOL4. Commun. ACM 16, 2 (Feb. 1973), 91-100. DOI=http://doi.acm.org/10.1145/361952.361960\n^ WORTH READING Wikipedia entry on SNOBOL -- the TRUE story NOT Wikipedias (Dave Farber, Interesting People mailing list, 26 December 2008)\nFurther reading\nEmmer, Mark B. SNOBOL4+: The SNOBOL4 Language for the Personal Computer User. Englewood Cliffs, NJ: Prentice Hall, 1985 (ISBN 0-13-815119-9).\nGimpel, James F. Algorithms in SNOBOL4. New York: Wiley, 1976 (ISBN 0-471-30213-9); republished Salida, CO: Catspaw, 1986 (ISBN 0-939793-00-8).\nGriswold, Ralph E., J. F. Poage, and I. P. Polonsky. The SNOBOL4 Programming Language. Englewood Cliffs, NJ: Prentice Hall, 1968 (ISBN 0-13-815373-6).\nGriswold, Ralph E. String and List Processing in SNOBOL4: Techniques and Applications. Englewood Cliffs, NJ: Prentice Hall, 1975 (ISBN 0-13-853010-6).\nHockey, Susan M. Snobol Programming for the Humanities. New York: Clarendon Press; Oxford: Oxford University Press, 1985 (ISBN 0-19-824676-5).\nCatspaw, Inc. offers implementations of and support for SNOBOL4\nSNOBOL at the Open Directory Project\nIntroduction to Snobol by James Ford\nA sample program in SNOBOL\nCharles Hall Collection on the SNOBOL Programming Language. Charles Babbage Institute, University of Minnesota, Minneapolis.\n"http://en.wikipedia.org/wiki/SNOBOL"\nCategories: Text-oriented programming languages | SNOBOL programming language family','\n',char(10)));
INSERT INTO pages VALUES('PHP','http://web.archive.org/web/20090109171033/http://en.wikipedia.org:80/wiki/PHP','en','2009-01-09 00:00:00',replace('For other uses, see PHP (disambiguation).\nPHP\nUsual file extensions\n.php\nParadigm\nimperative, object-oriented\nAppeared in\n1995 (1995)\nDesigned by\nRasmus Lerdorf\nDeveloper\nThe PHP Group\nLatest release\n5.2.8/ 08 December 2008; 32 days ago\nLatest unstable release\n5.3.0 Alpha 3, and 6.0-dev[1]\nTyping discipline\nDynamic, weak\nMajor implementations\nRoadsend PHP, Phalanger, Quercus, Project Zero\nInfluenced by\nC, Perl, Java, C++, Python, Tcl\nInfluenced\nPhp4delphi\nOS\nCross-platform\nLicense\nPHP License\nWebsite\nhttp://php.net/\nPHP is a scripting language originally designed for producing dynamic web pages. It has evolved to include a command line interface capability and can be used in standalone graphical applications.[2]\nWhile PHP was originally created by Rasmus Lerdorf in 1995, the main implementation of PHP is now produced by The PHP Group and serves as the de facto standard for PHP as there is no formal specification.[3] PHP is free software released under the PHP License, however it is incompatible with the GPL due to restrictions on the usage of the term PHP.[4]\nPHP is a widely-used general-purpose scripting language that is especially suited for web development and can be embedded into HTML. It generally runs on a web server, taking PHP code as its input and creating web pages as output. It can be deployed on most web servers and on almost every operating system and platform free of charge.[5] PHP is installed on more than 20 million websites and 1 million web servers.[6]\n1 History\n1.1 Release history\n2 Usage\n3 Speed optimization\n4 Security\n5 Syntax\n5.1 Data types\n5.2 Functions\n5.2.1 5.2 and earlier\n5.2.2 5.3 and newer\n5.3 Objects\n6 Resources\n7 See also\n8 Notes\n9 References\n10 Further reading\n11\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nRasmus Lerdorf, who wrote the original Common Gateway Interface binaries, and Andi Gutmans and Zeev Suraski, who rewrote the parser that formed PHP 3\nPHP originally stood for Personal Home Page.[7] It began in 1994 as a set of Common Gateway Interface binaries written in the C programming language by the Danish/Greenlandic programmer Rasmus Lerdorf. Lerdorf initially created these Personal Home Page Tools to replace a small set of Perl scripts he had been using to maintain his personal homepage. The tools were used to perform tasks such as displaying his résumé and recording how much traffic his page was receiving.[3] He combined these binaries with his Form Interpreter to create PHP/FI, which had more functionality. PHP/FI included a larger implementation for the C programming language and could communicate with databases, enabling the building of simple, dynamic web applications. Lerdorf released PHP publicly on June 8, 1995 to accelerate bug location and improve the code.[8] This release was named PHP version 2 and already had the basic functionality that PHP has today. This included Perl-like variables, form handling, and the ability to embed HTML. The syntax was similar to Perl but was more limited, simpler, and less consistent.[3]\nZeev Suraski and Andi Gutmans, two Israeli developers at the Technion IIT, rewrote the parser in 1997 and formed the base of PHP 3, changing the language''s name to the recursive initialism PHP: Hypertext Preprocessor.[3] The development team officially released PHP/FI 2 in November 1997 after months of beta testing. Afterwards, public testing of PHP 3 began, and the official launch came in June 1998. Suraski and Gutmans then started a new rewrite of PHP''s core, producing the Zend Engine in 1999.[9] They also founded Zend Technologies in Ramat Gan, Israel.[3]\nOn May 22, 2000, PHP 4, powered by the Zend Engine 1.0, was released.[3] On July 13, 2004, PHP 5 was released, powered by the new Zend Engine II.[3] PHP 5 included new features such as improved support for object-oriented programming, the PHP Data Objects extension (which defines a lightweight and consistent interface for accessing databases), and numerous performance enhancements.[10] The most recent update released by The PHP Group is for the older PHP version 4 code branch. As of August, 2008 this branch is up to version 4.4.9. PHP 4 is no longer under development nor will any security updates be released.[11][12]\nIn 2008, PHP 5 became the only stable version under development. Late static binding has been missing from PHP and will be added in version 5.3.[13][14] PHP 6 is under development alongside PHP 5. Major changes include the removal of register_globals,[15] magic quotes, and safe mode.[11][16]\nPHP does not have complete native support for Unicode or multibyte strings;[17] Unicode support will be included in PHP 6.[18] Many high profile open source projects ceased to support PHP 4 in new code as of February 5, 2008, due to the GoPHP5 initiative, provided by a consortium of PHP developers promoting the transition from PHP 4 to PHP 5.[19][20]\nIt runs in both 32-bit and 64-bit environments, but on Windows the only official distribution is 32-bit, requiring Windows 32-bit compatibility mode to be enabled while using IIS in a 64-bit Windows environment. There is a third-party distribution[21] available for 64-bit Windows.\nRelease history\nMeaning\nRed\nOld release; not supported\nYellow\nOld release; still supported\nGreen\nCurrent release\nBlue\nFuture release\nMajor Version\nMinor Version\nRelease date\nNotes\n1.0\n1.0.0\n1995-06-08\nOfficially called "Personal Home Page Tools (PHP Tools)". This is the first use of the name "PHP".[3]\n2.0\n2.0.0\n1996-04-16\nConsidered by its creator as the "fastest and simplest tool" for creating dynamic web pages.[3]\n3.0\n3.0.0\n1998-06-06\nDevelopment moves from one person to multiple developers. Zeev Suraski and Andi Gutmans rewrite the base for this version.[3]\n4.0\n4.0.0\n2000-05-22\nAdded more advanced two-stage parse/execute tag-parsing system called the Zend engine.[22]\n4.1.0\n2001-12-10\nIntroduced ''superglobals'' ($_GET, $_POST, $_SESSION, etc.)[22]\n4.2.0\n2002-04-22\nDisabled register_globals by default. Data received over the network is not inserted directly into the global namespace anymore, closing possible security holes in applications.[22]\n4.3.0\n2002-12-27\nIntroduced the CLI, in addition to the CGI.[22]\n4.4.0\n2005-07-11\nAdded man pages for phpize and php-config scripts.[22]\n4.4.8\n2008-01-03\nSeveral security enhancements and bug fixes. Was to be the end of life release for PHP 4. Security updates only until 2008-08-08, if necessary.[23]\n4.4.9\n2008-08-07\nMore security enhancements and bug fixes. The last release of the PHP 4.4 series.[24][25]\n5.0\n5.0.0\n2004-07-13\nZend Engine II with a new object model.[26]\n5.1.0\n2005-11-24\nPerformance improvements with introduction of compiler variables in re-engineered PHP Engine.[26]\n5.2.0\n2006-11-02\nEnabled the filter extension by default.[26]\n5.2.8\n2008-12-08[27]\nemergent bug fix[27]\n5.3.0\nFirst Quarter of 2009[28]\nNamespace support; Improved XML support through use of XMLReader and XMLWriter; SOAP support,[29] Late static bindings, Jump label (limited goto), Closures, Native PHP archives\n6.0\n6.0.0\nNo date set\nUnicode support; removal of ereg extension, ''register_globals'', ''magic_quotes'' and ''safe_mode''; Alternative PHP Cache; Removal of mime_magic and rewrite of fileinfo() for better MIME support[30]\nUsage\nPHP is a general-purpose scripting language that is especially suited for web development. PHP generally runs on a web server, taking PHP code as its input and creating web pages as output. It can also be used for command-line scripting and client-side GUI applications. PHP can be deployed on most web servers, many operating systems and platforms, and can be used with many relational database management systems. It is available free of charge, and the PHP Group provides the complete source code for users to build, customize and extend for their own use.[5]\nPHP primarily acts as a filter,[31] taking input from a file or stream containing text and/or PHP instructions and outputs another stream of data; most commonly the output will be HTML. It can automatically detect the language of the user.[32][33] From PHP 4, the PHP parser compiles input to produce bytecode for processing by the Zend Engine, giving improved performance over its interpreter predecessor.[34]\nOriginally designed to create dynamic web pages, PHP''s principal focus is server-side scripting,[35] and it is similar to other server-side scripting languages that provide dynamic content from a web server to a client, such as Microsoft''s ASP.NET system, Sun Microsystems'' JavaServer Pages,[36] and mod_perl. PHP has also attracted the development of many frameworks that provide building blocks and a design structure to promote rapid application development (RAD). Some of these include CakePHP, PRADO, Symfony, CodeIgniter, and Zend Framework, offering features similar to other web application frameworks.\nThe LAMP architecture has become popular in the web industry as a way of deploying web applications. PHP is commonly used as the P in this bundle alongside Linux, Apache and MySQL, although the P may also refer to Python or Perl.\nAs of April 2007, over 20 million Internet domains were hosted on servers with PHP installed, and PHP was recorded as the most popular Apache module.[37] Significant websites are written in PHP including the user-facing portion of Facebook,[38] Wikipedia (MediaWiki),[39] Yahoo!,[40] MyYearbook,[41], Digg, Wordpress and Tagged.[42]\nSpeed optimization\nAs with many scripting languages, PHP scripts are normally kept as human-readable source code, even on production web servers.[43] Therefore, these PHP scripts will be compiled at runtime by the PHP engine. Compiling at runtime increases the execution time of the script because it adds an extra step in runtime. PHP scripts can be compiled before runtime using PHP compilers just like other programming languages such as C (the programming language PHP is programmed in, and which is used to program PHP extensions).\nCode optimizers improve the quality of the compiled code by reducing its size and making changes that can reduce the execution time and improve performance. The nature of the PHP compiler is such that there are often opportunities for code optimization,[44] and an example of a code optimizer is the Zend Optimizer PHP extension.[45]\nPHP accelerators can offer significant performance gains by caching the compiled form of a PHP script in shared memory to avoid the overhead of parsing and compiling the code every time the script runs.\nSecurity\nThe proportion of insecure software written in PHP, out of the total of all common software vulnerabilities, amounted to: 12% in 2003, 20% in 2004, 28% in 2005, 43% in 2006, 36% in 2007, and 33.8% for the first quarter of 2008. More than a third of these PHP software vulnerabilities are listed recently.[46] Most of these software vulnerabilities can be exploited remotely, that is without being logged on the computer hosting the vulnerable application. The most common vulnerabilities are caused by not following best practice programming rules and vulnerabilities related to software written in old PHP versions. One very common security concern is register_globals which was disabled by default since 2002 in PHP 4.2.\nThere are advanced protection patches such as Suhosin and Hardening-Patch, especially designed for web hosting environments.[47] Installing PHP as a CGI binary rather than as an Apache module is the preferred method for added security.[48]\nSyntax\nMain article: PHP syntax and semantics\nSyntax-highlighted PHP code embedded within HTML\nPHP only parses code within its delimiters. Anything outside its delimiters is sent directly to the output and is not parsed by PHP. The most common delimiters are <?php and ?>, which are open and close delimiters respectively. <script language="php"> and </script> delimiters are also available. Short tags can be used to start PHP code, <? or <?= (which is used to echo back a string or variable) and the tag to end PHP code, ?>. These tags are commonly used, but like ASP-style tags (<% or <%= and %>), they are less portable as they can be disabled in the PHP configuration. For this reason, the use of short tags and ASP-style tags is discouraged.[49] The purpose of these delimiters is to separate PHP code from non-PHP code, including HTML. Everything outside the delimiters is ignored by the parser and is passed through as output.[50]\nVariables are prefixed with a dollar symbol and a type does not need to be specified in advance. Unlike function and class names, variable names are case sensitive. Both double-quoted ("") and heredoc strings allow the ability to embed a variable''s value into the string.[51] PHP treats newlines as whitespace in the manner of a free-form language (except when inside string quotes), and statements are terminated by a semicolon.[52] PHP has three types of comment syntax: /* */ serves as block comments, and // as well as # are used for inline comments.[53] The echo statement is one of several facilities PHP provides to output text (e.g. to a web browser).\nIn terms of keywords and language syntax, PHP is similar to most high level languages that follow the C style syntax. If conditions, for and while loops, and function returns are similar in syntax to languages such as C, C++, Java and Perl.\nData types\nPHP stores whole numbers in a platform-dependent range. This range is typically that of 32-bit signed integers. Unsigned integers are converted to signed values in certain situations; this behavior is different from other programming languages.[54] Integer variables can be assigned using decimal (positive and negative), octal, and hexadecimal notations. Real numbers are also stored in a platform-specific range. They can be specified using floating point notation, or two forms of scientific notation.[55] PHP has a native Boolean type that is similar to the native Boolean types in Java and C++. Using the Boolean type conversion rules, non-zero values are interpreted as true and zero as false, as in Perl and C++.[55] The null data type represents a variable that has no value. The only value in the null data type is NULL.[55] Variables of the "resource" type represent references to resources from external sources. These are typically created by functions from a particular extension, and can only be processed by functions from the same extension; examples include file, image, and database resources.[55] Arrays can contain elements of any type that PHP can handle, including resources, objects, and even other arrays. Order is preserved in lists of values and in hashes with both keys and values, and the two can be intermingled.[55] PHP also supports strings, which can be used with single quotes, double quotes, or heredoc syntax.[56]\nThe Standard PHP Library (SPL) attempts to solve standard problems and implements efficient data access interfaces and classes. [57]\nFunctions\nPHP has hundreds of base functions and thousands more from extensions. These functions are well documented on the PHP site, but unfortunately, the built-in library has a wide variety of naming conventions and inconsistencies.[58] PHP currently has no functions for thread programming.\n5.2 and earlier\nFunctions are not first-class functions and can only be referenced by their name--directly or dynamically by a variable containing the name of the function. [59] User-defined functions can be created at any time without being prototyped.[59] Functions can be defined inside code blocks, permitting a run-time decision as to whether or not a function should be defined. Function calls must use parentheses, with the exception of zero argument class constructor functions called with the PHP new operator, where parentheses are optional. PHP supports quasi-anonymous functions through the create_function() function, although they are not true anonymous functions because anonymous functions are nameless, but functions can only be referenced by name, or indirectly through a variable $function_name();, in PHP.[59]\n5.3 and newer\nPHP gained support for first-class functions and closures. True anonymous functions are supported using the following syntax:\nfunction getAdder($x)\n{\nreturn function ($y) use ($x) {\nreturn $x + $y;\n};\n}\n$adder = getAdder(8);\necho $adder(2); // prints "10"\nHere, getAdder() function creates a closure using parameter $x (keyword "use" forces getting variable from context), which takes additional argument $y and returns it to the caller. Such function can be stored, given as the parameter to another functions, etc. For more details see Lambda functions and closures RFC.\nObjects\nBasic object-oriented programming functionality was added in PHP 3.[3] Object handling was completely rewritten for PHP 5, expanding the feature set and enhancing performance.[60] In previous versions of PHP, objects were handled like primitive types.[60] The drawback of this method was that the whole object was copied when a variable was assigned or passed as a parameter to a method. In the new approach, objects are referenced by handle, and not by value. PHP 5 introduced private and protected member variables and methods, along with abstract classes and final classes as well as abstract methods and final methods. It also introduced a standard way of declaring constructors and destructors, similar to that of other object-oriented languages such as C++, and a standard exception handling model. Furthermore, PHP 5 added interfaces and allowed for multiple interfaces to be implemented. There are special interfaces that allow objects to interact with the runtime system. Objects implementing ArrayAccess can be used with array syntax and objects implementing Iterator or IteratorAggregate can be used with the foreach language construct. There is no virtual table feature in the engine, so static variables are bound with a name instead of a reference at compile time.[61]\nIf the developer creates a copy of an object using the reserved word clone, the Zend engine will check if a __clone() method has been defined or not. If not, it will call a default __clone() which will copy the object''s properties. If a __clone() method is defined, then it will be responsible for setting the necessary properties in the created object. For convenience, the engine will supply a function that imports the properties of the source object, so that the programmer can start with a by-value replica of the source object and only override properties that need to be changed.[62]\nResources\nPHP includes free and open source libraries with the core build. PHP is a fundamentally Internet-aware system with modules built in for accessing FTP servers, many database servers, embedded SQL libraries such as embedded MySQL and SQLite, LDAP servers, and others. Many functions familiar to C programmers such as those in the stdio family are available in the standard PHP build.[63] PHP has traditionally used features such as "magic_quotes_gpc" and "magic_quotes_runtime" which attempt to escape apostrophes ('') and quotes (") in strings in the assumption that they will be used in databases, to prevent SQL injection attacks. This leads to confusion over which data is escaped and which is not, and to problems when data is not in fact used as input to a database and when the escaping used is not completely correct.[64] To make code portable between servers which do and do not use magic quotes, developers can preface their code with a script to reverse the effect of magic quotes when it is applied.[65]\nPHP allows developers to write extensions in C to add functionality to the PHP language. These can then be compiled into PHP or loaded dynamically at runtime. Extensions have been written to add support for the Windows API, process management on Unix-like operating systems, multibyte strings (Unicode), cURL, and several popular compression formats. Some more unusual features include integration with Internet relay chat, dynamic generation of images and Adobe Flash content, and even speech synthesis. The PHP Extension Community Library (PECL) project is a repository for extensions to the PHP language.[66]\nZend provides a certification program for programmers to become certified PHP developers.\nSee also\nFree software portal\nActive Server Pages\nComparison of programming languages\nLAMP (software bundle)\nList of PHP editors\nList of web application frameworks\nPerl\nPHP accelerator\nPython (programming language)\nZend Framework\nNotes\n^ "PHP Snapshots".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Introduction". PHP Manual. Retrieved on 2006-11-15.\n^ a b c d e f g h i j k "History of PHP and related projects".\nThe PHP Group. Retrieved on 2008-02-25.\n^ "GPL-Incompatible, Free Software Licenses". Various Licenses and Comments about Them.\nFree Software Foundation. Retrieved on 2008-02-22.\n^ a b "Embedding PHP in HTML".\nO''Reilly (2001-05-03). Retrieved on 2008-02-25.\n^ "Usage Stats for April 2007". Retrieved on 2008-07-07.\n^ php.net/history\n^ Lerdorf, Rasmus (1995-06-08). "Announce: Personal Home Page Tools (PHP Tools)". comp.infosystems.www.authoring.cgi. (Web link). Retrieved on 2006-09-17.\n^ "Zend Engine version 2.0: Feature Overview and Design".\nZend Technologies Ltd.. Retrieved on 2006-09-17.\n^ Trachtenberg, Adam (2004-07-15). "Why PHP 5 Rocks!".\nO''Reilly. Retrieved on 2008-02-22.\n^ a b "php.net 2007 news archive".\nThe PHP Group (2007-07-13). Retrieved on 2008-02-22.\n^ Kerner, Sean Michael (2008-02-01). "PHP 4 is Dead—Long Live PHP 5".\nInternetNews. Retrieved on 2008-03-16.\n^ "Late Static Binding in PHP".\nDigital Sandwich (2006-02-23). Retrieved on 2008-03-25.\n^ "Static Keyword".\nThe PHP Group. Retrieved on 2008-03-25.\n^ "Using Register Globals".\nPHP. Retrieved on 2008-04-04.\n^ "Prepare for PHP 6".\nCorePHP (2005-11-23). Retrieved on 2008-03-24.\n^ "PHP 6 - Unicode Completion Stats".\nThe PHP Group (2008-03-25). Retrieved on 2008-03-25.\n^ "Unicode".\nThe PHP Group. Retrieved on 2008-03-25.\n^ GoPHP5. "PHP projects join forces to Go PHP 5" (PDF). GoPHP5 Press Release. Retrieved on 2008-02-23.\n^ "GoPHP5".\nGoPHP5. Retrieved on 2008-02-22.\n^ Fusion-X LAN. "The PHPx64 Project". Fusion-X LAN. Retrieved on 2008-05-05.\n^ a b c d e "PHP: PHP 4 ChangeLog".\nThe PHP Group (2008-01-03). Retrieved on 2008-02-22.\n^ PHP: PHP 4.4.8 Release Announcement\n^ PHP: Downloads\n^ PHP: PHP 4.4.9 Release Announcement\n^ a b c "PHP: PHP 5 ChangeLog".\nThe PHP Group (2007-11-08). Retrieved on 2008-02-22.\n^ a b PHP: News Archive - 2008\n^ PHP: todo:php53\n^ Zend Weekly Summaries Issue #359\n^ Personal homepage of Jeroen van der Meer\n^ "What does PHP do?".\nThe PHP Group. Retrieved on 2008-02-25.\n^ PHP Language Detection :: Detect System Languages, set headers :: $_SERVER["HTTP_ACCEPT_LANGUAGE"]\n^ Visitor’s language detection in php | Urbano''s Blog\n^ "PHP and MySQL".\nUniversity of Alabama. Retrieved on 2008-02-25.\n^ "PHP Server-Side Scripting Language".\nIndiana University (2007-04-04). Retrieved on 2008-02-25.\n^ "JavaServer Pages Technology - JavaServer Pages Comparing Methods for Server-Side Dynamic Content White Paper".\nSun Microsystems. Retrieved on 2008-02-25.\n^ "PHP: PHP Usage Stats".\nSecuritySpace (2007-04-01). Retrieved on 2008-02-24.\n^ http://blog.facebook.com/blog.php?post=2356432130\n^ http://www.mediawiki.org/wiki/Index.php\n^ http://yahoo.com\n^ http://myyearbook.com\n^ http://tagged.com\n^ (Gilmore 2006, p. 43)\n^ "PHP Accelerator 1.2 (page 3, Code Optimisation)" (PDF).\nNick Lindridge. Retrieved on 2008-03-28.\n^ "Setting Up Zend Optimizer Tutorial".\nWebHostGear. Retrieved on 2008-03-16.\n^ "PHP-related vulnerabilities on the National Vulnerability Database" (2008-03-01).\n^ "Hardened-PHP Project" (2008-08-15).\n^ "PHP: Installed as CGI binary" (2008-08-15).\n^ "PHP: Basic syntax".\nThe PHP Group. Retrieved on 2008-02-22.\n^ "Your first PHP-enabled page".\nThe PHP Group. Retrieved on 2008-02-25.\n^ "Variables".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Instruction separation".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Comments".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Integers in PHP, running with scissors, and portability".\nMySQL Performance Blog (March 27, 2007). Retrieved on 2007-03-28.\n^ a b c d e "Types".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Strings".\nThe PHP Group. Retrieved on 2008-03-21.\n^ "SPL - StandardPHPLibrary".\nPHP.net (September 8, 2008). Retrieved on 2008-09-08.\n^ "Do You PHP? By Rasmus Lerdorf". Retrieved on 2008-10-12.\n^ a b c "Functions".\nThe PHP Group. Retrieved on 2008-03-16.\n^ a b "PHP 5 Object References".\nmjtsai. Retrieved on 2008-03-16.\n^ "Classes and Objects (PHP 5)".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "Object cloning".\nThe PHP Group. Retrieved on 2008-03-16.\n^ "PHP Function List".\nThe PHP Group. Retrieved on 2008-02-25.\n^ Lerdorf, Rasmus (2005-08-12). "PHP 6.0 Wishlist".\nThe PHP Group. Retrieved on 2008-03-25.\n^ "Disabling Magic Quotes".\nThe PHP Group. Retrieved on 2008-03-25.\n^ "Developing Custom PHP Extensions".\ndevnewz (2002-09-09). Retrieved on 2008-02-25.\nReferences\nGilmore, W. Jason (2006), Beginning PHP and MySQL 5: From Novice to Professional, Apress, ISBN 1590595521, http://www.amazon.com/Beginning-PHP-MySQL-Novice-Professional/dp/1590595521\nFurther reading\nLerdorf, Rasmus (2006-04-28). Programming PHP. O''Reilly Media, Inc.. ISBN 0596006810. http://www.amazon.com/Programming-PHP-Rasmus-Lerdorf/dp/0596006810.\nWikibooks has a book on the topic of\nProgramming:PHP\nAt Wikiversity, you can learn about: PHP\nPHP: Hypertext Preprocessor\nPHP at the Open Directory Project\nv • d • e\nPHP\nPeople\nAndi Gutmans · Rasmus Lerdorf · Johannes Schlüter · Zeev Suraski\nResources\nZend Engine · Libraries · PEAR · Editors · Accelerator\nv • d • e\nFree and open source software\nGeneral\nCopyleft · Events and Awards · Free software · Free Software Definition · Gratis versus Libre · Open source software\nFree software\nportal\nNotable packages\nApache · CUPS · Firefox · GNOME · KDE · OpenOffice.org · Thunderbird · X Window System\nOperating systems\nBSD · Darwin · FreeDOS · GNU · Haiku · Linux · Mach · MINIX · OpenSolaris · ReactOS · AROS\nDevelopment\nGCC · LLVM · Java · Perl · PHP · Python · Lua · Ruby · Tcl\nHistory\nLinux · Mozilla (Application Suite · Firefox · Thunderbird)\nOrganizations\nApache Software Foundation · Blender Foundation · Eclipse Foundation · FLOSS Manuals · freedesktop.org · Free Software Foundation · GNOME Foundation · GNU Project · Google Code · Linux Foundation · Mozilla Foundation · Open Source Geospatial Foundation · Open Source Initiative · SourceForge · Xiph.Org Foundation · X.Org Foundation\nLicences\nApache · BSD · GPL · LGPL · MIT · MPL · Creative Commons · Permissive · Microsoft Public License · Microsoft Reciprocal License · FSF approved licenses\nChallenges\nBinary blob · Digital rights management · License proliferation · Mozilla software rebranding · Proprietary software · SCO-Linux controversies · Security · Software patents · Tivoization · Trusted Computing\nOther topics\nAlternative terms · Community · Linux distribution · Forking · Movement · Microsoft Open Specification Promise · Revolution OS · Comparison with closed source\nList of open source software packages\n"http://en.wikipedia.org/wiki/PHP"\nCategories: PHP | Curly bracket programming languages | Free compilers and interpreters | Procedural programming languages | Object-oriented programming languages | PHP programming language | Scripting languages | Acronyms | Cross-platform softwareHidden categories: All articles with unsourced statements | Articles with unsourced statements since December 2008','\n',char(10)));
INSERT INTO pages VALUES('SOAP','http://web.archive.org/web/20081218171125/http://en.wikipedia.org:80/wiki/SOAP','en','2008-12-18 00:00:00',replace('( SOAP)\nLook up soap in Wiktionary, the free dictionary.\nSoap is a surfactant cleaning compound, used for personal or minor cleaning.\nSoap may also refer to:\nAny fatty acid salt, which may have cleaning, lubricant, anticaking or cosmetic uses\nDetergent, cleaning substance with soap-like properties\nSoap shoes, type made for Grinds (skateboarding)\nIn film:\nEn Soap, 2006 Danish comedy film\nSoap, character from Lock, Stock and Two Smoking Barrels\nSnakes on a Plane (SoaP), 2006 horror-thriller feature film\nIn television:\nSoap (TV series), award-winning 1970s sitcom\nSoap opera, ongoing, episodic work of fiction on TV or radio\nIn fiction:\nSoap, a substance in the book Cloud Atlas\nSergeant John "Soap" MacTavish, main character in the Call of Duty 4: Modern Warfare video game\nSOAP may refer to:\nIn computing and electronics:\nSOAP (protocol), formerly known as ''Simple Object Access Protocol''\n''Short Oligonucleotide Alignment Program'', source code program used in bioinformatics\n''Solaris (operating system), Oracle Database, Apache HTTP Server and PHP'': a collection of software packages used for web services—see LAMP (software bundle)\n''Symbolic Optimal Assembly Program'', computer language used by the IBM 650\n''Satellite Orbit Analysis Program'', software used for simulating satellite communications\n''Syndicated Online Audio Programming'', also known as a ''podcast''\n''Soap'', a mid-air pointing device based on hardware found in a mouse (computing)\nOther uses:\nS.O.A.P., Danish pop music duo, now disbanded\n''SOAP note'', acronym for ''subjective, objective, assessment and plan'', a method of documentation used in medical charts\n''Society for Obstetric Anesthesia and Perinatology'', medical non-profit organization\n''Small Operator Assistance Program'', federal program from the Office of Surface Mining\n''Soap bar'', low quality form of hashish\n''Strategy On A Page'', concise methodology used in Strategic planning\nThis disambiguation page lists articles associated with the same title. If an internal link led you here, you may wish to change the link to point directly to the intended article.\n"http://en.wikipedia.org/wiki/Soap_(disambiguation)"\nCategory: Disambiguation pagesHidden categories: All disambiguation pages | All article disambiguation pages','\n',char(10)));
INSERT INTO pages VALUES('Solidity','http://web.archive.org/web/20060913000000/http://en.wikipedia.org:80/wiki/Solidity','en','2006-09-13 00:00:00','');
INSERT INTO pages VALUES('Seed7','http://web.archive.org/web/20060923111105/http://en.wikipedia.org/wiki/Seed7','en','2006-09-23 00:00:00',replace('Seed7 is a general-purpose programming language designed by Thomas Mertes. It is a higher level language compared to Ada, C / C++ and Java. The Seed7 interpreter and the example programs are open-source software. An open-source Seed7 compiler is also under development.\nIn Seed7 new statements and operators can be declared easily. Functions with type results and type parameters are more elegant than a template or generics concept. Object orientation is used when it brings advantages and not in places when other solutions are more obvious. Although Seed7 contains several concepts of other programming languages it is generally not considered as a direct descendant of any other programming language.\n1 Seed7 examples\n1.1 Echo the program arguments\n1.2 Declare a statement\n1.3 Template declaring a statement\n1.4 Declare an operator\n1.5 Read a file into a string\n1.6 Simple clock\n2\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nSeed7 examples\nKeywords are in blue, types are in red, strings in maroon, comments in green.\nEcho the program arguments\nThis example program writes its arguments\n$ include "seed7_05.s7i";\n# Standard Seed7 library\nconst proc: main is func\nlocal\nvar string: stri is "";\nbegin\nfor stri range argv(PROGRAM) do\nwrite(stri <& " ");\nend for;\nwriteln;\nend func;\nThe standard Seed7 library "seed7_05.s7i" defines the ''main'' function as entry point of a Seed7 program.\nThe ''argv(PROGRAM)'' function returns the program arguments as array of strings. The ''for'' loop iterates over all elements of this array. The ''for'' statement is overloaded for various collection types.\nDeclare a statement\nIn the standard Seed7 library "seed7_05.s7i" the ''for'' statement for arrays is declared as follows:\nconst proc: for (inout baseType: variable) range (in arrayType: arr_obj) do\n(in proc: statements)\nend for is func\nlocal\nvar integer: number is 0;\nbegin\nfor number range 1 to length(arr_obj) do\nvariable := arr_obj[number];\nstatements;\nend for;\nend func;\nThe syntax of this ''for'' statement is declared as:\n$ syntax expr: .for.().range.().to.().do.().end.for is\n-> 25;\nAdditionally everybody can overload the ''for'' statement also. Because of this powerful features Seed7 does not need Iterators.\nTemplate declaring a statement\nTemplates are just normal functions with types as parameters. The following template function declares ''for'' statements:\nconst proc: FOR_DECLS (in type: aType) is func\nbegin\nconst proc: for (inout aType: variable) range (in aType: low) to (in aType: high) do\n(in proc: statements) end for is func\nbegin\nvariable := low;\nif variable <= high then\nstatements;\nwhile variable < high do\nincr(variable);\nstatements;\nend while;\nend if;\nend func;\nend func;\nFOR_DECLS(char);\nFOR_DECLS(boolean);\nThe body of the ''FOR_DECLS'' function contains a declaration of the ''for'' statement for the type aType. Calling ''FOR_DECLS'' with char and boolean as parameter creates corresponding declarations of ''for'' statements. The example above is a simplified part of the standard Seed7 library "seed7_05.s7i".\nDeclare an operator\nThe standard Seed7 library "seed7_05.s7i" contains also the following declarations:\nconst type: color is new struct\nvar integer: red_part\nis 0;\nvar integer: green_part is 0;\nvar integer: blue_part\nis 0;\nend struct;\nconst func color: (in color: col1) + (in color: col2) is func\nresult\nvar color: result is color.value;\nbegin\nresult.red_part\n:= (col1.red_part\n+ col2.red_part)\ndiv 2;\nresult.green_part := (col1.green_part + col2.green_part) div 2;\nresult.blue_part\n:= (col1.blue_part\n+ col2.blue_part)\ndiv 2;\nend func;\nThis declares the type color and the ''+'' operator to add two colors in an additive color system.\nMemory for this color objects is managed automatically without garbage collection. Additionally it is not necessary to call constructors to initialize color objects.\nRead a file into a string\nThis example program interprets the arguments as file names and replaces the string "dog" by "cat" in the corresponding files:\n$ include "seed7_05.s7i";\n# Standard Seed7 library\ninclude "getf.s7i";\n# Import the getf and putf functions\nconst proc: main is func\nlocal\nvar string: file_name is "";\nbegin\nfor file_name range argv(PROGRAM) do\nputf(file_name, replace(getf(file_name), "dog", "cat"));\nend for;\nend func;\nThe ''getf'' function reads the complete file with the name ''file_name'' into a string and returns it. Seed7 strings can have any length and can contain any data (even null characters). The ''replace'' function replaces "dog" by "cat" and after that the ''putf'' function writes the string back to the file with the name ''file_name''.\nSimple clock\nThis example program displays a digital clock on the text console\n$ include "seed7_05.s7i";\ninclude "time.s7i";\ninclude "keybd.s7i";\nconst proc: main is func\nlocal\nvar time: next_time is time.value;\nbegin\nwriteln;\nnext_time := truncToSecond(time(NOW));\nwhile not keypressed(KEYBOARD) do\nnext_time +:= 1 . SECONDS;\nawait(next_time);\nwrite(next_time <& " \r");\nflush(OUT);\nend while;\nwriteln;\nwriteln;\nend func;\nThis example uses time functions like ''time(NOW)'' and ''await(next_time)''. There is an addition of a duration to a time and a time is written with ''write(next_time)''.\nThe program is terminated when a key is pressed. This check is done with the ''keypressed(KEYBOARD)'' function.\nSeed7 Homepage\nSeed7 project page\nAbstract of diploma thesis from Thomas Mertes in german\n"http://en.wikipedia.org/wiki/Seed7"\nCategories: Programming languages | Imperative programming languages | Object-oriented programming languages | Multi-paradigm programming languages | Algol programming language family | Procedural programming languages | Statically-typed programming languages | Structured programming languages','\n',char(10)));
INSERT INTO pages VALUES('VBA','http://web.archive.org/web/20090209103150/http://en.wikipedia.org:80/wiki/VBA','en','2009-02-09 00:00:00',replace('VBA can mean:\nVisual Basic for Applications, the application edition of Microsoft''s Visual Basic programming language.\nVeterans Benefits Administration, an organizational element of the U.S. Department of Veterans Affairs.\nVerbal Behavior Analysis, a type of therapy based on the principles of Applied Behavior Analysis and used to encourage and increase the use of language in autistic, developmentally delayed, and speech-impaired individuals\nVirgin Blue, an Australian Airline\nVisualBoyAdvance, an emulator for the Nintendo Game Boy Advance handheld video game system.\nVirginia Bar Association, a voluntary organization of Virginia lawyers.\nVision Benefits of America, a non-profit preferred provider organization.\nVojno-Bezbednosna Agencija (Military Security Agency), a Serbian intelligence organization\nThis disambiguation page lists articles associated with the same title. If an internal link led you here, you may wish to change the link to point directly to the intended article.\n"http://en.wikipedia.org/wiki/VBA"\nCategory: Disambiguation pagesHidden categories: All disambiguation pages | All article disambiguation pages','\n',char(10)));
INSERT INTO pages VALUES('Robotics','http://web.archive.org/web/20081217203613/http://en.wikipedia.org:80/wiki/Robotics','en','2008-12-17 00:00:00',replace('Robot\nThe Shadow robot hand system\nRobotics is the science and technology of robots, and their design, manufacture, and application.[1] Robotics Engineers also study electronics, mechanics and software.[2]\n1 Origins\n2 Components of robots\n2.1 Structure\n2.2 Actuation\n2.3 Manipulation\n2.4 Locomotion\n2.4.1 Rolling Robots\n2.4.2 Walking Robots\n2.4.3 Other methods of locomotion\n2.5 Human interaction\n3 Control\n4 Dynamics and kinematics\n5 Education\n6 HealthCare\n7 See also\n8 Notes\n9 References\n10\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nOrigins\nHistory of robots and Robot\nStories of artificial helpers and companions and attempts to create them have a long history, but fully autonomous machines only appeared in the 20th century. The first digitally operated and programmable robot, the Unimate, was installed in 1961 to lift hot pieces of metal from a die casting machine and stack them. Today, commercial and industrial robots are in widespread use performing jobs more cheaply or with greater accuracy and reliability than humans. They are also employed for jobs which are too dirty, dangerous or dull to be suitable for humans. Robots are widely used in manufacturing, assembly and packing, transport, earth and space exploration, surgery, weaponry, laboratory research, safety, and mass production of consumer and industrial goods.[3]\nDate\nSignificance\nRobot Name\nInventor\nFirst century A.D. and earlier\nDescriptions of more than 100 machines and automata, including a fire engine, a wind organ, a coin-operated machine, and a steam-powered engine, in Pneumatica and Automata by Heron of Alexandria\nCtesibius of Alexandria, Philo of Byzantium, Heron of Alexandria, and others\n1206\nFirst programmable humanoid robots\nBoat with four robotic musicians\nAl-Jazari\nc. 1495\nDesigns for a humanoid robot\nMechanical knight\nLeonardo da Vinci\n1738\nMechanical duck that was able to eat, flap its wings, and excrete\nDigesting Duck\nJacques de Vaucanson\n1800s\nJapanese mechanical toys that served tea, fired arrows, and painted\nKarakuri toys\nHisashige Tanaka\n1921\nFirst fictional automatons called "robots" appear in the play R.U.R.\nRossum''s Universal Robots\nKarel Čapek\n1930s\nHumanoid robot exhibited at the 1939 and 1940 World''s Fairs\nElektro\nWestinghouse Electric Corporation\n1948\nSimple robots exhibiting biological behaviors[4]\nElsie and Elmer\nWilliam Grey Walter\n1956\nFirst commercial robot, from the Unimation company founded by George Devol and Joseph Engelberger, based on Devol''s patents[5]\nUnimate\nGeorge Devol\n1961\nFirst installed industrial robot\nUnimate\nGeorge Devol\n1963\nFirst palletizing robot[6]\nPalletizer\nFuji Yusoki Kogyo\n1973\nFirst robot with six electromechanically driven axes\nFamulus\nKUKA Robot Group\n1975\nProgrammable universal manipulation arm, a Unimation product\nPUMA\nVictor Scheinman\nAccording to the Oxford English Dictionary, the word robotics was first used in print by Isaac Asimov, in his science fiction short story "Liar!", published in May 1941 in Astounding Science Fiction. Asimov was unaware that he was coining the term; since the science and technology of electrical devices is electronics, he assumed robotics already referred to the science and technology of robots.[7] The word robot was introduced to the public by Czech writer Karel Čapek in his play R.U.R. (Rossum''s Universal Robots), which premiered in 1921.[8]\nComponents of robots\nStructure\nThe structure of a robot is usually mostly mechanical and can be called a kinematic chain (its functionality being similar to the skeleton of the human body). The chain is formed of links (its bones), actuators (its muscles) and joints which can allow one or more degrees of freedom. Most contemporary robots use open serial chains in which each link connects the one before to the one after it. These robots are called serial robots and often resemble the human arm. Some robots, such as the Stewart platform, use a closed parallel kinematical chain. Other structures, such as those that mimic the mechanical structure of humans, various animals and insects, are comparatively rare. However, the development and use of such structures in robots is an active area of research (e.g. biomechanics). Robots used as manipulators have an end effector mounted on the last link. This end effector can be anything from a welding device to a mechanical hand used to manipulate the environment.\nActuation\nA robot leg powered by Air Muscles\nActuators are the "muscles" of a robot, the parts which convert stored energy into movement. By far the most popular actuators are electric motors, but there are many others, powered by electricity, chemicals, and compressed air.\nMotors: The vast majority of robots use electric motors, including brushed and brushless DC motors.\nStepper motors: As the name suggests, stepper motors do not spin freely like DC motors; they rotate in discrete steps, under the command of a controller. This makes them easier to control, as the controller knows exactly how far they have rotated, without having to use a sensor. Therefore they are used on many robots and CNC machines.\nPiezo motors: A recent alternative to DC motors are piezo motors or ultrasonic motors. These work on a fundamentally different principle, whereby tiny piezoceramic elements, vibrating many thousands of times per second, cause linear or rotary motion. There are different mechanisms of operation; one type uses the vibration of the piezo elements to walk the motor in a circle or a straight line.[9] Another type uses the piezo elements to cause a nut to vibrate and drive a screw. The advantages of these motors are nanometer resolution, speed and available force for their size.[10] These motors are already available commercially, and being used on some robots.[11][12]\nAir muscles: The air muscle is a simple yet powerful device for providing a pulling force. When inflated with compressed air, it contracts by up to 40% of its original length. The key to its behavior is the braiding visible around the outside, which forces the muscle to be either long and thin, or short and fat. Since it behaves in a very similar way to a biological muscle, it can be used to construct robots with a similar muscle/skeleton system to an animal.[13] For example, the Shadow robot hand uses 40 air muscles to power its 24 joints.\nElectroactive polymers: Electroactive polymers are a class of plastics which change shape in response to electrical stimulation.[14] They can be designed so that they bend, stretch or contract, but so far there are no EAPs suitable for commercial robots, as they tend to have low efficiency or are not robust.[15] Indeed, all of the entrants in a recent competition to build EAP powered arm wrestling robots, were beaten by a 17 year old girl.[16] However, they are expected to improve in the future, where they may be useful for microrobotic applications.[17]\nElastic nanotubes: These are a promising, early-stage experimental technology. The absence of defects in nanotubes enables these filaments to deform elastically by several percent, with energy storage levels of perhaps 10J per cu cm for metal nanotubes. Human biceps could be replaced with an 8mm diameter wire of this material. Such compact "muscle" might allow future robots to outrun and outjump humans.[18]\nManipulation\nRobots which must work in the real world require some way to manipulate objects; pick up, modify, destroy or otherwise have an effect. Thus the ''hands'' of a robot are often referred to as end effectors,[19] while the arm is referred to as a manipulator.[20] Most robot arms have replaceable effectors, each allowing them to perform some small range of tasks. Some have a fixed manipulator which cannot be replaced, while a few have one very general purpose manipulator, for example a humanoid hand.\nMechanical Grippers: One of the most common effectors is the gripper. In its simplest manifestation it consists of just two fingers which can open and close to pick up and let go of a range of small objects. See End effectors.\nVacuum Grippers: Pick and place robots for electronic components and for large objects like car windscreens, will often use very simple vacuum grippers. These are very simple astrictive [21] devices, but can hold very large loads provided the prehension surface is smooth enough to ensure suction.\nGeneral purpose effectors: Some advanced robots are beginning to use fully humanoid hands, like the Shadow Hand and the Schunk hand.[22] These highly dexterous manipulators, with as many as 20 degrees of freedom and hundreds of tactile sensors[23]\nFor the definitive guide to all forms of robot endeffectors, their design and usage consult the book "Robot Grippers".[24]\nLocomotion\nRolling Robots\nSegway in the Robot museum in Nagoya.\nFor simplicity, most mobile robots have four wheels. However, some researchers have tried to create more complex wheeled robots, with only one or two wheels.\nTwo-wheeled balancing: While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot. Several real robots do use a similar dynamic balancing algorithm, and NASA''s Robonaut has been mounted on a Segway.[25]\nBallbot: Carnegie Mellon University researchers have developed a new type of mobile robot that balances on a ball instead of legs or wheels. "Ballbot" is a self-contained, battery-operated, omnidirectional robot that balances dynamically on a single urethane-coated metal sphere. It weighs 95 pounds and is the approximate height and width of a person. Because of its long, thin shape and ability to maneuver in tight spaces, it has the potential to function better than current robots can in environments with people.[26]\nTrack Robot: Another type of rolling robot is one that has tracks, like NASA''s Urban Robot, Urbie.[27]\nWalking Robots\niCub robot, designed by the RobotCub Consortium\nWalking is a difficult and dynamic problem to solve. Several robots have been made which can walk reliably on two legs, however none have yet been made which are as robust as a human. Typically, these robots can walk well on flat floors, and can occasionally walk up stairs. None can walk over rocky, uneven terrain. Some of the methods which have been tried are:\nZMP Technique: The Zero Moment Point (ZMP) is the algorithm used by robots such as Honda''s ASIMO. The robot''s onboard computer tries to keep the total inertial forces (the combination of earth''s gravity and the acceleration and deceleration of walking), exactly opposed by the floor reaction force (the force of the floor pushing back on the robot''s foot). In this way, the two forces cancel out, leaving no moment (force causing the robot to rotate and fall over).[28] However, this is not exactly how a human walks, and the difference is quite apparent to human observers, some of whom have pointed out that ASIMO walks as if it needs the lavatory.[29][30][31] ASIMO''s walking algorithm is not static, and some dynamic balancing is used (See below). However, it still requires a smooth surface to walk on.\nHopping: Several robots, built in the 1980s by Marc Raibert at the MIT Leg Laboratory, successfully demonstrated very dynamic walking. Initially, a robot with only one leg, and a very small foot, could stay upright simply by hopping. The movement is the same as that of a person on a pogo stick. As the robot falls to one side, it would jump slightly in that direction, in order to catch itself.[32] Soon, the algorithm was generalised to two and four legs. A bipedal robot was demonstrated running and even performing somersaults.[33] A quadruped was also demonstrated which could trot, run, pace and bound.[34] For a full list of these robots, see the MIT Leg Lab Robots page.\nDynamic Balancing: A more advanced way for a robot to walk is by using a dynamic balancing algorithm, which is potentially more robust than the Zero Moment Point technique, as it constantly monitors the robot''s motion, and places the feet in order to maintain stability.[35] This technique was recently demonstrated by Anybots'' Dexter Robot,[36] which is so stable, it can even jump.[37]\nPassive Dynamics: Perhaps the most promising approach utilises passive dynamics where the momentum of swinging limbs is used for greater efficiency. It has been shown that totally unpowered humanoid mechanisms can walk down a gentle slope, using only gravity to propel themselves. Using this technique, a robot need only supply a small amount of motor power to walk along a flat surface or a little more to walk up a hill. This technique promises to make walking robots at least ten times more efficient than ZMP walkers, like ASIMO.[38][39]\nOther methods of locomotion\nRQ-4 Global Hawk Unmanned Aerial Vehicle\nFlying: A modern passenger airliner is essentially a flying robot, with two humans to manage it. The autopilot can control the plane for each stage of the journey, including takeoff, normal flight and even landing.[40] Other flying robots are uninhabited, and are known as Unmanned Aerial Vehicles (UAVs). They can be smaller and lighter without a human pilot onboard, and fly into dangerous territory for military surveillance missions. Some can even fire on targets under command. UAVs are also being developed which can fire on targets automatically, without the need for a command from a human. However these robots are unlikely to see service in the foreseeable future because of the morality issues involved. Other flying robots include cruise missiles, the Entomopter and the Epson micro helicopter robot.\nTwo robot snakes. Left one has 64 motors (with 2 degrees of freedom per segment), the right one 10.\nSnaking: Several snake robots have been successfully developed. Mimicking the way real snakes move, these robots can navigate very confined spaces, meaning they may one day be used to search for people trapped in collapsed buildings.[41] The Japanese ACM-R5 snake robot[42] can even navigate both on land and in water.[43]\nSkating: A small number of skating robots have been developed, one of which is a multi-mode walking and skating device, Titan VIII. It has four legs, with unpowered wheels, which can either step or roll.[44] Another robot, Plen, can use a miniature skateboard or rollerskates, and skate across a desktop.[45]\nSwimming: It is calculated that when swimming some fish can achieve a propulsive efficiency greater than 90%.[46] Furthermore, they can accelerate and manoeuver far better than any man-made boat or submarine, and produce less noise and water disturbance. Therefore, many researchers studying underwater robots would like to copy this type of locomotion.[47] Notable examples are the Essex University Computer Science Robotic Fish,[48] and the Robot Tuna built by the Institute of Field Robotics, to analyse and mathematically model thunniform motion.[49]\nHuman interaction\nKismet can produce a range of facial expressions.\nIf robots are to work effectively in homes and other non-industrial environments, the way they are instructed to perform their jobs, and especially how they will be told to stop will be of critical importance. The people who interact with them may have little or no training in robotics, and so any interface will need to be extremely intuitive. Science fiction authors also typically assume that robots will eventually communicate with humans by talking, gestures and facial expressions, rather than a command-line interface. Although speech would be the most natural way for the human to communicate, it is quite unnatural for the robot. It will be quite a while before robots interact as naturally as the fictional C3P0.\nSpeech recognition: Interpreting the continuous flow of sounds coming from a human (speech recognition), in real time, is a difficult task for a computer, mostly because of the great variability of speech. The same word, spoken by the same person may sound different depending on local acoustics, volume, the previous word, whether or not the speaker has a cold, etc.. It becomes even harder when the speaker has a different accent.[50] Nevertheless, great strides have been made in the field since Davis, Biddulph, and Balashek designed the first "voice input system" which recognized "ten digits spoken by a single user with 100% accuracy" in 1952.[51] Currently, the best systems can recognise continuous, natural speech, up to 160 words per minute, with an accuracy of 95%.[52]\nGestures: One can imagine, in the future, explaining to a robot chef how to make a pastry, or asking directions from a robot police officer. On both of these occasions, making hand gestures would aid the verbal descriptions. In the first case, the robot would be recognising gestures made by the human, and perhaps repeating them for confirmation. In the second case, the robot police officer would gesture to indicate "down the road, then turn right". It is quite likely that gestures will make up a part of the interaction between humans and robots.[53] A great many systems have been developed to recognise human hand gestures.[54]\nFacial expression: Facial expressions can provide rapid feedback on the progress of a dialog between two humans, and soon it may be able to do the same for humans and robots. A robot should know how to approach a human, judging by their facial expression and body language. Whether the person is happy, frightened or crazy-looking affects the type of interaction expected of the robot. Likewise, a robot like Kismet can produce a range of facial expressions, allowing it to have meaningful social exchanges with humans.[55]\nPersonality: Many of the robots of science fiction have a personality, and that is something which may or may not be desirable in the commercial robots of the future.[56] Nevertheless, researchers are trying to create robots which appear to have a personality:[57][58] i.e. they use sounds, facial expressions and body language to try to convey an internal state, which may be joy, sadness or fear. One commercial example is Pleo, a toy robot dinosaur, which can exhibit several apparent emotions.[59]\nControl\nA robot-manipulated marionette, with complex control systems\nThe mechanical structure of a robot must be controlled to perform tasks. The control of a robot involves three distinct phases - perception, processing and action (robotic paradigms). Sensors give information about the environment or the robot itself (e.g. the position of its joints or its end effector). This information is then processed to calculate the appropriate signals to the actuators (motors) which move the mechanical .\nThe processing phase can range in complexity. At a reactive level, it may translate raw sensor information directly into actuator commands. Sensor fusion may first be used to estimate parameters of interest (e.g. the position of the robot''s gripper) from noisy sensor data. An immediate task (such as moving the gripper in a certain direction) is inferred from these estimates. Techniques from control theory convert the task into commands that drive the actuators.\nAt longer time scales or with more sophisticated tasks, the robot may need to build and reason with a "cognitive" model. Cognitive models try to represent the robot, the world, and how they interact. Pattern recognition and computer vision can be used to track objects. Mapping techniques can be used to build maps of the world. Finally, motion planning and other artificial intelligence techniques may be used to figure out how to act. For example, a planner may figure out how to achieve a task without hitting obstacles, falling over, etc.\nControl systems may also have varying levels of autonomy. Direct interaction is used for haptic or tele-operated devices, and the human has nearly complete control over the robot''s motion. Operator-assist modes have the operator commanding medium-to-high-level tasks, with the robot automatically figuring out how to achieve them. An autonomous robot may go for extended periods of time without human interaction. Higher levels of autonomy do not necessarily require more complex cognitive capabilities. For example, robots in assembly plants are completely autonomous, but operate in a fixed pattern.\nDynamics and kinematics\nThe study of motion can be divided into kinematics and dynamics. Direct kinematics refers to the calculation of end effector position, orientation, velocity and acceleration when the corresponding joint values are known. Inverse kinematics refers to the opposite case in which required joint values are calculated for given end effector values, as done in path planning. Some special aspects of kinematics include handling of redundancy (different possibilities of performing the same movement), collision avoidance and singularity avoidance. Once all relevant positions, velocities and accelerations have been calculated using kinematics, methods from the field of dynamics are used to study the effect of forces upon these movements. Direct dynamics refers to the calculation of accelerations in the robot once the applied forces are known. Direct dynamics is used in computer simulations of the robot. Inverse dynamics refers to the calculation of the actuator forces necessary to create a prescribed end effector acceleration. This information can be used to improve the control algorithms of a robot.\nIn each area mentioned above, researchers strive to develop new concepts and strategies, improve existing ones and improve the interaction between these areas. To do this, criteria for "optimal" performance and ways to optimize design, structure and control of robots must be developed and implemented.\nEducation\nRobotics as an undergraduate area of study is fairly common, although few universities offer robotics degrees. In the US, only Worcester Polytechnic Institute offers a Bachelor of Science in Robotics Engineering. Universities that have graduate degrees focused on robotics include Carnegie Mellon University, MIT, UPENN and UCLA . In Australia, there are Bachelor of Engineering degrees at the universities belonging to the Centre for Autonomous Systems (CAS) [60]: University of Sydney, University of New South Wales and the University of Technology, Sydney. Other universities include Deakin University, Flinders University, Swinburne University of Technology, and the University of Western Sydney. Others offer degrees in Mechatronics. In India a post-graduate degree in Mechatronics is offered at Madras Institute of Technology, Chennai. In the UK, Robotics degrees are offered by a number of institutions including the Heriot-Watt University, University of Essex, the University of Liverpool, University of Reading, Sheffield Hallam University, Staffordshire University,University of Sussex, The Robert Gordon University and the University of Wales, Newport. In Mexico, the Monterrey Institute of Technology and Higher Education offers a Bachelor of Science in Digital Systems and Robotics Engineering[61] and a Bachelor of Science in Mechatronics.[62]\nRobots recently became a popular tool in raising interests in computing for middle and high school students. First year computer science courses at several university were developed which involves the programming of a robot instead of the traditional software engineering based coursework. Examples include Course 6 at MIT and the Institute for Personal Robots in Education at the Georgia Institute of Technology with Bryn Mawr College.\nHealthCare\nScript Pro manufactures a robot designed to help pharmacies fill prescriptions that consist of oral solids or medications in pill form. The pharmacist or pharmacy technician enters the prescription information into its information system. The system, upon determining whether or not the drug is in the robot, will send the information to the robot for filling. The robot has 3 different size vials to fill determined by the size of the pill. The robot technician, user or pharmacist determines the needed size of the vial based on the tablet when the robot is stocked. Once the vial is filled it is brought up to a conveyor belt that delivers it to a holder that spins the vial and attaches the patient label. Afterwards it is set on another conveyor that delivers the patient’s medication vial to a slot labeled with the patients name on an LED read out. The pharmacist or technician then checks the contents of the vial to ensure it’s the correct drug for the correct patient and then seals the vials and sends it out front to be picked up. The robot is a very time efficient device that the pharmacy depends on to fill prescriptions.\nMcKesson’s Robot RX is another healthcare robotics product that helps inpatient pharmacies dispense thousands of medications daily with little or no errors. The robot can be ten feet wide and thirty feet long and can hold hundreds of different kinds of medications and thousands of doses. The pharmacy saves many resources like staff members that are otherwise unavailable in a resource scarce industry. It uses an electromechanical head coupled with a pneumatic system to capture each dose and deliver it to its either stocked or dispensed location. The head moves along a single axis while it rotates 180 degrees to pull the medications. During this process it uses barcode technology to verify its pulling the correct drug. It then delivers the drug to a patient specific bin on a conveyor belt. Once the bin is filled will all of the drugs that a particular patient needs and that the robot stocks, the bin is then released and returned out on the conveyor belt to a technician waiting to load it into a cart for delivery to the floor\nTUG robots, from Aethon, are a necessity for any hospital’s inpatient pharmacy. TUGs are a medication delivery robot. They are stationed at or near the pharmacy on a charging base designed to keep their batteries at optimal levels. Once a pharmacy has a number of meds to send to the floors, they load the TUGs by putting in their code to unlock the drawers and start sorting the meds by delivery station. After it has been loaded the user selects the locations in the order they want them delivered and then they hit the send button. The TUG backs up, turns and goes on it path to its destination. It uses a series of navigational tools to find it way around. For the most part it is laser guided and uses a 180 degree laser to check for walls and obstacles in its path. It also makes use of infrared sensors and sonar for navigation, obstacle avoidance and detection. Using these navigational tools it uses an internal map that is designed by the TUG itself and an Implementation Specialist from Aethon to drive down a planned path to its destinations. If it needs to navigate between floors the company will, with help from an elevator vendor, set up an elevator computer interface and the TUG will communicate wirelessly with an elevator controller to gain access and control of an elevator to take it to the desired floor. From that point the TUG will make its delivery, return home and wait for another delivery.\nSee also\nRobotics portal\nOpen source robotics\nRobotics suite\nCategory:Robotics suites\nNotes\n^ "Definition of robotics - Merriam-Webster Online Dictionary". Retrieved on 2007-08-26.\n^ "Industry Spotlight: Robotics from Monster Career Advice". Retrieved on 2007-08-26.\n^ "Robotics: About the Exhibition".\nThe Tech Museum of Innovation. Retrieved on 2008-09-15.\n^ Imitation of Life: A History of the First Robots\n^ Waurzyniak, Patrick (2006-07). "Masters of Manufacturing: Joseph F. Engelberger". Society of Manufacturing Engineers 137 (1). http://www.sme.org/cgi-bin/find-articles.pl?&ME06ART39&ME&20060709#article.\n^ "Company History".\nFuji Yusoki Kogyo Co.. Retrieved on 2008-09-12.\n^ Asimov, Isaac (2003). Gold. Eos.\n^ Zunt, Dominik. "Who did actually invent the word "robot" and what does it mean?".\nThe Karel Čapek website. Retrieved on 2007-09-11.\n^ "Piezo LEGS® - -09-26".\n^ "Squiggle Motors: Overview". Retrieved on 2007-10-08.\n^ Nishibori et al. (2003). "Robot Hand with Fingers Using Vibration-Type Ultrasonic Motors (Driving Characteristics)".\nJournal of Robotics and Mechatronics. Retrieved on 2007-10-09.\n^ Yamano and Maeno (2005). "Five-fingered Robot Hand using Ultrasonic Motors and Elastic Elements" (PDF).\nProceedings of the 2005 IEEE International Conference on Robotics and Automation. Retrieved on 2007-10-09.\n^ "Shadow Robot Company: Air Muscles". Retrieved on 2007-10-15.\n^ You must specify title = and url = when using {{cite web}}."". Retrieved on 2007-10-15.\n^ Yoseph Bar-Cohen (2002). "Electro-active polymers: current capabilities and challenges" (PDF).\nProceedings of the SPIE Smart Structures and Materials Symposium. Retrieved on 2007-10-15.\n^ Arm wrestling robots beaten by a teenaged girlham-Rowe. 2002-03-08. http://www.newscientisttech.com/article/dn7113. Retrieved on 15 October 2007.\n^ Otake et al. (2001). "Shape Design of Gel Robots made of Electroactive Polymer Gel" (PDF). Retrieved on 2007-10-16.\n^ John D. Madden, 2007, Mobile Robots: Motor Challenges and Materials Solutions, Science 16 November 2007: Vol. 318. no. 5853, pp. 1094 - 1097, DOI: 10.1126/science.1146351\n^ "What is a a robotic end-effector?".\nATI Industrial Automation (2007). Retrieved on 2007-10-16.\n^ Crane, Carl D.; Joseph Duffy (1998-03). Kinematic Analysis of Robot Manipulators. Cambridge University Press. ISBN 0521570638. http://www.cambridge.org/us/catalogue/catalogue.asp?isbn=0521570638. Retrieved on 16 October 2007.\n^ Definition "astrictive" (to bind, confine, or constrict) in Collins English Dictionary & Thesaurus\n^ Allcock, Andrew (2006-09). "Anthropomorphic hand is almost human".\nMachinery. Retrieved on 2007-10-17.\n^ [1]\n^ G.J. Monkman, S. Hesse, R. Steinmann & H. Schunk – Robot Grippers - Wiley, Berlin 2007\n^ "ROBONAUT Activity Report".\nNASA (2004-02). Retrieved on 2007-10-20.\n^ Carnegie Mellon (2006-08-09). "Carnegie Mellon Researchers Develop New Type of Mobile Robot That Balances and Moves on a Ball Instead of Legs or Wheels". Press release.\n^ JPL Robotics: System: Commercial Rovers\n^ "Achieving Stable Walking".\nHonda Worldwide. Retrieved on 2007-10-22.\n^ "Funny Walk".\nPooter Geek (2004-12-28). Retrieved on 2007-10-22.\n^ "ASIMO''s Pimp Shuffle".\nPopular Science (2007-01-09). Retrieved on 2007-10-22.\n^ Vtec Forum: A drunk robot? thread\n^ "3D One-Leg Hopper (1983–1984)".\nMIT Leg Laboratory. Retrieved on 2007-10-22.\n^ "3D Biped (1989–1995)".\nMIT Leg Laboratory.\n^ "Quadruped (1984–1987)".\nMIT Leg Laboratory.\n^ "About the robots".\nAnybots. Retrieved on 2007-10-23.\n^ "Homepage".\nAnybots. Retrieved on 2007-10-23.\n^ "Dexter Jumps video".\nYouTube (2007-03). Retrieved on 2007-10-23.\n^ Collins, Steve; Wisse, Martijn; Ruina, Andy; Tedrake, Russ (2005-02-11). "Efficient bipedal robots based on passive-dynamic Walkers" (PDF). Science 307 (307): 1082–1085. doi:10.1126/science.1107799. PMID 15718465. http://ruina.tam.cornell.edu/research/topics/locomotion_and_robotics/papers/efficient_bipedal_robots/efficient_bipedal_robots.pdf. Retrieved on 11 September 2007.\n^ Collins, Steve; Ruina, Andy. "A bipedal walking robot with efficient and human-like gait". Proc. IEEE International Conference on Robotics and Automation..\n^ "Testing the Limits" page 29.\nBoeing. Retrieved on 2008-04-09.\n^ Miller, Gavin. "Introduction".\nsnakerobots.com. Retrieved on 2007-10-22.\n^ ACM-R5\n^ Swimming snake robot (commentary in Japanese)\n^ "Commercialized Quadruped Walking Vehicle "TITAN VII"".\nHirose Fukushima Robotics Lab. Retrieved on 2007-10-23.\n^ "Plen, the robot that skates across your desk".\nSCI FI Tech (2007-01-23). Retrieved on 2007-10-23.\n^ Sfakiotakis, et al. (1999-04). "Review of Fish Swimming Modes for Aquatic Locomotion" (PDF).\nIEEE Journal of Oceanic Engineering. Retrieved on 2007-10-24.\n^ Richard Mason. "What is the market for robot fish?".\n^ "Robotic fish powered by Gumstix PC and PIC".\nHuman Centred Robotics Group at Essex University. Retrieved on 2007-10-25.\n^ Witoon Juwarahawong. "Fish Robot".\nInstitute of Field Robotics. Retrieved on 2007-10-25.\n^ Survey of the State of the Art in Human Language Technology: 1.2: Speech Recognition\n^ Fournier, Randolph Scott., and B. June. Schmidt. "Voice Input Technology: Learning Style and Attitude Toward Its Use." Delta Pi Epsilon Journal 37 (1995): 1_12.\n^ "History of Speech & Voice Recognition and Transcription Software".\nDragon Naturally Speaking. Retrieved on 2007-10-27.\n^ Waldherr, Romero & Thrun (2000). "A Gesture Based Interface for Human-Robot Interaction" (PDF).\nKluwer Academic Publishers. Retrieved on 2007-10-28.\n^ Markus Kohler. "Vision Based Hand Gesture Recognition Systems".\nUniversity of Dortmund. Retrieved on 2007-10-28.\n^ "Kismet: Robot at MIT''s AI Lab Interacts With Humans".\nSam Ogden. Retrieved on 2007-10-28.\n^ (Park et al. 2005) Synthetic Personality in Robots and its Effect on Human-Robot Relationship\n^ National Public Radio: Robot Receptionist Dishes Directions and Attitude\n^ New Scientist: A good robot has personality but not looks\n^ Ugobe: Introducing Pleo\n^ [ http://www.cas.edu.au ]\n^ ITESM: B.S. Digital Systems and Robotics Engineering\n^ [2]\nReferences\nK. S. Fu & R.C. Gonzalez & C.S.G. Lee, Robotics: Control, Sensing, Vision, and Intelligence (CAD/CAM, robotics, and computer vision)\nC.S.G. Lee & R.C. Gonzalez & K.S. Fu, Tutorial on robotics\n“SP200 With Open Control Center. Robotic Prescription Dispensing System”. Available from http://www.scriptpro.com/products/sp-200/SP_200_OCC_Low_Res.pdf. Interent; accessed November 22, 2008.\n“McKesson Empowering HealthCare. Robot RX”. Available from http://www.mckesson.com/en_us/McKesson.com/For%2BPharmacies/Inpatient/Pharmacy%2BAutomation/ROBOT-Rx.html. Internet; accessed November 22, 2008.\n“Aethon. You Deliver the Care. TUG Delivers the Rest”. Available from http://aethon.com/brochure.pdf Internet; accessed November 22, 2008.\nMarco Ceccarelli, "Fundamentals of Mechanics of Robotic Manipulators"\nAll external links for this article can be found at Robot.\n"http://en.wikipedia.org/wiki/Robotics"\nCategory: RoboticsHidden category: Articles with broken citations','\n',char(10)));
INSERT INTO pages VALUES('Squeak','http://web.archive.org/web/20081219132922/http://en.wikipedia.org:80/wiki/Squeak','en','2008-12-19 00:00:00',replace('This article is about the programming language.\nFor the food, see bubble and squeak.\nSqueak\nParadigm\nobject-oriented\nAppeared in\n1996\nDesigned by\nAlan Kay, Dan Ingalls, Adele Goldberg\nDeveloper\nAlan Kay, Dan Ingalls, Ted Kaehler, Scott Wallace, John Maloney, Andreas Raab, Mike Rueger\nTyping discipline\ndynamic\nMajor implementations\nSqueak, Croquet\nInfluenced by\nSmalltalk, Lisp, Logo; Sketchpad, Simula; Self\nInfluenced\nEtoys, Tweak, Croquet\nWebsite\nhttp://www.squeak.org/\nScreenshot of the Squeak VM running under X11.\nLook up Squeak in\nWiktionary, the free dictionary.\nThe Squeak programming language is a Smalltalk implementation, derived directly from Smalltalk-80 by a group at Apple Computer that included some of the original Smalltalk-80 developers. Its development was continued by the same group at Walt Disney Imagineering, where it was intended for use in internal Disney projects. Some Squeak users refer to Squeak as a programming language rather than as a Smalltalk implementation. It is object-oriented, class-based, and reflective. Squeak is available for many platforms, and programs produced on one platform run bit-identical on all other platforms. The Squeak system includes code for generating a new version of the virtual machine (VM) on which it runs. It also includes a VM simulator written in itself (Squeak). For this reason, it is easily ported.\n1 Developers\n2 User interface frameworks\n3 Uses\n4 License\n5 See also\n6\n6.1 Books\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nDevelopers\nDan Ingalls is one of the important contributors to the Squeak project. Ingalls wrote the paper "Back to the Future: the story of Squeak, a practical Smalltalk written in itself", as well as built the architecture for five generations of the Smalltalk language upon which Squeak is built. Squeak incorporates many of the elements Alan Kay proposed in the Dynabook concept, which he formulated in the 1960s. Kay is an important contributor to the Squeak project. Andreas Raab seems to have the most commits.\nUser interface frameworks\nSqueak includes a number of user interface frameworks:\nAn implementation of Morphic, Self''s graphical direct manipulation interface framework. This is Squeak''s main interface.\nTile-based, limited visual programming scripting in eToys, based on Morphic.\nA new, experimental interface called Tweak. In 2001, it became clear that the eToy architecture in Squeak had reached its limits in what the Morphic interface infrastructure could do. Hewlett-Packard researcher Andreas Raab proposed defining a "script process" and providing a default scheduling mechanism that avoids several more general problems[1]. The result was a new user interface, proposed to replace the Squeak Morphic user interface in the future. Tweak added mechanisms of islands, asynchronous messaging, players and costumes, language extensions, projects, and tile scripting[2]. Its underlying object system is class-based, but to users, during programming (scripting), it acts like it is prototype-based. Tweak objects are created and run in Tweak project windows.\nMVC, derived from the original Smalltalk-80 user interface framework which first introduced and popularized the Model-View-Controller architectural pattern[3] (so named after the three core classes of the framework). Thus, the term "MVC" in the context of Squeak refers to both one of the available user interface frameworks and the pattern the framework follows. MVC is provided for programmers who wish to use this older type of interface.\nUses\nMany Squeak contributors collaborate on the free and open source Croquet project, which is built on Squeak, and offers a networked, real time, collaborative workspace with 2D and 3D abilities.\nSqueak is also used in the es operating system.\nLicense\nSqueak may be downloaded at no cost, including all its source code. Unlike other languages, Squeak is distributed in a prebuilt virtual machine image form rather than bootstrappable source code.\nThere is some debate as to whether the Squeak license qualifies as free software or not, due to the presence of an indemnity clause in the original Squeak License. Version 1.1 of the environment, originally released on October 1997 under the Squeak License, has been released in May 2006 under the free and open source Apple Public Source License. It has been relicensed under the Apache License allowing inclusion in the One Laptop Per Child initiative. [4]\nSee also\nCroquet project\nSeaside\nScratch\nAlice\nEToys\nSqueakNOS\nSqueak.org\nSqueak Swiki\nBack to the future: the story of Squeak, a practical Smalltalk written in itself (PDF version) (HTML versions:[5][6])\nSqueakland.org\nSqueakNotes\nLearning Squeak at c2.com\nSearch engine related to Squeak\nSqueakCMI Champaign, IL\n(Spanish) Small-Land.org\nSqueak at the Open Directory Project\nBooks\nSqueak by Example Squeak by Example is a new open-source book about the Squeak development environment.\nDownloadable books about Smalltalk Permission obtained to make these books freely available. Over a dozen full texts scanned from print.)\nProgramando con Smalltalk - Un ambiente de objetos vivos Book in Spanish by Diego Gomez Deck.\nSqueak: Object-Oriented design With Multimedia Applications, by Mark Guzdial\n"http://en.wikipedia.org/wiki/Squeak"\nCategories: Class-based programming languages | Dynamically-typed programming languages | Smalltalk programming language family | Educational programming languages | Visual programming languages','\n',char(10)));
INSERT INTO pages VALUES('Compiler','http://web.archive.org/web/20081219012447/http://en.wikipedia.org:80/wiki/Compiler','en','2008-12-19 00:00:00',replace('This article is about the computing term.\nFor the anime, see Compiler (anime).\nA diagram of the operation of a typical multi-language, multi-target compiler.\nA compiler is a computer program (or set of programs) that translates text written in a computer language (the source language) into another computer language (the target language). The original sequence is usually called the source code and the output called object code. Commonly the output has a form suitable for processing by other programs (e.g., a linker), but it may be a human-readable text file.\nThe most common reason for wanting to translate source code is to create an executable program. The name "compiler" is primarily used for programs that translate source code from a high-level programming language to a lower level language (e.g., assembly language or machine language). A program that translates from a low level language to a higher level one is a decompiler. A program that translates between high-level languages is usually called a language translator, source to source translator, or language converter. A language rewriter is usually a program that translates the form of expressions without a change of language.\nA compiler is likely to perform many or all of the following operations: lexical analysis, preprocessing, parsing, semantic analysis, code generation, and code optimization.\n1 History\n1.1 Compilers in education\n2 Compiler output\n2.1 Compiled versus interpreted languages\n2.2 Hardware compilation\n3 Compiler design\n3.1 One-pass versus multi-pass compilers\n3.2 Front end\n3.3 Back end\n4 Related techniques\n5 See also\n6 Notes\n7 References\n8\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nSoftware for early computers was primarily written in assembly language for many years. Higher level programming languages were not invented until the benefits of being able to reuse software on different kinds of CPUs started to become significantly greater than the cost of writing a compiler. The very limited memory capacity of early computers also created many technical problems when implementing a compiler.\nTowards the end of the 1950s, machine-independent programming languages were first proposed. Subsequently, several experimental compilers were developed. The first compiler was written by Grace Hopper, in 1952, for the A-0 programming language. The FORTRAN team led by John Backus at IBM is generally credited as having introduced the first complete compiler, in 1957. COBOL was an early language to be compiled on multiple architectures, in 1960.[1]\nIn many application domains the idea of using a higher level language quickly caught on. Because of the expanding functionality supported by newer programming languages and the increasing complexity of computer architectures, compilers have become more and more complex.\nEarly compilers were written in assembly language. The first self-hosting compiler — capable of compiling its own source code in a high-level language — was created for Lisp by Hart and Levin at MIT in 1962.[2] Since the 1970s it has become common practice to implement a compiler in the language it compiles, although both Pascal and C have been popular choices for implementation language. Building a self-hosting compiler is a bootstrapping problem -- the first such compiler for a language must be compiled either by a compiler written in a different language, or (as in Hart and Levin''s Lisp compiler) compiled by running the compiler in an interpreter.\nCompilers in education\nCompiler construction and compiler optimization are taught at universities as part of the computer science curriculum. Such courses are usually supplemented with the implementation of a compiler for an educational programming language. A well-documented example is Niklaus Wirth''s PL/0 compiler, which Wirth used to teach compiler construction in the 1970s.[3] In spite of its simplicity, the PL/0 compiler introduced several influential concepts to the field:\nProgram development by stepwise refinement (also the title of a 1971 paper by Wirth[4])\nThe use of a recursive descent parser\nThe use of EBNF to specify the syntax of a language\nA code generator producing portable P-code\nThe use of T-diagrams in the formal description of the bootstrapping problem\nCompiler output\nOne classification of compilers is by the platform on which their generated code executes. This is known as the target platform.\nA native or hosted compiler is one whose output is intended to directly run on the same type of computer and operating system as the compiler itself runs on. The output of a cross compiler is designed to run on a different platform. Cross compilers are often used when developing software for embedded systems that are not intended to support a software development environment.\nThe output of a compiler that produces code for a virtual machine (VM) may or may not be executed on the same platform as the compiler that produced it. For this reason such compilers are not usually classified as native or cross compilers.\nCompiled versus interpreted languages\nHigher-level programming languages are generally divided for convenience into compiled languages and interpreted languages. However, there is rarely anything about a language that requires it to be exclusively compiled, or exclusively interpreted. The categorization usually reflects the most popular or widespread implementations of a language — for instance, BASIC is sometimes called an interpreted language, and C a compiled one, despite the existence of BASIC compilers and C interpreters.\nIn a sense, all languages are interpreted, with "execution" being merely a special case of interpretation performed by transistors switching on a CPU. Modern trends toward just-in-time compilation and bytecode interpretation also blur the traditional categorizations.\nThere are exceptions. Some language specifications spell out that implementations must include a compilation facility; for example, Common Lisp. Other languages have features that are very easy to implement in an interpreter, but make writing a compiler much harder; for example, APL, SNOBOL4, and many scripting languages allow programs to construct arbitrary source code at runtime with regular string operations, and then execute that code by passing it to a special evaluation function. To implement these features in a compiled language, programs must usually be shipped with a runtime library that includes a version of the compiler itself.\nHardware compilation\nThe output of some compilers may target hardware at a very low level. For example a Field Programmable Gate Array (FPGA) or structured Application-specific integrated circuit (ASIC). Such compilers are said to be hardware compilers or synthesis tools because the programs they compile effectively control the final configuration of the hardware and how it operates; the output of the compilation are not instructions that are executed in sequence - only an interconnection of transistors or lookup tables. For example, XST is the Xilinx Synthesis Tool used for configuring FPGAs. Similar tools are available from Altera, Synplicity, Synopsys and other vendors.\nCompiler design\nThe approach taken to compiler design is affected by the complexity of the processing that needs to be done, the experience of the person(s) designing it, and the resources (eg, people and tools) available.\nA compiler for a relatively simple language written by one person might be a single, monolithic piece of software. When the source language is large and complex, and high quality output is required the design may be split into a number of relatively independent phases, or passes. Having separate phases means development can be parceled up into small parts and given to different people. It also becomes much easier to replace a single phase by an improved one, or to insert new phases later (eg, additional optimizations).\nThe division of the compilation processes in phases (or passes) was championed by the Production Quality Compiler-Compiler Project (PQCC) at Carnegie Mellon University. This project introduced the terms front end, middle end, and back end.\nAll but the smallest of compilers have more than two phases. However, these phases are usually regarded as being part of the front end or the back end. The point at where these two ends meet is always open to debate. The front end is generally considered to be where syntactic and semantic processing takes place, along with translation to a lower level of representation (than source code).\nThe middle end is usually designed to perform optimizations on a form other than the source code or machine code. This source code/machine code independence is intended to enable generic optimizations to be shared between versions of the compiler supporting different languages and target processors.\nThe back end takes the output from the middle. It may perform more analysis, transformations and optimizations that are for a particular computer. Then, it generates code for a particular processor and OS.\nThis front-end/middle/back-end approach makes it possible to combine front ends for different languages with back ends for different CPUs. Practical examples of this approach are the GNU Compiler Collection, LLVM, and the Amsterdam Compiler Kit, which have multiple front-ends, shared analysis and multiple back-ends.\nOne-pass versus multi-pass compilers\nClassifying compilers by number of passes has its background in the hardware resource limitations of computers. Compiling involves performing lots of work and early computers did not have enough memory to contain one program that did all of this work. So compilers were split up into smaller programs which each made a pass over the source (or some representation of it) performing some of the required analysis and translations.\nThe ability to compile in a single pass is often seen as a benefit because it simplifies the job of writing a compiler and one pass compilers generally compile faster than multi-pass compilers. Many languages were designed so that they could be compiled in a single pass (e.g., Pascal).\nIn some cases the design of a language feature may require a compiler to perform more than one pass over the source. For instance, consider a declaration appearing on line 20 of the source which affects the translation of a statement appearing on line 10. In this case, the first pass needs to gather information about declarations appearing after statements that they affect, with the actual translation happening during a subsequent pass.\nThe disadvantage of compiling in a single pass is that it is not possible to perform many of the sophisticated optimizations needed to generate high quality code. It can be difficult to count exactly how many passes an optimizing compiler makes. For instance, different phases of optimization may analyse one expression many times but only analyse another expression once.\nSplitting a compiler up into small programs is a technique used by researchers interested in producing provably correct compilers. Proving the correctness of a set of small programs often requires less effort than proving the correctness of a larger, single, equivalent program.\nWhile the typical multi-pass compiler outputs machine code from its final pass, there are several other types:\nA "source-to-source compiler" is a type of compiler that takes a high level language as its input and outputs a high level language. For example, an automatic parallelizing compiler will frequently take in a high level language program as an input and then transform the code and annotate it with parallel code annotations (e.g. OpenMP) or language constructs (e.g. Fortran''s DOALL statements).\nStage compiler that compiles to assembly language of a theoretical machine, like some Prolog implementations\nThis Prolog machine is also known as the Warren Abstract Machine (or WAM). Bytecode compilers for Java, Python, and many more are also a subtype of this.\nJust-in-time compiler, used by Smalltalk and Java systems, and also by Microsoft .Net''s Common Intermediate Language (CIL)\nApplications are delivered in bytecode, which is compiled to native machine code just prior to execution.\nFront end\nThe front end analyzes the source code to build an internal representation of the program, called the intermediate representation or IR. It also manages the symbol table, a data structure mapping each symbol in the source code to associated information such as location, type and scope. This is done over several phases, which includes some of the following:\nLine reconstruction. Languages which strop their keywords or allow arbitrary spaces within identifiers require a phase before parsing, which converts the input character sequence to a canonical form ready for the parser. The top-down, recursive-descent, table-driven parsers used in the 1960s typically read the source one character at a time and did not require a separate tokenizing phase. Atlas Autocode, and Imp (and some implementations of Algol and Coral66) are examples of stropped languages whose compilers would have a Line Reconstruction phase.\nLexical analysis breaks the source code text into small pieces called tokens. Each token is a single atomic unit of the language, for instance a keyword, identifier or symbol name. The token syntax is typically a regular language, so a finite state automaton constructed from a regular expression can be used to recognize it. This phase is also called lexing or scanning, and the software doing lexical analysis is called a lexical analyzer or scanner.\nPreprocessing. Some languages, e.g., C, require a preprocessing phase which supports macro substitution and conditional compilation. Typically the preprocessing phase occurs before syntactic or semantic analysis; e.g. in the case of C, the preprocessor manipulates lexical tokens rather than syntactic forms. However, some languages such as Scheme support macro substitutions based on syntactic forms.\nSyntax analysis involves parsing the token sequence to identify the syntactic structure of the program. This phase typically builds a parse tree, which replaces the linear sequence of tokens with a tree structure built according to the rules of a formal grammar which define the language''s syntax. The parse tree is often analyzed, augmented, and transformed by later phases in the compiler.\nSemantic analysis is the phase in which the compiler adds semantic information to the parse tree and builds the symbol table. This phase performs semantic checks such as type checking (checking for type errors), or object binding (associating variable and function references with their definitions), or definite assignment (requiring all local variables to be initialized before use), rejecting incorrect programs or issuing warnings. Semantic analysis usually requires a complete parse tree, meaning that this phase logically follows the parsing phase, and logically precedes the code generation phase, though it is often possible to fold multiple phases into one pass over the code in a compiler implementation.\nBack end\nThe term back end is sometimes confused with code generator because of the overlapped functionality of generating assembly code. Some literature uses middle end to distinguish the generic analysis and optimization phases in the back end from the machine-dependent code generators.\nThe main phases of the back end include the following:\nAnalysis: This is the gathering of program information from the intermediate representation derived from the input. Typical analyses are data flow analysis to build use-define chains, dependence analysis, alias analysis, pointer analysis, escape analysis etc. Accurate analysis is the basis for any compiler optimization. The call graph and control flow graph are usually also built during the analysis phase.\nOptimization: the intermediate language representation is transformed into functionally equivalent but faster (or smaller) forms. Popular optimizations are inline expansion, dead code elimination, constant propagation, loop transformation, register allocation or even automatic parallelization.\nCode generation: the transformed intermediate language is translated into the output language, usually the native machine language of the system. This involves resource and storage decisions, such as deciding which variables to fit into registers and memory and the selection and scheduling of appropriate machine instructions along with their associated addressing modes (see also Sethi-Ullman algorithm).\nCompiler analysis is the prerequisite for any compiler optimization, and they tightly work together. For example, dependence analysis is crucial for loop transformation.\nIn addition, the scope of compiler analysis and optimizations vary greatly, from as small as a basic block to the procedure/function level, or even over the whole program (interprocedural optimization). Obviously, a compiler can potentially do a better job using a broader view. But that broad view is not free: large scope analysis and optimizations are very costly in terms of compilation time and memory space; this is especially true for interprocedural analysis and optimizations.\nInterprocedural analysis and optimizations are common in modern commercial compilers from HP, IBM, SGI, Intel, Microsoft, and Sun Microsystems. The open source GCC was criticized for a long time for lacking powerful interprocedural optimizations, but it is changing in this respect. Another open source compiler with full analysis and optimization infrastructure is Open64, which is used by many organizations for research and commercial purposes.\nDue to the extra time and space needed for compiler analysis and optimizations, some compilers skip them by default. Users have to use compilation options to explicitly tell the compiler which optimizations should be enabled.\nRelated techniques\nAssembly language is not a high-level language and a program that compiles it is more commonly known as an assembler, with the inverse program known as a disassembler.\nA program that translates from a low level language to a higher level one is a decompiler.\nA program that translates between high-level languages is usually called a language translator, source to source translator, language converter, or language rewriter. The last term is usually applied to translations that do not involve a change of language.\nSee also\nList of compilers\nAbstract interpretation\nAttribute grammar\nBottom-up parsing\nError avalanche\nJust-in-time compilation\nLinker\nList of important publications in computer science#Compilers\nMetacompilation\nSemantics encoding\nNotes\n^ IP: "The World''s First COBOL Compilers" -- 12 June 1997\n^ T. Hart and M. Levin "The New Compiler", AIM-39 CSAIL Digital Archive - Artificial Intelligence Laboratory Series\n^ "The PL/0 compiler/interpreter"\n^ Book description at the ACM Digital Library\nReferences\nCompiler textbook references A collection of references to mainstream Compiler Construction Textbooks\nCompilers: Principles, Techniques and Tools by Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman (ISBN 0-201-10088-6) link to publisher. Also known as “The Dragon Book.”\nAdvanced Compiler Design and Implementation by Steven Muchnick (ISBN 1-55860-320-4).\nEngineering a Compiler by Keith D. Cooper and Linda Torczon. Morgan Kaufmann 2004, ISBN 1-55860-699-8.\nUnderstanding and Writing Compilers: A Do It Yourself Guide (ISBN 0-333-21732-2) by Richard Bornat. An on-line version of the book.\nAn Overview of the Production Quality Compiler-Compiler Project by Leverett, Cattel, Hobbs, Newcomer, Reiner, Schatz and Wulf. Computer 13(8):38-49 (August 1980)\nCompiler Construction by Niklaus Wirth (ISBN 0-201-40353-6) Addison-Wesley 1996, 176 pages, [1].\n"Programming Language Pragmatics" by Michael Scott (ISBN 0-12-633951-1) Morgan Kaufmann 2005, 2nd edition, 912 pages. The author''s site.\n"A History of Language Processor Technology in IBM", by F.E. Allen, IBM Journal of Research and Development, v.25, no.5, September 1981.\nLook up compiler in\nWiktionary, the free dictionary.\nWikibooks has a book on the topic of\nCompiler construction\nThe comp.compilers newsgroup and RSS feed\nHardware compilation mailing list\n"http://en.wikipedia.org/wiki/Compiler"\nCategories: Compilers | Compiler theory | Computer libraries | Programming language implementation','\n',char(10)));
INSERT INTO pages VALUES('MapReduce','http://web.archive.org/web/20081218210401/http://en.wikipedia.org:80/wiki/MapReduce','en','2008-12-18 00:00:00',replace('1 Overview\n2 Logical view\n2.1 Example\n3 Dataflow\n3.1 Input reader\n3.2 Map function\n3.3 Partition function\n3.4 Comparison function\n3.5 Reduce function\n3.6 Output writer\n4 Distribution and reliability\n5 Uses\n6 Criticism\n7 Implementations\n8 References\n9\n9.1 Papers\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nMapReduce is a software framework introduced by Google to support distributed computing on large data sets on clusters of computers [1]. The framework is inspired by map and reduce functions commonly used in functional programming,[2] although their purpose in the MapReduce framework is not the same as their original forms[3]. MapReduce libraries have been written in C++, Java, Python and other programming languages.\nOverview\nMapReduce is a framework for computing certain kinds of distributable problems using a large number of computers (nodes), collectively referred to as a cluster.\n"Map" step: The master node takes the input, chops it up into smaller sub-problems, and distributes those to worker nodes. (A worker node may do this again in turn, leading to a multi-level tree structure.)\nThe worker node processes that smaller problem, and passes the answer back to its master node.\n"Reduce" step: The master node then takes the answers to all the sub-problems and combines them in a way to get the output - the answer to the problem it was originally trying to solve.\nThe advantage of MapReduce is that it allows for distributed processing of the map and reduction operations. Provided each mapping operation is independent of the other, all maps can be performed in parallel - though in practise it is limited by the data source and/or the number of CPUs near that data. Similarly, a set of ''reducers'' can perform the reduction phase - all that is required is that all outputs of the map operation which share the same key are presented to the same reducer, at the same time. While this process can often appear inefficient compared to algorithms that are more sequential, MapReduce can be applied to significantly larger datasets than that which "commodity" servers can handle - a large server farm can use MapReduce to sort a petabyte of data in only a few hours. The parallelism also offers some possibility of recovering from partial failure of servers or storage during the operation: if one mapper or reducer fails, the work can be rescheduled -assuming the input data is still available.\nLogical view\nThe Map and Reduce functions of MapReduce are both defined with respect to data structured in (key, value) pairs. Map takes one pair of data with a type on a data domain, and returns a list of pairs in a different domain:\nMap(k1,v1) -> list(k2,v2)\nThe map function is applied in parallel to every item in the input dataset. This produces a list of (k2,v2) pairs for each call. After that, the MapReduce framework collects all pairs with the same key from all lists and groups them together, thus creating one group for each one of the different generated keys.\nThe Reduce function is then applied in parallel to each group, which in turn produces a collection of values in the same domain:\nReduce(k2, list (v2)) -> list(v2)\nEach Reduce call typically produces either one value v2 or an empty return, though one call is allowed to return more than one value. The returns of all calls are collected as the desired result list.\nThus the MapReduce framework transforms a list of (key, value) pairs into a list of values. This behavior is different from the functional programming map and reduce combination, which accepts a list of arbitrary values and returns one single value that combines all the values returned by map.\nIt is necessary but not sufficient to have implementations of the map and reduce abstractions in order to implement MapReduce. Furthermore effective implementations of MapReduce require a distributed file system to connect the processes performing the Map and Reduce phases.\nExample\nThe canonical example application of MapReduce is a process to count the appearances of each different word in a set of documents:\nmap(String name, String document):\n// key: document name\n// value: document contents\nfor each word w in document:\nEmitIntermediate(w, 1);\nreduce(String word, Iterator partialCounts):\n// key: a word\n// values: a list of aggregated partial counts\nint result = 0;\nfor each v in partialCounts:\nresult += ParseInt(v);\nEmit(result);\nHere, each document is split in words, and each word is counted initially with a "1" value by the Map function, using the word as the result key. The framework puts together all the pairs with the same key and feeds them to the same call to Reduce, thus this function just needs to sum all of its input values to find the total appearances of that word.\nDataflow\nThe frozen part of the MapReduce framework is a large distributed sort. The hot spots, which the application defines, are:\nan input reader\na Map function\na partition function\na compare function\na Reduce function\nan output writer\nInput reader\nThe input reader divides the input into 16MB to 128MB splits and the framework assigns one split to each Map function. The input reader reads data from stable storage (typically a distributed file system like Google File System) and generates key/value pairs.\nA common example will read a directory full of text files and return each line as a record.\nMap function\nEach Map function takes a series of key/value pairs, processes each, and generates zero or more output key/value pairs. The input and output types of the map can be (and often are) different from each other.\nIf the application is doing a word count, the map function would break the line into words and output the word as the key and "1" as the value.\nPartition function\nThe output of all of the maps is allocated to particular reduces by the application''s partition function. The partition function is given the key and the number of reduces and returns the index of the desired reduce.\nA typical default is to hash the key and modulo the number of reduces.\nComparison function\nThe input for each reduce is pulled from the machine where the map ran and sorted using the application''s comparison function.\nReduce function\nThe framework calls the application''s reduce function once for each unique key in the sorted order. The reduce can iterate through the values that are associated with that key and output 0 or more key/value pairs.\nIn the word count example, the reduce function takes the input values, sums them and generates a single output of the word and the final sum.\nOutput writer\nThe Output Writer writes the output of the reduce to stable storage, usually a distributed file system, such as Google File System.\nDistribution and reliability\nMapReduce achieves reliability by parceling out a number of operations on the set of data to each node in the network; each node is expected to report back periodically with completed work and status updates. If a node falls silent for longer than that interval, the master node (similar to the master server in the Google File System) records the node as dead, and sends out the node''s assigned work to other nodes. Individual operations use atomic operations for naming file outputs as a double check to ensure that there are not parallel conflicting threads running; when files are renamed, it is possible to also copy them to another name in addition to the name of the task (allowing for side-effects).\nThe reduce operations operate much the same way, but because of their inferior properties with regard to parallel operations, the master node attempts to schedule reduce operations on the same node, or in the same rack as the node holding the data being operated on; this property is desirable as it conserves bandwidth across the backbone network of the datacenter.\nImplementations may not be highly-available; in Hadoop, for example, the NameNode is a single point of failure for the distributed filesystem; if the JobTracker fails, all outstanding work is lost.\nUses\nMapReduce is useful in a wide range of applications, including: "distributed grep, distributed sort, web link-graph reversal, term-vector per host, web access log stats, inverted index construction, document clustering, machine learning, statistical machine translation..." Most significantly, when MapReduce was finished, it was used to completely regenerate Google''s index of the World Wide Web, and replaced the old ad hoc programs that updated the index and ran the various analyses. [4]\nMapReduce''s stable inputs and outputs are usually stored in a distributed file system. The transient data is usually stored on local disk and fetched remotely by the reduces.\nCriticism\nDavid DeWitt and Michael Stonebraker, pioneering experts in parallel databases and shared nothing architectures, have made some controversial assertions about the breadth of problems that MapReduce can be used for. They called its interface too low-level, and questioned whether it really represents the paradigm shift its proponents have claimed it is.[5] They challenge the MapReduce proponents'' claims of novelty, citing Teradata as an example of prior art that has existed for over two decades; they compared MapReduce programmers to Codasyl programmers, noting both are "writing in a low-level language performing low-level record manipulation".[5] MapReduce''s use of input files and lack of schema support prevents the performance improvements enabled by common database system features such as B-trees and hash partitioning, though projects such as PigLatin and Sawzall are starting to address these problems.[6]\nImplementations\nThe Google MapReduce framework is implemented in C++ with interfaces in Python and Java.\nGreenplum is a commercial MapReduce implementation, with support for Python, Perl, SQL and other languages.[7]\nGridGain is a free open source Java MapReduce implementation.\nThe Hadoop project is a free open source Java MapReduce implementation.\nPhoenix [1] is a shared-memory implementation of MapReduce implemented in C.\nMapReduce has also been implemented for the Cell Broadband Engine, also in C. [2]\nMapReduce has been implemented on NVIDIA GPUs (Graphics Processors) using CUDA [3].\nQt Concurrent is a simplified version of the framework, implemented in C++, used for distributing a task between multiple processor cores.\nCouchDB uses a MapReduce framework for defining views over distributed documents\nSkynet is an open source Ruby implementation of Google’s MapReduce framework\nDisco is an open source MapReduce implementation by Nokia. Its core is written in Erlang and jobs are normally written in Python.\nAster Data Systems nCluster In-Database MapReduce implements MapReduce inside the database.\nThe open-source Hive framework from Facebook (which provides a SQL-like language over files, layered on the open-source Hadoop MapReduce engine.)\nReferences\nSpecific references:\n^ Google spotlights data center inner workings | Tech news blog - CNET News.com\n^ "Our abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages." -"MapReduce: Simplified Data Processing on Large Clusters", by Jeffrey Dean and Sanjay Ghemawat; from Google Labs\n^ "Google''s MapReduce Programming Model -- Revisited" — paper by Ralf Lammel; from Microsoft\n^ "How Google Works".\nbaselinemag.com. "As of October, Google was running about 3,000 computing jobs per day through MapReduce, representing thousands of machine-days, according to a presentation by Dean. Among other things, these batch routines analyze the latest Web pages and update Google''s indexes."\n^ a b David DeWitt; Michael Stonebraker. "MapReduce: A major step backwards".\ndatabasecolumn.com. Retrieved on 2008-08-27.\n^ David DeWitt; Michael Stonebraker. "MapReduce II".\ndatabasecolumn.com. Retrieved on 2008-08-27.\n^ Parallel Programming in the Age of Big Data\nGeneral references:\nDean, Jeffrey & Ghemawat, Sanjay (2004). "MapReduce: Simplified Data Processing on Large Clusters". Retrieved Apr. 6, 2005.\n"High-performance analytics".\nThe external links in this article may not follow Wikipedia''s content policies or guidelines.\nPlease improve this article by removing excessive or inappropriate external links. (August 2008)\nPapers\n"MapReduce: Simplified Data Processing on Large Clusters" — paper by Jeffrey Dean and Sanjay Ghemawat; from Google Labs\n"Interpreting the Data: Parallel Analysis with Sawzall" — paper by Rob Pike, Sean Dorward, Robert Griesemer, Sean Quinlan; from Google Labs\n"Evaluating MapReduce for Multi-core and Multiprocessor Systems" — paper by Colby Ranger, Ramanan Raghuraman, Arun Penmetsa, Gary Bradski, and Christos Kozyrakis; from Stanford University\n"Why MapReduce Matters to SQL Data Warehousing" — analysis related to the August, 2008 introduction of MapReduce/SQL integration by Aster Data Systems and Greenplum\n"MapReduce for the Cell B.E. Architecture" — paper by Marc de Kruijf and Karthikeyan Sankaralingam; from University of Wisconsin-Madison\n"Mars: A MapReduce Framework on Graphics Processors" — paper by Bingsheng He, Wenbin Fang, Qiong Luo, Naga K. Govindaraju, Tuyong Wang; from Hong Kong University of Science and Technology; published in Proc. PACT 2008. It presents the design and implementation of MapReduce on graphics processors.\n"Map-Reduce-Merge: Simplified Relational Data Processing on Large Clusters" — paper by Hung-Chih Yang, Ali Dasdan, Ruey-Lung Hsiao, and D. Stott Parker; from Yahoo and UCLA; published in Proc. of ACM SIGMOD, pp. 1029--1040, 2007. (This paper shows how to extend MapReduce for relational data processing.)\nFLuX: the Fault-tolerant, Load Balancing eXchange operator from UC Berkeley provides an integration of partitioned parallelism with process pairs. This results in a more pipelined approach than Google''s MapReduce with instantaneous failover, but with additional implementation cost.\n"http://en.wikipedia.org/wiki/MapReduce"\nCategories: Google | Programming constructs | Parallel computingHidden category: Wikipedia external links cleanup','\n',char(10)));
INSERT INTO pages VALUES('LabVIEW','http://web.archive.org/web/20081207140237/http://en.wikipedia.org:80/wiki/LabVIEW','en','2008-12-07 00:00:00',replace('LabVIEW\nDeveloped by\nNational Instruments\nLatest release\n8.6 / 04 August 2008; 125 days ago\nOS\nCross-platform: Windows, Mac OS X, Linux\nType\nData Acquisition, Instrument Control, Test Automation, Analysis and Signal Processing, Industrial Control, Embedded Design\nLicense\nProprietary\nWebsite\nni.com/labview\nLabVIEW (short for Laboratory Virtual Instrumentation Engineering Workbench) is a platform and development environment for a visual programming language from National Instruments. The graphical language is named "G". Originally released for the Apple Macintosh in 1986, LabVIEW is commonly used for data acquisition, instrument control, and industrial automation on a variety of platforms including Microsoft Windows, various flavors of UNIX, Linux, and Mac OS. The latest version of LabVIEW is version 8.6, released in August of 2008.\n1 Dataflow programming\n2 Graphical programming\n3 Using LabVIEW with Excel\n4 Benefits\n5 Criticism\n6 Repositories and libraries\n7 Related software\n8 See also\n9 References\n10 Further reading\n10.1 Articles about specific applications of LabVIEW\n10.2 Articles about using LabVIEW in education\n11\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nDataflow programming\nThe programming language used in LabVIEW, also referred to as G, is a dataflow programming language. Execution is determined by the structure of a graphical block diagram (the LV-source code) on which the programmer connects different function-nodes by drawing wires. These wires propagate variables and any node can execute as soon as all its input data become available. Since this might be the case for multiple nodes simultaneously, G is inherently capable of parallel execution. Multi-processing and multi-threading hardware is automatically exploited by the built-in scheduler, which multiplexes multiple OS threads over the nodes ready for execution.\nGraphical programming\nLabVIEW ties the creation of user interfaces (called front panels) into the development cycle. LabVIEW programs/subroutines are called virtual instruments (VIs). Each VI has three components: a block diagram, a front panel, and a connector panel. The last is used to represent the VI in the block diagrams of other, calling VIs. Controls and indicators on the front panel allow an operator to input data into or extract data from a running virtual instrument. However, the front panel can also serve as a programmatic interface. Thus a virtual instrument can either be run as a program, with the front panel serving as a user interface, or, when dropped as a node onto the block diagram, the front panel defines the inputs and outputs for the given node through the connector pane. This implies each VI can be easily tested before being embedded as a subroutine into a larger program.\nThe graphical approach also allows non-programmers to build programs simply by dragging and dropping virtual representations of lab equipment with which they are already familiar. The LabVIEW programming environment, with the included examples and the documentation, makes it simple to create small applications. This is a benefit on one side, but there is also a certain danger of underestimating the expertise needed for good quality "G" programming. For complex algorithms or large-scale code, it is important that the programmer possesses an extensive knowledge of the special LabVIEW syntax and the topology of its memory management. The most advanced LabVIEW development systems offer the possibility of building stand-alone applications. Furthermore, it is possible to create distributed applications, which communicate by a client/server scheme, and are therefore easier to implement due to the inherently parallel nature of G-code.\nTo maintain clean and legible VI user interfaces keep these tips in mind: keep panels simple and clean, maintain a consistent style, clean up wires where ever possible, and use proper terminology when labeling controls and indicators.\nUsing LabVIEW with Excel\nComma delimited files can be saved from LabVIEW and read by Excel. They should be saved with the .csv file extension when operating in the Windows environment.\nA better solution is to use Excel to call the LabVIEW VI using VBA code and pass data back and forth between LabVIEW and Excel. Alternatively, you can make ActiveX calls to Excel from within a LabVIEW VI and perform those same operations. An example of how to do both of these can be found in LabVIEW’s help file.\nBenefits\nOne benefit of LabVIEW over other development environments is the extensive support for accessing instrumentation hardware. Drivers and abstraction layers for many different types of instruments and buses are included or are available for inclusion. These present themselves as graphical nodes. The abstraction layers offer standard software interfaces to communicate with hardware devices. The provided driver interfaces save program development time. The sales pitch of National Instruments is, therefore, that even people with limited coding experience can write programs and deploy test solutions in a reduced time frame when compared to more conventional or competing systems. A new hardware driver topology (DAQmxBase), which consists mainly of G-coded components with only a few register calls through NI Measurement Hardware DDK (Driver Development Kit) functions, provides platform independent hardware access to numerous data acquisition and instrumentation devices. The DAQmxBase driver is available for LabVIEW on Windows, Mac OS X and Linux platforms.\nIn terms of performance, LabVIEW includes a compiler that produces native code for the CPU platform. The graphical code is translated into executable machine code by interpreting the syntax and by compilation. The LabVIEW syntax is strictly enforced during the editing process and compiled into the executable machine code when requested to run or upon saving. In the latter case, the executable and the source code are merged into a single file. The executable runs with the help of the LabVIEW run-time engine, which contains some precompiled code to perform common tasks that are defined by the G language. The run-time engine reduces compile time and also provides a consistent interface to various operating systems, graphic systems, hardware components, etc. The run-time environment makes the code portable across platforms. Generally, LV code can be slower than equivalent compiled C code, although the differences often lie more with program optimization than inherent execution speed.\nMany libraries with a large number of functions for data acquisition, signal generation, mathematics, statistics, signal conditioning, analysis, etc., along with numerous graphical interface elements are provided in several LabVIEW package options. The number of advanced mathematic blocks for functions such as integration, filters, and other specialized capabilities usually associated with data capture from hardware sensors is immense. In addition, LabVIEW includes a text-based programming component called MathScript with additional functionality for signal processing, analysis and mathematics. MathScript can be integrated with graphical programming using "script nodes" and uses .m file script syntax that is generally compatible with Matlab.\nThe fully object-oriented character of LabVIEW code allows code reuse without modifications: as long as the data types of input and output are consistent, two sub VIs are interchangeable.\nThe LabVIEW Professional Development System allows creating stand-alone executables and the resultant executable can be distributed an unlimited number of times. The run-time engine and its libraries can be provided freely along with the executable.\nA benefit of the LabVIEW environment is the platform independent nature of the G code, which is (with the exception of a few platform-specific functions) portable between the different LabVIEW systems for different operating systems (Windows, Mac OS X and Linux). National Instruments is increasingly focusing on the capability of deploying LabVIEW code onto an increasing number of targets including devices like Phar Lap OS based LabVIEW real-time controllers, PocketPCs, PDAs, FieldPoint modules and into FPGAs on special boards.\nThere is a low cost LabVIEW Student Edition aimed at educational institutions for learning purposes. There is also an active community of LabVIEW users who communicate through several e-mail groups and Internet forums.\nCriticism\nLabVIEW is a proprietary product of National Instruments. Unlike common programming languages such as C or FORTRAN, LabVIEW is not managed or specified by a third party standards committee such as ANSI.\nIn addition, as of version 8, all LabVIEW installations require customers to contact National Instruments by Internet or phone to "activate" the product.[1] The increasing dependence on the vendor suggests a possible threat to privacy and data security. For example, although National Instruments claims the process is "secure and anonymous" the immediate implication is that a legal but privately installed instance of LabVIEW seems no longer possible.\nBuilding a stand-alone application with LabVIEW requires the Application Builder component which is included with the Professional Development System but requires a separate purchase if using the Base Package or Full Development System.[2] Compiled executables produced by the Application Builder are not truly standalone in that they also require that the LabVIEW run-time engine be installed on any target computer on which users run the application.[3] The use of standard controls requires a runtime library for any language and all major operating system suppliers supply the required libraries for common languages such as ''C''. However, the runtime required for LabVIEW is not supplied with any operating system and is required to be specifically installed by the administrator or user. This requirement can cause problems if an application is distributed to a user who may be prepared to run the application but does not have the inclination or permission to install additional files on the host system prior to running the executable.\nThere is some debate as to whether LabVIEW is really a general purpose programming language (or in some cases whether it is really a programming language at all) as opposed to an application-specific development environment for measurement and automation.[4] Critics point to a lack of features, common in most other programming languages, such as native recursion and, until version 8.20, object oriented features.\nFurthermore, the language is extremely slow to perform any development in at all. More time is spent searching for the correct control than producing results. As all logic must be drag and dropped, anything more complicated than adding two signals together takes much more time than it would in an equivalent language.\nRepositories and libraries\nOpenG, as well as LAVA Code Repository (LAVAcr), serve as repositories for a wide range of LabVIEW applications and libraries.\nVI Package Manager has become the standard package manager for LabVIEW libraries. It is very similar in purpose to Ruby''s RubyGems and Perl''s CPAN, although it provides a graphical user interface similar to the Synaptic Package Manager. VI Package Manager provides access to a repository of the OpenG (and other) libraries for LabVIEW.\nRelated software\nNational Instruments also offers a product called Measurement Studio, which offers many of the test, measurement and control capabilities of LabVIEW, as a set of classes for use with Microsoft Visual Studio. This allows developers to harness some of LabVIEW''s strengths within the text-based .NET framework. National Instruments also offers LabWindows/CVI as an alternative for ANSI C programmers.\nThe TRIL Centre Ireland offers the BioMobius platform as an alternate to LabView which is free for research purposes.\nSee also\nDataflow programming\nGraphical programming\nVirtual instrumentation\nComparison of numerical analysis software\nFourth-generation programming language\nReferences\n^ "Product Activation FAQ", National Instruments.\n^ "Building a Stand-Alone Application", National Instruments.\n^ "Using the LabVIEW Run-Time Engine", National Instruments.\n^ Is LabVIEW a general purpose programming language?\nFurther reading\nPeter A. Blume: The LabVIEW Style Book, February 27 2007, Prentice Hall. Part of the National Instruments Virtual Instrumentation Series series. ISBN 0-13-145835-3\nJeffrey Travis, Jim Kring: LabVIEW for Everyone: Graphical Programming Made Easy and Fun, 3rd Edition, July 27 2006, Prentice Hall. Part of the National Instruments Virtual Instrumentation Series series. ISBN 0-13-185672-3\nArticles about specific applications of LabVIEW\nDesnica V, Schreiner M (October 2006). "A LabVIEW-controlled portable x-ray fluorescence spectrometer for the analysis of art objects". X-Ray Spectrometry 35 (5): 280–286. doi:10.1002/xrs.906, http://www3.interscience.wiley.com/cgi-bin/abstract/112748693/ABSTRACT.\nKeleshis C, Ionita C, Rudin S (June 2006). "Labview graphical user interface for micro angio-fluoroscopic high resolution detector". Medical Physics 33 (6): 2007. doi:10.1118/1.2240285, http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=MPHYA6000033000006002007000001&idtype=cvips&gifs=Yes.\nFedak W, Bord D, Smith C, Gawrych D, Lindeman K (May 2003). "Automation of the Franck-Hertz experiment and the Tel-X-Ometer x-ray machine using LABVIEW". American Journal of Physics (AAPT) 71 (5): 501–506. doi:10.1119/1.1527949, http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=AJPIAS000071000005000501000001&idtype=cvips&gifs=Yes.\nArticles about using LabVIEW in education\nBelletti A, Borromei R, Ingletto G (September 2006). "Teaching physical chemistry experiments with a computer simulation by LabVIEW". Journal of Chemical Education (ACS) 83 (9): 1353–1355, http://jchemed.chem.wisc.edu/Journal/Issues/2006/Sep/abs1353.html.\nMoriarty PJ, Gallagher BL, Mellor CJ, Baines RR (October 2003). "Graphical computing in the undergraduate laboratory: Teaching and interfacing with LabVIEW". American Journal of Physics (AAPT) 71 (10): 1062–1074. doi:10.1119/1.1582189, http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal&id=AJPIAS000071000010001062000001&idtype=cvips&gifs=Yes.\nLauterburg, Urs (June 2001). "LabVIEW in Physics Education" (PDF). A white paper about using LabVIEW in physics demonstration and laboratory experiments and simulations., http://www.clab.unibe.ch/labview/whitepaper/LV-PhysicsWPScreen.pdf.\nDrew SM (December 1996). "Integration of national instruments'' LabVIEW software into the chemistry curriculum". Journal of Chemical Education (ACS) 73 (12): 1107–1111, http://jchemed.chem.wisc.edu/Journal/Issues/1996/Dec/abs1107.html.\nMuyskens MA, Glass SV, Wietsma TW, Gray TM (December 1996). "Data acquisition in the chemistry laboratory using LabVIEW software". Journal of Chemical Education (ACS) 73 (12): 1112–1114, http://jchemed.chem.wisc.edu/Journal/Issues/1996/Dec/abs1112.html.\nOgren PJ, Jones TP (December 1996). "Laboratory interfacing using the LabVIEW software package". Journal of Chemical Education (ACS) 73 (12): 1115–1116, http://jchemed.chem.wisc.edu/Journal/Issues/1996/Dec/abs1115.html.\nTrevelyan, J.P. (June 2004). "10 Years Experience with Remote Laboratories" (PDF). International Conference on Engineering Education Research (ACS), http://telerobot.mech.uwa.edu.au/Information/Trevelyan-INEER-2004.pdf.\nOfficial Home Page - The National Instruments web site for the LabVIEW product line.\nLabVIEW Help - NI''s entire set of online help documentation for LabVIEW 8.20.\nOfficial LabVIEW Community Home Page - NI''s "LabVIEW Zone" web site.\nLAVA (LabVIEW Advanced Virtual Architects) - Independent community, with discussion forums and a code repository.\nInfo-LabVIEW - A LabVIEW electronic mailing list\nOpenG - Open-source LabVIEW utilities.\nThe LabVIEW Wiki - A user editable LabVIEW knowledge base powered by MediaWiki.\nFree, online LabVIEW programming course - This course was authored by NI, and is hosted by Connexions.\nv • d • e\nNumerical software\nOpen source\nFreeMat · GNU Octave · R · Scilab\nRetail\nGAUSS · LabVIEW · MATLAB · Mathematica\nList\n• Comparison\n"http://en.wikipedia.org/wiki/LabVIEW"\nCategories: Data analysis software | Domain-specific programming languages | Numerical software | Visual programming languages | Numerical programming languages | Linux numerical analysis software | Cross-platform software','\n',char(10)));
INSERT INTO pages VALUES('TeX','http://web.archive.org/web/20081225050826/http://en.wikipedia.org:80/wiki/TeX','en','2008-12-25 00:00:00',replace('For help displaying mathematical formulae in Wikipedia, see Wikipedia:Editing Math.\nTeX\nDeveloped by\nDonald Knuth\nLatest release\n3.1415926 / March 2008\nOS\nCross-platform\nType\nTypesetting\nLicense\nPermissive\nWebsite\nhttp://www.tug.org/\nTeX (pronounced /ˈtɛx/, as in Greek, often /ˈtɛk/ in English; written with a lowercase ''e'' in imitation of the logo) is a typesetting system designed and mostly written by Donald Knuth.[1] Together with the METAFONT language for font description and the Computer Modern typefaces, it was designed with two main goals in mind: to allow anybody to produce high-quality books using a reasonable amount of effort, and to provide a system that would give the exact same results on all computers, now and in the future. Within the typesetting system, its name is formatted as TeX.\nTeX is considered by many to be the best way to typeset complex mathematical formulae.[2] TeX is popular in academia, especially in the mathematics and physics communities. It has largely displaced Unix troff, the other favored formatter, in many Unix installations, which use both for different purposes. It is now also being used for many other typesetting tasks, especially in the form of LaTeX and other template packages.\nThe widely-used MIME Type for TeX is application/x-tex. TeX is free software.\n1 History\n2 The typesetting system\n2.1 How TeX is run\n2.2 Mathematical example\n3 Novel aspects\n3.1 Mathematical spacing\n3.2 Hyphenation and justification\n3.3 METAFONT\n3.4 Macro language\n4 Development\n4.1 Packages\n4.2 Editors\n4.3 License\n5 Use of TeX\n6 Pronouncing and writing "TeX"\n7 Community\n8 See also\n9 References\n10 Notes\n11\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nWhen the first volume of Knuth''s The Art of Computer Programming was published in 1969, it was typeset using hot metal type set by a Monotype Corporation typecaster a hot metal typesetting machine from the 19th century which produced a "good classic style" appreciated by Knuth. When the second edition of the second volume was published, in 1976, the whole book had to be typeset again because the Monotype technology had been largely replaced by photographic techniques, and the original fonts were no longer available.[3] However, when Knuth received the galley proofs of the new book on 30 March 1977, he found them awful.[4] Around that time, Knuth saw for the first time the output of a high-quality digital typesetting system, and became interested in digital typography. The disappointing galley proofs gave him the final motivation to solve the problem at hand once and for all by designing his own typesetting system. On May 13, 1977, he wrote a memo to himself describing the basic features of TeX.[5]\nHe planned to finish it on his sabbatical in 1978, but as it happened the language was frozen only in 1989, more than ten years later. Guy Steele happened to be at Stanford during the summer of 1978, when Knuth was developing his first version of TeX. When Steele returned to MIT that fall, he rewrote TeX''s I/O to run under the ITS operating system. The first version of TeX was written in the SAIL programming language to run on a PDP-10 under Stanford''s WAITS operating system. For later versions of TeX, Knuth invented the concept of literate programming, a way of producing compilable source code and high quality cross-linked documentation (typeset in TeX, of course) from the same original file. The language used is called WEB and produces programs in DEC PDP-10 Pascal.\nA new version of TeX, rewritten from scratch and called TeX82, was published in 1982. Among other changes, the original hyphenation algorithm was replaced by a new algorithm written by Frank Liang. TeX82 also uses fixed-point arithmetic instead of floating-point, to ensure reproducibility of the results across different computer hardware,[6] and includes a real, Turing-complete programming language, following intense lobbying by Guy Steele.[7]\nIn 1989, Donald Knuth released new versions of TeX and METAFONT.[8] Despite his desire to keep the program stable, Knuth realised that 128 different characters for the text input were not enough to accommodate foreign languages; the main change in version 3.0 of TeX is thus the ability to work with 8-bits inputs, allowing 256 different characters in the text input.\nSince version 3, TeX has used an idiosyncratic version numbering system, where updates have been indicated by adding an extra digit at the end of the decimal, so that the version number asymptotically approaches π. This is a reflection of the fact that TeX is now very stable, and only minor updates are anticipated. The current version of TeX is 3.1415926; it was last updated in March 2008. The design was frozen after version 3.0, and no new feature or fundamental change will be added, so all newer versions will contain only bug fixes. Even though Donald Knuth himself has suggested a few areas in which TeX could have been improved, he indicated that he firmly believes that having an unchanged system that will produce the same output now and in the future is more important than introducing new features. For this reason, he has stated that the "absolutely final change (to be made after my death)" will be to change the version number to π, at which point all remaining bugs will become features.[9] Likewise, versions of METAFONT after 2.0 asymptotically approach e, and a similar change will be applied after Knuth''s death.\nHowever, since the source code of TeX is essentially in the public domain (see below), other programmers are allowed (and explicitly encouraged) to improve the system, but are required to use another name to distribute the modified TeX, meaning that the source code can still evolve. For example, the Omega project was developed after 1991, primarily to enhance TeX''s multilingual typesetting abilities. Donald Knuth himself created “unofficial” modified versions, such as TeX-XeT, which allows a user to mix texts written in left-to-right and right-to-left writing systems in the same document.[10]\nThe typesetting system\nTeX commands commonly start with a backslash and are grouped with curly braces. However, almost all of TeX''s syntactic properties can be changed on the fly which makes TeX input hard to parse by anything but TeX itself. TeX is a macro- and token-based language: many commands, including most user-defined ones, are expanded on the fly until only unexpandable tokens remain which get executed. Expansion itself is practically side-effect free. Tail recursion of macros takes no memory, and if-then-else constructs are available. This makes TeX a Turing-complete language even at expansion level.\nThe system can be divided into four levels: in the first, characters are read from the input file and assigned a category code (sometimes called “catcode”, for short). Combinations of a backslash (really: any character of category zero) followed by letters (characters of category 11) or a single other character are replaced by a control sequence token. In this sense this stage is like lexical analysis, although it does not form numbers from digits. In the next stage, expandable control sequences (such as conditionals or defined macros) are replaced by their replacement text. The input for the third stage is then a stream of characters (including ones with special meaning) and unexpandable control sequences (typically assignments and visual commands). Here characters get assembled into a paragraph. TeX''s paragraph breaking algorithm works by optimizing breakpoints over the whole paragraph. The fourth stage breaks the vertical list of lines and other material into pages.\nThe TeX system has precise knowledge of the sizes of all characters and symbols, and using this information, it computes the optimal arrangement of letters per line and lines per page. It then produces a DVI file (“DeVice Independent”) containing the final locations of all characters. This dvi file can be printed directly given an appropriate printer driver, or it can be converted to other formats. Nowadays, PDFTeX is often used which bypasses DVI generation altogether.\nThe base TeX system understands about 300 commands, called primitives.[11] However, these low-level commands are rarely used directly by users, and most functionality is provided by format files (predumped memory images of TeX after large macro collections have been loaded). Knuth''s original default format, which adds about 600 commands, is Plain TeX (available from CTAN). The most widely used format is LaTeX, originally developed by Leslie Lamport, which incorporates document styles for books, letters, slides, etc, and adds support for referencing and automatic numbering of sections and equations. Another widely used format, AMS-TeX, is produced by the American Mathematical Society, and provides many more user-friendly commands, which can be altered by journals to fit with their house style. Most of the features of AMS-TeX can be used in LaTeX by using the AMS “packages”. This is then referred to as AMS-LaTeX. Other formats include ConTeXt, used primarily for desktop publishing and written mostly by Hans Hagen at Pragma.\nHow TeX is run\nA sample page produced using TeX with the LaTeX macros.\nA sample Hello world program in plain TeX is:\nHello, World\n\end\n% marks the end of the file; not shown in the final output\nThis might be in a file myfile.tex, as .tex is a common file extension for plain TeX files.\nBy default, everything that follows a percent sign on a line is a comment, ignored by TeX. Running TeX on this file (for example, by typing tex myfile.tex in a command line interpreter, or by calling it from a graphical user interface) will create an output file called myfile.dvi, representing the content of the page in a device independent format (DVI). The results can either be printed directly from a DVI viewer or converted to a more common format such as PostScript using the dvips program. This was because TeX natively uses bitmap fonts, which are only designed to display well at one particular size, whereas PostScript typically uses scalable Type 1 fonts. It is now possible to make dvips output scalable fonts with a bit of tweaking (newer versions of Ghostscript support it). TeX variants such as PDFTeX produce PDF files directly.\nMathematical example\nTeX provides a text syntax for mathematical formulae. For example, the well-known quadratic formula would appear as:\nThe quadratic formula is $-b \pm \sqrt{b^2 - 4ac} \over 2a$\n\end\nand the output would resemble:\nThe quadratic formula is\nThe formula is printed in a way a person would write by hand, or typeset the equation. In a document, entering mathematics mode is done by starting with a $, then entering a formula in TeX semantics and closing again with another $. Knuth explained in a jest that he chose the dollar sign to indicate the beginning and end of mathematical mode in plain TeX because typesetting mathematics was traditionally supposed to be expensive.[12] Display mathematics (mathematics presented centered on a new line) is similar but uses $$ instead of $. For example, the above with the quadratic formula in display math:\nThe quadratic formula is $$-b \pm \sqrt{b^2 - 4ac} \over 2a$$\n\end\nrenders as\nThe quadratic formula is\nNovel aspects\nThe TeX software incorporates several aspects that were not available, or were of lower quality, in other typesetting programs at the time when TeX was released. Some of the innovations are based on interesting algorithms, and have led to a number of theses for Knuth''s students. While some of these discoveries have now been incorporated into other typesetting programs, others, such as the rules for mathematical spacing, are still unique.\nMathematical spacing\nMathematical text typeset using TeX and the AMS Euler font.\nSince the primary goal of TeX was the high-quality typesetting of his book The Art of Computer Programming, Knuth gave a lot of attention to the choice of proper spacing rules for mathematical formulae. He took three bodies of work that he considered as standards of excellence for mathematical typography: the books typeset by Addison-Wesley, the publisher of The Art of Computer Programming, in particular the work done by Hans Wolf; editions of the mathematical journal Acta Mathematica dating from around 1910; and a copy of Indagationes Mathematicae, a Dutch mathematics journal. Knuth looked closely at these examples to derive a set of spacing rules for TeX.[13] While TeX provides some basic rules and the tools needed to specify proper spacing, the exact parameters depend on the font used to typeset the formula. For example, the spacing for Knuth''s Computer Modern fonts has been precisely fine-tuned over the years and is now frozen, but when other fonts, such as AMS Euler, were used by Knuth for the first time, new spacing parameters had to be defined.[14]\nHyphenation and justification\nThis section may need to be rewritten entirely to comply with Wikipedia''s quality standards. You can help. The discussion page may contain suggestions.\nIn comparison with manual typesetting, the problem of justification is easy to solve with a digital system such as TeX, which, provided that good points for line breaking have been defined, can automatically spread the spaces between words to fill in the line. The problem is thus to find the set of breakpoints that will give the most pleasing result. Many line breaking algorithms use a first-fit approach, where the breakpoints for each line are determined one after the other, and no breakpoint is changed after it has been chosen.[15] Such a system is not able to define a breakpoint depending on the effect that it will have on the following lines. In comparison, the total-fit line breaking algorithm used by TeX and developed by Donald Knuth and Michael Plass considers all the possible breakpoints in a paragraph, and finds the combination of line breaks that will produce the most globally pleasing arrangement.\nFormally, the algorithm defines a value called badness associated with each possible line break; the badness is increased if the spaces on the line must stretch or shrink too much to make the line the correct width. Penalties are added if a breakpoint is particularly undesirable: for example, if a word must be hyphenated, if two lines in a row are hyphenated, or if a very loose line is immediately followed by a very tight line. The algorithm will then find the breakpoints that will minimize the sum of squares of the badness (including penalties) of the resulting lines. If the paragraph contains n possible breakpoints, the number of situations that must be evaluated naively is 2n. However, by using the method of dynamic programming, the complexity of the algorithm can be brought down to O(n2) (see Big O notation). Further simplifications (for example, not testing extremely unlikely breakpoints such as a hyphenation in the first word of a paragraph) lead to an efficient algorithm whose running time is almost always of order n. However, in general, a thesis by Michael Plass shows how the page breaking problem can be NP-complete because of the added complication of placing figures.[16] A similar algorithm is used to determine the best way to break paragraphs across two pages, in order to avoid widows or orphans (lines that appear alone on a page while the rest of the paragraph is on the following or preceding page).\nTeX''s line breaking algorithm has been adopted by several other programs, such as Adobe InDesign, a desktop publishing application,[17] and the GNU fmt Unix command line utility.[18]\nIf no suitable line break can be found for a line, the system will try to hyphenate a word. The original version of TeX used a hyphenation algorithm based on a set of rules for the removal of prefixes and suffixes of words, and for deciding if it should insert a break between the two consonants in a pattern of the form vowel–consonant–consonant–vowel (which is possible most of the time).[19] TeX82 introduced a new hyphenation algorithm, designed by Frank Liang in 1983, to assign priorities to breakpoints in letter groups. A list of hyphenation patterns is first generated automatically from a corpus of hyphenated words (a list of 50,000 words). If TeX must find the acceptable hyphenation positions in the word encyclopedia, for example, it will consider all the subwords of the extended word .encyclopedia., where . is a special marker to indicate the beginning or end of the word. The list of subwords include all the subwords of length 1 (., e, n, c, y, etc), of length 2 (.e, en, nc, etc), etc, up to the subword of length 14, which is the word itself, including the markers. TeX will then look into its list of hyphenation patterns, and find subwords for which it has calculated the desirability of hyphenation at each position. In the case of our word, 11 such patterns can be matched, namely 1c4l4, 1cy, 1d4i3a, 4edi, e3dia, 2i1a, ope5d, 2p2ed, 3pedi, pedia4, y1c. For each position in the word, TeX will calculate the maximum value obtained among all matching pattern, yielding en1cy1c4l4o3p4e5d4i3a4. Finally, the acceptable positions are those indicated by an odd number, yielding the acceptable hyphenations en-cy-clo-pe-di-a. This system based on subwords allows the definition of very general patterns (such as 2i1a), with low indicative numbers (either odd or even), which can then be superseded by more specific patterns (such as 1d4i3a) if necessary. These patterns find about 90% of the hyphens in the original dictionary; more importantly, they do not insert any spurious hyphen. In addition, a list of exceptions (words for which the patterns do not predict the correct hyphenation) are included with the Plain TeX format; additional ones can be specified by the user.[20][21]\nMETAFONT\nMain article: METAFONT\nMETAFONT, not strictly part of TeX, is a font description system which allows the designer to describe characters algorithmically. It uses Bezier curves in a fairly standard way to generate the actual characters to be displayed, but Knuth devotes lots of attention to the rasterizing problem on bitmapped displays. Another thesis, by John Hobby, further explores this problem of digitizing “brush trajectories”. This term derives from the fact that METAFONT describes characters as having been drawn by abstract brushes (and erasers).\nIt is possible to use TeX and LaTeX without METAFONT. Adobe PostScript (“Type 1”) fonts may be used instead. (La)TeX expects fonts to be supplied as bitmaps at specific point sizes, while PostScript is a vector (outline) description scalable over a wide range, so this does introduce some minor complications. Nonetheless, with the help of some prewritten packages, (La)TeX can be made to use PostScript fonts. Further note that “Type 1” or “T1” can refer in documentation to two very different things: the TeX T1 character encoding scheme to map byte values to glyphs, and Adobe PostScript fonts.\nMacro language\nTeX provides an unusual macro language; the definition of a macro not only includes a list of commands but also the syntax of the call. Macros are completely integrated with a full-scale interpreted compile-time language that also guides processing.\nTeX''s macro level of operation is lexical, but it is a built-in facility of TeX, that makes use of syntax interpretation. Comparing with most widely used lexical preprocessors like M4, it differs slightly, as the body of a macro gets tokenized at definition time, that is, it is not completely raw text. Except for a few very special cases, this gives the same behaviour.\nThe TeX macro language has been successfully used to extend TeX to, for instance, LaTeX and ConTeXt.\nDevelopment\nThe original source code for the current TeX software is written in WEB, a mixture of documentation written in TeX and a Pascal subset in order to ensure portability. For example, TeX does all of its dynamic allocation itself from fixed-size arrays and uses only fixed-point arithmetic for its internal calculations. As a result, TeX has been ported to almost all operating systems, usually by using the web2c program to convert the source code into C instead of directly compiling the Pascal code.\nKnuth has kept a very detailed log of all the bugs he has corrected and changes he has made in the program since 1982; as of 2008[update], the list contains 427 entries, not including the version modification that should be done after his death as the final change in TeX.[22][23] Donald Knuth offers monetary awards to people who find and report a bug in TeX. The award per bug started at $2.56 (one "hexadecimal dollar"[24]) and doubled every year until it was frozen at its current value of $327.68. Knuth, however, has lost relatively little money as there have been very few bugs claimed. In addition, people have been known to frame a check proving they found a bug in TeX instead of cashing it.[25][26]\nPackages\nTeX is usually provided in the form of an easy-to-install bundle of TeX itself along with METAFONT and all the necessary fonts, documents formats, and utilities needed to use the typesetting system. On UNIX-compatible systems, including Linux and Mac OS X, TeX is distributed in the form of the teTeX distribution and more recently the TeX Live distribution. On Microsoft Windows, there is the MiKTeX distribution (enhanced by ProTeX ) and the fpTeX distribution.\nSeveral document processing systems are based on TeX, notably jadeTeX, which uses TeX as a backend for printing from James Clark''s DSSSL Engine, the Arbortext publishing system, and Texinfo, the GNU documentation processing system. TeX has been the official typesetting package for the GNU operating system since 1984.\nXeTeX is a new TeX engine that supports Unicode. Originally making use of advanced Mac OS X-specific font technologies, it now supports OpenType and is available on Linux and Microsoft Windows.\nNumerous extensions and companion programs for TeX exist, among them BibTeX for bibliographies (distributed with LaTeX), pdfTeX, which bypasses dvi and produces output in Adobe Systems'' Portable Document Format, and Omega, which allows TeX to use the Unicode character set. Most TeX extensions are available for free from CTAN, the Comprehensive TeX Archive Network.\nEditors\nThe TeXmacs text editor is a WYSIWYG scientific text editor that is intended to be compatible with TeX and Emacs. It uses Knuth''s fonts, and can generate TeX output.\nLyX is a “What You See is What You Mean” document processor which runs on a variety of platforms including Linux, Windows (newer versions require Windows 2000 or later) or Mac OS X (using a non-native Qt front-end).\nTeXShop for Mac OS X, and WinShell for Windows are similar tools and provide integrated development environment (IDE) for working with LaTeX or TeX. For KDE, Kile provides such an IDE.\nGNU Emacs has various built-in and third party packages with support for TeX, the major one being AUCTeX. For Vim there is the Vim-LaTeX Suite.\nLicense\nDonald Knuth has indicated several times[27][28] that the source code of TeX has been placed into the "public domain," and he strongly encourages modifications or experimentations with this source code. However, since the code is still copyrighted, it is technically free/open-source software but is not in the public domain in the legal sense. In particular, since Knuth highly values the reproducibility of the output of all versions of TeX, any changed version must not be called TeX, TeX, or anything confusingly similar. To enforce this rule, any implementation of the system must pass a test suite called the TRIP test[29] before being allowed to be called TeX. The question of license is somewhat confused by the statements included at the beginning of the TeX source code,[30] which indicate that “all rights are reserved. Copying of this file is authorized only if (...) you make absolutely no changes to your copy”. However, this restriction should be interpreted as a prohibition to change the source code as long as the file is called tex.web. This interpretation is confirmed later in the source code when the TRIP test is mentioned (“If this program is changed, the resulting system should not be called ‘TeX’”).\nThe American Mathematical Society has also claimed a trademark for TeX, which was rejected, because at the time this was tried (early 1980s), “TEX” (all caps) was registered by Honeywell for the “Text EXecutive” text processing system.[31]\nUse of TeX\nIn several technical fields, in particular computer science, mathematics and physics, TeX has become a de facto standard. Many thousands of books have been published using TeX, including books published by Addison-Wesley, Cambridge University Press, Elsevier, Oxford University Press and Springer. Numerous journals in these fields are produced using TeX or LaTeX, allowing authors to submit their raw manuscript written in TeX.[32]\nWhile many publications in other fields, including dictionaries and legal publications, have been produced using TeX, it has not been as successful as in more technical fields, in particular because TeX was primarily designed for mathematics. When he designed TeX, Donald Knuth did not believe that a single typesetting system would fit everyone''s needs; instead, he designed many hooks inside the program so that it would be possible to write extensions, and released the source code, hoping that publishers would design versions tailored to their needs. While such extensions have been created (including some by Knuth himself[10]), most people have extended TeX only using macros and it has remained a system associated with technical typesetting.[33][34]\nPronouncing and writing "TeX"\nThe name TeX is intended to be pronounced /ˈtɛx/. The X is meant to represent the Greek letter χ (chi). TeX is the abbreviation of τέχνη (ΤΕΧΝΗ – technē), Greek for both "art" and "craft", which is also the root word of technical. English speakers often pronounce it /ˈtɛk/, like the first syllable of technical.\nThe name is properly typeset with the "E" below the baseline and reduced spacing between the letters. This is done, as Donald Knuth mentions in his TeXBook, to distinguish ΤeΧ from other system names such as TEX, the Text EXecutive processor (developed by Honeywell Information Systems).[35] Fans like to proliferate names from the word “TeX” — such as TeXnician (user of TeX software), TeXpert, TeXhacker (TeX programmer), TeXmaster (competent TeX programmer), TeXhax, and TeXnique.\nCommunity\nNotable entities in the TeX community include the TeX Users Group, which publishes TUGboat and The PracTeX Journal, and Deutschsprachige Anwendervereinigung TeX, a large user group in Germany. The TeX Users Group was founded in 1980 for educational and scientific purposes, provides an organization for those who have an interest in typography and font design, and are users of the TeX typesetting system invented by Donald Knuth. TUG is run by and for its members and represents the interests of TeX users worldwide. TUG publishes the journal TUGboat three times per year, covering a wide range of topics in digital typography relevant to TeX.\nSee also\nFree software portal\nList of document markup languages\nComparison of document markup languages\nMathML\nFormula editor\nTexvc\nPSTricks\nReferences\nThis article was originally based on material from the Free On-line Dictionary of Computing, which is licensed under the GFDL.\nDonald E. Knuth. The TeXbook (Computers and Typesetting, Volume A). Reading, Massachusetts: Addison-Wesley, 1984. ISBN 0-201-13448-9. The source code of the book in TeX (and a needed set of macros [4]) is available online on CTAN. It is provided only as an example and its use to prepare a book like The TeXbook is not allowed.\nDonald E. Knuth. TeX: The Program (Computers and Typesetting, Volume B). Reading, Massachusetts: Addison-Wesley, 1986. ISBN 0-201-13437-3. The full source code of TeX; also available on CTAN at [5]. Being written using literate programming, it contains plenty of human-readable documentation.\nDonald E. Knuth. Digital Typography (CSLI lecture notes, no 78). Center for the Study of Language and Information, 1999. ISBN 1-57586-010-4.\nDonald E. Knuth and Michael F. Plass. Breaking Paragraphs Into Lines, Software — Practice and Experience 11 (1981), 1119–1184. Reprinted as chapter 3 of Digital Typography, p. 67–155.\nLeslie Lamport. LaTeX: A Document Preparation System. Addison-Wesley, Reading, Massachusetts: Addison-Wesley, 2nd. ed., 1994. ISBN 0-201-52983-1.\nFranklin Mark Liang. Word Hy-phen-a-tion by Com-put-er, PhD thesis, Department of Computer Science, Stanford University, August 1983.\nM.D. Spivak. The Joy of TeX (2nd edition). American Mathematical Society, 1990. ISBN 0-8218-2997-1. Reference on AMS-TeX.\nNelson H.F. Beebe. 25 Years of TeX and METAFONT: Looking Back and Looking Forward, TUGboat 25 (2004), 7–30.\nMichael Vulis, Modern TeX and Its Applications, CRC Press, 1992. ISBN 0-8493-4431-X\nDavid Salomon, The Advanced TeXbook, Springer, 1995, ISBN 0387945563\nNotes\n^ "Per Bothner (assistant of Knuth) discusses authorship". "Knuth definitely wrote most of the code himself, at least for the Metafont re-write, for which I have personal knowledge. However, some of his students (such as Michael Plass and John Hob by) did work on the algorithms used in TeX and Metafont."\n^ Beccari, Claudio (1997). "Typesetting mathematics for science and technology according to ISO31XI". TUGboat.\n^ Donald E. Knuth. Digital Typography. Commemorative lecture for the Kyoto Prize, Kyoto, 1996. Reprinted as chapter 1 of the book Digital Typography.\n^ Digital Typography, p. 5. “I had spent 15 years writing those books, but if they were going to look awful I didn''t want to write any more.”\n^ Donald E. Knuth. TEXDR.AFT, chapter 24 of the book Digital Typography.\n^ Knuth and Plass, p. 144\n^ Donald E. Knuth, Knuth meets NTG members, NTG: MAPS. 16 (1996), 38–49. Reprinted as Questions and Answers, III, chapter 33 of Digital Typography, p. 648.\n^ Donald E. Knuth. The New Versions of TeX and METAFONT, TUGboat 10 (1989), 325–328; 11 (1990), 12. Reprinted as chapter 29 of Digital Typography.\n^ Donald E. Knuth. The future of TeX and METAFONT, NTG journal MAPS (1990), 489. Reprinted as chapter 30 of Digital Typography, p. 571.\n^ a b Donald E. Knuth and Pierre MacKay. Mixing Right-to-Left Texts with Left-to-Right Texts, TUGboat 8 (1987), 14–25. Reprinted as chapter 4 of Digital Typography.\n^ The TeXbook, p. 9.\n^ Donald E. Knuth, The TeXbook, Ch. 16: Typing Math Formulas, p. 127.\n^ Donald E. Knuth. Questions and Answers II, TUGboat 17 (1996), 355–367. Reprinted as chapter 32 of Digital Typography, p. 620.\n^ Donald E. Knuth. Typesetting Concrete Mathematics, TUGboat 10 (1989), 31–36, 342. Reprinted as chapter 18 of Digital Typography.\n^ Michael P. Barnett. Computer Typesetting: Experiments and Prospects. Cambridge, Massachusetts: MIT Press, 1965.\n^ Knuth and Plass\n^ Advogato. Interview of Donald E. Knuth (PDF file, also available in HTML at [1]), TUGboat 21 (2000), 103–110.\n^ GNU Project, GNU text utilities manual, 4.1 fmt: Reformat paragraph text. 2000.\n^ Liang, p. 3\n^ Liang, PhD thesis\n^ The TeXbook, Appendix H: Hyphenation, pp. 449–455.\n^ Donald E. Knuth, List of updates to the TeX82 listing published in September 1982, available on CTAN.\n^ Donald E. Knuth, Appendix to the Errors of TeX paper, available on CTAN, last modified in January 2003.\n^ Frequently Asked Questions on Don Knuth''s webpage\n^ Kara Platoni, Love at First Byte. Stanford Magazine, May-June 2006\n^ The History of TeX\n^ The future of TeX and METAFONT, p. 572 of the book Digital Typography.\n^ Donald E. Knuth. Computers and Typesettings (available online split into 2 files: [2] [3]), TUGboat 7 (1986), 95–98. Reprinted as chapter 28 of Digital Typography, p. 560.\n^ available on CTAN\n^ Donald E. Knuth, TeX: The Program.\n^ The TeXbook, p. 1.\n^ Beebe, p.10\n^ Donald E. Knuth. Questions and Answers I, TUGboat 17 (1996), 7–22. Reprinted as chapter 31 of Digital Typography, p. 598.\n^ Donald E. Knuth. Questions and Answers II, TUGboat 17 (1996), 355–367. Reprinted as chapter 32 of Digital Typography, p. 616–617.\n^ Donald E. Knuth. The TeX Logo in Various Fonts, TUGboat 7 (1986), 101. Reprinted as chapter 6 of Digital Typography.\nFind more about TeX on Wikipedia''s sister projects:\nDictionary definitions\nTextbooks\nQuotations\nSource texts\nImages and media\nNews stories\nLearning resources\nPlain TeX Quick Reference (PDF)\nUK TeX Users'' Group FAQ\nSimon Eveson. An Introduction to Mathematical Document Production Using AmSLaTeX.\nThe TeX showcase gallery of typesetting examples\nEijkhout, Victor. TeX by Topic\nTeX for the Impatient (PDF)\nWalsh, Norman. Making TeX Work\nTeX Reference Manual via Google Book Search\nv • d • e\nTeX editors\nOpen source\nAUCTEX · Kile · LyX · MeWa · TeXShop · TeXnicCenter · Texmaker · Winefish\nFreeware\nLaTeX-Editor · proTeXt · WinShell\nRetail\nScientific WorkPlace · WinEdt\n"http://en.wikipedia.org/wiki/TeX"\nCategories: TeX editors | Desktop publishing software | Digital typography | Free TeX software | Macro programming languages | Typesetting | TeX | Donald KnuthHidden categories: Wikipedia articles needing rewrite | Articles containing potentially dated statements from 2008 | All articles containing potentially dated statements','\n',char(10)));
INSERT INTO pages VALUES('Tcl','http://web.archive.org/web/20090102220513/http://en.wikipedia.org:80/wiki/Tcl','en','2009-01-02 00:00:00',replace('For other uses, see Tcl (disambiguation).\012This article includes a list of references or external links, but its sources remain unclear because it lacks inline citations. Please improve this article by introducing more precise citations where appropriate. (February 2008)\012This article is written like an advertisement. Please help rewrite this article from a neutral point of view. For blatant advertising that would require a fundamental rewrite to become encyclopedic, use {{db-spam}} to mark for speedy deletion. (September 2008)\012Tcl\012Paradigm\012multi-paradigm: object-oriented, functional, procedural, event-driven programming\012Appeared in\0121988\012Designed by\012John Ousterhout\012Developer\012John Ousterhout\012Latest release\0128.5.5/ 15 October 2008; 79 days ago\012Typing discipline\012dynamic typing, everything can be treated as a string\012Major implementations\012ActiveTcl\012Influenced\012PowerShell[1]\012Website\012http://www.tcl.tk\012Tcl (originally from "Tool Command Language", but nonetheless conventionally rendered as "Tcl" rather than "TCL"; pronounced as "tickle" or "tee-cee-ell"[2]) is a scripting language created by John Ousterhout. Originally "born out of frustration"[3]—according to the author—with programmers devising their own (poor quality) languages intended to be embedded into applications, Tcl quickly gained wide acceptance on its own and is generally thought to be easy to learn[4], but powerful in competent hands. It is most commonly used for rapid prototyping, scripted applications, GUIs and testing. Tcl is used extensively on embedded systems platforms, both in its full form and in several other small-footprinted versions. Tcl is also used for CGI scripting and as the scripting language for eggdrop bots.\012The combination of Tcl and the Tk GUI toolkit is referred to as Tcl/Tk.\0121 History\0122 Features\0123 Syntax and Fundamental Semantics\0124 Interfacing with other languages\0124.1 C++ Interoperability\0124.2 Java Interoperability\0125 Extension packages\0125.1 Tk\0125.2 Tile/Ttk\0125.3 Itcl/IncrTcl\0125.4 Tcllib\0125.5 Databases\0126 See also\0127 References\0127.1 Notes\0128\012//<![CDATA[\012if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\012//]]>\012History\012The Tcl programming language was created in the spring of 1988 by John Ousterhout while working at the University of California, Berkeley.\012Date\012Event\012January 1990\012Tcl announced beyond Berkeley (Winter USENIX).\012June 1990\012Expect announced (Summer USENIX).\012January 1991\012First announcement of Tk (Winter USENIX).\012June 1993\012First Tcl/Tk conference (Berkeley). [table] geometry manager (forerunner of [grid]), [incr Tcl], TclDP and Groupkit, announced there.\012September 2002\012Ninth Tcl/Tk conference (Vancouver). Announcement of starkit packaging system.\012Tcl conferences and workshops are held in both the United States and Europe.\012Features\012Tcl''s features include:\012Everything is a command, including language structures. They are in Prefix notation.\012Commands can be variadic.\012Everything can be dynamically redefined and overridden.\012All data types can be manipulated as strings, including code.\012Extremely simple syntactic rules.\012Event-driven interface to sockets and files. Time-based and user-defined events are also possible.\012Flexible scope, with variable visibility restricted to lexical (static) scope by default, but uplevel and upvar allowing procs to interact with the enclosing functions'' scopes.\012Simple exception handling using exception code returned by all command executions.\012All commands defined by Tcl itself generate informative error messages on incorrect usage.\012Readily extensible, via C, C++, Java, and Tcl.\012Interpreted language using bytecode for improved speed whilst maintaining dynamic modifiability\012Full Unicode (3.1) support, first released 1999.\012Platform independent: Win32, UNIX, Linux, Mac, etc.\012Close integration with windowing (GUI) interface Tk.\012Easy to maintain code. Tcl scripts are often more compact and readable than functionally equivalent code in other languages.\012Can be used for many purposes, and in many environments: as a text-only scripted language, as a GUI-capable language for applications, as an embedded language in: web pages (server-side), and databases (server-side, in PostgreSQL).\012Exists as development version (e. g. ActiveState Tcl), as tclkit (kind of runtime version, only about 1 megabyte in size), as starpack (single-file executable of a script/program), as BSD licensed freely distributable source\012Tcl did not originally support object oriented syntax, being a functional language, but recent versions do support extensions which provide OO functionality, such as the XOTcl extension to Tcl. Other OO extensions also exist, such as incr Tcl, Snit, and STOOOP (simple tcl-only object-oriented programming).\012Syntax and Fundamental Semantics\012A Tcl script consists of several command invocations. A command invocation is a list of words separated by whitespace and terminated by a newline or semicolon.\012word0 word1 word2 ... wordN\012The first word is the name of a command, which is not built into the language, but which is in the library. The following words are arguments. So we have:\012commandName argument1 argument2 ... argumentN\012Practical example, using the puts command which outputs a string, adding a trailing newline, by default to the stdout channel:\012puts "Hello, world!"\012Variables and the results of other commands can be substituted inside strings too, such as in this example where we use set and expr to store a calculation result in a variable, and puts to print the result together with some explanatory text:\012set sum [expr 1+2+3+4+5]\012puts "The sum of the numbers 1..5 is $sum."\012Formally, words are either written as-is, with double-quotes around them (allowing whitespace characters to be embedded), or with curly-brace characters around them, which suppresses all substitutions inside (except for backslash-newline elimination). In bare and double-quoted words, three types of substitution occur (once, in a single left-to-right scan through the word):\012Command substitution replaces the contents of balanced square brackets with the result of evaluating the script contained inside. For example, “[expr 1+2+3]” is replaced with the result of evaluating the contained expression (i.e. 6) since that''s what the expr command does.\012Variable substitution replaces a dollar-sign followed by the name of a variable with the contents of the variable. For example, “$foo” is replaced with the contents of the variable called “foo”. The variable name may be surrounded in curly braces so as to delimit what is and isn''t the variable name in otherwise ambiguous cases.\012Backslash substitution replaces a backslash followed by a letter with another character. For example, “\n” is replaced with a newline.\012From Tcl 8.5 onwards, any word may be prefixed by “{*}” to cause that word to be split apart into its constituent sub-words for the purposes of building the command invocation (similar to the “,@” sequence of Lisp macro definitions).\012As a consequence of these rules, the result of any command may be used as an argument to any other command. Also, there is no operator or command for string concatenation, as the language concatenates directly. Note that, unlike in Unix command shells, Tcl does not reparse any string unless explicitly directed to do so, which makes interactive use more cumbersome but scripted use more predictable (e.g. the presence of spaces in filenames does not cause difficulties).\012To summarize: there is one basic construct (the command) and a set of simple substitution rules. The single equality sign (=) for example is not used at all, and the double equality sign (==) is the test for equality, and even then only in expression contexts such as the expr command or the first argument to if. (Both of those commands are just part of the standard library; they have no particularly special place in the library and can be replaced if so desired.)\012The majority of Tcl commands, especially in the standard library, are variadic, and the proc (the constructor for scripted command procedures) supports the definition of both default values for arguments and a catch-all argument to allow the code to process arbitrary numbers of arguments.\012Tcl is not statically typed: each variable may contain integers, floats, strings, lists, command names, dictionaries, or any other value; values are reinterpreted (subject to syntactic constraints) as other types on demand. However, values are immutable and operations that appear to change them actually just return a new value instead.\012Interfacing with other languages\012Please help improve this article or section by expanding it. Further information might be found on the talk page. (January 2008)\012Tcl interfaces natively with the C language.\012C++ Interoperability\012Main article: C++/Tcl\012Java Interoperability\012Main article: Tcl/Java\012Extension packages\012The Tcl language has always supported extension packages, which provide additional functionality (such as a GUI, terminal-based application automation, database access, etc.)\012Tk\012Main article: Tk (framework)\012The most popular Tcl extension is the Tk toolkit, which provides a graphical user interface library for a variety of operating systems. Each GUI consists of one or more frames. Each frame has a layout manager.\012Tile/Ttk\012Tile/Ttk is a styles and theming widget collection which can replace most of the widgets in Tk with variants which are truly platform native through calls to an operating system''s API. Themes covered in this way are Windows XP, Windows Classic, Qt (which hooks into the X11 KDE environment libraries) and Aqua (Mac OS X). A theme can also be constructed without these calls using widget definitions supplemented with image pixmaps. Themes created this way include Classic Tk, Step, Alt/Revitalized, Plastik and Keramik.\012Under Tcl 8.4, this package is known as Tile, while in Tcl 8.5 it is included in the core distribution as Ttk.\012Itcl/IncrTcl\012Itcl is an object system for Tcl, and is normally named as [incr Tcl] (that being the way to increment in Tcl, similar in fashion to the name C++).\012Tcllib\012Tcllib is a set of scripted packages for Tcl that can be used with no compilation steps.\012Databases\012A number of database extensions are available:\012tclodbc\012mk4tcl\012SQLite\012Pgtcl, pgintcl\012mysqltcl, msqltcl\012AdabasTcl\012FBSQL\012ibtcl\012Oratcl\012Sybtcl\012db2tcl\012and many, many others - see the Tcl/Tk Wiki, specifically the Tcl/Tk Wiki Database Category.\012See also\012Wikibooks has a book on the topic of\012Programming:Tcl\012Eggdrop\012Expect\012Itcl\012Itk\012Snit\012Tcllib\012TclX\012Tk\012XOTcl\012References\012John K. Ousterhout, Tcl and the Tk Toolkit, Addison-Wesley, Reading, MA, USA, ISBN 0-201-63337-X, 1994.\012Brent B. Welch, Practical Programming in Tcl and Tk, Prentice Hall, Upper Saddle River, NJ, USA, ISBN 0-13-038560-3, 2003.\012J Adrian Zimmer, Tcl/Tk for Programmers, IEEE Computer Society, distributed by John Wiley and Sons, ISBN 0-8186-8515-8, 1998.\012Mark Harrison and Michael McLennan, Effective Tcl/Tk Programming, Addison-Wesley, Reading, MA, USA, ISBN 0-201-63474-0, 1998\012Mark Harrison (ed), Tcl/Tk Tools, O''Reilly Media, ISBN 1-56592-218-2, 1997\012Notes\012^ Windows PowerShell : PowerShell and WPF: WTF\012^ From the Tcler''s Wiki Tcl vs. TCL\012^ From the inside flap of Tcl and the Tk Toolkit, ISBN 0-201-63337-X\012^ Flynt, Clif. "Tcl/Tk - A developer''s guide" (First edition ed.). Morgan Kaufmann Publishers. pp. 759. ISBN 1-55860-802-8.\012Tcl at the Open Directory Project\012"http://en.wikipedia.org/wiki/Tcl"\012Categories: Scripting languages | Dynamically-typed programming languages | Tcl programming language family | Text-oriented programming languagesHidden categories: Articles lacking in-text citations | Wikipedia articles needing style editing from September 2008 | All articles needing style editing | All articles with unsourced statements | Articles with unsourced statements since September 2008 | Articles to be expanded since January 2008 | All articles to be expanded','\012',char(10)));
INSERT INTO pages VALUES('PowerShell','http://web.archive.org/web/20081110171826/http://en.wikipedia.org:80/wiki/PowerShell','en','2008-11-10 00:00:00',replace('( PowerShell)\nWindows PowerShell\nScreenshot of a sample PowerShell session\nDeveloped by\nMicrosoft Corporation\nInitial release\nNovember 14, 2006\nLatest release\n1.0 / 14 November 2006; 727 days ago\nPreview release\n2.0 CTP2 / 02 May 2008; 192 days ago\nOS\nWindows XP\nWindows Server 2003\nWindows Vista\nWindows Server 2008\nWindows 7\nPlatform\nx86, x86-64 and Itanium\nAvailable in\nMultilingual\nDevelopment status\nActive\nType\nOperating system shell\nLicense\nMS-EULA\nWebsite\nWindows PowerShell\nPowerShell Scripting Language\nParadigm\nMulti-paradigm: imperative, pipeline, object-oriented, functional, reflective\nAppeared in\n2006\nDesigned by\nJeffrey Snover, Bruce Payette (et al.)\nDeveloper\nMicrosoft Corporation\nTyping discipline\nstrong, safe, implicit, dynamic\nMajor implementations\nWindows PowerShell, Pash[1]\nInfluenced by\nC#, DCL, ksh, Perl, Ruby/LISP, CL, SQL, COMMAND.COM/ cmd.exe[2]\nOS\nCross-platform[1]\nWindows PowerShell is an extensible command-line shell and associated scripting language from Microsoft. It was released in 2006 and is currently available for Windows XP SP2, Windows Server 2003, Windows Vista and is included in Windows Server 2008 as an optional feature.\nWindows PowerShell integrates with the Microsoft .NET Framework and provides an environment to perform administrative tasks by execution of cmdlets (pronounced commandlets) which are specialized .NET classes implementing a particular operation, scripts which are composition of cmdlets along with imperative logic, executables which are standalone applications, or by instantiating regular .NET classes.[3][4] These work by accessing data in different data stores, like filesystem or registry, which are made available to the PowerShell runtime via Windows PowerShell providers.\nWindows PowerShell also provides a hosting mechanism with which the Windows PowerShell runtime can be embedded inside other applications, which can then leverage Windows PowerShell functionality to implement certain operations, including those exposed via the graphical interface. This capability has been utilized by Microsoft Exchange Server 2007[3][5] to expose its management functionality as PowerShell cmdlets and providers and implement the graphical management tools as PowerShell hosts which invoke the necessary cmdlets. Other Microsoft applications including Microsoft SQL Server 2008[6] also expose their management interface via PowerShell cmdlets. In the future, graphical interface-based management applications on Windows will be layered on top of Windows PowerShell.\nWindows PowerShell includes its own extensive, console-based help, reminiscent of man pages in Unix shells. The help topics include help for cmdlets, providers, and concepts in PowerShell. To see the help, use the Get-Help cmdlet. Online help for Windows PowerShell is updated weekly in the TechNet Library.\n1 Background\n2 Overview\n2.1 PowerShell 1.0\n2.1.1 Cmdlets\n2.1.2 Scripting\n2.1.3 Hosting\n2.2 PowerShell 2.0\n3 Cmdlets\n4 Reception\n5 Examples\n6 File extensions\n7 Application support\n7.1 SnapIns and Hosts\n7.2 Other\n8 See also\n9 References\n10 Books\n11\n11.1 3rd-party tools\n11.2 PowerShell providers\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nBackground\nEvery released version of Microsoft DOS and Microsoft Windows for personal computers has featured a command-line interface tool. These are COMMAND.COM (in installations relying on MS-DOS, including Windows 9x) and cmd.exe (in Windows NT-based installations). These are regular command line interpreters which include only a handful of basic commands. For other purposes, a separate console application needs to be provided, to be invoked from these shells. They also include a scripting language (batch files) which can be used to automate various tasks. However, they cannot be used to automate all facets of GUI functionality, in part because command-line equivalents of operations exposed via the graphical interface are limited, and the scripting language is elementary, preventing the creation of complex scripts by composing available functionality. In Windows Server 2003, the situation was improved,[7] but scripting support was still considered unsatisfactory.\nMicrosoft attempted to address some of these shortcomings by introducing the Windows Script Host in 1998 with Windows 98, and its command-line based host: cscript.exe . It integrates with the Active Script engine and allows scripts to be written in compatible languages, such as JScript and VBScript, leveraging the APIs exposed by applications via COM. However, it has its own deficiencies, as well. It is not integrated with the shell, its documentation not very accessible, and it quickly gained a reputation as a system vulnerability vector after several high-profile computer viruses exploited weaknesses in its security provisions. Different versions of Windows provided various special-purpose command line interpreters (such as netsh and WMIC) with their own command sets. None of them were integrated with the command shell, nor were they interoperable.\nBy 2003 Microsoft had started to develop a new shell called Monad (aka Microsoft Shell or MSH). Monad was to be a new extensible command shell with a fresh design which would be capable of automating a full range of core administrative tasks. Microsoft published the first Monad public beta release on June 17, 2005, Beta 2 on September 11, 2005 and Beta 3 on January 10, 2006. They announced on April 25, 2006 that Monad was renamed to Windows PowerShell, positioning it as a significant part of their management technology offerings.[8] Release Candidate 1 of PowerShell was released at the same time. Release Candidate 2 of PowerShell was released September 26, 2006 and released to web (RTW) on November 14, 2006. PowerShell for Vista was released on January 30, 2007.[9] A CTP release of Windows PowerShell v2.0 has been made available since November 6, 2007.[10]\nOverview\nPowerShell 1.0\nThe commands Windows PowerShell executes may be in the form of ''cmdlets'', which are specialized .NET classes designed expressly to expose a functionality via PowerShell, PowerShell scripts (*.ps1) or regular executables. If a command is an executable file, PowerShell launches it in a separate process; if it is a cmdlet, it is executed in the PowerShell process. PowerShell also provides an interactive command line interface wherein the commands can be entered and their output displayed. The user interface, based on the Win32 console, offers customizable tab completion but lacks syntax highlighting. PowerShell also enables the creation of aliases for cmdlets, which are textually translated by PowerShell into invocations of the original commands. Powershell also supports both named and positional parameters for commands. In executing a cmdlet, the job of binding the parameter value to the parameter is done by PowerShell itself, but for external executables, parameters are passed via the argv (or equivalent) variable array to be parsed by the executable.\nAnother concept used by PowerShell is that of a pipeline. Like Unix pipelines, PowerShell pipelines are used to compose complex commands, allowing the output of one command to be passed as input to another. A pipeline is set up by piping the output of one command (or pipeline) to another command, using the | operator. But unlike its Unix counterpart, the PowerShell pipeline is an object pipeline; that is, the data passed between cmdlets are fully typed objects, rather than byte streams. When data is piped as objects, the elements they encapsulate retain their structure and types across cmdlets, without the need for any serialization or explicit parsing of the stream, as would be the need if only byte streams were shared. An object can also encapsulate certain functions that work on the contained data. These also become available to the recipient command for use.[11][12] For the last cmdlet in a pipeline, PowerShell automatically pipes its output object to the Write-Host cmdlet, which creates a formatted text representation of its data, writing it to the screen.[13][14]\nBecause all PowerShell objects are .NET objects, they share a .ToString() method, which retrieves the text representation of the data in an object. Windows PowerShell uses this method to convert an object to text. In addition, it also allows formatting definitions to be specified, so the text representation of objects may be customized by choosing which data elements to display, and how. However, in order to maintain backwards compatibility, if an external executable is used in a pipeline, it receives a text stream representing the object, and does not integrate with the PowerShell type system.\nThe PowerShell Extended Type System (ETS) is based on the .NET type system, but with certain extensions. For example, it enables the creation of different views of objects by exposing only a subset of the data fields, properties, and methods, as well as specifying custom formatting and sorting behavior. These views are mapped to the original object using an XML-based language.[15]\nCmdlets\nCmdlets are specialized commands in the PowerShell environment that implement specific functions. These are the native commands in the PowerShell stack. Cmdlets follow a <verb>-<noun> naming pattern, such as Get-ChildItem, helping to make them (according to Microsoft) self-descriptive.[16] Cmdlets output their results as objects, or collections thereof (including arrays), and can optionally receive input in that form, making them suitable for use as recipients in a pipeline. But while PowerShell allows arrays and other collection of objects to be written to the pipeline, cmdlets always process objects individually. For collections of objects, PowerShell invokes the cmdlet on each object in the collection, in sequence.[16]\nCmdlets are specialized .NET classes, which the PowerShell runtime instantiates and invokes when they are run. Cmdlets derive either from Cmdlet or from PSCmdlet, the latter being used when the cmdlet needs to interact with the PowerShell runtime.[16] These base classes specify certain methods - BeginProcessing(), ProcessRecord() and EndProcessing() - one of which the cmdlet''s implementation overrides to provide the functionality. Whenever a cmdlet is run, these methods are invoked by PowerShell in sequence, with ProcessRecord() being called if it receives pipeline input.[17] If a collection of objects are piped, the method is invoked for each object in the collection. The class implementing the Cmdlet must have one .NET attribute - CmdletAttribute - which specifies the verb and the noun that make up the name of the cmdlet. Common verbs are provided as an enum.\nIf a cmdlet receives either pipeline input or command-line parameter input, there must be a corresponding property in the class, with a mutator implementation. PowerShell invokes the mutator with the parameter value or pipeline input, which is saved by the mutator implementation in class variables. These values are then referred to by the methods which implement the functionality. Properties that map to command-line parameters are marked by ParameterAttribute[18] and are set before the call to BeginProcessing(). Those which map to pipeline input are also flanked by ParameterAttribute, but with the ValueFromPipeline attribute parameter set.[19]\nThe implementation of these cmdlet classes can refer to any .NET API and may be in any .NET language. In addition, PowerShell makes certain APIs available, such as WriteObject(), which is used to access PowerShell-specific functionality, such as writing resultant objects to the pipeline. Cmdlets can use .NET data access APIs directly or use the PowerShell infrastructure of PowerShell Providers, which make data stores addressable using unique paths. Data stores are exposed using drive letters, and hierarchies within them, addressed as directories. Windows PowerShell ships with providers for the file system, registry, the certificate store, as well as the namespaces for command aliases, variables, and functions.[20] Windows PowerShell also includes various cmdlets for managing various Windows systems, including the file system, or using Windows Management Instrumentation to control Windows components. Other applications can register cmdlets with PowerShell, thus allowing it to manage them, and if they enclose any datastore (such as databases), they can add specific providers as well.\nScripting\nWindows PowerShell includes a dynamically typed scripting language which can implement complex operations using cmdlets imperatively. The scripting language supports variables, functions, branching (if-then-else), loops (while, do, for, and foreach), and error handling, as well as integration with .NET. Variables in PowerShell scripts have names that start with $; they can be assigned any value, including the output of cmdlets. While the language is untyped, internally the variables are stored with their types, which can be either primitive types or objects. Strings can be enclosed either in single quotes or in double quotes; in the former case, variables will be expanded even if they are inside the quotation marks. According to the variable syntax, if the path to a file is enclosed in braces preceded by a dollar sign (as in ${C:\foo.txt}), it refers to the contents of the file. If it is used as an L-value, anything assigned to it will be written to the file. When used as an R-value, it will be read from the file. If an object is assigned, it is serialized before storing it.\nObject members can be accessed using . notation, as in C# syntax. PowerShell provides special variables, such as $args, which is an array of all the command line arguments passed to a function from the command line, and $_, which refers to the current object in the pipeline.[21] PowerShell also provides arrays and associative arrays. The PowerShell scripting language also evaluates arithmetic expressions entered on the command line immediately, and it parses common abbreviations, such as GB, MB, and KB.\nUsing the function keyword, PowerShell provides for the creation of functions, which can take parameters. It provides two syntaxes for invoking a function:\n<function> <param1> <param2> …'': In this case, the function need not define the parameters it accepts; the parameters will be passed as an array accessible from inside the function via the $args array.[22]\n<function>(<param1>, <param2>): In this case, the function declaration must specify the parameters it accepts, and their types. The parameters passed will be bound to the parameter variables when the function is called.[23]\nPowerShell allows any .NET methods to be called by providing their namespaces enclosed in brackets ([]), and then using a pair of colons (::) to indicate the static method.[24] For example, [System.Console]::WriteLine("PowerShell") Objects are created using the New-Object cmdlet. Calling methods of .NET objects is accomplished by using the regular . notation.[24]\nFor error handling, PowerShell provides a .NET-based exception handling mechanism. In case of errors, objects containing information about the error (Exception object) are thrown, which are caught using the trap keyword. However, the action-or-error is configurable; in case of an error PowerShell can be configured to silently resume execution, without trapping the exception.[25]\nScripts written using PowerShell can be made to persist across sessions in a .ps1 file. Later, either the entire script or individual functions in the script can be used. Scripts and functions are used analogously with cmdlets, in that they can be used as commands in pipelines, and parameters can be bound to them. Pipeline objects can be passed between functions, scripts, and cmdlets seamlessly. However, script execution is disabled by default and must be enabled explicitly.[26] PowerShell scripts can be signed to verify their integrity, and are subject to .NET Code Access Security.\nThe PowerShell scripting language supports binary prefix notation similar to the scientific notation supported by many programming languages in the C-family.\nHosting\nAnother use of PowerShell is being embedded in a management application, which then uses the PowerShell runtime to implement the management functionality. For this, PowerShell provides a managed hosting API. Via the APIs, the application can instantiate a runspace (one instantiation of the PowerShell runtime), which runs in the application''s process and is exposed as a Runspace object.[3] The state of the runspace is encased in a SessionState object. When the runspace is created, the Windows PowerShell runtime initializes the instantiation, including initializing the providers and enumerating the cmdlets, and updates the SessionState object accordingly. The Runspace then must be opened for either synchronous processing or asynchronous processing. After that it can be used to execute commands.\nTo execute a command, a pipeline (represented by a Pipeline object) must be created and associated with the runspace. The pipeline object is then populated with the cmdlets that make up the pipeline. For sequential operations (as in a PowerShell script), a Pipeline object is created for each statement and nested inside another Pipeline object.[3] When a pipeline is created, Windows PowerShell invokes the pipeline processor, which resolves the cmdlets into their respective assemblies (the command processor) and adds a reference to them to the pipeline, and associates them with an InputPipe, Outputpipe and ErrorOutputPipe objects, to represent the connection with the pipeline. The types are verified and parameters bound using reflection.[3] Once the pipeline is set up, the host calls the Invoke() method to run the commands, or its asynchronous equivalent - InvokeAsync(). If the pipeline has the Write-Host cmdlet at the end of the pipeline, it writes the result onto the console screen. If not, the results are handed over to the host, which might either apply further processing or display it itself.\nThe hosting APIs are used by Microsoft Exchange Server 2007 to provide its management GUI. Each operation exposed in the GUI is mapped to a sequence of PowerShell commands (or pipelines). The host creates the pipeline and executes them. In fact, the interactive PowerShell console itself is a PowerShell host, which interprets the scripts entered at command line and creates the necessary Pipeline objects and invokes them.\nPowerShell 2.0\nThis article or section contains information about scheduled or expected future software.\nThe content may change as the software release approaches and more information becomes available.\nGraphical Windows PowerShell, with multiple open RunSpaces in the Windows PowerShell 2.0 CTP2\nMicrosoft is working on the next version of PowerShell and has made two CTP releases of the same publicly available. Windows PowerShell 2.0 will be installed by default on Windows Server 2008 R2 and Windows 7[27] and includes changes to the scripting language and hosting API, in addition to including more than 240 new cmdlets.[28][29] A non-exhaustive list of the new features is:[30][31]\nPowerShell Remoting: Using WS-Management, PowerShell 2.0 allows scripts and cmdlets to be invoked on a remote machine or a large set of remote machines.\nBackground Jobs: Also called a PSJob, it allows a command sequence (script) or pipeline to be invoked asynchronously. Jobs can be run on the local machine or on multiple remote machines. A PSJob cannot include interactive cmdlets.\nTransactions: Enable cmdlet and provider developers to perform transacted operations. PowerShell 2.0 includes transaction cmdlets for starting, committing, and rolling back a PSTransaction as well as features to manage and direct the transaction to the participating cmdlet and provider operations. The PowerShell Registry provider supports transactions.\nScriptCmdlets: These are cmdlets written using the PowerShell scripting language.\nSteppablePipelines: This allows the user to control when the BeginProcessing(), ProcessRecord() and EndProcessing() functions of a cmdlet are called.\nModules: This allows script developers and administrators to organize and partition PowerShell scripts in self-contained, reusable units. Code from a module executes in its own self-contained context and does not affect the state outside of the module. Modules can define a restricted runspace environment by using a script. They have a persistent state as well as public and private members.\nData Language: A domain-specific subset of the PowerShell scripting language, that allows data definitions to be decoupled from the scripts and allow localized string resources to be imported into the script at runtime (Script Internationalization).\nScript Debugging: It allows breakpoints to be set in a PowerShell script or function. Breakpoints can be set on lines, line & columns, commands and read or write access of variables. It includes a set of cmdlets to control the breakpoints via script.\nEventing: This feature allows listening, forwarding, and acting on management and system events. Eventing allows PowerShell Hosts to be notified about state changes to their managed entities. It also enables PowerShell scripts to subscribe to ObjectEvents, PSEvents, and WmiEvents and process them synchronously and asynchronously.\nWindows PowerShell Integrated Scripting Environment: PowerShell 2.0 includes a GUI-based PowerShell host (formerly known as Graphical Windows PowerShell) that provides integrated debugger, syntax highlighting, tab completion and up to 8 PowerShell unicode-enabled consoles (Runspaces) in a tabbed UI, as well as to run only the selected parts in a script.\nNetwork File Transfer: Native support for prioritized, throttled, and asynchronous transfer of files between machines using the Background Intelligent Transfer Service (BITS).[32]\nNew Cmdlets: Including Out-GridView, which displays tabular data in the WPF GridView object.\nNew Operators: -Split, -Join, and Splatting (@) operators.\nException Handling with Try-Catch-Finally: Unlike other .NET languages, this allows multiple exception types for a single catch block.\nNestable Here-Strings: PowerShell Here-Strings have been improved and can now nest.[33]\nNew APIs: The new APIs range from handing more control over the PowerShell parser and runtime to the host, to creating and managing collection of Runspaces (RunspacePools) as well as the ability to create Restricted Runspaces which only allow a configured subset of PowerShell to be invoked. The new APIs also support participation in a Windows PowerShell managed transaction.\nCmdlets\nThe following table contains a selection of the more than 129 Cmdlets that ship with PowerShell as well as the equivalent commands in other command line interpreters.\nWindows PowerShell\n(Cmdlet)\nWindows PowerShell\n(Alias)\ncmd.exe / COMMAND.COM\n(MS-DOS, Windows, OS/2, etc.)\nBash\n(Unix, BSD, Linux, Mac OS X etc.)\nDescription\nGet-Location\ngl, pwd\ncd\npwd\nDisplay the current directory\nSet-Location\nsl, cd, chdir\ncd, chdir\ncd\nChange the current directory\nClear-Host\ncls, clear\ncls\nclear\nClear the screen[34]\nCopy-Item\ncpi, copy, cp\ncopy\ncp\nCopy one or several files / a whole directory tree\nGet-Help\nhelp, man\nhelp\nman\nHelp on commands\nRemove-Item\nri, del, rmdir, rd, rm\ndel, rmdir, rd\nrm, rmdir\nDelete a file / a directory\nRename-Item\nrni, ren\nren, rename\nmv\nRename a file / a directory\nMove-Item\nmi, move, mv\nmove\nmv\nMove a file / a directory to a new location\nGet-ChildItem\ngci, dir, ls\ndir\nls\nList all files / directories in the (current) directory\nWrite-Output\necho, write\necho\necho\nPrint strings, variables etc. to standard output\nPop-Location\npopd\npopd\npopd\nChange the current directory to the directory most recently pushed onto the stack\nPush-Location\npushd\npushd\npushd\nPush the current directory onto the stack\nSet-Variable\nsv, set\nset\nset\nSet the value of a variable / create a variable\nGet-Content\ngc, type, cat\ntype\ncat\nGet the content of a file\nSelect-String\nfindstr\ngrep\nPrint lines matching a pattern\nGet-Process\ngps, ps\ntlist[35], tasklist[36]\nps\nList all currently running processes\nStop-Process\nspps, kill\nkill[35], taskkill[36]\nkill\nStop a running process\nTee-Object\ntee\nn/a\ntee\nPipe input to a file or variable, then pass the input along the pipeline\nReception\nPublic reception of Windows PowerShell 1.0 has generally been quite positive.\neWeek judged Windows PowerShell to be #7 of the top 10 best products Microsoft has ever shipped.[37]\nDr. Dobb''s Journal concludes:\n“\nFor administrators, PowerShell provides efficient, powerful access to key indicators of the operating system. […] For developers, PowerShell is helpful in SQL scripting or developing DLLs. The concepts and cmdlets of PowerShell offer new ways to work with old information. […] PowerShell is flexible, extensible, and easily integrated.[38]\n”\nThe popular IT magazine Computerworld states:\n“\nWindows has never enjoyed the powerful shell scripting environments that its Unix rivals have long included. That''s changed now with the inclusion of PowerShell […] in Windows Server 2008 and a passel of other Microsoft server products as well. Finally, Windows has a classy, robust and powerful solution that can access just about every part of the operating system.[39]\n”\nThe SANS Technology Institute affirms:\n“\nUnlike the CMD shell''s meager batch language, PowerShell''s scripting language supports a large variety of flow-control elements, type casting, functions, full-featured arrays, object reference variables, default variables in flow-control blocks, regular expressions, and other constructs often associated only with UNIX shells like bash and ksh. At first glance, the PowerShell language looks somewhat similar to Perl or C#, but it''s not even half as difficult to learn.[40]\n”\nIn his Windows Server 2008 review technology reporter and editor of the popular SuperSite for Windows Paul Thurrott states:\n“\nPowerShell is a complex but technically impressive environment, with support for discoverable .NET-based objects, properties, and methods. It provides all of the power of UNIX command line environments with none of the inconsistencies.[41]\n”\nAccording to Microsoft, PowerShell has had almost a million downloads in its first six months.[42] There is also a growing list of products that are shipping with PowerShell support.\nExamples\nExamples are provided first using the long-form canonical syntax and then using more terse unix-like aliases that are set up in the default configuration. Examples that could harm a system include the -whatif parameter to prevent them from actually executing\nStop all processes that begin with the letter "p":\nPS> get-process p* | stop-process -whatif\nPS> ps p* | kill -whatif\nFind the processes that use more than 1000 MB of memory and kill them:\nPS> get-process | where-object { $_.WS -gt 1000MB } | stop-process -whatif\nPS> ps | ? { $_.WS -gt 1000MB } | kill -whatif\nCalculate the number of bytes in the files in a directory:\nPS> get-childitem | measure-object -property length -sum\nPS> ls | measure-object -p length -s\nDetermine whether a specific process is no longer running:\nPS> $processToWatch = get-process notepad\nPS> $processToWatch.WaitForExit()\nPS> $p = ps notepad\nPS> $p.WaitForExit()\nChange the case of a string from lower to upper:\nPS> "hello, world!".ToUpper()\nInsert the string "ABC" after the first character in the word "string" to have the result "sABCtring":\nPS> "string".Insert(1, "ABC")\nDownload a specific RSS feed and show the titles of the 8 most recent entries:\nPS> $rssUrl = "http://blogs.msdn.com/powershell/rss.aspx"\nPS> $blog = [xml](new-object System.Net.WebClient).DownloadString($rssUrl)\nPS> $blog.rss.channel.item | select title -first 8\nSets $UserProfile to the value of the UserProfile environment variable\nPS> $UserProfile = $env:UserProfile\nFile extensions\nPS1 – Windows PowerShell shell script\nPS1XML – Windows PowerShell format and type definitions\nPSC1 – Windows PowerShell console file\nPSD1 – Windows PowerShell data file\nPSM1 – Windows PowerShell module file\nApplication support\nSnapIns and Hosts\nApplication\nVersion\nCmdlets\nProvider\nManagement GUI\nExchange Server\n2007\n402\nYes\nYes\nWindows Server\n2008\nYes\nYes\nNo\nMicrosoft SQL Server\n2008\nYes\nYes\nNo\nSystem Center Operations Manager\n2007\n74\nYes\nNo\nSystem Center Virtual Machine Manager\n2007\nYes\nYes\nYes\nSystem Center Data Protection Manager\n2007\nYes\nNo\nNo\nWindows Compute Cluster Server\n2007\nYes\nYes\nNo\nMicrosoft Transporter Suite for Lotus Domino[43]\n08.02.0012\n47\nNo\nNo\nMicrosoft PowerTools for Open XML[44]\n1.0\n33\nNo\nNo\nIBM WebSphere MQ[45]\n6.0.2.2\n44\nNo\nNo\nQuest Management Shell for Active Directory[46]\n1.1\n40\nNo\nNo\nSpecial Operations Software Specops Command[47]\n1.0\nYes\nNo\nYes\nVMware Infrastructure Toolkit[48]\n1.0 Update 1\n125\nNo\nNo\nInternet Information Services[49]\n7.0\n54\nYes\nNo\nEnsim Unify Enterprise Edition[50]\n1.6\nYes\nNo\nYes\nOther\nSAPIEN Technologies ActiveX PowerShell (ActiveXPosh) — An ActiveX COM component that allows creating a PowerShell host and use cmdlets and scripts from within COM-compatible scripting languages such as VBScript, JScript and KiXtart.[51]\nSense/Net 6.0 A currently beta open source implementation of a .NET based Enterprise Content Management System accessible from PowerShell, information availbale from the Sense/Net development blog\nSee also\nComparison of computer shells\nComparison of programming languages\nWeb-Based Enterprise Management\nCommon Information Model\nWindows Script Host\nReferences\n^ a b igor.moochnick - Pash\n^ Jsnover @ Wikipedia: Generational list of programming languages\n^ a b c d e "How Windows PowerShell works".\nMSDN. Retrieved on 2007-11-27.\n^ "Extend Windows PowerShell With Custom Commands".\nMSDN. Retrieved on 2007-11-27.\n^ "Exchange 2007: Get used to the command line".\nTech Republic. Retrieved on 2007-11-28.\n^ "SQL Server Support for PowerShell!". Retrieved on 2007-11-28.\n^ Dragan, Richard V. (April 23, 2003). "Windows Server 2003 Delivers Improvements All Around".\nPC Magazine. Retrieved on 2007-11-02. "A standout feature here is that virtually all admin utilities now work from the command line (and most are available through telnet)."\n^ Snover, Jeffrey (April 25, 2006). "Windows PowerShell (Monad) Has Arrived". Windows PowerShell team blog.\nMSDN. Retrieved on 2006-04-26.\n^ Snover, Jeffrey (November 15, 2006). "Windows PowerShell : Windows PowerShell & Windows Vista". Windows PowerShell team blog.\nMSDN. Retrieved on 2007-01-26.\n^ Hansen, Kenneth (November 6, 2007). "The Community Technology Preview (CTP) of Windows PowerShell 2.0". Windows PowerShell team blog.\nMSDN. Retrieved on 2007-11-06.\n^ "Rethinking the Pipeline". Retrieved on 2007-11-28.\n^ "Windows PowerShell Object Concepts". Retrieved on 2007-11-28.\n^ "How PowerShell Formatting and Outputting REALLY works". Retrieved on 2007-11-28.\n^ "More - How does PowerShell formatting really work?". Retrieved on 2007-11-28.\n^ "Windows PowerShell Extended Type System". Retrieved on 2007-11-28.\n^ a b c "Windows PowerShell Cmdlets". Retrieved on 2007-11-28.\n^ "Creating Your First Cmdlet". Retrieved on 2007-11-28.\n^ "Adding parameters That Process Command Line Input". Retrieved on 2007-11-28.\n^ "Adding parameters That Process Pipeline Input". Retrieved on 2007-11-28.\n^ "Windows PowerShell Providers". Retrieved on 2007-11-28.\n^ "Introduction to Windows PowerShell''s Variables". Retrieved on 2007-11-28.\n^ "Functions in PowerShell". Retrieved on 2007-11-28.\n^ "Calling a Function with Parameters". Retrieved on 2007-11-28.\n^ a b "Lightweight Testing with Windows PowerShell". Retrieved on 2007-11-28.\n^ "Trap [Exception] { “In PowerShell” }". Retrieved on 2007-11-28.\n^ "Running Windows PowerShell Scripts". Retrieved on 2007-11-28.\n^ http://blogs.msdn.com/powershell/archive/2008/10/28/powershell-will-be-installed-by-default-on-windows-server-08-r2-ws08r2-and-windows-7-w7.aspx\n^ http://blogs.msdn.com/powershell/archive/2008/10/29/574-reasons-why-we-are-so-proud-and-optimistic-about-w7-and-ws08r2.aspx\n^ http://channel9.msdn.com/pdc2008/ES24/\n^ "What''s New in CTP of PowerShell 2.0". Retrieved on 2007-11-28.\n^ "Windows PowerShell V2 Community Technology Preview 2 (CTP2) - releaseNotes". Retrieved on 2008-05-05.\n^ http://blogs.msdn.com/powershell/archive/2008/10/14/gogrid-snap-in-managing-cloud-services-with-powershell.aspx\n^ http://blogs.msdn.com/powershell/archive/2008/10/18/emit-xml.aspx\n^ Clear-Host is implemented as a predefined PowerShell function.\n^ a b Available in Windows NT4, Windows 98 Resource Kit, Windows 2000 Support Tools\n^ a b Available in Windows XP Professional Edition and later\n^ Page 9 - The Best and Worst Microsoft Products - Security\n^ Windows PowerShell\n^ PowerShell Tips and Tricks\n^ What is Windows PowerShell?\n^ Windows Server 2008 Review\n^ PowerShell Hits a Million Downloads in the First Six Months\n^ "Microsoft Transporter Suite for Lotus Domino". Retrieved on 2008-03-07.\n^ "PowerTools for Open XML". Retrieved on 2008-06-20.\n^ "MO74: WebSphere MQ - Windows Powershell Library". Retrieved on 2007-12-05.\n^ "PowerShell Commands for Active Directory by Quest Software". Retrieved on 2008-07-02.\n^ "PowerShell Remoting through Group Policy". Retrieved on 2007-12-07.\n^ "VMware Infrastructure Toolkit for Windows". Retrieved on 2008-10-10.\n^ "Windows PowerShell : IIS7 PowerShell Provider Tech Preview 2". Retrieved on 2008-07-03.\n^ "Exchange Manager for 2003 and 2007". Retrieved on 2008-04-23.\n^ http://support.sapien.com/bulletins/activexposh.pdf\nBooks\nFord, Jerry Lee Jr. Microsoft Windows Powershell Programming for the Absolute Beginner. ISBN 1-59863-354-6.\nHolmes, Lee. Windows PowerShell Quick Reference. ISBN 0-596-52813-2.\nHolmes, Lee. Windows PowerShell Cookbook. ISBN 0-596-52849-3.\nJohnson, Willis. Scripting SQL Management Objects in Windows PowerShell. ISBN 978-0-470-27935-9.\nJones, Don. Windows PowerShell: TFM. ISBN 0-9776597-2-0.\nKopczynski, Tyson. Microsoft Powershell Unleashed. ISBN 0672329530.\nKumaravel, Arul; Jon White, Michael Naixin Li, Scott Happell, Guohui Xie, Krishna C. Vutukuri. Professional Windows PowerShell Programming: Snapins, Cmdlets, Hosts and Providers. ISBN 0-470-17393-9.\nOakley, Andy. Monad (AKA PowerShell). ISBN 0-596-10009-4.\nPayette, Bruce. Windows PowerShell in Action. ISBN 1-932394-90-7.\nWatt, Andrew. Professional Windows PowerShell. ISBN 0-471-94693-1.\nWilson, Ed. Microsoft Windows PowerShell Step By Step. ISBN 0-7356-2395-3.\nPowerShell homepage\nWindows PowerShell Team Blog\nScripting with Windows PowerShell\nMonad Manifesto - The Origin of Windows PowerShell\nChannel9 Interviews/Demos with Jeffrey Snover - the Architect of Windows PowerShell\nWindows PowerShell and the “PowerShell Worm” - an analysis, by Leonard Chung of the Windows PowerShell Team, of the "PowerShell Worm" and a walkthrough of Windows PowerShell''s security features and how they strongly reduce the risk of scripting malware.\n3rd-party tools\nPowerShell remoting - Replace login scripts Specops Command is the standard for deploying and executing PowerShell anywhere anytime\nPowerGUI Extensible graphical administrative console for managing systems based on Windows PowerShell.\nPowershell.com - Powershell Analyzer and Powershell Plus - Powershell Hosting, Editor and Debugging Products.\nPowerShell Community Extensions\nsudo for Powershell - run specific commands as an administrator on Windows Vista\nPrimalScript 2007 General scripting IDE with PowerShell support and debugger\nPowerShell providers\nS3Nas PowerShell Provider - S3Nas Amazon S3 PowerShell Provider\nPowerShell SharePoint Provider - PowerShell SharePoint Provider\nOneNote PowerShell Provider - OneNote PowerShell Provider\nWindows Mobile PowerShell Provider - Windows Mobile PowerShell Provider\nv • d • e\nMicrosoft Windows components\nCore\nAero · ClearType · Desktop Window Manager · DirectX · Explorer · Taskbar · Start menu · Shell (namespace · Special Folders · File associations) · Search (Saved search · iFilters) · Graphics Device Interface · WIM · Next Generation TCP/IP stack (Server Message Block) · .NET Framework · Audio · Printing (XML Paper Specification) · Active Scripting (WSH · VBScript · JScript) · COM (OLE · OLE Automation · DCOM · ActiveX · ActiveX Document · Structured storage · Transaction Server) · Previous Versions · Win32 console\nManagement\ntools\nBackup and Restore Center · command.com · cmd.exe · Control Panel (Applets) · Device Manager · Disk Cleanup · Disk Defragmenter · Event Viewer · Management Console · Netsh · Problem Reports and Solutions · Sysprep · System Configuration · Task Manager · System File Checker · System Restore · Windows Installer · Windows PowerShell · Windows Update · WinSAT · Windows Easy Transfer · System Policy Editor\nApplications\nCalculator · Calendar · Character Map · Contacts · DVD Maker · Fax and Scan · Internet Explorer · Journal · Mail · Magnifier · Media Center · Meeting Space · Mobile Device Center · Mobility Center · Movie Maker · Narrator · Notepad · Paint · Photo Gallery · Private Character Editor · Remote Assistance · Sidebar · Snipping Tool · Sound Recorder · Windows Media Player (11) · Windows Speech Recognition · WordPad\nGames\nChess Titans · FreeCell · Hearts · Hold ''Em · InkBall · Mahjong Titans · Minesweeper · Purble Place · Solitaire · Spider Solitaire\n· Tinker\nKernel\nNtoskrnl.exe · hal.dll · System Idle Process · Svchost.exe · Registry · Windows service · Service Control Manager · DLL · EXE · NTLDR / Boot Manager · Winlogon · Recovery Console · I/O · WinRE · WinPE · Kernel Patch Protection\nServices\nAutorun · BITS · Task Scheduler · Wireless Zero Configuration · Shadow Copy · Windows Error Reporting · Multimedia Class Scheduler · CLFS\nFile systems\nNTFS (Hard link · Junction point · Mount Point · Reparse point · Symbolic link · TxF · EFS) · FAT32·FAT16·FAT12 · exFAT · CDFS · UDF · DFS · IFS\nServer\nDomains · Active Directory · DNS · Group Policy · Roaming user profiles · Folder redirection · Distributed Transaction Coordinator · MSMQ · Windows SharePoint Services · Windows Media Services · Rights Management Services · IIS · Terminal Services · WSUS · Network Access Protection · DFS Replication · Remote Differential Compression · Print Services for UNIX · Remote Installation Services · Windows Deployment Services · Windows System Resource Manager · Hyper-V\nArchitecture\nNT series architecture · Object Manager · Startup process (Vista) · I/O request packets · Kernel Transaction Manager · Logical Disk Manager · Security Accounts Manager · Windows Resource Protection · LSASS · CSRSS · SMSS · MinWin\nSecurity\nUAC · BitLocker · Defender · DEP · Protected Media Path · Mandatory Integrity Control · UIPI · Windows Firewall · Security Center\nCompatibility\nUnix subsystem (Microsoft POSIX\n· Interix) · Virtual DOS machine · Windows on Windows · WOW64\nv • d • e\nWindows command line programs and builtins (more)\nFile system\n(basic)\nattrib · cd · chdir · copy · del · deltree · dir · erase · fdisk · format · md · mkdir · mklink · mountvol · move · ntbackup · rd · rename · ren · rmdir · robocopy · sys · type · xcopy\nFile system\n(advanced)\nassoc · cacls · chkdsk · chkntfs · comp · compact · convert · defrag · diskcomp · diskcopy · fc · ftype · icacls · label · recover · reg · regsvr32 · replace · subst · tree · verify · vol · vssadmin\nProcesses\nat · exit · kill · schtasks · start · shutdown · taskkill · tasklist · tlist\nUser environment\nappend · chcp · color · date · finger · graftabl · mode · path · popd · pushd · runas · set · setx · time · title · ver · whoami\nText processing\nedit · edlin · more · sort\nShell programming\nbreak · call · cmd · command · cscript · doskey · echo · endlocal · for · goto · if · pause · powershell · prompt · rem · setlocal · shift · forfiles · choice\nNetworking\narp · ftp · getmac · hostname · ipconfig · net · netsh · netstat · nslookup · pathping · ping · telnet · tftp · tracert\nSearching\nfind · findstr\nMiscellaneous\nbcdedit · bootcfg · cls · help · print · debug · exe2bin · wmic\nv • d • e\n.NET Framework\nArchitecture\nBase Class Library · Common Language Runtime · Code Access Security · Assembly · Metadata · COM Interop\nCommon Language\nInfrastructure (CLI)\nCommon Language Infrastructure · Common Type System · Common Intermediate Language · Virtual Execution System\nCLI Languages\nCommon1\nC# · Visual Basic .NET · C++/CLI (Managed) · J# · JScript .NET\nOther2\nA# · Boo · Oxygene\n· F#\n· IronLisp · IronPython · IronRuby · Nemerle · Phalanger · P# · Windows PowerShell\nComponents\nADO.NET (Entity Framework · Data Services) · ASP.NET (AJAX · MVC · Dynamic Data) · Language Integrated Query · CardSpace · ClickOnce · Communication Foundation · Dynamic Language Runtime · Forms · Presentation Foundation · Remoting · Workflow\n· XAML\nOther implementations\nMono · Compact Framework (Xbox 360) · Micro Framework · Portable.NET · Silverlight · SSCLI\nComparisons\nC# and Java · C# and Visual Basic .NET · Java and .NET platforms\nUpcoming\n"Acropolis" · "Jasper" · Parallel FX Library\n1 Languages that are or have been included with Visual Studio.\n2 Non-academic or research languages with relatively large user-bases.\nv • d • e\nMicrosoft APIs and frameworks\nGraphics\nAero · DirectX · Direct3D · GDI / GDI+ · WPF · Windows Color System · Windows Image Acquisition · Windows Imaging Component\nAudio\nDirectSound · DirectMusic · DirectX plugin · XACT · Speech API\nMultimedia\nDirectShow · DirectX Media Objects · DXVA · Windows Media · Media Foundation · Image Mastering API\nWeb\nMSHTML · RSS Platform · JScript · VBScript · BHO · XDR · SideBar Gadgets\nData access\nData Access Components · Extensible Storage Engine · ADO.NET · ADO.NET Entity Framework · Sync Framework · Jet Engine · MSXML\nNetworking\nWinsock (LSP) · Winsock Kernel · Filtering Platform · Network Driver Interface Specification · Windows Rally · BITS · P2P API · MSMQ · MPI\nCommunication\nMessaging API · Telephony API\nAdministration and\nmanagement\nWin32 console · Windows Script Host · WMI (extensions) · PowerShell · Task Scheduler · Offline Files · Shadow Copy · Windows Installer · Error Reporting · Event Log · Common Log File System\nComponent model\nCOM · COM+ · ActiveX · Distributed Component Object Model · .NET Framework\nLibraries\nMicrosoft Foundation Class (MFC) · Active Template Library (ATL) · Windows Template Library (WTL)\nDrivers\nWindows Driver Model (Broadcast Driver Architecture) · Windows Driver Foundation (KMDF · UMDF) · WDDM · ASIO · NDIS · UAA · Native Jet ISAM Driver · VxD\nSecurity\nCrypto API (CAPICOM) · Windows CardSpace · Data protection API · Security Support Provider Interface (SSPI)\n.NET\nASP.NET · ADO.NET · Remoting · Silverlight · TPL · WCF · WCS · WPF · WWF · XNA\nSoftware factories\nEFx Factory · Enterprise Library · Composite UI · CCF · CSF\nIPC\nMSRPC · Named pipes · Memory-mapped file · Dynamic Data Exchange (DDE) · MailSlot\nAccessibility\nActive Accessibility · UI Automation\nText and multilingual\nsupport\nText Services Framework · Text Object Model · Input method editor (IME) · Language Interface Pack · Multilingual User Interface (MUI) · Uniscribe\nGames\nDirect3D · D3DX · DirectSound · DirectInput · DirectPlay · DirectMusic · Managed DirectX · XNA\n"http://en.wikipedia.org/wiki/Windows_PowerShell"\nCategories: Upcoming software | .NET programming languages | Curly bracket programming languages | Dynamically-typed programming languages | Interpreters (computing) | Windows administration | Object-oriented programming languages | Procedural programming languages | Scripting languages | Text-oriented programming languages | Command shells','\n',char(10)));
INSERT INTO pages VALUES('BCPL','http://web.archive.org/web/20081207055839/http://en.wikipedia.org:80/wiki/BCPL','en','2008-12-07 00:00:00',replace('This article is about the programming language.\nFor the library system, see Baltimore County Public Library.\nBCPL\nParadigm\nprocedural, imperative, structured\nAppeared in\n1966\nDesigned by\nMartin Richards\nInfluenced by\nCPL\nInfluenced\nB (indirectly C)\nBCPL (Basic Combined Programming Language) is a computer programming language designed by Martin Richards of the University of Cambridge in 1966.\n1 Design\n2 Examples\n3 Sources\n4\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nDesign\nOriginally intended for writing compilers for other languages, BCPL is no longer in common use. However, its influence is still felt because the language B, upon which the C programming language was based, was a stripped down and syntactically changed version of BCPL. BCPL was the first curly bracket programming language, and the curly brackets survived the syntactical changes and have become a common means of denoting program source code statements. In practice, on limited keyboards of the day, source programs often used the sequences $( and $) in place of the symbols { and }. The single-line ''//'' comments of BCPL, which were not taken up in C, reappeared in C++, and later in C99.\nBCPL was a response to difficulties with its predecessor CPL, created during the early 1960s; Richards created BCPL by "removing those features of the full language which make compilation difficult". The first compiler implementation, for the IBM 7094 under CTSS, was written while Richards was visiting Project MAC at MIT in the spring of 1967. The language was first described in a paper presented to the 1969 Spring Joint Computer Conference.\nThe language is clean, powerful, and portable. It therefore proved possible to write small and simple compilers for it; reputedly some compilers could be run in 16 kilobytes. In addition, the Richards compiler, itself written in BCPL, was easily portable. BCPL was therefore a popular choice for bootstrapping a system.\nA major reason for the compiler''s portability lay in its structure. It was split into two parts: the front end parsed the source and generated O-code for a virtual machine, and the back end took the O-code and translated it into the code for the target machine. Only 1/5th of the compiler''s code needed to be rewritten to support a new machine, a task that usually took between 2 and 5 man-months. Soon afterwards this structure became fairly common practice, cf. Pascal or Java, but the Richards BCPL compiler was the first to define a virtual machine for this purpose.\nThe language is unusual in having only one data type: a word, a fixed number of bits, usually chosen to align with the architecture''s machine word and of adequate capacity to represent any valid storage address. For many machines of the time, this data type was a 16-bit word. This choice later proved to be a significant problem when BCPL was used on machines in which the smallest addressable item was not a word, but a byte or on machines with larger word sizes: 32-bit and 64-bit words, which allowed them to manage large address spaces.\nThe interpretation of any value was determined by the operators used to process the values. (For example, + added two values together treating them as integers; ! indirected through a value, effectively treating it as a pointer.) In order for this to work, the implementation provided no type checking. The Hungarian Notation was developed to help programmers avoid inadvertent type errors.\nThe mismatch between BCPL''s word orientation and byte-oriented hardware was addressed in a number of ways. One was the provision of standard library routines for packing and unpacking words into byte strings. Later, two language features—the bit-field selection operator and the infix byte indirection operator (denoted by the ''%'' character) – were added.\nBCPL handles bindings spanning separate compilation units in a unique way. There are no user-declarable global variables; instead there is a global vector, which is similar to "blank common" in Fortran. All data shared between different compilation units comprises scalars and pointers to vectors stored in a pre-arranged place in the global vector. Thus the header files (files included during compilation using the "GET" directive) become the primary means of synchronizing global data between compilation units, containing "GLOBAL" directives that present lists of symbolic names, each paired with a number that associates the name with the corresponding numerically addressed word in the global vector. As well as variables, the global vector also contains bindings for external procedures. This makes dynamic loading of compilation units very simple to achieve. Instead of relying on the link loader of the underlying implementation, effectively BCPL gives the programmer control of the linking process.\nBCPL is reputedly the language in which the original hello world program was written. The first MUD was also written in BCPL [1].\nSeveral operating systems were written partially or wholly in BCPL (for example, TRIPOS and significant parts of AmigaOS, including Kickstart and the earliest versions of AmigaDOS). BCPL was also the initial language used in the seminal Xerox PARC Alto project, the first modern personal computer; among many other influential projects, the ground-breaking Bravo document preparation system was written in BCPL.\nBy 1970, implementations existed for the Honeywell 635 and 645, the IBM 360, the TX-2, the CDC 6400, the Univac 1108, the PDP-9, the KDF 9 and the Atlas 2. In 1979 implementations existed for at least 25 architectures; in 2001 it sees little use.\nThe philosophy of BCPL can be summarised by quoting from the book BCPL, the language and its compiler:\nThe philosophy of BCPL is not one of the tyrant who thinks he knows best and lays down the law on what is and what is not allowed; rather, BCPL acts more as a servant offering his services to the best of his ability without complaint, even when confronted with apparent nonsense. The programmer is always assumed to know what he is doing and is not hemmed in by petty restrictions.\nThe design, and philosophy, of BCPL strongly influenced B, which in turn influenced C.\nExamples\nThese complete and compilable examples are from Martin Richards'' BCPL distribution.\nPrinting factorials:\nGET "libhdr"\nLET start() = VALOF\n{ FOR i = 1 TO 5 DO writef("fact(%n) = %i4*n", i, fact(i))\nRESULTIS 0\n}\nAND fact(n) = n=0 -> 1, n*fact(n-1)\nCounting solutions to the N queens problem:\nGET "libhdr"\nGLOBAL { count:200; all:201\n}\nLET try(ld, row, rd) BE TEST row=all\nTHEN count := count + 1\nELSE { LET poss = all & ~(ld | row | rd)\nUNTIL poss=0 DO\n{ LET p = poss & -poss\nposs := poss - p\ntry(ld+p << 1, row+p, rd+p >> 1)\n}\n}\nLET start() = VALOF\n{ all := 1\nFOR i = 1 TO 12 DO\n{ count := 0\ntry(0, 0, 0)\nwritef("Number of solutions to %i2-queens is %i5*n", i, count)\nall := 2*all + 1\n}\nRESULTIS 0\n}\nSources\nMartin Richards, The BCPL Reference Manual (Memorandum M-352, Project MAC, Cambridge, July, 1967)\nMartin Richards, BCPL - a tool for compiler writing and systems programming (Proceedings of the Spring Joint Computer Conference, Vol 34, pp 557-566, 1969)\nMartin Richards, Arthur Evans, Robert F. Mabee, The BCPL Reference Manual (MAC TR-141, Project MAC, Cambridge, 1974)\nMartin Richards, C. Whitby-Strevens, BCPL, the language and its compiler (Cambridge University Press, 1980) ISBN 0-521-28681-6\nMartin Richards'' BCPL distribution\nMartin Richards''s BCPL Reference Manual by Dennis M. Ritchie also includes some fascinating commentary from him about BCPL''s influence on C\nBCPL entry in the Jargon File\n"http://en.wikipedia.org/wiki/BCPL"\nCategories: Systems programming languages | 1960s software | Curly bracket programming languages','\n',char(10)));
INSERT INTO pages VALUES('VHDL','http://web.archive.org/web/20081221084051/http://en.wikipedia.org:80/wiki/VHDL','en','2008-12-21 00:00:00',replace('The introduction to this article may not adequately summarize its contents. To comply with Wikipedia''s lead section guidelines, it should be expanded to provide an accessible overview of the article''s key points.\nThis article is written like a manual or guidebook. Please help rewrite this article from a neutral point of view. Mark blatant copyright violations for speedy deletion, using {{db-copyvio}}.(December 2008)\nVHDL\nParadigm\nbehavioural\nAppeared in\n1980s\nTyping discipline\nstrong\nWebsite\nIEEE VASG\nVHDL (VHSIC hardware description language) is commonly used as a design-entry language for field-programmable gate arrays and application-specific integrated circuits in electronic design automation of digital circuits.\n1 History\n2 Design\n3 Getting started\n4 Code examples\n4.1 Synthesizeable constructs and VHDL templates\n4.2 MUX templates\n4.3 Latch templates\n4.4 D-type flip-flops\n4.5 The counter example\n4.6 Simulation-only constructs\n5 References\n6 See also\n7\n8 Further reading\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nVHDL was originally developed at the behest of the US Department of Defense in order to document the behavior of the ASICs that supplier companies were including in equipment. That is to say, VHDL was developed as an alternative to huge, complex manuals which were subject to implementation-specific details.\nThe idea of being able to simulate this documentation was so obviously attractive that logic simulators were developed that could read the VHDL files. The next step was the development of logic synthesis tools that read the VHDL, and output a definition of the physical implementation of the circuit. Modern synthesis tools can extract RAM, counter, and arithmetic blocks out of the code, and implement them according to what the user specifies. Thus, the same VHDL code could be synthesized differently for lowest area, lowest power consumption, highest clock speed, or other requirements.\nVHDL borrows heavily from the Ada programming language in both concepts (for example, the slice notation for indexing part of a one-dimensional array) and syntax. VHDL has constructs to handle the parallelism inherent in hardware designs, but these constructs (processes) differ in syntax from the parallel constructs in Ada (tasks). Like Ada, VHDL is strongly-typed and is not case sensitive. There are many features of VHDL which are not found in Ada, such as an extended set of Boolean operators including nand and nor, in order to represent directly operations which are common in hardware. VHDL also allows arrays to be indexed in either direction (ascending or descending) because both conventions are used in hardware, whereas Ada (like most programming languages) provides ascending indexing only. The reason for the similarity between the two languages is that the Department of Defense required as much of the syntax as possible to be based on Ada, in order to avoid re-inventing concepts that had already been thoroughly tested in the development of Ada.\nThe initial version of VHDL, designed to IEEE standard 1076-1987, included a wide range of data types, including numerical (integer and real), logical (bit and boolean), character and time, plus arrays of bit called bit_vector and of character called string.\nA problem not solved by this edition, however, was "multi-valued logic", where a signal''s drive strength (none, weak or strong) and unknown values are also considered. This required IEEE standard 1164, which defined the 9-value logic types: scalar std_ulogic and its vector version std_ulogic_vector.\nThe second issue of IEEE 1076, in 1993, made the syntax more consistent, allowed more flexibility in naming, extended the character type to allow ISO-8859-1 printable characters, added the xnor operator, etc.\nMinor changes in the standard (2000 and 2002) added the idea of protected types (similar to the concept of class in C++) and removed some restrictions from port mapping rules.\nIn addition to IEEE standard 1164, several child standards were introduced to extend functionality of the language. IEEE standard 1076.2 added better handling of real and complex data types. IEEE standard 1076.3 introduced signed and unsigned types to facilitate arithmetical operations on vectors. IEEE standard 1076.1 (known as VHDL-AMS) provided analog and mixed-signal circuit design extensions.\nSome other standards support wider use of VHDL, notably VITAL (VHDL Initiative Towards ASIC Libraries) and microwave circuit design extensions.\nIn June 2006, VHDL Technical Committee of Accellera (delegated by IEEE to work on next update of the standard) approved so called Draft 3.0 of VHDL-2006. While maintaining full compatibility with older versions, this proposed standard provides numerous extensions that make writing and managing VHDL code easier. Key changes include incorporation of child standards (1164, 1076.2, 1076.3) into the main 1076 standard, an extended set of operators, more flexible syntax of ''case'' and ''generate'' statements, incorporation of VHPI (interface to C/C++ languages) and a subset of PSL (Property Specification Language). These changes should improve quality of synthesizable VHDL code, make testbenches more flexible, and allow wider use of VHDL for system-level descriptions.\nIn February 2008, Accellera approved VHDL 4.0 also informally known as VHDL 2008, which addressed more than 90 issues discovered during the trial period for version 3.0 and includes enhanced generic types. In 2008, Accellera plans to release VHDL 4.0 to the IEEE for balloting for inclusion in IEEE 1076-2008.\nDesign\nThis article or section contains weasel words, vague phrasing that often accompanies biased or unverifiable information. Such statements should be clarified or removed. (February 2007)\nVHDL is a fairly general-purpose language, and it doesn''t require a simulator on which to run the code. There are a lot of VHDL compilers, which build executable binaries. It can read and write files on the host computer, so a VHDL program can be written that generates another VHDL program to be incorporated in the design being developed. Because of this general-purpose nature, it is possible to use VHDL to write a testbench that verifies the functionality of the design using files on the host computer to define stimuli, interacts with the user, and compares results with those expected. This is similar to the capabilities of the Verilog language. VHDL is a strongly typed language, and as a result is considered by some to be superior to Verilog. The superiority of one language over the other has been the subject of intense debate among developers, for a long time. Both languages make it relatively easy for an inexperienced developer to produce code that simulates successfully but that cannot be synthesized into a real device, or is too large to be practicable. One particular pitfall in both languages is the accidental production of transparent latches rather than D-type flip-flops as storage elements.\nVHDL is not a case sensitive language. One can design hardware in a VHDL IDE (such as Xilinx or Quartus) to produce the RTL schematic of the desired circuit. After that, the generated schematic can be verified using simulation software (such as ModelSim) which shows the waveforms of inputs and outputs of the circuit after generating the appropriate testbench. To generate an appropriate testbench for a particular circuit or VHDL code, the inputs have to be defined correctly. For example, for clock input, a loop process or an iterative statement is required.\nThe key advantage of VHDL when used for systems design is that it allows the behavior of the required system to be described (modeled) and verified (simulated) before synthesis tools translate the design into real hardware (gates and wires).\nAnother benefit is that VHDL allows the description of a concurrent system (many parts, each with its own sub-behavior, working together at the same time). VHDL is a Dataflow language, unlike procedural computing languages such as BASIC, C, and assembly code, which all run sequentially, one instruction at a time.\nA final point is that when a VHDL model is translated into the "gates and wires" that are mapped onto a programmable logic device such as a CPLD or FPGA, then it is the actual hardware being configured, rather than the VHDL code being "executed" as if on some form of a processor chip.\nGetting started\nAlthough background in a computer programming language (such as C) is helpful, it is not essential. Free VHDL simulators are readily available, and although these are limited in functionality compared to commercial VHDL simulators, they are more than sufficient for independent study. If the user''s goal is to learn RTL coding, (that is, design hardware circuits in VHDL, as opposed to simply document or simulate circuit behavior), then a synthesis/design package is also needed.\nAs with VHDL simulators, free FPGA synthesis tools are readily available, and are more than adequate for independent study. Feedback from the synthesis tool gives the user a feel for the relative efficiencies of different coding styles. A schematic/gate viewer shows the user the synthesized design as a navigable netlist diagram. Many FPGA design packages offer alternative design input methods, such as block-diagram (schematic) and state-diagram capture. These provide a useful starting template for coding certain types of repetitive structures, or complex state-transition diagrams. Finally, the included tutorials and examples are valuable aids.\nNearly all FPGA design and simulation flows support both Verilog and VHDL, allowing the user to learn either or both languages.\nFree design & simulation packages for VHDL/Verilog:\nVendor\nTrial Software\nLicense\nSimulator\nSynthesizer\nRTL view\nGate view\nActel\nLibero gold\none year free license\nModelSim Actel Edition\nSynplify Actel Edition\nNo\nyes**\nAldec\nActive-HDL (Student Edition)\none year free license\nAldec (mixed language) Student\nAll Synthesis (interfaces)\nyes\nyes\nAltera\nQuartus II web edition\n6 months renewable free license\nModelSim Altera Edition\nAltera Quartus II\nyes\nyes**\nLattice\nispLever starter\n6 months renewable free license\nPrecision/Synplify Lattice Edition\nNo\nyes\nDolphin\nnone\nfree seduction license\nSMASH\nno\n?\n?\nMentor\nnone\n6 months renewable free license\nModelSim PE Student Edition\nno\nyes\nno\nXilinx\nISE webpack\nfree license\nISE Simulator*\nXilinx XST\nyes\nyes**\nBlue Pacific\nBlueHDL\nfree license\nBlueSim\n?\n?\n?\nGHDL\nGHDL\nGPL\nGHDL\nno\nvia GTKWave\nno\n* If Modelsim is installed on the computer, the ISE software can call ModelSim''s features if desired. (ISE 9.2i comes with an integrated simulator)\n** Limited to vendor''s device-database\nCode examples\nThis article or section may contain poor or irrelevant examples.\nArticles should only contain pertinent examples.\nPlease improve the article or discuss proposed changes on the talk page.\nYou can edit the article to add more encyclopaedic text. See Wikipedia''s guide to writing better articles for further suggestions.\nIn VHDL, a design consists at a minimum of an entity which describes the interface and an architecture which contains the actual implementation. In addition, most designs import library modules. Some designs also contain multiple architectures and configurations.\nA simple AND gate in VHDL would look something like this:\n-- (this is a VHDL comment)\n-- import std_logic from the IEEE library\nlibrary IEEE;\nuse IEEE.std_logic_1164.all;\n-- this is the entity\nentity ANDGATE is\nport (\nIN1 : in std_logic;\nIN2 : in std_logic;\nOUT1: out std_logic);\nend ANDGATE;\narchitecture RTL of ANDGATE is\nbegin\nOUT1 <= IN1 and IN2;\nend RTL;\nWhile the example above may seem very verbose to HDL beginners, one should keep in mind that many parts are either optional or need to be written only once. And generally simple functions like this are part of a larger behavioral module, instead of having a separate module for something so simple. In addition, use of elements such as the std_logic type might at first seem an overkill. One could easily use the built-in bit type and avoid the library import in the beginning. However, using this 9-valued logic (U,X,0,1,Z,W,H,L,-) instead of simple bits (0,1) offers a very powerful simulation and debugging tool to the designer which currently does not exist in any other HDL.\nIn the examples that follow, you will see that VHDL code can be written in a very compact form. However, the experienced designers usually avoid these compact forms and use a more verbose coding style for the sake of readability and maintainability. Another advantage to the verbose coding style is the smaller amount of resources used when programming to a Programmable Logic Device such as a CPLD.\nSynthesizeable constructs and VHDL templates\nVHDL is frequently used for two different goals: simulation of electronic designs and synthesis of such designs. Synthesis is a process where a VHDL is compiled and mapped into an implementation technology such as an FPGA or an ASIC. Many FPGA vendors have free (or inexpensive) tools to synthesize VHDL for use with their chips, where ASIC tools are often very expensive.\nNot all constructs in VHDL are suitable for synthesis. For example, most constructs that explicitly deal with timing such as wait for 10ns; are not synthesizable despite being valid for simulation. While different synthesis tools have different capabilities, there exists a common synthesizable subset of VHDL that defines what language constructs and idioms map into common hardware for many synthesis tools. IEEE 1076.6 defines a subset of the language that is considered the official synthesis subset. It is generally considered a "best practice" to write very idiomatic code for synthesis as results can be incorrect or suboptimal for non-standard constructs.\nSome examples of code that map into hardware multiplexers in common tools follow:\nMUX templates\nThe multiplexer, or ''MUX'' as it is usually called, is a simple construct very common in hardware design. The example below demonstrates a simple two to one MUX, with inputs A and B, selector S and output X:\n-- template 1:\nX <= A when S = ''1'' else B;\n-- template 2:\nwith S select X <= A when ''1'' else B;\n-- template 3:\nprocess(A,B,S)\nbegin\ncase S is\nwhen ''1''\n=> X <= A;\nwhen others => X <= B;\nend case;\nend process;\n-- template 4:\nprocess(A,B,S)\nbegin\nif S = ''1'' then\nX <= A;\nelse\nX <= B;\nend if;\nend process;\n-- template 5 - 4:1 MUX, where S is a 2-bit std_logic_vector :\nprocess(A,B,C,D,S)\nbegin\ncase S is\nwhen "00"\n=> X <= A;\nwhen "01"\n=> X <= B;\nwhen "10"\n=> X <= C;\nwhen others => X <= D; -- or when "11"\nend case;\nend process;\nThe three last templates make use of what VHDL calls ''sequential'' code. The sequential sections are always placed inside a process and have a slightly different syntax which may resemble more traditional programming languages.\nLatch templates\nA transparent latch is basically one bit of memory which is updated when an enable signal is raised:\n-- latch template 1:\nQ <= D when Enable = ''1'' else Q;\n-- latch template 2:\nprocess(D,Enable)\nbegin\nif Enable = ''1'' then\nQ <= D;\nend if;\nend process;\nA SR-latch uses a set and reset signal instead:\n-- SR-latch template 1:\nQ <= ''1'' when S = ''1'' else\n''0'' when R = ''1'' else Q;\n-- SR-latch template 2:\nprocess(S,R)\nbegin\nif S = ''1'' then\nQ <= ''1'';\nelsif R = ''1'' then\nQ <= ''0'';\nend if;\nend process;\nTemplate 2 has an implicit "else Q <= Q;" which may be explicitly added if desired.\n-- This one is a RS-latch (i.e. reset dominates)\nprocess(S,R)\nbegin\nif R = ''1'' then\nQ <= ''0'';\nelsif S = ''1'' then\nQ <= ''1'';\nend if;\nend process;\nD-type flip-flops\nThe D-type flip-flop samples an incoming signal at the rising or falling edge of a clock. The DFF is the basis for all synchronous logic.\n-- simplest DFF template (not recommended)\nQ <= D when rising_edge(CLK);\n-- recommended DFF template:\nprocess(CLK)\nbegin\n-- use falling_edge(CLK) to sample at the falling edge instead\nif rising_edge(CLK) then\nQ <= D;\nend if;\nend process;\n-- alternative DFF template:\nprocess\nbegin\nwait until rising_edge(CLK);\nQ <= D;\nend process;\nSome flip-flops also have Enable signals and asynchronous or synchronous Set and Reset signals:\n-- template for asynchronous reset with clock enable:\nprocess(CLK, RESET)\nbegin\nif RESET = ''1'' then\n-- or ''0'' if RESET is active low...\nQ <= ''0'';\nelsif rising_edge(CLK) then\nif Enable = ''1'' then\n-- or ''0'' if Enable is active low...\nQ <= D;\nend if;\nend if;\nend process;\n-- template for synchronous reset with clock enable:\nprocess(CLK)\nbegin\nif rising_edge(CLK) then\nif RESET = ''1'' then\nQ <= ''0'';\nelsif Enable = ''1'' then\n-- or ''0'' if Enable is active low...\nQ <= D;\nend if;\nend if;\nend process;\nA common beginner mistake is to have a set or reset input but not use it. For example, the following two snippets are not equal, the first one is a simple D-type flip-flop, while the second one is a DFF with a feedback MUX.\n-- simple D-type flip-flop\nprocess(CLK)\nbegin\nif rising_edge(CLK) then\nQ <= D;\nend if;\nend process;\n-- BAD VHDL: this does NOT make the flip-flop a DFF without a reset!!\nprocess(CLK, RESET)\nbegin\nif RESET = ''1'' then\n-- do nothing. Q is not set here...\nelsif rising_edge(CLK) then\nQ <= D;\nend if;\nend process;\nThis is very similar to the ''transparent latch'' mistake mentioned earlier.\nThe counter example\nThe following example is an up-counter with asynchronous reset, parallel load and configurable width. It demonstrates the use of the ''unsigned'' type and VHDL generics. The generics are very close to arguments or templates in other traditional programming languages like C or C++.\nlibrary IEEE;\nuse IEEE.std_logic_1164.all;\nuse IEEE.numeric_std.all;\n-- for the unsigned type\nentity counter_example is\ngeneric ( WIDTH : integer := 32);\nport (\nCLK, RESET, LOAD : in std_logic;\nDATA : in\nunsigned(WIDTH-1 downto 0);\nQ\n: out unsigned(WIDTH-1 downto 0));\nend entity counter_example;\narchitecture counter_example_a of counter_example is\nsignal cnt : unsigned(WIDTH-1 downto 0);\nbegin\nprocess(RESET, CLK)\nbegin\nif RESET = ''1'' then\ncnt <= (others => ''0'');\nelsif rising_edge(CLK) then\nif LOAD = ''1'' then\ncnt <= DATA;\nelse\ncnt <= cnt + 1;\nend if;\nend if;\nend process;\nQ <= cnt;\nend architecture counter_example_a;\nWhile not recommended for new designs, the std_logic_vector type can be used instead of the unsigned type.\nMore complex counters may add if/then/else statements within the rising_edge(CLK) elsif to add other functions, such as count enables, stopping or rolling over at some count value, generating output signals like terminal count signals, etc. Care must be taken with the ordering and nesting of such controls if used together, in order to produce the desired priorities and minimize the number of logic levels needed.\nSimulation-only constructs\nA large subset of VHDL cannot be translated into hardware. This subset is known as the non-synthesizable or the simulation-only subset of VHDL and can only be used for prototyping, simulation and debugging. For example, the following code will generate a clock with the frequency of 50 MHz. It can, for example, be used to drive a clock input in a design during simulation. It is, however, a simulation-only construct and cannot be implemented in hardware.\nprocess\nbegin\nCLK <= ''1''; wait for 10 ns;\nCLK <= ''0''; wait for 10 ns;\nend process;\nThe simulation-only constructs can be used to build complex waveforms in very short time. Such waveform can be used, for example, as test vectors for a complex design or as a prototype of some synthesizable logic that will be implemented in future.\nprocess\nbegin\nwait until START = ''1''; -- wait until START is high\nfor i in 1 to 10 loop -- then wait for a few clock periods...\nwait until rising_edge(CLK);\nend loop;\nfor i in 1 to 10 loop\n-- write numbers 1 to 10 to DATA, 1 every cycle\nDATA <= to_unsigned(i, 8);\nwait until rising_edge(CLK);\nend loop;\n-- wait until the output changes\nwait on RESULT;\n-- now raise ACK for clock period\nACK <= ''1'';\nwait until rising_edge(CLK);\nACK <= ''0'';\n-- and so on...\nend process;\nReferences\nThis article does not cite any references or sources. Please help improve this article by adding citations to reliable sources. Unverifiable material may be challenged and removed. (August 2006)\n[1] VHDL Primer by J.Bhasker.\nSee also\nVerilog\nSystemC\nRegister transfer level\nElectronic design automation\nComplex programmable logic device (CPLD)\nField Programmable Gate Array (FPGA)\nApplication Specific Integrated Circuit (ASIC)\nFree VHDL Simulator from Xilinx [1]\nThe Wikibook Programmable Logic has a page on the topic of\nVHDL Module Structure\nThe FAQ of news://comp.lang.vhdl\ncomp.lang.vhdl Newsgroup\nIEEE VASG (VHDL Analysis and Standardization Group) - Official VHDL Working Group\nGHDL, a complete Free Software VHDL compiler/simulator, built on top of GCC.\nJohn''s FPGA Page - List of VHDL and FPGA resources, including VHDL tutorials.\nwww.opencores.org - home of many open source VHDL and Verilog projects\nFurther reading\nJohan Sandstrom (October 1995). "Comparing Verilog to VHDL Syntactically and Semantically", Integrated System Design, EE Times.\n— Sandstrom presents a table relating VHDL constructs to Verilog constructs.\nQualis Design Corporation (2000-07-20). "VHDL quick reference card" (PDF).\n1.1. Qualis Design Corporation.\nQualis Design Corporation (2000-07-20). "1164 packages quick reference card" (PDF).\n1.0. Qualis Design Corporation.\nQualis Design Corporation (2007-03-29). "VHDL quick reference card" (PDF).\n2.2. Qualis Design Corporation.\nQualis Design Corporation (2007-03-29). "1164 packages quick reference card" (PDF).\n2.2. Qualis Design Corporation.\nJanick Bergerdon, "Writing Testbenches: Functional Verification of HDL Models", 2000, ISBN 0-7923-7766-4. (The HDL Testbench Bible)\n"http://en.wikipedia.org/wiki/VHDL"\nCategories: Ada programming language family | Hardware description languagesHidden categories: Wikipedia introduction cleanup | All pages needing cleanup | Wikipedia articles needing style editing from December 2008 | All articles needing style editing | Articles with weasel words | All articles with unsourced statements | Articles with unsourced statements since April 2008 | Articles with too many examples | Articles lacking sources from August 2006 | All articles lacking sources','\n',char(10)));
INSERT INTO pages VALUES('CouchDB','http://web.archive.org/web/20081219102950/http://en.wikipedia.org:80/wiki/CouchDB','en','2008-12-19 00:00:00',replace('Apache CouchDB\nDeveloped by\nApache Software Foundation\nInitial release\n2005\nWritten in\nErlang\nOS\nCross-platform\nAvailable in\nEnglish\nType\nDocument-oriented database\nLicense\nApache Licence\nWebsite\nhttp://couchdb.apache.org/\nFree software portal\nApache CouchDB, commonly referred to as CouchDB, is a free software document-oriented database written in the Erlang programming language. It is designed for extreme scalability and is easily deployed to multi-core or multi-server clusters.\nLike other document-oriented database systems, such as Lotus Notes, CouchDB is not a Relational Database Management System. Instead of storing data in rows and columns, the database manages a collection of JSON documents (early versions of CouchDB used XML). As a result, it is often compared with column-oriented datastores like Google''s BigTable; however, CouchDB is not a column-oriented store, since the documents in a collection need not share a schema.\nViews are defined with Aggregate functions and filters and are computed in parallel, much like MapReduce. Views are generally stored in the database and their indexes updated continuously, although queries may introduce temporary views.\nCouchDB exposes a RESTful HTTP API and a large number of pre-written clients are available. Additionally, a plugin architecture allows for using different computer languages as the view server such as JavaScript (default), PHP, Ruby and Python. Support for other languages can be easily added.\nCouchDB supports a view system using external socket servers and a JSON based protocol. [1] As a consequence, view servers have been developed in a series of languages.\nCouchDB was accepted into Apache incubation in February 2008[2] and became a top level project in November 2008[3].\nReferences\n^ View Server Documentation on wiki.apache.org\n^ Apache mailing list announcement on mail-archives.apache.org\n^ Re: Proposed Resolution: Establish CouchDB TLP on mail-archives.apache.org\nSee also\nDocument-oriented database\nMnesia\nOfficial CouchDB Project Website\nOfficial CouchDB Wiki\nv • d • e\nApache Software Foundation\nTop level projects\nActiveMQ · Ant · Apache HTTP Server · APR · Beehive · Cayenne · Cocoon · Commons · CouchDB · CXF · Derby · Directory · Excalibur · Felix · Forrest · Geronimo · Gump · Hadoop · Harmony · HiveMind · iBATIS · Jackrabbit · James · Lenya · Maven · mod_perl · MyFaces · OFBiz · OpenEJB · OpenJPA · POI · Roller · Shale · SpamAssassin · stdcxx · Struts · Tapestry · Tomcat · Tuscany · Velocity · Wicket · XMLBeans\nOther projects\nJakarta Project · Apache Lucene · Apache XML · Apache Incubator · Mobile Web Server\nSub-projects\nBCEL · BSF · Cactus · Camel · JMeter · Slide · Xerces · Batik · FOP · Log4j · XAP · River · ServiceMix · Log4Net · Abdera · Ivy · ODE · JSPWiki\nLicense: Apache License · Website: http://apache.org/\nThis database software-related article is a stub. You can help Wikipedia by expanding it.\n"http://en.wikipedia.org/wiki/CouchDB"\nCategories: Database software stubs | Erlang programming language | Database management systems | Open source database management systems | Document-oriented databases','\n',char(10)));
INSERT INTO pages VALUES('ECMAScript','http://web.archive.org/web/20081220035659/http://en.wikipedia.org:80/wiki/ECMAScript','en','2008-12-20 00:00:00',replace('ECMAScript\nParadigm\nMulti-paradigm: prototype-oriented, functional, imperative, scripting\nAppeared in\n1997\nDesigned by\nBrendan Eich, Ecma International\nTyping discipline\nduck, weak, dynamic\nDialects\nJavaScript, ActionScript, JScript, QtScript, DMDScript, InScript\nInfluenced by\nSelf, HyperTalk, AWK, C, Perl, Python, Java\nECMAScript\nFilename extension\n.es\nInternet media type\napplication/ecmascript[1]\nDeveloped by\nSun Microsystems,\nEcma International\nInitial release\nJune 1997\nLatest release\nEdition 3 / December 1999\nType of format\nScripting language\nExtended from\nJavaScript\nWebsite\nECMA-262, ECMA-290,\nECMA-327, ECMA-357\nThis article is part of\nthe JavaScript series.\nJavaScript\nJavaScript syntax\nECMAScript\nJavaScript topics\nThis box: view • talk • edit\nECMAScript is a scripting language, standardized by Ecma International in the ECMA-262 specification. The language is widely used on the web, and is often confused with JavaScript or JScript, the two major dialects from which ECMAScript was standardized.\n1 History\n2 Versions\n3 Features\n4 Syntax\n5 Dialects\n6 Version correspondence\n7 Fourth edition\n7.1 Features\n7.2 Bug fixes and backwards compatibility\n7.3 History\n7.4 ECMAScript 3.1\n7.5 ECMAScript Harmony\n8 See also\n9 References\n10\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nHistory\nJavaScript was originally developed by Brendan Eich of Netscape under the name Mocha, later LiveScript, and finally renamed to JavaScript.[2] In December 1995, Sun Microsystems and Netscape announced JavaScript in a press release.[3] In March 1996 Netscape Navigator 2.0 was out, featuring support for JavaScript.\nDue to the wide-spread success of JavaScript as a client-side scripting language for web pages, Microsoft developed a compatible language known as JScript. JScript added new date methods to fix the non-Y2K-friendly methods in JavaScript, which were based on java.util.Date.[4] JScript was included in Internet Explorer 3.0, released in August 1996.\nNetscape submitted JavaScript to Ecma International for standardization; the work on the specification, ECMA-262, began in November 1996.[5] The first edition of ECMA-262 was adopted by the ECMA General Assembly of June 1997.[6]\nECMAScript is the name of the scripting language standardized in ECMA-262. Both JavaScript and JScript aim to be compatible with ECMAScript, while providing additional features not described in the ECMA specification.\nThe name "ECMAScript" was a compromise between the organizations involved in standardizing the language, especially Netscape and Microsoft. Brendan Eich, the creator of JavaScript, is on record as saying that "ECMAScript was always an unwanted trade name that sounds like a skin disease."[7]\nVersions\nThere are three editions of ECMA-262 published, and the work on the fourth edition is in progress.\nEdition\nDate published\nDifferences to the previous edition\n1\nJune 1997\nFirst edition, editor Guy L. Steele, Jr.\n2\nJune 1998\nEditorial changes to keep the specification fully aligned with ISO/IEC 16262 international standard; editor Mike Cowlishaw.\n3\nDecember 1999\nAdded regular expressions, better string handling, new control statements, try/catch exception handling, tighter definition of errors, formatting for numeric output and other enhancements; editor Mike Cowlishaw.\n4\nWork in progress\nMultiple new concepts and language features — see the section "Fourth edition" below\nIn June 2004 Ecma International published ECMA-357 standard, defining an extension to ECMAScript, known as E4X (ECMAScript for XML).\nECMA also defined a "Compact Profile" for ECMAScript — known as ES-CP, or ECMA 327 — which is designed for resource-constrained devices. Several of the dynamic features of ECMAScript (such as the "eval" function) are made optional, thus allowing the runtime to make more assumptions about the behaviour of programs and therefore make more performance trade-offs when running the code. The HD DVD standard is one place where the ECMAScript Compact Profile is used in favour of full ECMAScript in order to reduce processing and memory requirements on a device.\nFeatures\nFurther information: ECMAScript features\nThe ECMAScript language includes structured, dynamic, functional, and prototype-based features.\nSyntax\nFurther information: ECMAScript syntax\nDialects\nECMAScript is supported in many applications, especially web browsers, where it is commonly called JavaScript. Dialects typically include their own, different standard libraries, of which some are standardized separately — such as the W3C-specified DOM. This means that applications written in one dialect of ECMAScript will not likely work in another, unless they are designed to be compatible.\nNote that there is a distinction between a dialect and an implementation. A dialect of a language is significant variation of the language, while an implementation of a language/dialect executes a program written in that dialect.\nApplication\nDialect\nLatest dialect version\nCorresponding ECMAScript edition\nMozilla Firefox, the Gecko layout engine, SpiderMonkey, and Rhino 7\nJavaScript 1\n1.8\nECMA-262, edition 3\nInternet Explorer, the Trident layout engine\nJScript\n5.7\nECMA-262, edition 3\nOpera\nECMAScript, with both JavaScript and JScript extensions\n1.3/1.5\nECMA-262, edition 3\nKHTML layout engine, KDE''s Konqueror, and Apple''s Safari8\nJavaScript 1\n1.5\nECMA-262, edition 3 6\nAppweb Web Server, Samba 4\nEjscript\n0.9.2\nECMA-262, edition 4 (preliminary) 9\nMicrosoft .NET Framework\nJScript .NET\n8.0\nECMA-262, edition 3 2\nAdobe Flash and Adobe Flex\nActionScript\n2\n3\nECMA-262, edition 3 3\nECMA-262, edition 4 (preliminary) 4\nAdobe Acrobat\nJavaScript 1\n1.5\nECMA-262, edition 3\nGeneral purpose scripting language\nDMDScript\n1.06\nECMA-262\nOpenLaszlo Platform\nJavaScript 1\n1.4\nECMA-262, edition 3 5\nCriScript, JScript for game platforms\nCriScript\n0.9.0\nECMA-262, edition 3\niCab\nInScript\n3.22\nECMA-262, edition 3\nMax/MSP\nJavaScript 1\n1.5\nECMA-262, edition 3\nNote (1): Mozilla manages the official version of JavaScript. Most non-Mozilla implementations claiming JavaScript "compliance" do not actually support most JavaScript extensions; rather, they target ECMA-262, edition 3.\nNote (2): Microsoft asserts that JScript 8.0 supports "almost all of the features of the ECMAScript Edition 3 Language Specification" but does not list the unsupported features.\nNote (3): In addition to supporting ECMA-262 edition 3, ActionScript 2 also included support of properties, methods, and mechanisms that were proposed in early draft specifications of as yet unseen versions of ECMAScript. It remains to be seen if ActionScript will stay in sync with future changes to the ECMAScript specifications.\nNote (4): Adobe asserts it implements the preliminary edition 4 of ECMA-262[8]\nNote (5): As of version 4, OpenLaszlo implements standard ECMAScript edition 3 with some preliminary ECMAScript edition 4 extensions[9]\nNote (6): The current WebKit binaries, as of April 2007, also implement at least part of the Javascript 1.6 extras\nNote (7): The Mozilla implementations, (SpiderMonkey in the C programming language and Rhino in the Java programming language), are used in several third-party programs, including the Yahoo! Widget Engine (Konfabulator) and the Macintosh system-level scripting language JavaScript OSA.\nNote (8): Apple''s Safari uses JavaScriptCore which is based on the KDE KJS library.\nNote (9): Embedthis asserts it implements the preliminary edition 4 of ECMA-262[10]\nVersion correspondence\nThe following table is based on [1] and [2]; items on the same line are approximately the same language.\nJavaScript\nJScript\nECMAScript\n1.0 (Netscape 2.0, March 1996)\n1.0 (IE 3.0 - early versions, August 1996)\n1.1 (Netscape 3.0, August 1996)\n2.0 (IE 3.0 - later versions, January 1997)\n1.2 (Netscape 4.0-4.05, June 1997)\n1.3 (Netscape 4.06-4.7x, October 1998)\n3.0 (IE 4.0, Oct 1997)\nEdition 1 (June 1997) / Edition 2 (June 1998)\n1.4 (Netscape Server only)\n4.0 (Visual Studio 6, no IE release)\n5.0 (IE 5.0, March 1999)\n5.1 (IE 5.01)\n1.5 (Netscape 6.0, Nov 2000; also\nlater Netscape and Mozilla releases)\n5.5 (IE 5.5, July 2000)\nEdition 3 (December 1999)\n5.6 (IE 6.0, October 2001)\n1.6 (Gecko 1.8, Firefox 1.5, November 2005)\nEdition 3, with some compliant enhancements: E4X, Array extras (e.g. Array.prototype.forEach), Array and String generics (New in JavaScript 1.6)\n1.7 (Gecko 1.8.1, Firefox 2, October 2006)\nEdition 3 plus all JavaScript 1.6 enhancements, plus Pythonic generators and array comprehensions ([a*a for (a in iter)]), block scope with let, destructuring assignment (var [a,b]=[1,2]) (New in JavaScript 1.7)\n1.8 (Gecko 1.9, Firefox 3, June 2008)\nEdition 3 plus all JavaScript 1.7 enhancements, plus expression closures (function(x) x * x), generator expressions, and more (New in JavaScript 1.8)\nJScript .NET (ASP.NET; no IE release)\n(JScript .NET is said to be designed with the participation of other ECMA members)\nJavaScript 2.0 (Work in progress)\nEdition 4 (Work in progress; see the section "Fourth edition" below).\nFourth edition\nThe ECMA-262 fourth edition is the first major update to ECMAScript since the third edition published in 1999. The specification (along with the reference implementation) is currently under development and was targeted for completion by October 2008.[11] An overview of the language was released by the working group on October 22, 2007.\nAs of August 2008, the ECMAScript 4th edition proposal has been scaled back into a project codenamed ECMAScript Harmony.\nFeatures\nThe new version of the language is mostly backwards compatible with ECMAScript 3 (see below), while adding multiple new features, such as:\nClasses\nStructural types\nPackages and namespaces\nOptional type annotations and static typing\nGenerators and iterators\nDestructuring assignment\nJSON encoding/decoding\nAlgebraic data types\nECMAScript 4 intends to better support "programming in the large" and to let programmers sacrifice some of the script''s ability to be dynamic for performance. For example, Tamarin — the virtual machine for ActionScript developed and open sourced by Adobe — has JIT compilation support for certain classes of scripts.\nBug fixes and backwards compatibility\nIn addition to introducing new features, some ES3 bugs are fixed in edition 4.[12] A document describing known incompatibilities between ES3 and ES4 is available.\nHistory\nWork started on Edition 4 after the ES-CP (Compact Profile) specification was completed, and continued for approximately 18 months where slow progress was made balancing the theory of Netscape''s JavaScript 2 specification with the implementation experience of Microsoft''s JScript .NET. After some time, the focus shifted to the E4X standard.\nThe update is not without controversy. In late 2007, a debate between Eich, now the Mozilla Foundation''s CTO, and Chris Wilson, Microsoft''s platform architect for Internet Explorer, became public on a number of blogs. Wilson cautioned that because the proposed changes to ECMAScript made it backwards incompatible in some respects to earlier versions of the language, the update amounted to "breaking the Web,"[13] and that stakeholders who opposed the changes were being "hidden from view".[14] Eich responded by stating that Wilson seemed to be "repeating falsehoods in blogs" and denied that there was attempt to suppress dissent and challenging critics to give specific examples of incompatibility.[15] He also pointed out that Microsoft Silverlight and Adobe AIR rely on C# and ActionScript 3 respectively, both of which are larger and more complex than ECMAScript Edition 3.[16]\nECMAScript 3.1\nMicrosoft, Yahoo, and other 4th edition dissenters formed their own subcommittee to design a less ambitious update of ECMAScript 3, tentatively named ECMAScript 3.1. This edition would focus on security and library updates with a large emphasis on compatibility. After the aforementioned public sparring, the ECMAScript 3.1 and ECMAScript 4 teams agreed to a compromise: the two editions would be worked on in parallel, with coordination between the teams to ensure that ECMAScript 3.1 remains a strict subset of ECMAScript 4 in both semantics and syntax.\nHowever, the differing philosophies in each team resulted in repeated breakages of the subset rule, and it remained doubtful that the ECMAScript 4 dissenters would ever support or implement ECMAScript 4 in the future. After over a year since the disagreement over the future of ECMAScript within the ECMA Technical Committee 39, the two teams reached a compromise: ECMA TC39 announced it would focus work on the ECMAScript 3.1 project with full collaboration of all parties, and it would target two interoperable implementations by early 2009.[17]\nECMAScript Harmony\nIn the same announcement, ECMA TC39 also stated that the ECMAScript 4 proposal would be superseded by a new project, code-named ECMAScript Harmony. ECMAScript Harmony will include syntactic extensions, but the changes will be more modest than ECMAScript 4 in both semantic and syntactic innovation. Packages, namespaces and early binding from ECMAScript 4 are no longer included for planned releases. In addition, other goals and ideas from ECMAScript 4 are being rephrased to keep consensus in the committee; these include a notion of classes based on existing ECMAScript 3 concepts combined with proposed ECMAScript 3.1 extensions.[18] As of August 2008, there is no publicly announced release date for ECMAScript Harmony. Depending on how ECMAScript 3.1 is officially named, ECMAScript Harmony may end up being the new ECMAScript 4th edition.\nSee also\nActionScript\nComparison of layout engines (ECMAScript)\nDocument Object Model\nE4X\nList of ECMAScript engines\nJavaScript\nReferences\n^ RFC 4329\n^ InfoWorld: JavaScript creator ponders past, future\n^ JavaScript Press Release\n^ Brendan''s Roadmap Updates: Popularity\n^ JavaScript Standardization Press Release\n^ ECMAScript 3rd Edition specification\n^ es4-discuss: Will there be a suggested file suffix for es4?\n^ The Kiwi Project: AS3 language 101 for C/C++ coders\n^ OpenLaszlo 4\n^ Ejscript Overview\n^ es4-discuss: ES4 overview paper released\n^ John Resig - Bug Fixes in JavaScript 2\n^ IEBlog: ECMAScript 3 and Beyond\n^ Albatross!: What I think about ES4\n^ Brendan''s Roadmap Updates: Open letter to Chris Wilson\n^ Brendan''s Roadmap Updates: My @media Ajax Keynote\n^ ECMAScript Harmony announcement\n^ John Resig: ECMAScript Harmony\nECMAScript 4 Reference Implementation\nStandard ECMA-262 ECMAScript Language Specification 3rd edition (December 1999)\nStandard ECMA-290 ECMAScript Components Specification (June 1999)\nStandard ECMA-327 ECMAScript 3rd Edition Compact Profile (June 2001)\nStandard ECMA-357 ECMAScript for XML (E4X) Specification (June 2004)\nExport Root of the ECMAScript 4 Committee Wiki\nThe World of ECMAScript : John Resig''s map on ECMAScript\nv • d • e\nLayout engines\nList of layout engines\nAmaya · Boxely · Gecko · GtkHTML · Gzilla · HTMLayout · KHTML · Mariner · Presto · Prince · Tasman · Tkhtml · Trident · WebKit\nComparison of layout engines\nHTML · XML · XHTML · Graphics · CSS · DOM · HTML 5 · ECMAScript · SVG · Non-standard HTML\nv • d • e\nECMAScript (comparison)\nDialects\nActionScript · Caja · JavaScript / LiveScript · JScript · JavaScript OSA · JScript .NET · QtScript\nECMAScript engines\nInScript · JavaScriptCore · JScript · KJS · futhark · linear_b · Narcissus · QtScript · Rhino · SpiderMonkey · SunSpider · Tamarin · TraceMonkey · V8 · SquirrelFish\nOther\nBrendan Eich · Ecma International\nv • d • e\nStandards of Ecma International\nANSI escape code · C++/CLI · C# · CD-ROM · CLI · DDS · E4X · ECMAScript · Eiffel · FAT · FD · HVD · Office Open XML · U3D · UDF · UMD\n"http://en.wikipedia.org/wiki/ECMAScript"\nCategories: C programming language family | Curly bracket programming languages | Domain-specific programming languages | JavaScript dialect engines | JavaScript programming language family | Object-based programming languages | Prototype-based programming languages | Computer and telecommunication standards | Scripting languages | Ecma standards','\n',char(10)));
INSERT INTO pages VALUES('Cryptography','http://web.archive.org/web/20090108061116/http://en.wikipedia.org:80/wiki/Cryptography','en','2009-01-08 00:00:00',replace('The German Lorenz cipher machine, used in World War II for encryption of very high-level general staff messages\nCryptography (or cryptology; from Greek κρυπτός, kryptos, "hidden, secret"; and γράφω, gráphō, "I write", or -λογία, -logia, respectively)[1] is the practice and study of hiding information. In modern times, cryptography is considered a branch of both mathematics and computer science, and is affiliated closely with information theory, computer security, and engineering. Cryptography is used in applications present in technologically advanced societies; examples include the security of ATM cards, computer passwords, and electronic commerce, which all depend on cryptography.\n1 Terminology\n2 History of cryptography and cryptanalysis\n3 Modern cryptography\n3.1 Symmetric-key cryptography\n3.2 Public-key cryptography\n3.3 Cryptanalysis\n3.4 Cryptographic primitives\n3.5 Cryptosystems\n4 Legal issues involving cryptography\n4.1 Prohibitions\n4.2 Export Controls\n4.3 NSA involvement\n4.4 Digital Rights Management\n5 See also\n6 References\n7 Further reading\n8\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nTerminology\nUntil modern times, cryptography referred almost exclusively to encryption, the process of converting ordinary information (plaintext) into unintelligible gibberish (i.e., ciphertext).[2] Decryption is the reverse, moving from unintelligible ciphertext to plaintext. A cipher (or cypher) is a pair of algorithms which creates the encryption and the reversing decryption. The detailed operation of a cipher is controlled both by the algorithm and, in each instance, by a key. This is a secret parameter (ideally, known only to the communicants) for a specific message exchange context. Keys are important, as ciphers without variable keys are trivially breakable and therefore less than useful for most purposes. Historically, ciphers were often used directly for encryption or decryption, without additional procedures such as authentication or integrity checks.\nIn colloquial use, the term "code" is often used to mean any method of encryption or concealment of meaning. However, in cryptography, code has a more specific meaning; it means the replacement of a unit of plaintext (i.e., a meaningful word or phrase) with a code word (for example, apple pie replaces attack at dawn). Codes are no longer used in serious cryptography—except incidentally for such things as unit designations (e.g., Bronco Flight or Operation Overlord) —- since properly chosen ciphers are both more practical and more secure than even the best codes, and better adapted to computers as well.\nSome use the terms cryptography and cryptology interchangeably in English, while others use cryptography to refer specifically to the use and practice of cryptographic techniques, and cryptology to refer to the combined study of cryptography and cryptanalysis.[3][4]\nThe study of characteristics of languages which have some application in cryptology, i.e. frequency data, letter combinations, universal patterns, etc. is called cryptolinguistics.\nHistory of cryptography and cryptanalysis\nThe Ancient Greek scytale (rhymes with Italy), probably much like this modern reconstruction, may have been one of the earliest devices used to implement a cipher.\nMain article: History of cryptography\nBefore the modern era, cryptography was concerned solely with message confidentiality (i.e., encryption) — conversion of messages from a comprehensible form into an incomprehensible one, and back again at the other end, rendering it unreadable by interceptors or eavesdroppers without secret knowledge (namely, the key needed for decryption of that message). In recent decades, the field has expanded beyond confidentiality concerns to include techniques for message integrity checking, sender/receiver identity authentication, digital signatures, interactive proofs, and secure computation, amongst others.\nThe earliest forms of secret writing required little more than local pen and paper analogs, as most people could not read. More literacy, or opponent literacy, required actual cryptography. The main classical cipher types are transposition ciphers, which rearrange the order of letters in a message (e.g., ''help me'' becomes ''ehpl em'' in a trivially simple rearrangement scheme), and substitution ciphers, which systematically replace letters or groups of letters with other letters or groups of letters (e.g., ''fly at once'' becomes ''gmz bu podf'' by replacing each letter with the one following it in the English alphabet). Simple versions of either offered little confidentiality from enterprising opponents, and still don''t. An early substitution cipher was the Caesar cipher, in which each letter in the plaintext was replaced by a letter some fixed number of positions further down the alphabet. It was named after Julius Caesar who is reported to have used it, with a shift of 3, to communicate with his generals during his military campaigns, just like EXCESS-3 code in boolean algebra.\nEncryption attempts to ensure secrecy in communications, such as those of spies, military leaders, and diplomats. There is record of several early Hebrew ciphers as well. Cryptography is recommended in the Kama Sutra as a way for lovers to communicate without inconvenient discovery.[5] Steganography (i.e., hiding even the existence of a message so as to keep it confidential) was also first developed in ancient times. An early example, from Herodotus, concealed a message - a tattoo on a slave''s shaved head - under the regrown hair.[2] More modern examples of steganography include the use of invisible ink, microdots, and digital watermarks to conceal information.\nCiphertexts produced by classical ciphers (and some modern ones) always reveal statistical information about the plaintext, which can often be used to break them. After the discovery of frequency analysis by the Arab mathematician and polymath, Al-Kindi (also known as Alkindus), in the 9th century, nearly all such ciphers became more or less readily breakable by an informed attacker. Such classical ciphers still enjoy popularity today, though mostly as puzzles (see cryptogram). Essentially all ciphers remained vulnerable to cryptanalysis using this technique until the development of the polyalphabetic cipher, most clearly by Leon Battista Alberti around the year 1467, though there is some indication that it was known to earlier Arab mathematicians such as Al-Kindi.[6] Alberti''s innovation was to use different ciphers (i.e., substitution alphabets) for various parts of a message (perhaps for each successive plaintext letter in the limit). He also invented what was probably the first automatic cipher device, a wheel which implemented a partial realization of his invention. In the polyalphabetic Vigenère cipher, encryption uses a key word, which controls letter substitution depending on which letter of the key word is used. In the mid 1800s Babbage showed that polyalphabetic ciphers of this type remained partially vulnerable to extended frequency analysis techniques.[2]\nThe Enigma machine, used, in several variants, by the German military between the late 1920s and the end of World War II, implemented a complex electro-mechanical polyalphabetic cipher to protect sensitive communications. Breaking the Enigma cipher at the Biuro Szyfrów, and the subsequent large-scale decryption of Enigma traffic at Bletchley Park, was an important factor contributing to the Allied victory in WWII.[2]\nAlthough frequency analysis is a powerful and general technique against many ciphers, encryption was still often effective in practice; many a would-be cryptanalyst was unaware of the technique. Breaking a message without using frequency analysis essentially required knowledge of the cipher used and perhaps of the key involved, thus making espionage, bribery, burglary, defection, etc. more attractive approaches. It was finally explicitly recognized in the 19th century that secrecy of a cipher''s algorithm is not a sensible or practical safeguard; in fact, it was further realized any adequate cryptographic scheme (including ciphers) should remain secure even if the adversary fully understands the cipher algorithm itself. Secrecy of the key should alone be sufficient for a good cipher to maintain confidentiality under an attack. This fundamental principle was first explicitly stated in 1883 by Auguste Kerckhoffs and is generally called Kerckhoffs'' principle; alternatively and more bluntly, it was restated by Claude Shannon, the inventor of information theory and the fundamentals of theoretical cryptography, as Shannon''s Maxim — ''the enemy knows the system''.\nVarious physical devices and aids have been used to assist with ciphers. One of the earliest may have been the scytale of ancient Greece, a rod supposedly used by the Spartans as an aid for a transposition cipher. In medieval times, other aids were invented such as the cipher grille, also used for a kind of steganography. With the invention of polyalphabetic ciphers came more sophisticated aids such as Alberti''s own cipher disk, Johannes Trithemius'' tabula recta scheme, and Thomas Jefferson''s multi-cylinder (reinvented independently by Bazeries around 1900). Several mechanical encryption/decryption devices were invented early in the 20th century, and many patented, among them rotor machines — famously including the Enigma machine used by the German government and military from the late 20s and during World War II.[7] The ciphers implemented by better quality examples of these designs brought about a substantial increase in cryptanalytic difficulty after WWI.[8]\nThe development of digital computers and electronics after WWII made possible much more complex ciphers. Furthermore, computers allowed for the encryption of any kind of data representable within omputers in any binary format, unlike classical ciphers which only encrypted written language texts. Thus dissolved much of the utility of linguistic cryptanalytic approaches. Many computer ciphers can be characterized by their operation on binary bit sequences (sometimes in groups or blocks), unlike classical and mechanical schemes, which generally manipulate traditional characters (i.e., letters and digits) directly. However, computers have also assisted cryptanalysis, which has compensated to some extent for increased cipher complexity. Nonetheless, good modern ciphers have stayed ahead of cryptanalysis; it is typically the case that use of a quality cipher is very efficient (i.e., fast and requiring few resources), while breaking it requires an effort many orders of magnitude larger than before, making cryptanalysis so inefficient and impractical as to be effectively impossible. Alternate methods of attack, as before, have become more attractive in consequence.\nA credit card with smart card capabilities. The 3 by 5 mm chip embedded in the card is shown enlarged in the insert. Smart cards attempt to combine portability with the power to compute modern cryptographic algorithms.\nExtensive open academic research into cryptography is relatively recent; it began only in the mid-1970s. Medieval work was both less systematic, less comprehensive, and more likely to attract attention from the Church or others as Satatanicly inspried or dangerous to the state or those in power. In recent times, IBM personnel designed the algorithm that became the Federal (ie, US) Data Encryption Standard; Whitfield Diffie and Martin Hellman published their key agreement algorithm,[9]; and the RSA algorithm was published in Martin Gardner''s Scientific American column. Since then, cryptography has become a widely used tool in communications, computer networks, and computer security generally. Most modern cryptographic techniques can only keep their keys secret if certain mathematical problems are intractable, such as the integer factorisation or the discrete logarithm problems. Generally, there are no absolute proofs that a cryptographic technique is secure (but see one-time pad); at best, there are proofs that some techniques are secure if some computational problem is difficult to solve.\nAs well as being aware of cryptographic history, cryptographic algorithm and system designers must also sensibly consider probable future developments while working on their designs. For instance, continuous improvements in computer processing power have increased the scope of brute-force attacks, thus when specifying key lengths, the required key lengths are similarly advancing. The potential effects of quantum computing are already being considered by some cryptographic system designers; the announced imminence of small implementations of these machines may be making the need for this preemptive caution less than merely speculative.[10]\nEssentially, prior to the early 20th century, cryptography was chiefly concerned with linguistic and lexicographic patterns. Since then the emphasis has shifted, and cryptography now makes extensive use of mathematics, including aspects of information theory, computational complexity, statistics, combinatorics, abstract algebra, and number theory. Cryptography is, also, a branch of engineering, but an unusual one as it deals with active, intelligent, and malevolent opposition (see cryptographic engineering and security engineering); most other kinds of engineering need deal only with neutral natural forces. There is also active research examining the relationship between cryptographic problems and quantum physics (see quantum cryptography and quantum computing).\nModern cryptography\nThe modern field of cryptography can be divided into several areas of study. The chief ones are discussed here; see Topics in Cryptography for more.\nSymmetric-key cryptography\nMain article: Symmetric key algorithm\nSymmetric-key cryptography refers to encryption methods in which both the sender and receiver share the same key (or, less commonly, in which their keys are different, but related in an easily computable way). This was the only kind of encryption publicly known until June 1976.[9]\nOne round (out of 8.5) of the patented IDEA cipher, used in some versions of PGP for high-speed encryption of, for instance, e-mail\nThe modern study of symmetric-key ciphers relates mainly to the study of block ciphers and stream ciphers and to their applications. A block cipher is, in a sense, a modern embodiment of Alberti''s polyalphabetic cipher: block ciphers take as input a block of plaintext and a key, and output a block of ciphertext of the same size. Since messages are almost always longer than a single block, some method of knitting together successive blocks is required. Several have been developed, some with better security in one aspect or another than others. They are the modes of operation and must be carefully considered when using a block cipher in a cryptosystem.\nThe Data Encryption Standard (DES) and the Advanced Encryption Standard (AES) are block cipher designs which have been designated cryptography standards by the US government (though DES''s designation was finally withdrawn after the AES was adopted).[11] Despite its deprecation as an official standard, DES (especially its still-approved and much more secure triple-DES variant) remains quite popular; it is used across a wide range of applications, from ATM encryption[12] to e-mail privacy[13] and secure remote access.[14] Many other block ciphers have been designed and released, with considerable variation in quality. Many have been thoroughly broken. See Category:Block ciphers.[10][15]\nStream ciphers, in contrast to the ''block'' type, create an arbitrarily long stream of key material, which is combined with the plaintext bit-by-bit or character-by-character, somewhat like the one-time pad. In a stream cipher, the output stream is created based on a hidden internal state which changes as the cipher operates. That internal state is initially set up using the secret key material. RC4 is an example of a well-known, and widely used, stream cipher; see Category:Stream ciphers.[10]\nCryptographic hash functions (often called message digest functions) do not necessarily use keys, but are a related and important class of cryptographic algorithms. They take input data (often an entire message), and output a short, fixed length hash, and do so as a one-way function. For good ones, collisions (two plaintexts which produce the same hash) are essentially impossible to find. MD4 is a long-used hash function which is now broken, another in that series is MD5 against which much cryptanalytic progress has been made; the SHA hash function family, developed by the National Security Agency, includes better algorithms, though the first version was found to be defective and was withdrawn. A hash function design competition is underway and scheduled to select a new national standard by 2012.\nMessage authentication codes (MACs) are much like cryptographic hash functions, except that a secret key is used to authenticate the hash value[10] on receipt. These block an attack against plain hash functions.\nPublic-key cryptography\nMain article: Public-key cryptography\nSymmetric-key cryptosystems use the same key for encryption and decryption of a message, though a message or group of messages may have a different key than others. A significant disadvantage of symmetric ciphers is the key management necessary to use them securely. Each distinct pair of communicating parties must, ideally, share a different key, and perhaps each ciphertext exchanged as well. The number of keys required increases as the square of the number of network members, which very quickly requires complex key management schemes to keep them all straight and secret. The difficulty of securely establishing a secret key between two communicating parties, when a secure channel doesn''t already exist between them, also presents a chicken-and-egg problem which is a considerable practical obstacle for cryptography users in the real world.\nWhitfield Diffie and Martin Hellman, authors of the first paper on public-key cryptography\nIn a groundbreaking 1976 paper, Whitfield Diffie and Martin Hellman proposed the notion of public-key (also, more generally, called asymmetric key) cryptography in which two different but mathematically related keys are used — a public key and a private key.[16] A public key system is so constructed that calculation of one key (the ''private key'') is computationally infeasible from the other (the ''public key''), even though they are necessarily related. Instead, both keys are generated secretly, as an interrelated pair.[17] The historian David Kahn described public-key cryptography as "the most revolutionary new concept in the field since polyalphabetic substitution emerged in the Renaissance".[18]\nIn public-key cryptosystems, the public key may be freely distributed, while its paired private key must remain secret. The public key is typically used for encryption, while the private or secret key is used for decryption. Diffie and Hellman showed that public-key cryptography was possible by presenting the Diffie-Hellman key exchange protocol.[9]\nIn 1978, Ronald Rivest, Adi Shamir, and Len Adleman invented RSA, another public-key system.[19]\nIn 1997, it finally became publicly known that asymmetric key cryptography had been invented by James H. Ellis at GCHQ, a British intelligence organization, and that, in the early 1970s, both the Diffie-Hellman and RSA algorithms had been previously developed (by Malcolm J. Williamson and Clifford Cocks, respectively).[20]\nThe Diffie-Hellman and RSA algorithms, in addition to being the first publicly known examples of high quality public-key algorithms, have been among the most widely used. Others include the Cramer-Shoup cryptosystem, ElGamal encryption, and various elliptic curve techniques. See Category:Asymmetric-key cryptosystems.\nPadlock icon from the Firefox Web browser, meant to indicate a page has been sent in SSL or TLS-encrypted protected form. However, such an icon is not a guarantee of security; any subverted browser might mislead a user by displaying such an icon when a transmission is not actually being protected by SSL or TLS.\nIn addition to encryption, public-key cryptography can be used to implement digital signature schemes. A digital signature is reminiscent of an ordinary signature; they both have the characteristic that they are easy for a user to produce, but difficult for anyone else to forge. Digital signatures can also be permanently tied to the content of the message being signed; they cannot then be ''moved'' from one document to another, for any attempt will be detectable. In digital signature schemes, there are two algorithms: one for signing, in which a secret key is used to process the message (or a hash of the message, or both), and one for verification, in which the matching public key is used with the message to check the validity of the signature. RSA and DSA are two of the most popular digital signature schemes. Digital signatures are central to the operation of public key infrastructures and many network security schemes (eg, SSL/TLS, many VPNs, etc).[15]\nPublic-key algorithms are most often based on the computational complexity of "hard" problems, often from number theory. For example, the hardness of RSA is related to the integer factorization problem, while Diffie-Hellman and DSA are related to the discrete logarithm problem. More recently, elliptic curve cryptography has developed in which security is based on number theoretic problems involving elliptic curves. Because of the difficulty of the underlying problems, most public-key algorithms involve operations such as modular multiplication and exponentiation, which are much more computationally expensive than the techniques used in most block ciphers, especially with typical key sizes. As a result, public-key cryptosystems are commonly hybrid cryptosystems, in which a fast high-quality symmetric-key encryption algorithm is used for the message itself, while the relevant symmetric key is sent with the message, but encrypted using a public-key algorithm. Similarly, hybrid signature schemes are often used, in which a cryptographic hash function is computed, and only the resulting hash is digitally signed.[10]\nCryptanalysis\nMain article: Cryptanalysis\nMonument to Polish cryptologists who supported Allied victory, Poznan\nThe goal of cryptanalysis is to find some weakness or insecurity in a cryptographic scheme, thus permitting its subversion or evasion.\nIt is a commonly held misconception that every encryption method can be broken. In connection with his WWII work at Bell Labs, Claude Shannon proved that the one-time pad cipher is unbreakable, provided the key material is truly random, never reused, kept secret from all possible attackers, and of equal or greater length than the message.[21] Most ciphers, apart from the one-time pad, can be broken with enough computational effort by brute force attack, but the amount of effort needed may be exponentially dependent on the key size, as compared to the effort needed to use the cipher. In such cases, effective security could be achieved if it is proven that the effort required (i.e., "work factor", in Shannon''s terms) is beyond the ability of any adversary. This means it must be shown that no efficient method (as opposed to the time-consuming brute force method) can be found to break the cipher. Since no such showing can be made currently, as of today, the one-time-pad remains the only theoretically unbreakable cipher.\nThere are a wide variety of cryptanalytic attacks, and they can be classified in any of several ways. A common distinction turns on what an attacker knows and what capabilities are available. In a ciphertext-only attack, the cryptanalyst has access only to the ciphertext (good modern cryptosystems are usually effectively immune to ciphertext-only attacks). In a known-plaintext attack, the cryptanalyst has access to a ciphertext and its corresponding plaintext (or to many such pairs). In a chosen-plaintext attack, the cryptanalyst may choose a plaintext and learn its corresponding ciphertext (perhaps many times); an example is gardening, used by the British during WWII. Finally, in a chosen-ciphertext attack, the cryptanalyst may be able to choose ciphertexts and learn their corresponding plaintexts.[10] Also important, often overwhelmingly so, are mistakes (generally in the design or use of one of the protocols involved; see Cryptanalysis of the Enigma for some historical examples of this).\nCryptanalysis of symmetric-key ciphers typically involves looking for attacks against the block ciphers or stream ciphers that are more efficient than any attack that could be against a perfect cipher. For example, a simple brute force attack against DES requires one known plaintext and 255 decryptions, trying approximately half of the possible keys, to reach a point at which chances are better than even the key sought will have been found. But this may not be enough assurance; a linear cryptanalysis attack against DES requires 243 known plaintexts and approximately 243 DES operations.[22] This is a considerable improvement on brute force attacks.\nPublic-key algorithms are based on the computational difficulty of various problems. The most famous of these is integer factorization (e.g., the RSA algorithm is based on a problem related to integer factoring), but the discrete logarithm problem is also important. Much public-key cryptanalysis concerns numerical algorithms for solving these computational problems, or some of them, efficiently (ie, in a practical time). For instance, the best known algorithms for solving the elliptic curve-based version of discrete logarithm are much more time-consuming than the best known algorithms for factoring, at least for problems of more or less equivalent size. Thus, other things being equal, to achieve an equivalent strength of attack resistance, factoring-based encryption techniques must use larger keys than elliptic curve techniques. For this reason, public-key cryptosystems based on elliptic curves have become popular since their invention in the mid-1990s.\nWhile pure cryptanalysis uses weaknesses in the algorithms themselves, other attacks on cryptosystems are based on actual use of the algorithms in real devices, and are called side-channel attacks. If a cryptanalyst has access to, say, the amount of time the device took to encrypt a number of plaintexts or report an error in a password or PIN character, he may be able to use a timing attack to break a cipher that is otherwise resistant to analysis. An attacker might also study the pattern and length of messages to derive valuable information; this is known as traffic analysis,[23] and can be quite useful to an alert adversary. Poor administration of a cryptosystem, such as permitting too short keys, will make any system vulnerable, regardless of other virtues. And, of course, social engineering, and other attacks against the personnel who work with cryptosystems or the messages they handle (e.g., bribery, extortion, blackmail, espionage, torture, ...) may be the most productive attacks of all.\nCryptographic primitives\nMuch of the theoretical work in cryptography concerns cryptographic primitives — algorithms with basic cryptographic properties — and their relationship to other cryptographic problems. More complicated cryptographic tools are then built from these basic primitives. These primitives provide fundamental properties, which are used to develop more complex tools called cryptosystems or cryptographic protocols, which guarantee one or more high-level security properties. Note however, that the distinction between cryptographic primitives and cryptosystems, is quite arbitrary; for example, the RSA algorithm is sometimes considered a cryptosystem, and sometimes a primitive. Typical examples of cryptographic primitives include pseudorandom functions, one-way functions, etc.\nCryptosystems\nOne or more cryptographic primitives are often used to develop a more complex algorithm, called a cryptographic system, or cryptosystem. Cryptosystems (e.g. El-Gamal encryption) are designed to provide particular functionality (e.g. public key encryption) while guaranteeing certain security properties (e.g. CPA security in the random oracle model). Cryptosystems use the properties of the underlying cryptographic primitives to support the system''s security properties. Of course, as the distinction between primitives and cryptosystems is somewhat arbitrary, a sophisticated cryptosystem can be derived from a combination of several more primitive cryptosystems. In many cases, the cryptosystem''s structure involves back and forth communication among two or more parties in space (e.g., between the sender of a secure message and its receiver) or across time (e.g., cryptographically protected backup data). Such cryptosystems are sometimes called cryptographic protocols.\nSome widely known cryptosystems include RSA encryption, Schnorr signature, El-Gamal encryption, PGP, etc. More complex cryptosystems include electronic cash[24] systems, signcryption systems, etc. Some more ''theoretical'' (i.e., less practical) cryptosystems include interactive proof systems,[25] (like zero-knowledge proofs,[26]), systems for secret sharing[27][28], etc.\nTill recently, most security properties of most cryptosystems were demonstrated using empirical techniques, or using ad hoc reasoning. Recently, there has been considerable effort to develop formal techniques for establishing the security of cryptosystems; this has been generally called provable security. The general idea of provable security is to give arguments about the computational difficulty needed to compromise some security aspect of the cryptosystem (ie, to any adversary).\nThe study of how best to implement and integrate cryptography in software applications is itself a distinct field, see: cryptographic engineering and security engineering.\nLegal issues involving cryptography\nProhibitions\nCryptography has long been of interest to intelligence gathering and law enforcement agencies. Actually secret communications may be criminal or even treasonous; those whose communications are open to inspection may be less likely to be either. Because of its facilitation of privacy, and the diminution of privacy attendant on its prohibition, cryptography is also of considerable interest to civil rights supporters. Accordingly, there has been a history of controversial legal issues surrounding cryptography, especially since the advent of inexpensive computers has made possible widespread access to high quality cryptography.\nIn some countries, even the domestic use of cryptography is, or has been, restricted. Until 1999, France significantly restricted the use of cryptography domestically. In China, a license is still required to use cryptography. Many countries have tight restrictions on the use of cryptography. Among the more restrictive are laws in Belarus, Kazakhstan, Mongolia, Pakistan, Russia, Singapore, Tunisia, Venezuela, and Vietnam.[29]\nIn the United States, cryptography is legal for domestic use, but there has been much conflict over legal issues related to cryptography. One particularly important issue has been the export of cryptography and cryptographic software and hardware. Because of the importance of cryptanalysis in World War II and an expectation that cryptography would continue to be important for national security, many western governments have, at some point, strictly regulated export of cryptography. After World War II, it was illegal in the US to sell or distribute encryption technology overseas; in fact, encryption was defined legally to be a munition.[30] Until the advent of the personal computer and the Internet, this was not especially problematic. Good cryptography is indistinguishable from bad cryptography for nearly all users, and in any case, most of the cryptographic techniques generally available were slow and error prone whether good or bad. However, as the Internet grew and computers became more widely available, high quality encryption techniques became well-known around the globe. As a result, export controls came to be seen to be an impediment to commerce and to research.\nExport Controls\nMain article: Export of cryptography\nIn the 1990s, there were several challenges to US export regulations of cryptography. One involved Philip Zimmermann''s Pretty Good Privacy (PGP) encryption program; it was released in the US, together with its source code, and found its way onto the Internet in June 1991. After a complaint by RSA Security (then called RSA Data Security, Inc., or RSADSI), Zimmermann was criminally investigated by the Customs Service and the FBI for several years. No charges were ever filed, however.[31][32] Also, Daniel Bernstein, then a graduate student at UC Berkeley, brought a lawsuit against the US government challenging some aspects of the restrictions based on free speech grounds. The 1995 case Bernstein v. United States which ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.[33]\nIn 1996, thirty-nine countries signed the Wassenaar Arrangement, an arms control treaty that deals with the export of arms and "dual-use" technologies such as cryptography. The treaty stipulated that the use of cryptography with short key-lengths (56-bit for symmetric encryption, 512-bit for RSA) would no longer be export-controlled.[34] Cryptography exports from the US are now much less strictly regulated than in the past as a consequence of a major relaxation in 2000;[29] there are no longer very many restrictions on key sizes in US-exported mass-market software. In practice today, since the relaxation in US export restrictions, and because almost every personal computer connected to the Internet, everywhere in the world, includes US-sourced web browsers such as Mozilla Firefox or Microsoft Internet Explorer, almost every Internet user worldwide has access to quality cryptography (i.e., when using sufficiently long keys with properly operating and unsubverted software, etc) in their browsers; examples are Transport Layer Security or SSL stack. The Mozilla Thunderbird and Microsoft Outlook E-mail client programs similarly can connect to IMAP or POP servers via TLS, and can send and receive email encrypted with S/MIME. Many Internet users don''t realize that their basic application software contains such extensive cryptosystems. These browsers and email programs are so ubiquitous that even governments whose intent is to regulate civilian use of cryptography generally don''t find it practical to do much to control distribution or use of cryptography of this quality, so even when such laws are in force, actual enforcement is often effectively impossible.\nNSA involvement\nClipper chip\nAnother contentious issue connected to cryptography in the United States is the influence of the National Security Agency on cipher development and policy. NSA was involved with the design of DES during its development at IBM and its consideration by the National Bureau of Standards as a possible Federal Standard for cryptography.[35] DES was designed to be resistant to differential cryptanalysis,[36] a powerful and general cryptanalytic technique known to NSA and IBM, that became publicly known only when it was rediscovered in the late 1980s.[37] According to Steven Levy, IBM rediscovered differential cryptanalysis,[38] but kept the technique secret at NSA''s request. The technique became publicly known only when Biham and Shamir re-rediscovered and announced it some years later. The entire affair illustrates the difficulty of determining what resources and knowledge an attacker might actually have.\nAnother instance of NSA''s involvement was the 1993 Clipper chip affair, an encryption microchip intended to be part of the Capstone cryptography-control initiative. Clipper was widely criticized by cryptographers for two reasons. The cipher algorithm was then classified (the cipher, called Skipjack, though it was declassified in 1998 long after the Clipper initiative lapsed). The secret cipher caused concerns that NSA had deliberately made the cipher weak in order to assist its intelligence efforts. The whole initiative was also criticized based on its violation of Kerckhoffs'' principle, as the scheme included a special escrow key held by the government for use by law enforcement, for example in wiretaps.[32]\nDigital Rights Management\nMain article: Digital Rights Management\nCryptography is central to digital rights management (DRM), a group of techniques for technologically controlling use of copyrighted material, being widely implemented and deployed at the behest of some copyright holders. In 1998, American President Bill Clinton signed the Digital Millennium Copyright Act (DMCA), which criminalized all production, dissemination, and use of certain cryptanalytic techniques and technology (now known or later discovered); specifically, those that could be used to circumvent DRM technological schemes.[39] This had a noticeable impact on the cryptography research community since an argument can be made that any cryptanalytic research violated, or might violate, the DMCA. Similar statutes have since been enacted in several countries and regions, including the implementation in the EU Copyright Directive. Similar restrictions are called for by treaties signed by World Intellectual Property Organization member-states.\nThe United States Department of Justice and FBI have not enforced the DMCA as rigorously as had been feared by some, but the law, nonetheless, remains a controversial one. One well-respected cryptography researcher, Niels Ferguson, has publicly stated that he will not release some of his research into an Intel security design for fear of prosecution under the DMCA, and both Alan Cox (longtime number 2 in Linux kernel development) and Professor Edward Felten (and some of his students at Princeton) have encountered problems related to the Act. Dmitry Sklyarov was arrested during a visit to the US from Russia, and jailed for some months for alleged violations of the DMCA which had occurred in Russia, where the work for which he was arrested and charged was then, and when he was arrested, legal. In 2007, the cryptographic keys responsible for DVD and HD DVD content scrambling were discovered and released onto the internet. Both times, the MPAA sent out numerous DMCA takedown notices, and there was a massive internet backlash as a result of the implications of such notices on fair use and free speech both legally protected in the US and in some other jurisdictions.\nSee also\nCryptography Portal\nBooks on cryptography\nCryptography Classification\nCategory:Cryptographers\nEncyclopedia of Cryptography and Security\nJapanese cryptology from the 1500s to Meiji\nKish cypher\nList of cryptographers\nList of important publications in computer science#Cryptography\nTopics in cryptography\nUnsolved problems in computer science\nReferences\n^ Liddell and Scott''s Greek-English Lexicon. Oxford University Press. (1984)\n^ a b c d David Kahn, The Codebreakers, 1967, ISBN 0-684-83130-9.\n^ Oded Goldreich, Foundations of Cryptography, Volume 1: Basic Tools, Cambridge University Press, 2001, ISBN 0-521-79172-3\n^ "Cryptology (definition)". Merriam-Webster''s Collegiate Dictionary (11th edition ed.). Merriam-Webster. http://www.merriam-webster.com/dictionary/cryptology/. Retrieved on 1 February 2008.\n^ Kama Sutra, Sir Richard F. Burton, translator, Part I, Chapter III, 44th and 45th arts.\n^ Ibrahim A. Al-Kadi (April 1992), "The origins of cryptology: The Arab contributions”, Cryptologia 16 (2): 97–126\n^ Hakim, Joy (1995). A History of Us: War, Peace and all that Jazz. New York: Oxford University Press. ISBN 0-19-509514-6.\n^ James Gannon, Stealing Secrets, Telling Lies: How Spies and Codebreakers Helped Shape the Twentieth Century, Washington, D.C., Brassey''s, 2001, ISBN 1-57488-367-4.\n^ a b c Whitfield Diffie and Martin Hellman, "New Directions in Cryptography", IEEE Transactions on Information Theory, vol. IT-22, Nov. 1976, pp: 644–654. (pdf)\n^ a b c d e f AJ Menezes, PC van Oorschot, and SA Vanstone, Handbook of Applied Cryptography ISBN 0-8493-8523-7.\n^ FIPS PUB 197: The official Advanced Encryption Standard.\n^ NCUA letter to credit unions, July 2004\n^ RFC 2440 - Open PGP Message Format\n^ SSH at windowsecurity.com by Pawel Golen, July 2004\n^ a b Bruce Schneier, Applied Cryptography, 2nd edition, Wiley, 1996, ISBN 0-471-11709-9.\n^ Whitfield Diffie and Martin Hellman, "Multi-user cryptographic techniques" [Diffie and Hellman, AFIPS Proceedings 45, pp109–112, June 8, 1976].\n^ Ralph Merkle was working on similar ideas at the time and encountered publication delays, and Hellman has suggested that the term used should be Diffie-Hellman-Merkle aysmmetric key cryptography.\n^ David Kahn, "Cryptology Goes Public", 58 Foreign Affairs 141, 151 (fall 1979), p. 153.\n^ R. Rivest, A. Shamir, L. Adleman. A Method for Obtaining Digital Signatures and Public-Key Cryptosystems. Communications of the ACM, Vol. 21 (2), pp.120–126. 1978. Previously released as an MIT "Technical Memo" in April 1977, and published in Martin Gardner''s Scientific American Mathematical Recreations column\n^ Clifford Cocks. A Note on ''Non-Secret Encryption'', CESG Research Report, 20 November 1973.\n^ "Shannon": Claude Shannon and Warren Weaver, "The Mathematical Theory of Communication", University of Illinois Press, 1963, ISBN 0-252-72548-4\n^ Pascal Junod, "On the Complexity of Matsui''s Attack", SAC 2001.\n^ Dawn Song, David Wagner, and Xuqing Tian, "Timing Analysis of Keystrokes and Timing Attacks on SSH", In Tenth USENIX Security Symposium, 2001.\n^ S. Brands, "Untraceable Off-line Cash in Wallets with Observers", In Advances in Cryptology — Proceedings of CRYPTO, Springer-Verlag, 1994.\n^ László Babai. "Trading group theory for randomness". Proceedings of the Seventeenth Annual Symposium on the Theory of Computing, ACM, 1985.\n^ S. Goldwasser, S. Micali, and C. Rackoff, "The Knowledge Complexity of Interactive Proof Systems", SIAM J. Computing, vol. 18, num. 1, pp. 186–208, 1989.\n^ G. Blakley. "Safeguarding cryptographic keys." In Proceedings of AFIPS 1979, volume 48, pp. 313–317, June 1979.\n^ A. Shamir. "How to share a secret." In Communications of the ACM, volume 22, pp. 612–613, ACM, 1979.\n^ a b RSA Laboratories'' Frequently Asked Questions About Today''s Cryptography\n^ Cryptography & Speech from Cyberlaw\n^ "Case Closed on Zimmermann PGP Investigation", press note from the IEEE.\n^ a b Levy, Steven (2001). "Crypto: How the Code Rebels Beat the Government — Saving Privacy in the Digital Age. Penguin Books. pp. 56. ISBN 0-14-024432-8. OCLC 244148644 48066852 48846639.\n^ Bernstein v USDOJ, 9th Circuit court of appeals decision.\n^ The Wassenaar Arrangement on Export Controls for Conventional Arms and Dual-Use Goods and Technologies\n^ "The Data Encryption Standard (DES)" from Bruce Schneier''s CryptoGram newsletter, June 15, 2000\n^ Coppersmith, D. (May 1994). "The Data Encryption Standard (DES) and its strength against attacks" (PDF). IBM Journal of Research and Development 38 (3): 243. http://www.research.ibm.com/journal/rd/383/coppersmith.pdf.\n^ E. Biham and A. Shamir, "Differential cryptanalysis of DES-like cryptosystems", Journal of Cryptology, vol. 4 num. 1, pp. 3–72, Springer-Verlag, 1991.\n^ Levy, pg. 56\n^ Digital Millennium Copyright Act\nFurther reading\nIbrahim A. Al-Kadi, "The Origins of Cryptology: the Arab Contributions," Cryptologia, vol. 16, no. 2 (April 1992), pp. 97–126.\nAlvin''s Secret Code by Clifford B. Hicks (children''s novel that introduces some basic cryptography and cryptanalysis).\nBecket, B (1988). Introduction to Cryptology. Blackwell Scientific Publications. ISBN 0-632-01836-4. OCLC 16832704.\nExcellent coverage of many classical ciphers and cryptography concepts and of the "modern" DES and RSA systems.\nCryptography and Mathematics by Bernhard Esslinger, 200 pages, part of the free open-source package CrypTool, http://www.cryptool.com.\nCryptonomicon by Neal Stephenson (novel, WW2 Enigma cryptanalysis figures into the story, though not always realistically).\nJames Gannon, Stealing Secrets, Telling Lies: How Spies and Codebreakers Helped Shape the Twentieth Century, Washington, D.C., Brassey''s, 2001, ISBN 1-57488-367-4.\nHandbook of Applied Cryptography by A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone CRC Press, (PDF download available), somewhat more mathematical than Schneier''s Applied Cryptography.\nIn Code: A Mathematical Journey by Sarah Flannery (with David Flannery). Popular account of Sarah''s award-winning project on public-key cryptography, co-written with her father.\nIntroduction to Modern Cryptography by Jonathan Katz and Yehuda Lindell. [1].\nIntroduction to Modern Cryptography by Phillip Rogaway and Mihir Bellare, a mathematical introduction to theoretical cryptography including reduction-based security proofs. PDF download.\nAndreas Pfitzmann: Security in IT Networks: Multilateral Security in Distributed and by Distributed Systems\nLook up cryptography in\nWiktionary, the free dictionary.\nWikimedia Commons has media related to: Cryptography\nAt Wikiversity you can learn more and teach others about Cryptography at:\nThe Department of Cryptography\nAttackPrevention Resource for Cryptography Whitepapers, Tools, Videos, and Podcasts.\nCryptography: The Ancient Art of Secret Messages by Monica Pawlan - February 1998\nDeclassified U.S. Government Documents on Cryptography\nHandbook of Applied Cryptography by A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone (PDF download available), somewhat more mathematical than Schneier''s book.\nNSA''s CryptoKids.\nOverview and Applications of Cryptology by the CrypTool Team; PDF; 3,8 MB -- July 2008\nRSA Laboratories'' frequently asked questions about today''s cryptography\nsci.crypt mini-FAQ\nv • d • e\nCryptography\nHistory of cryptography · Cryptanalysis · Cryptography portal · Topics in cryptography\nSymmetric-key algorithm · Block cipher · Stream cipher · Public-key cryptography · Cryptographic hash function · Message authentication code · Random numbers · Steganography\nv • d • e\nEspionage\nAgent handling · Black op · Black bag operation · Concealment device · Cryptography · Dead drop · Eavesdropping · False flag · Honeypot · Industrial espionage · Interrogation · Non-official cover · Official cover · Steganography · Surveillance\nv • d • e\nIntelligence cycle management\nIntelligence\ncollection\nmanagement\nHUMINT/\nHuman Intelligence\nClandestine HUMINT (recruiting · operational techniques · Covert action · Direct action · Clandestine cell system)\nSpecial reconnaissance (organizations)\nEspionage (Agent handling · Black bag operation · Concealment device · Cryptography · Cut-out · Dead drop · Eavesdropping · False flag operations · Honeypot · Non-official cover · Interrogation · Numbers messaging · One-way voice link · Steganography · Surveillance)\nSIGINT/\nSignals Intelligence\nSIGINT by Alliances, Nations and Industries · SIGINT Operational Platforms by Nation · SIGINT in Modern History · TEMPEST · Direction finding · Traffic analysis\nMASINT/\nMeasurement and\nSignature Intelligence\nElectro-optical · Nuclear · Geophysical · Radar · Radiofrequency · Materials · Casualty estimation\nOthers\nOSINT/Open Source Intelligence · IMINT/Imagery Intelligence · FININT/Financial Intelligence · TECHINT/Technical intelligence\nIntelligence\nanalysis\nmanagement\nIntelligence analysis · Cognitive traps for intelligence analysis · Words of Estimative Probability · Analysis of Competing Hypotheses · Intelligence cycle (target-centric approach)\nIntelligence\ndissemination\nmanagement\nIntelligence cycle security · Counter-intelligence · Counter-intelligence and counter-terrorism organizations · List of counterintelligence organizations · Counterintelligence failures\n"http://en.wikipedia.org/wiki/Cryptography"\nCategories: Featured articles | Cryptography | Formal sciences | Mathematical science occupations | Banking technologyHidden category: Wikipedia indefinitely move-protected pages','\n',char(10)));
INSERT INTO pages VALUES('ALGOL','http://web.archive.org/web/20090108184943/http://en.wikipedia.org:80/wiki/ALGOL','en','2009-01-08 00:00:00',replace('For other uses of "Algol", see Algol (disambiguation).\nALGOL\nParadigm\nprocedural, imperative, structured\nAppeared in\n1958\nDesigned by\nInternational Committee\nInfluenced\nMost subsequent imperative languages (Algol-like)\nALGOL (short for ALGOrithmic Language)[1] is a family of imperative computer programming languages originally developed in the mid 1950s which greatly influenced many other languages and became the de facto way algorithms were described in textbooks and academic works for almost the next 30 years[2]. It was designed to avoid some of the perceived problems with FORTRAN and eventually gave rise to many other programming languages (including BCPL, B and C). ALGOL introduced code blocks and was the first language to use begin end pairs for delimiting them. Fragments of ALGOL-like syntax are sometimes still used as a notation for algorithms, so-called Pidgin Algol.\nThere were three major specifications:\nALGOL 58 - originally known as the IAL (for International Algorithmic Language.)\nALGOL 60 - revised 1963[3]\nALGOL 68 - revised 1973[4]\nNiklaus Wirth based his own Algol-W on ALGOL 60 before moving to develop Pascal. Algol-W was intended to be the next generation ALGOL but the ALGOL 68 committee decided on a design that was more complex and advanced rather than a cleaned simplified ALGOL 60. The official ALGOL versions are named after the year they were first published.\nAlgol68 is substantially different from Algol60 but was not well received so that in general "Algol" means dialects of Algol60.\n1 Import and implementations\n2 History\n2.1 IAL implementations timeline\n3 Properties\n3.1 ALGOL 60 Reserved words and restricted identifiers\n4 Examples and portability issues\n4.1 Code sample (ALGOL 60)\n4.2 Timeline: Hello world\n4.2.1 ALGOL 58 (IAL)\n4.2.2 ALGOL 60 family\n4.2.3 ALGOL 68\n5 See also\n6 References\n7 Further reading\n8\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nImport and implementations\nThe International Algorithmic Language (IAL) was extremely influential and is generally considered the ancestor of most of the modern programming languages (the so-called Algol-like languages). The Burroughs corporation built their line of computers to directly execute it. Additionally, in computer science, ALGOL object code was a simple and compact and stack-based instruction set architecture mainly used in teaching compiler construction and other high order language (of which Algol is generally considered the first) physical implementations such as Lisp machines and P-code machines. [5]\nHistory\nALGOL was developed jointly by a committee of European and American computer scientists in a meeting in 1958 at ETH Zurich. It specified three different syntaxes: a reference syntax, a publication syntax, and an implementation syntax. The different syntaxes permitted it to use different keyword names and conventions for decimal points (commas vs periods) for different languages.\nALGOL was used mostly by research computer scientists in the United States and in Europe. Its use in commercial applications was hindered by the absence of standard input/output facilities in its description and the lack of interest in the language by large computer vendors. ALGOL 60 did however become the standard for the publication of algorithms and had a profound effect on future language development.\nJohn Backus developed the Backus normal form method of describing programming languages specifically for ALGOL 58. It was revised and expanded by Peter Naur for ALGOL 60, and at Donald Knuth''s suggestion renamed Backus-Naur form.[6]\nPeter Naur: "As editor of the ALGOL Bulletin I was drawn into the international discussions of the language and was selected to be member of the European language design group in November 1959. In this capacity I was the editor of the ALGOL 60 report, produced as the result of the ALGOL 60 meeting in Paris in January 1960."\nThe following people attended the meeting in Paris (from January 1 to 16):\nFriedrich L. Bauer, Peter Naur, Heinz Rutishauser, Klaus Samelson, Bernard Vauquois, Adriaan van Wijngaarden, and Michael Woodger (from Europe)\nJohn W. Backus, Julien Green, Charles Katz, John McCarthy, Alan J. Perlis, and Joseph Henry Wegstein (from the USA).\nAlan Perlis gave a vivid description of the meeting: "The meetings were exhausting, interminable, and exhilarating. One became aggravated when one''s good ideas were discarded along with the bad ones of others. Nevertheless, diligence persisted during the entire period. The chemistry of the 13 was excellent."\nBoth John Backus and Peter Naur served on the committee which created ALGOL 60 as did Wally Feurzeig, who later created Logo.\nALGOL 60 inspired many languages that followed it. Tony Hoare remarked: "Here is a language so far ahead of its time that it was not only an improvement on its predecessors but also on nearly all its successors."[7]\nIAL implementations timeline\nTo date there have been at least 70 augmentations, extensions, derivations and sublanguages of Algol 60.[8]\nName\nYear\nAuthor\nState\nDescription\nTarget CPU\nZMMD-implementation\n1958\nFriedrich L. Bauer, Heinz Rutishauser, Klaus Samelson, Hermann Bottenbruch\nGermany\nimplementation of ALGOL 58\nZ22\nElliott ALGOL\n1960\nC. A. R. Hoare\nUK\nSubject of the famous Turing lecture\nNational-Elliott 803 & the Elliott 503\nJOVIAL\n1960\nJules Schwarz\nUSA\nWas the DOD HOL prior to Ada (programming language)\nVarious (see article)\nBurroughs Algol\n(Several variants)\n1961\nBurroughs Corporation (with participation by Hoare, Dijkstra, and others)\nUSA\nBasis of the Burroughs (and now Unisys MCP based) computers\nBurroughs large systems\nand their midrange as well.\nCase ALGOL\n1961\nUSA\nSimula was originally contracted as a simulation extension of the Case ALGOL\nUNIVAC 1107\nGOGOL\n1961\nBill McKeeman\nUSA\nFor ODIN time-sharing system\nPDP-1\nX1 Algol 60\n1961\nEdsger Dijkstra and J.A. Zonneveld\nNetherlands\nMathematical Centre, Amsterdam\nX1\nDartmouth ALGOL 30\n1962\nThomas Eugene Kurtz et al\nUSA\nLGP-30\nUSS 90 Algol\n1962\nL. Petrone\nItaly\nAlgol Translator\n1962\nG. van der May and W.L. van der Poel\nNetherlands\nStaatsbedrijf der Posterijen, Telegrafie en Telefonie\nZEBRA\nKidsgrove Algol\n1963\nF. G. Duncan\nUK\nEnglish Electric Company KDF9\nVALGOL\n1963\nVal Schorre\nUSA\nA test of the META II compiler compiler\nWhetstone\n1964\nBrian Randell and L J Russell\nUK\nAtomic Power Division of English Electric Company. Precursor to Ferranti Pegasus (computer), National Physical Laboratories ACE (computer) and English Electric DEUCE implementations.\nEnglish Electric Company KDF9\nNU ALGOL\n1965\nNorway\nUNIVAC\nALGEK\n1965\nUSSR\nMinsk-22\nАЛГЭК, based on ALGOL-60 and COBOL support, for economical tasks\nMALGOL\n1966\npubl. A. Viil, M Kotli & M. Rakhendi,\nEstonian SSR\nMinsk-22\nALGAMS\n1967\nGAMS group (ГАМС, группа автоматизации программирования для машин среднего класса), cooperation of Comecon Academies of Science\nComecon\nMinsk-22, later ES EVM, BESM\nALGOL/ZAM\n1967\nPoland\nPolish ZAM computer\nRegneCentralen ALGOL\n1967\nPeter Naur\nDenmark\nSimula 67\n1967\nOle-Johan Dahl and Kristen Nygaard\nNorway\nAlgol 60 with classes\nUNIVAC 1107\nChinese Algol\n1972\nChina\nChinese characters, expressed via the Symbol system\nDG/L\n1972\nUSA\nDG Eclipse family of computers\nThe Burroughs dialects included special bootstrapping dialects such as ESPOL and NEWP.\nProperties\nALGOL 60 as officially defined had no I/O facilities; implementations defined their own in ways that were rarely compatible with each other. In contrast, ALGOL 68 offered an extensive library of transput (ALGOL 68 parlance for Input/Output) facilities.\nALGOL 60 allowed for two evaluation strategies for parameter passing: the common call-by-value, and call-by-name. Call-by-name had certain limitations in contrast to call-by-reference, making it an undesirable feature in imperative language design. For example, it is impossible in ALGOL 60 to develop a procedure that will swap the values of two parameters if the actual parameters that are passed in are an integer variable and an array that is indexed by that same integer variable.[9] However, call-by-name is still beloved of ALGOL implementors for the interesting "thunks" that are used to implement it. Donald Knuth devised the "Man or boy test" to separate compilers that correctly implemented "recursion and non-local references". This test contains an example of call-by-name.\nALGOL 68 was defined using a two-level grammar formalism invented by Adriaan van Wijngaarden and which bears his name. Van Wijngaarden grammars use a context-free grammar to generate an infinite set of productions that will recognize a particular ALGOL 68 program; notably, they are able to express the kind of requirements that in many other programming language standards are labelled "semantics" and have to be expressed in ambiguity-prone natural language prose, and then implemented in compilers as ad hoc code attached to the formal language parser.\nALGOL 60 Reserved words and restricted identifiers\nThere are 35 such reserved words in the standard Burroughs large systems sub-language: ALPHA, ARRAY, BEGIN, BOOLEAN, COMMENT, CONTINUE, DIRECT, DO, DOUBLE, ELSE, END, EVENT, FALSE, FILE, FOR, FORMAT, GO, IF, INTEGER, LABEL, LIST, LONG, OWN, POINTER, PROCEDURE, REAL, STEP, SWITCH, TASK, THEN, TRUE, UNTIL, VALUE, WHILE, ZIP.\nThere are 71 such restricted identifiers in the standard Burroughs large systems sub-language: ACCEPT, AND, ATTACH, BY, CALL, CASE, CAUSE, CLOSE, DEALLOCATE, DEFINE, DETACH, DISABLE, DISPLAY, DIV, DUMP, ENABLE, EQL, EQV, EXCHANGE, EXTERNAL, FILL, FORWARD, GEQ, GTR, IMP, IN, INTERRUPT, IS, LB, LEQ, LIBERATE, LINE, LOCK, LSS, MERGE, MOD, MONITOR, MUX, NEQ, NO, NOT, ON, OPEN, OR, OUT, PICTURE, PROCESS, PROCURE, PROGRAMDUMP, RB, READ, RELEASE, REPLACE, RESET, RESIZE, REWIND, RUN, SCAN, SEEK, SET, SKIP, SORT, SPACE, SWAP, THRU, TIMES, TO, WAIT, WHEN, WITH, WRITE and also the names of all the intrinsic functions.\nExamples and portability issues\nCode sample (ALGOL 60)\n(The way the bold text has to be written depends on the implementation, e.g. ''INTEGER'' (including the quotation marks) for integer; this is known as stropping.)\nprocedure Absmax(a) Size:(n, m) Result:(y) Subscripts:(i, k);\nvalue n, m; array a; integer n, m, i, k; real y;\ncomment The absolute greatest element of the matrix a, of size n by m\nis transferred to y, and the subscripts of this element to i and k;\nbegin integer p, q;\ny := 0; i := k := 1;\nfor p:=1 step 1 until n do\nfor q:=1 step 1 until m do\nif abs(a[p, q]) > y then\nbegin y := abs(a[p, q]);\ni := p; k := q\nend\nend Absmax\nHere''s an example of how to produce a table using Elliott 803 ALGOL.[10]\nFLOATING POINT ALGOL TEST''\nBEGIN REAL A,B,C,D''\nREAD D''\nFOR A:= 0.0 STEP D UNTIL 6.3 DO\nBEGIN\nPRINT PUNCH(3),££L??''\nB := SIN(A)''\nC := COS(A)''\nPRINT PUNCH(3),SAMELINE,ALIGNED(1,6),A,B,C''\nEND''\nEND''\nPUNCH(3) sends output to the teleprinter rather than the tape punch.\nSAMELINE suppresses the carriage return + line feed normally printed between arguments.\nALIGNED(1,6) controls the format of the output with 1 digit before and 6 after the decimal point.\nTimeline: Hello world\nThe variations and lack of portability of the programs from one implementation to another is easily demonstrated by the classic hello world program.\nALGOL 58 (IAL)\nMain article: ALGOL 58\nALGOL 58 had no I/O facilities.\nALGOL 60 family\nSince ALGOL 60 had no I/O facilities, there is no portable hello world program in ALGOL. The following program could (and still will) compile and run on an ALGOL implementation for a Unisys A-Series mainframe, and is a straightforward simplification of code taken from The Language Guide at the University of Michigan-Dearborn Computer and Information Science Department Hello world! ALGOL Example Program page.\nBEGIN\nFILE F(KIND=REMOTE);\nEBCDIC ARRAY E[0:11];\nREPLACE E BY "HELLO WORLD!";\nWRITE(F, *, E);\nEND.\nAn alternative example, using Elliott Algol I/O is as follows. Elliott Algol used different characters for "open-string-quote" and "close-string-quote", represented here by ‘ and ’.\nprogram HiFolks;\nbegin\nprint ‘Hello world’;\nend;\nHere''s a version for the Elliott 803 Algol (A104) The standard Elliott 803 used 5 hole paper tape and thus only had upper case. The code lacked any quote characters so £ (UK Pound Sign) was used for open quote and ? (Question Mark) for close quote. Special sequences were placed in double quotes (e.g. ££L?? produced a new line on the teleprinter).\nHIFOLKS''\nBEGIN\nPRINT £HELLO WORLD££L???''\nEND''\nThe ICL 1900 Algol I/O version allowed input from paper tape or punched card. Paper tape ''full'' mode allowed lower case. Output was to a line printer.\n''BEGIN''\n''WRITE TEXT''("HELLO WORLD");\n''END''\nALGOL 68\nMain article: ALGOL 68\nIn the language of the "Algol 68 Report", Input/output facilities were collectively called the "Transput".\nALGOL 68 code was published with reserved words typically in lowercase, but bolded or underlined.\nbegin\nprint(("Hello, world!",newline))\nend\nOR using a specific transput channel:\nbegin\nputf((stand out,$gl$,"Hello, world!"))\nend\nFor ease of programming computers with 7-bit characters of the time there were "official" methods to "BOLD" reserved words, for example, by using uppercase:\nBEGIN\nprint(("Hello, world!",newline))\nEND\nProgrammers were sometimes required to totally "THINK IN UPPERCASE" on computers that only had 6-bit characters, eg the CDC 6600 "super computers". In this case the above code would be written:\n''BEGIN''\nPRINT(("HELLO, WORLD!",NEWLINE))\n''END''\nThe "Algol 68 Report" was translated into Russian, German, French and Bulgarian, and allowed programming in languages with larger character sets, eg Cyrillic alphabet. eg the Russian BESM-4.\nBEGIN\nprint(("Здравствуй, мир!",newline))\nEND\nNote: The 1964 Russian standard GOST 10859 allowed the encoding of 4-bit, 5-bit, 6-bit and 7-bit characters in ALGOL.[11]\nSee also\nALGOL 58\nALGOL 60\nALGOL N\nALGOL 68\nALGOL N\nAlgol-W\nAtlas Autocode\nCORAL66\nEdinburgh IMP\nJensen''s Device\nISWIM\nJOVIAL\nNELIAC\nSimula\nS-algol\nReferences\n^ The name of the family is sometimes given in mixed case (Algol 60), and sometimes in all uppercase (ALGOL 68). For simplicity this article uses ALGOL.\n^ cf. Pseudocode\n^ "Revised Report on the Algorithmic Language Algol 60" (1963). Retrieved on June 8, 2007.\n^ "Revised Report on the Algorithmic Language ALGOL 68" (1973). Retrieved on June 8, 2007.\n^ "Compiler Construction Theory and Practice, Ch.9". Science Research Associates, Inc. 1979.\n^ Knuth, Donald E. (1964) Backus Normal Form vs Backus Naur Form. Communications of the ACM 7(12):735-736\n^ "Hints on Programming Language Design", C.A.R. Hoare, December 1973. Page 27. (This statement is sometimes erroneously attributed to Edsger Dijkstra, also involved in implementing the first ALGOL 60 compiler.)\n^ The Encyclopedia of Computer Languages\n^ Aho, Alfred V.; Ravi Sethi, Jeffrey D. Ullman (1986). Compilers: Principles, Techniques, and Tools (1st edition ed.). Addison-Wesley. ISBN 0-201-10194-7. , Section 7.5, and references therein\n^ "803 ALGOL", the manual for Elliott 803 ALGOL\n^ "GOST 10859 standard". Retrieved on June 5, 2007.\nFurther reading\nB. Randell and L.J. Russell, ALGOL 60 Implementation: The Translation and Use of ALGOL 60 Programs on a Computer. Academic Press, 1964. The design of the Whetstone Compiler. One of the early published descriptions of implementing a compiler. See the related papers: Whetstone Algol Revisited, and The Whetstone KDF9 Algol Translator by B. Randell\nE. W, Dijkstra, Algol 60 translation: an algol 60 translator for the x1 and making a translator for algol 60, report MR 35/61. Mathematisch Centrum, Amsterdam, 1961. [1]\nRevised Report on the Algorithmic Language Algol 60 by Peter Naur, et al. ALGOL definition\nA BNF syntax summary of ALGOL 60\n"The Emperor''s Old Clothes" - Hoare''s 1980 ACM Turing Award speech, which discusses ALGOL history and his involvement\nMARST, a free Algol-to-C translator\nAN IMPLEMENTATION OF ALGOL 60 FOR THE FP6000 Discussion of some implementation issues.\n"The European Side of the Last Phase of the Development of ALGOL 60" by Peter Naur\nEdinburgh University wrote compilers for Algol60 (later updated for Algol60M) based on their Atlas Autocode compilers initially bootstrapped from the Atlas to the KDF-9. The Edinburgh compilers generated code for the ICL1900, the ICL4/75 (an IBM360 clone), and the ICL2900. Here is the BNF for Algol60 and the ICL2900 compiler source, library documentation, and a considerable test suite including Brian Wichmann''s tests. Also there is a rather superficial Algol60 to Atlas Autocode source-level translator.\nEric Raymond''s Retrocomputing Museum, among others a link to the NASE Algol-60 interpreter written in C.\n"http://en.wikipedia.org/wiki/ALGOL"\nCategories: ALGOL 60 dialects | Articles with example ALGOL 60 code | Procedural programming languages | Structured programming languages | Systems programming languages','\n',char(10)));
INSERT INTO pages VALUES('REXX','http://web.archive.org/web/20090219195713/http://en.wikipedia.org:80/wiki/REXX','en','2009-02-19 00:00:00',replace('REXX\nParadigm\nmultiparadigm: object-oriented, procedural, structured\nAppeared in\n1979\nDesigned by\nMike Cowlishaw\nDeveloper\nMike Cowlishaw & IBM\nTyping discipline\ndynamic, everything is a string (ClassicREXX) or object (ObjectRexx)\nMajor implementations\nIBM NetREXX, Open Object Rexx, Regina, others\nDialects\nObject Rexx, Open Object Rexx, NetRexx\nInfluenced by\nPL/I, EXEC 2, BASIC\nREXX (REstructured eXtended eXecutor) is an interpreted programming language which was developed at IBM. It is a structured high-level programming language which was designed to be both easy to learn and easy to read. Both commercial and open source interpreters for REXX are available on a wide range of computing platforms, and compilers are available for IBM mainframes.\n1 Features\n2 History\n2.1 Spelling\n3 Syntax\n3.1 Looping\n3.2 Conditionals\n3.3 Testing for multiple conditions\n3.4 Simple variables\n3.5 Compound variables\n3.6 Keyword instructions\n3.6.1 PARSE\n3.6.2 INTERPRET\n3.6.3 NUMERIC\n3.6.4 SIGNAL\n3.7 Error handling and exceptions\n3.7.1 Conditions\n4 See also\n5 References\n6 Books\n7\n7.1 Classic interpreters\n7.2 Other interpreters\n7.3 Compilers\n7.4 Newsgroups\n7.5 Tutorials\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nFeatures\nREXX has the following characteristics and features:\ncharacter string basis\ndynamic data typing (no declarations)\nno reserved keywords (except in local context)\narbitrary numerical precision\ndecimal arithmetic (floating-point)\na rich selection of built-in functions (especially string and word processing)\nautomatic storage management\ncrash protection\nassociative arrays\nstraightforward access to system commands and facilities\nsimple error-handling, and built-in tracing and debugger\nfew artificial limitations\nsimplified I/O facilities.\nREXX has just twenty-three, largely self-evident, instructions (e.g., call, parse, and select) with minimal punctuation and formatting requirements. It is essentially an almost free-form language with only one data-type, the character string; this philosophy means that all data are visible (symbolic) and debugging and tracing are simplified.\nREXX syntax looks similar to PL/I, but has fewer notations; this makes it harder to parse (by program) but easier to use.\nHistory\nREXX was designed and first implemented, in assembly language, as an ‘own-time’ project between 20 March 1979 and mid-1982 by Mike Cowlishaw of IBM, originally as a scripting programming language to replace the languages EXEC and EXEC 2[1]. It was designed to be a macro or scripting language for any system. As such, REXX is considered a precursor to Tcl and Python.\nIt was first described in public at the SHARE 56 conference in Houston, Texas, in 1981[2], where customer reaction, championed by Ted Johnston of SLAC, led to it being shipped as an IBM product in 1982.\nOver the years IBM included REXX in almost all of its operating systems (VM/CMS, VM/GCS, MVS TSO/E, AS/400, VSE/ESA, AIX, CICS/ESA, PC-DOS, and OS/2), and has made versions available for Novell NetWare, Windows, Java, and Linux.\nThe first non-IBM version was written for PC-DOS by Charles Daney in 1984/5. Other versions have also been developed for Atari, AmigaOS, Unix (many variants), Solaris, DEC, Windows, Windows CE, PocketPC, MS-DOS, Palm OS, QNX, OS/2, Linux, BeOS, EPOC32, AtheOS, OpenVMS, OpenEdition, Macintosh, and Mac OS X.[3]\nThe Amiga version of REXX, called ARexx was included with AmigaOS 2 onwards and was popular for scripting as well as application control. Many Amiga applications have an "ARexx port" built into them which allows control of the application from Rexx. One single Rexx script could even switch between different Rexx ports in order to control several running applications.\nSeveral freeware versions of REXX are available. In 1992, the two most widely-used open-source ports appeared: Ian Collier''s REXX/imc for Unix and Anders Christensen''s Regina (later adopted by Mark Hessling) for Windows and Linux. BREXX is well-known for WinCE and PocketPC platforms.\nIn 1996 ANSI published a standard for REXX: ANSI X3.274–1996 “Information Technology – Programming Language REXX”. More than two dozen books on REXX have been published since 1985.\nSince the mid-1990s, two newer variants of REXX have appeared:\nNetRexx — which compiles to Java byte-code via Java source code; this has no reserved keywords at all, and uses the Java object model, and is therefore not generally upwards-compatible with ‘classic’ REXX.\nObject REXX — which is an object-oriented generally upwards-compatible version of REXX.\nIn 1990, Cathy Dager of SLAC organized the first independent REXX symposium, which led to the forming of the REXX Language Association. Symposia are held annually.\nREXX marked its 25th anniversary on 20 March 2004, which was celebrated at the REXX Language Association’s 15th International REXX Symposium in Böblingen, Germany, in May 2004.\nOn October 12, 2004, IBM announced their plan to release their Object REXX implementation under the Common Public License.\nOn February 22, 2005, the first public release of Open Object Rexx (ooRexx) was announced.\nSpelling\nThis section does not cite any references or sources.\nPlease help improve this section by adding citations to reliable sources. Unverifiable material may be challenged and removed. (July 2008)\nOriginally it was just called "Rex", "A Reformed EXecutor"; the extra "X" was added to avoid collisions with other products'' names. The expansion of Rexx to the REstructured EXtended EXecutor is believed to be a backronym. REX was originally all uppercase because the mainframe code was uppercase oriented. The style in those days was to have all-caps names (partly because almost all code was still all-caps then). For the product it became REXX, and both editions of Mike Cowlishaw''s book use all-caps. By the 1990s it was largely written Rexx or, with small caps: REXX. As of 2008, Mike Cowlishaw seems to prefer Rexx, IBM documents use REXX, and the ANSI standard uses REXX.\nSyntax\nLooping\nThe loop control structure in REXX begins with a DO and ends with an END but comes in several varieties. NetRexx uses the keyword LOOP instead of DO for looping, while ooRexx treats LOOP and DO as equivalent when looping.\nTraditional forms:\ndo until [condition]\n[instructions]\nend\ndo while [condition]\n[instructions]\nend\nWith an index variable:\ndo i = x [to y ][by z]\n[instructions]\nend\nThe step increment (z above) may be omitted and defaults to 1. The upper limit (y above) can also be omitted, which makes the loop continue forever. You can also loop forever without an index variable with this:\ndo forever\n[instructions]\nend\nA program can break out of the current loop with the leave instruction (which is the normal way to exit a "forever" loop), or can short-circuit it with the iterate instruction. The do while and do until forms are equivalent to:\ndo forever\nif [condition] then leave\n[instructions]\nend\nand:\ndo forever\n[instructions]\nif [condition] then leave\nend\nConditionals\nTesting conditions with IF\nif [condition] then\ndo\n[instructions]\nend\nelse\ndo\n[instructions]\nend\nFor single instructions, DO and END can also be omitted:\nif [condition] then\n[instruction]\nelse\n[instruction]\nTesting for multiple conditions\nSELECT is REXX''s CASE structure, like many other constructs derived from PL/I:\nselect\nwhen [condition] then\n[instruction]\nwhen [condition] then\ndo\n[instructions]\nend\notherwise\n[instructions] or NOP\nend\nNOP indicates no instruction is to be executed.\nSimple variables\nVariables in REXX are typeless, and initially are evaluated as their names, in upper case. Thus a variable''s type can vary with its use in the program:\nsay hello\n/* =>\nHELLO\n*/\nhello = 25\nsay hello\n/* =>\n25\n*/\nhello = "say 5 + 3"\nsay hello\n/* =>\nsay 5 + 3\n*/\ninterpret hello\n/* =>\n8\n*/\ndrop hello\nsay hello\n/* =>\nHELLO\n*/\nCompound variables\nUnlike many other programming languages, classic REXX has no direct support for arrays of variables addressed by a numerical index. Instead it provides compound variables. A compound variable consists of a stem followed by a tail. A . (dot) is used to join the stem to the tail. If the tails used are numeric, it is easy to produce the same effect as an array.\ndo i = 1 to 10\nstem.i = 10 - i\nend\nAfterwards the following variables with the following values exist: stem.1 = 9, stem.2 = 8, stem.3 = 7...\nUnlike arrays, the index for a stem variable is not required to have an integer value. For example, the following code is valid:\ni = ''Monday''\nstem.i = 2\nIn REXX it is also possible to set a default value for a stem.\nstem. = ''Unknown''\nstem.1 = ''USA''\nstem.44 = ''UK''\nstem.33 = ''France''\nAfter these assignments the term stem.3 would produce ''Unknown''.\nThe whole stem can also be erased with the DROP statement.\ndrop stem.\nThis also has the effect of removing any default value set previously.\nBy convention (and not as part of the language) the compound stem.0 is often used to keep track of how many items are in a stem, for example a procedure to add a word to a list might be coded like this:\nadd_word: procedure expose dictionary.\nparse arg w\nn = dictionary.0 + 1\ndictionary.n = w\ndictionary.0 = n\nreturn\nIt is also possible to have multiple elements in the tail of a compound variable. For example:\nm = ''July''\nd = 15\ny = 2005\nday.y.m.d = ''Friday''\nMultiple numerical tail elements can be used to provide the effect of a multi-dimensional array.\nFeatures similar to REXX compound variables are found in many other languages (associative arrays in AWK, hashes in Perl, Hashtables in Java, etc). Most of these languages provide an instruction to iterate over all the keys (or tails in REXX terms) of such a construct, but this is lacking in classic REXX. Instead it is necessary to keep auxiliary lists of tail values as appropriate. For example in a program to count words the following procedure might be used to record each occurrence of a word.\nadd_word: procedure expose count. word_list\nparse arg w .\ncount.w = count.w + 1 /* assume count. has been set to 0 */\nif count.w = 1 then word_list = word_list w\nreturn\nand then later\ndo i = 1 to words(word_list)\nw = word(word_list,i)\nsay w count.w\nend\nAt the cost of some opacity it is possible to combine these techniques into a single stem.\nadd_word: procedure expose dictionary.\nparse arg w .\ndictionary.w = dictionary.w + 1\nif dictionary.w = 1 /* assume dictionary. = 0 */\nthen do\nn = dictionary.0+1\ndictionary.n = w\ndictionary.0 = n\nend\nreturn\nand later\ndo i = 1 to dictionary.0\nw = dictionary.i\nsay i w dictionary.w\nend\nHowever, REXX provides no safety net here, so if one of your words happens to be a whole number less than dictionary.0 the above technique will fail mysteriously.\nRecent implementations of REXX, include IBM''s Object REXX and the open source implementations like ooRexx include a new language construct to simplify iteration over the value of a stem, or over another collection object such as an array, table, list, etc.\ndo i over stem.\nsay i ''-->'' stem.i\nend\nKeyword instructions\nPARSE\nThe PARSE instruction is particularly powerful; it combines some useful string-handling functions. Its syntax is:\nparse [upper] origin template\nwhere origin specifies the source:\narg (arguments, at top level tail of command line)\nlinein (standard input, e.g. keyboard)\npull (REXX data queue or standard input)\nsource (info on how program was executed)\nvalue (an expression) with\nthe keyword with is required to indicate where the expression ends\nvar (a variable)\nversion (version/release number)\nand template can be:\nlist of variables\ncolumn number delimiters\nliteral delimiters\nupper is optional; if you specify it, data will be converted to upper case.\nExamples:\nUsing a list of variables as template\nmyVar = "John Smith"\nparse var myVar firstName lastName\nsay "First name is:" firstName\nsay "Last name is:"\nlastName\ndisplays the following:\nFirst name is: John\nLast name is: Smith\nUsing a delimiter as template:\nmyVar = "Smith, John"\nparse var myVar LastName "," FirstName\nsay "First name is:" firstName\nsay "Last name is:"\nlastName\nalso displays the following:\nFirst name is: John\nLast name is: Smith\nUsing column number delimiters:\nmyVar = "(202) 123-1234"\nparse var MyVar 2 AreaCode 5\n7 SubNumber\nsay "Area code is:" AreaCode\nsay "Subscriber number is:" SubNumber\ndisplays the following:\nArea code is: 202\nSubscriber number is: 123-1234\nA template can use a combination of variables, literal delimiters, and column number delimiters.\nINTERPRET\nThe INTERPRET instruction is powerful and one of the two reasons why writing REXX compilers isn''t trivial, the other reason being REXX''s decimal arbitrary precision arithmetic:\n/* a touch of LISP */\nX = ''square''\ninterpret ''say'' X || ''(4) ; exit''\nSQUARE: return arg(1) * arg(1)\nThis displays 16 and exits. Because variable contents in REXX are strings, including rational numbers with exponents and even entire programs, REXX offers to interpret strings as evaluated expressions.\nThis feature could be used to pass functions as function parameters, such as passing SIN, COS, etc. to a procedure to calculate integrals.\nNote that REXX offers only basic math functions like ABS, DIGITS, MAX, MIN, SIGN, RANDOM, and a complete set of hex plus binary conversions with bit operations. More complex functions like SIN had to be implemented from scratch or obtained form third party external libraries. Some external libraries, typically those implemented in traditional languages, did not support extended precision.\nLater versions (non-classic) support CALL variable constructs. Together with the built-in function VALUE, CALL can be used in place of many cases of INTERPRET. This is a classic program:\n/* terminated by input "exit" or similar */\ndo forever ; interpret linein() ; end\nA slightly more sophisticated REXX calculator:\nX = ''input BYE to quit''\ndo until X = ''BYE'' ; interpret ''say'' X ; pull X ; end\n// (PULL is a shorthand for parse upper pull like ARG for parse upper arg.)\nThe power of the INTERPRET instruction had other uses. The Valour software package relied upon Rexx''s interpretive ability to implement an OOPS environment. Another use was found in an unreleased Westinghouse product called Time Machine that was able to fully recover following a fatal error.\nNUMERIC\nsay digits() fuzz() form() /* => 9 0 SCIENTIFIC */\nsay 999999999 + 1 /* => 1.000000000E+9 */\nnumeric digits 10 /* only limited by available memory */\nsay 999999999 + 1 /* => 1000000000 */\nsay 0.9999999999 = 1 /* => 0 (false) */\nnumeric fuzz 3\nsay 0.99999999 = 1\n/* => 1 (true) */\nsay 0.99999999 == 1 /* => 0 (false) */\nsay 100 * 123456789 /* => 1.23456789E+10 */\nnumeric form engineering\nsay 100 * 123456789 /* => 12.34567890E+9 */\nSIGNAL\nThe REXX SIGNAL instruction is intended for abnormal changes in the flow of control (see the next section). However, it can be misused and treated like the GOTO statement found in other languages (although it is not strictly equivalent, because it terminates loops and other constructs). This can produce difficult to read code.\nError handling and exceptions\nIt is possible in REXX to intercept and deal with errors and other exceptions, using the SIGNAL instruction. There are seven system conditions: ERROR, FAILURE, HALT, NOVALUE, NOTREADY, LOSTDIGITS and SYNTAX. Handling of each can be switched on and off in the source code as desired.\nThis example will run until stopped by the user:\nsignal on halt;\ndo a = 1\nsay a\ndo 100000 /* a delay */\nend\nend\nhalt:\nsay "The program was stopped by the user"\nexit\nVirtually all serious REXX programs contain signal on novalue or a similar statement. This disables the "feature", where undefined variables get their own (upper case) name as value. The status of a variable can be checked with the built-in function SYMBOL returning VAR for defined variables.\nFunction VALUE can be used to get the value of variables without triggering a NOVALUE condition, but its main purpose is to read and set environment variables - similar to POSIX getenv and putenv.\nConditions\nERROR\nPositive RC from a system command\nFAILURE\nNegative RC for a system command (e.g. command doesn''t exist)\nHALT\nAbnormal termination (see above)\nNOVALUE\nAn unset variable was referenced (see above)\nNOTREADY\nInput or output error (e.g. read attempts beyond end of file)\nSYNTAX\nInvalid program syntax, or some error condition not covered above\nLOSTDIGITS\nSignificant digits are lost (ANSI REXX, not in TRL second edition)\nWhen a condition is handled by SIGNAL ON, the SIGL and RC system variables can be analyzed to understand the situation. RC contains the REXX error code and SIGL contains the line number where the error arose.\nBeginning with REXX version 4 conditions can get names, and there''s also a CALL ON construct. That''s handy if external functions do not necessarily exist:\nChangeCodePage: procedure /* protect SIGNAL settings */\nsignal on syntax name ChangeCodePage.Trap\nreturn SysQueryProcessCodePage()\nChangeCodePage.Trap: return 1004 /* windows-1252 on OS/2 */\nSee also\nARexx - The native REXX interpreter of AmigaOS\nXEDIT - text editor(s) with native REXX support\nComparison of computer shells\nComparison of programming languages\nReferences\n^ Cowlishaw, Mike. "IBM REXX Brief History". IBM. http://www-306.ibm.com/software/awdtools/rexx/library/rexxhist.html. Retrieved on 2006-08-15.\n^ Cowlishaw, Mike (1981-02-18). "REX -- A Command Programming Language". SHARE. http://www-306.ibm.com/software/awdtools/rexx/library/share56.html. Retrieved on 2006-08-15.\n^ "Rexx Implementations". RexxLA. http://www.rexxla.org/About_Rexx/mfc/rexxplat.html. Retrieved on 2006-08-15.\nBooks\nCallaway, Merrill. The Rexx Cookbook: A Tutorial Guide to the Rexx Language in OS/2 & Warp on the IBM Personal Computer. WHITESTONE, 1995. ISBN 0-96-327734-0.\nCowlishaw, Michael. The Rexx Language: A Practical Approach to Programming. Prentice Hall, 1990. ISBN 0-13-780651-5.\nCowlishaw, Michael. The NetRexx Language. Prentice Hall, 1997. ISBN 0-13-806332-X.\nDaney, Charles. Programming in REXX. McGraw-Hill, TX, 1990. ISBN 0-07-015305-1.\nDeuring, Johannes. REXX Grundlagen für die z/OS Praxis. Germany, 2005. ISBN 3-486-20025-9.\nEnder, Tom. Object-Oriented Programming With Rexx. John Wiley & Sons, 1997. ISBN 0-471-11844-3.\nFosdick, Howard. Rexx Programmer''s Reference. Wiley/Wrox, 2005. ISBN 0-7645-7996-7.\nGargiulo, Gabriel. REXX with OS/2, TSO, & CMS Features. MVS Training, 1999 (third edition 2004). ISBN 1-892559-03-X.\nGoldberg, Gabriel and Smith, Philip H. The Rexx Handbook . McGraw-Hill, TX, 1992. ISBN 0-07-023682-8.\nGoran, Richard K. REXX Reference Summary Handbook. CFS Nevada, Inc.,1997. ISBN 0-9639854-3-4.\nIBM Redbooks. Implementing Rexx Support in Sdsf. Vervante, 2007. ISBN 0-738-48914-X.\nKiesel, Peter C. Rexx: Advanced Techniques for Programmers. McGraw-Hill, TX, 1992. ISBN 0-07-034600-3.\nO''Hara, Robert P. and Gomberg, David Roos. Modern Programming Using Rexx. Prentice Hall, 1988. ISBN 0-13-597329-5.\nRudd, Anthony S. Practical Usage of Rexx. Ellis Horwood Ltd., 1991. ISBN 0-13682-790-X.\nSchindler, William. Down to Earth Rexx. Perfect Niche Software, 2000. ISBN 0-9677590-0-5.\nMike Cowlishaw at IBM\nREXX language page at IBM\nREXX Language Association\nRexxLA''s list of Rexx books\nREXX Information-- Downloads, tools, tutorials, reference materials, etc.\nThe Script Library\nClassic interpreters\nRegina: open-source (LGPL) interpreter for Linux, BSD, Windows, etc.\nREXX/imc: open-source (nonstandard license) interpreter for Unix and Linux systems.\nBREXX: open-source (GPL) interpreter for DOS, Linux, Windows CE, etc.\nReginald: free interpreter for Windows.\nroo!: freeware interpreter for Windows with object-oriented extensions from Kilowatt Software.\nr4: freeware interpreter for Windows from Kilowatt Software.\nREXX for Palm OS: shareware interpreter for Palm OS from Jaxo Inc.\nPersonal REXX: commercial interpreter for Windows, OS/2 and DOS from Quercus Systems.\nS/REXX: commercial interpreter for UNIX and Windows from Benaroya.\nuni-REXX: commercial interpreter for UNIX from The Workstation Group Ltd.\nOther interpreters\nOpen Object Rexx web site\nIBM NetREXX web site\nCompilers\nIBM Compiler and Library for REXX on zSeries\nNewsgroups\ncomp.lang.rexx\nTutorials\nRexx for everyone: An introduction by David Mertz for IBM developerWorks.\nVladimir Zabrodsky''s Album of Algorithms and Techniques for Standard Rexx\nVladimir Zabrodsky''s An Introduction to the Rexx Programming Language\nPLEAC-REXX: Programming Language Examples Alike Cookbook for REXX\nTips & tricks 3.60 by Bernd Schemmer (OS/2 INF format, 755 KB ZIP, 2004)\nRexx Frequently Asked Questions (FAQ)\nIntroductory Rexx Tutorial - SHARE, Spring 1997\n"http://en.wikipedia.org/wiki/REXX"\nCategories: IBM software | Scripting languages | Text-oriented programming languages | Command shells | IBM Mainframe computer operating systemsHidden category: Articles needing additional references from July 2008','\n',char(10)));
INSERT INTO pages VALUES('Database','http://web.archive.org/web/20081219060743/http://en.wikipedia.org:80/wiki/Database','en','2008-12-19 00:00:00',replace('This article is principally about managing and structuring the collections of data held on computers. For a fuller discussion of DBMS software, see Database management system.\nA database is a structured collection of records or data that is stored in a computer system. The structure is achieved by organizing the data according to a database model. The model in most common use today is the relational model. Other models such as the hierarchical model and the network model use a more explicit representation of relationships.\n1 Database topics\n1.1 Architecture\n1.2 Database management systems\n1.3 Database models\n1.3.1 Post-relational database models\n1.3.2 Object database models\n1.4 Database storage structures\n1.5 Indexing\n1.6 Transactions and concurrency\n1.7 Replication\n1.8 Security\n1.9 Locking\n2 Applications of databases\n3 See also\n4 References\n5 Further reading\n6\n//<![CDATA[\nif (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); }\n//]]>\nDatabase topics\nArchitecture\nDepending on the intended use, there are a number of database architectures in use. Many databases use a combination of strategies. On-line Transaction Processing systems (OLTP) often use a row-oriented datastore architecture, while data-warehouse and other retrieval-focused applications like Google''s BigTable, or bibliographic database(library catalogue) systems may use a Column-oriented DBMS architecture.\nDocument-Oriented, XML, Knowledgebases, as well as frame databases and rdf-stores (aka Triple-Stores), may also use a combination of these architectures in their implementation.\nFinally it should be noted that not all database have or need a database ''schema'' (so called schema-less databases).\nOver many years the database industry has been dominated by General Purpose database systems, which offer a wide range of functions that are applicable to many, if not most circumstances in modern data processing. These have been enhanced with extensible datatypes, pioneered in the PostgreSQL project, to allow a very wide range of applications to be developed.\nAlso there are other types of database which cannot be classified as relational databases\nDatabase management systems\nA computer database relies upon software to organize the storage of data. This software is known as a database management system (DBMS). Database management systems are categorized according to the database model that they support. The model tends to determine the query languages that are available to access the database. A great deal of the internal engineering of a DBMS, however, is independent of the data model, and is concerned with managing factors such as performance, concurrency, integrity, and recovery from hardware failures. In these areas there are large differences between products.\nA Relational Database Management System implements the features of the relational model outlined above. In this context, Date''s "Information Principle" states: "the entire information content of the database is represented in one and only one way. Namely as explicit values in column positions (attributes) and rows in relations (tuples). Therefore, there are no explicit pointers between related tables."\nDatabase models\nMain article: Database model\nPost-relational database models\nSeveral products have been identified as post-relational because the data model incorporates relations but is not constrained by the Information Principle, requiring that all information is represented by data values in relations. Products using a post-relational data model typically employ a model that actually pre-dates the relational model. These might be identified as a directed graph with trees on the nodes.\nExamples of models that could be classified as post-relational are PICK aka MultiValue, and MUMPS.\nObject database models\nIn recent years, the object-oriented paradigm has been applied to database technology, creating a new programming model known as object databases. These databases attempt to bring the database world and the application programming world closer together, in particular by ensuring that the database uses the same type system as the application program. This aims to avoid the overhead (sometimes referred to as the impedance mismatch) of converting information between its representation in the database (for example as rows in tables) and its representation in the application program (typically as objects). At the same time, object databases attempt to introduce the key ideas of object programming, such as encapsulation and polymorphism, into the world of databases.\nA variety of these ways have been tried for storing objects in a database. Some products have approached the problem from the application programming end, by making the objects manipulated by the program persistent. This also typically requires the addition of some kind of query language, since conventional programming languages do not have the ability to find objects based on their information content. Others have attacked the problem from the database end, by defining an object-oriented data model for the database, and defining a database programming language that allows full programming capabilities as well as traditional query facilities.\nDatabase storage structures\nMain article: Database storage structures\nPlease help improve this section by expanding it. Further information might be found on the talk page. (June 2008)\nDatabase tables/indexes are typically stored in memory or on hard disk in one of many forms, ordered/unordered flat files, ISAM, heaps, hash buckets or B+ trees. These have various advantages and disadvantages discussed further in the main article on this topic. The most commonly used are B+ trees and ISAM.\nOther important design choices relate to the clustering of data by category (such as grouping data by month, or location), creating pre-computed views known as materialized views, partitioning data by range or hash. As well memory management and storage topology can be important design choices for database designers. Just as normalization is used to reduce storage requirements and improve the extensibility of the database, conversely denormalization is often used to reduce join complexity and reduce execution time for queries. [1]\nIndexing\nAll of these databases can take advantage of indexing to increase their speed. This technology has advanced tremendously since its early uses in the 1960s and 1970s. The most common kind of index is a sorted list of the contents of some particular table column, with pointers to the row associated with the value. An index allows a set of table rows matching some criterion to be located quickly. Typically, indexes are also stored in the various forms of data-structure mentioned above (such as B-trees, hashes, and linked lists). Usually, a specific technique is chosen by the database designer to increase efficiency in the particular case of the type of index required.\nRelational DBMS''s have the advantage that indexes can be created or dropped without changing existing applications making use of it. The database chooses between many different strategies based on which one it estimates will run the fastest. In other words, indexes are transparent to the application or end-user querying the database; while they affect performance, any SQL command will run with or without index to compute the result of an SQL statement. The RDBMS will produce a plan of how to execute the query, which is generated by analyzing the run times of the different algorithms and selecting the quickest. Some of the key algorithms that deal with joins are nested loop join, sort-merge join and hash join. Which of these is chosen depends on whether an index exists, what type it is, and its cardinality.\nAn index speeds up access to data, but it has disadvantages as well. First, every index increases the amount of storage on the hard drive necessary for the database file, and second, the index must be updated each time the data are altered, and this costs time. (Thus an index saves time in the reading of data, but it costs time in entering and altering data. It thus depends on the use to which the data are to be put whether an index is on the whole a net plus or minus in the quest for efficiency.)\nA special case of an index is a primary index, or primary key, which is distinguished in that the primary index must ensure a unique reference to a record. Often, for this purpose one simply uses a running index number (ID number). Primary indexes play a significant role in relational databases, and they can speed up access to data considerably.\nTransactions and concurrency\nIn addition to their data model, most practical databases ("transactional databases") attempt to enforce a database transaction . Ideally, the database software should enforce the ACID rules, summarized here:\nAtomicity: Either all the tasks in a transaction must be done, or none of them. The transaction must be completed, or else it must be undone (rolled back).\nConsistency: Every transaction must preserve the integrity constraints — the declared consistency rules — of the database. It cannot place the data in a contradictory state.\nIsolation: Two simultaneous transactions cannot interfere with one another. Intermediate results within a transaction are not visible to other transactions.\nDurability: Completed transactions cannot be aborted later or their results discarded. They must persist through (for instance) restarts of the DBMS after crashes\nIn practice, many DBMSs allow most of these rules to be selectively relaxed for better performance.\nConcurrency control is a method used to ensure that transactions are executed in a safe manner and follow the ACID rules. The DBMS must be able to ensure that only serializable, recoverable schedules are allowed, and that no actions of committed transactions are lost while undoing aborted transactions.\nReplication\nReplication of databases is closely related to transactions. If a database can log its individual actions, it is possible to create a duplicate of the data in real time. The duplicate can be used to improve performance or availability of the whole database system. Common replication concepts include:\nMaster/Slave Replication: All write requests are performed on the master and then replicated to the slaves\nQuorum: The result of Read and Write requests are calculated by querying a "majority" of replicas.\nMultimaster: Two or more replicas sync each other via a transaction identifier.\nParallel synchronous replication of databases enables transactions to be replicated on multiple servers simultaneously, which provides a method for backup and security as well as data availability.\nSecurity\nDatabase security denotes the system, processes, and procedures that protect a database from unintended activity.\nSecurity is usually enforced through access control, auditing, and encryption.\nAccess control ensures and restricts who can connect and what can be done to the database.\nAuditing logs what action or change has been performed, when and by whom.\nEncryption: Since security has become a major issue in recent years, many commercial database vendors provide built-in encryption mechanism. Data is encoded natively into the tables and deciphered "on the fly" when a query comes in. Connections can also be secured and encrypted if required using DSA, MD5, SSL or legacy encryption standard.\nEnforcing security is one of the major tasks of the DBA.\nIn the United Kingdom, legislation protecting the public from unauthorized disclosure of personal information held on databases falls under the Office of the Information Commissioner. United Kingdom based organizations holding personal data in electronic format (databases for example) are required to register with the Data Commissioner.[2]\nLocking\nPlease help improve this section by expanding it. Further information might be found on the talk page. (June 2008)\nLocking is how the database handles multiple concurrent operations. This is how concurrency and some form of basic integrity is managed within the database system. Such locks can be applied on a row level, or on other levels like page (a basic data block), extend (multiple array of pages) or even an entire table. This helps maintain the integrity of the data by ensuring that only one process at a time can modify the same data.\nUnlike a basic filesystem files or folders, where only one lock at the time can be set, restricting the usage to one process only. A database can set and hold mutiple locks at the same time on the different level of the physical data structure. How locks are set, last is determined by the database engine locking scheme based on the submitted SQL or transactions by the users. Generally speaking, no activity on the database should be translated by no or very light locking.\nFor most DBMS systems existing on the market, locks are generally shared or exclusive. Exclusive locks mean that no other lock can acquire the current data object as long as the exclusive lock lasts. Exclusive locks are usually set while the database needs to change data, like during an UPDATE or DELETE operation.\nShared locks can take ownership one from the other of the current data structure. Shared locks are usually used while the database is reading data, during a SELECT operation. The number, nature of locks and time the lock holds a data block can have a huge impact on the database performances. Bad locking can lead to disastrous performance response (usually the result of poor SQL requests, or inadequate database physical structure)\nDefault locking behavior is enforced by the isolation level of the dataserver. Changing the isolation level will affect how shared or exclusive locks must be set on the data for the entire database system. Default isolation is generally 1, where data can not be read while it is modified, forbidding to return "ghost data" to end user.\nAt some point intensive or inappropriate exclusive locking, can lead to the "dead lock" situation between two locks. Where none of the locks can be released because they try to acquire resources mutually from each other. The Database has a fail safe mechanism and will automatically "sacrifice" one of the locks releasing the resource. Doing so processes or transactions involved in the "dead lock" will be rolled back.\nDatabases can also be locked for other reasons, like access restrictions for given levels of user. Some databases are also locked for routine database maintenance, which prevents changes being made during the maintenance. See "Locking tables and databases" (section in some documentation / explanation from IBM) for more detail.) However, many modern databases don''t lock the database during routine maintenance. e.g. "Routine Database Maintenance" for PostgreSQL.\nApplications of databases\nDatabases are used in many applications, spanning virtually the entire range of computer software. Databases are the preferred method of storage for large multiuser applications, where coordination between many users is needed. Even individual users find them convenient, and many electronic mail programs and personal organizers are based on standard database technology. Software database drivers are available for most database platforms so that application software can use a common Application Programming Interface to retrieve the information stored in a database. Two commonly used database APIs are JDBC and ODBC.\nFor example suppliers database contains the data relating to suppliers such as;\nsupplier name\nsupplier code\nsupplier address\nIt is often used by schools to teach students and grade them.\nSee also\nComparison of relational database management systems\nComparison of database tools\nDatabase-centric architecture\nDatabase theory\nGovernment database\nOnline database\nReal time database\nReferences\n^ S. Lightstone, T. Teorey, T. Nadeau, Physical Database Design: the database professional''s guide to exploiting indexes, views, storage, and more, Morgan Kaufmann Press, 2007. ISBN 0123693896\n^ Information Commissioner''s Office - ICO\nThis article needs additional citations for verification. Please help improve this article by adding reliable references. Unsourced material may be challenged and removed. (November 2008)\nFurther reading\nConnolly, Thomas, and Caroln Begg. Database Systems. New York: Harlow, 2002.\nDate, C. J. An Introduction to Database Systems, Eighth Edition, Addison Wesley, 2003.\nGalindo, J., Urrutia, A., Piattini, M., Fuzzy Databases: Modeling, Design and Implementation (FSQL guide). Idea Group Publishing Hershey, USA, 2006.\nGalindo, J., Ed. Handbook on Fuzzy Information Processing in Databases. Hershey, PA: Information Science Reference (an imprint of Idea Group Inc.), 2008.\nGray, J. and Reuter, A. Transaction Processing: Concepts and Techniques, 1st edition, Morgan Kaufmann Publishers, 1992.\nKroenke, David M. Database Processing: Fundamentals, Design, and Implementation (1997), Prentice-Hall, Inc., pages 130-144.\nKroenke, David M., and David J. Auer. Database Concepts. 3rd ed. New York: Prentice, 2007.\nLightstone, S., T. Teorey, and T. Nadeau, Physical Database Design: the database professional''s guide to exploiting indexes, views, storage, and more, Morgan Kaufmann Press, 2007. ISBN 0-12369-389-6.\nShih, J. "Why Synchronous Parallel Transaction Replication is Hard, But Inevitable?", white paper, 2007.\nTeorey, T.; Lightstone, S. and Nadeau, T. Database Modeling & Design: Logical Design, 4th edition, Morgan Kaufmann Press, 2005. ISBN 0-12-685352-5\nTukey, John W. Exploratory Data Analysis. Reading, MA: Addison Wesley, 1977.\nWikimedia Commons has media related to: Database\ncomp.databases.theory (Database Theory Discussion Group)\nDatabase discussion forums\nThe EM-DAT International Disaster Database\nThe CE-DAT Complex Emergency Database\nv • d • e\nDatabase management systems\nDatabase models · Database normalization · Database storage · Distributed DBMS · Referential integrity · Relational algebra · Relational calculus · Relational database · Relational DBMS · Relational model · Object-relational database · Transaction processing\nConcepts\nDatabase · ACID · CRUD · Null · Candidate key · Foreign key · Primary key · Superkey · Surrogate key\nObjects\nTrigger · View · Table · Cursor · Log · Transaction · Index · Stored procedure · Partition\nSQL\nSelect · Insert · Update · Merge · Delete · Join · Union · Create · Drop · Begin work · Commit · Rollback · Truncate · Alter\nComponents\nConcurrency control · Data dictionary · JDBC · ODBC · Query language · Query optimizer · Query plan\nDatabase products: Object-oriented (comparison) · Relational (comparison) · Document-oriented\n"http://en.wikipedia.org/wiki/Database"\nCategories: Database management systems | Databases | Database theoryHidden categories: Articles to be expanded since June 2008 | All articles to be expanded | Articles needing additional references from November 2008','\n',char(10)));

