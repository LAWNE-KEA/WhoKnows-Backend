[
{"url": "https://en.wikipedia.org/wiki/List_of_programming_languages", "title": "List of programming languages", "content": "\n This is an index to notable  , in current or historical use.   of  ,  , and   are not included. A programming language does not need to be   or  , but must be   and so does not include   such as   or  , but does include   such as   and its dialects.\n            \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Lists_of_programming_languages", "title": "Lists of programming languages", "content": "\n There are thousands of  . These are listed in various ways:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_programming_languages_by_type", "title": "List of programming languages by type", "content": "\n This is a list of notable  , grouped by type.\n The groupings are overlapping; not mutually exclusive. A language can be listed in multiple groupings.\n Agent-oriented programming allows the developer to build, extend and use  , which are abstractions of objects that can message other agents.\n  (also termed   or  ) languages generalize operations on scalars to apply transparently to  ,  , and  .\n Aspect-oriented programming enables developers to add new functionality to code, known as \"advice\", without modifying that code itself; rather, it uses a   to implement the advice into code blocks.\n  directly correspond to a   (see  ), so machine code instructions appear in a form understandable by humans, although there may not be a one-to-one mapping between an individual statement and an individual instruction. Assembly languages let programmers use symbolic addresses, which the   converts to absolute or   addresses. Most assemblers also support   and  .\n An   is a programming language designed for use by a non-computer expert to easily create tutorials, websites, and other interactive computer programs.\n  (CLI) languages are also called batch languages or job control languages. Examples:\n These are languages typically processed by  , though theoretically any language can be compiled or interpreted.\n A   is a   computer   in which all expressions denote  , and the   of   denotes  .  Concatenative programming replaces  , which is common in other programming styles, with   as the default way to build  .\n  languages provide language constructs for  . The predominant paradigm for concurrency in mainstream languages such as   is   concurrency. Concurrent languages that make use of message passing have generally been inspired by process calculi such as   (CSP) or the  .\n A   is a   where relationships between variables are expressed as  . Execution proceeds by attempting to find values for the variables which satisfy all declared constraints.\n A   or   language has syntax that defines a block as the statements between  . This syntax originated with   (1966), and was popularized by  . Many curly bracket languages  . Examples:\n  languages rely on a (usually visual) representation of the flow of data to specify the program.  Frequently used for reacting to discrete events or for processing streams of data.  Examples of dataflow languages include:\n Data-oriented languages provide powerful ways of searching and manipulating the relations that have been described as entity relationship tables which map one set of things into other sets.  Examples of data-oriented languages include:\n  can be used as an aid to clarifying the logic before writing a program in any language, but in the 1960s a number of languages were developed where the main logic is expressed directly in the form of a decision table, including:\n  express the logic of a computation without describing its control flow in detail.   stands in contrast to   via imperative programming languages, where control flow is specified by serial orders (imperatives). (Pure)   and   programming languages are also declarative, and constitute the major subcategories of the declarative category. This section lists additional examples not in those subcategories.\n Source embeddable languages embed small pieces of executable code inside a piece of free-form text, often a web page.\n Client-side embedded languages are limited by the abilities of the browser or intended client. They aim to provide dynamism to web pages without the need to recontact the server.\n Server-side embedded languages are much more flexible, since almost any language can be built into a server. The aim of having fragments of server-side code embedded in a web page is to generate additional markup dynamically; the code itself disappears when the page is served, to be replaced by its output.\n The above examples are particularly dedicated to this purpose. A large number of other languages, such as  ,  ,  ,   and   can be adapted (for instance, by being made into   modules).\n A wide variety of dynamic or scripting languages can be embedded in compiled executable code. Basically, object code for the language's   needs to be linked into the executable. Source code fragments for the embedded language can then be passed to an evaluation function as strings. Application control languages can be implemented this way, if the source code is input by the user. Languages with small interpreters are preferred.\n Languages developed primarily for the purpose of teaching and learning of programming.\n An   is a programming language designed as a test of the boundaries of computer programming language design, as a proof of concept, or as a joke.\n  are languages embedded into another program and used to harness its features in extension scripts.\n  are high-level languages built around database systems. They are generally used in commercial environments.\n  languages define programs and subroutines as mathematical functions and treat them as first-class. Many so-called functional languages are \"impure\", containing imperative features. Many functional languages are tied to mathematical calculation tools. Functional languages include:\n In electronics, a   (HDL) is a specialized computer language used to describe the structure, design, and operation of electronic circuits, and most commonly, digital logic circuits. The two most widely used and well-supported HDL varieties used in industry are   and  . Hardware description languages include:\n Imperative programming languages may be multi-paradigm and appear in other classifications. Here is a list of programming languages that follow the  :\n Known as   - Interactive mode languages act as a kind of shell: expressions or statements can be entered one at a time, and the result of their evaluation seen immediately.\n  are programming languages in which programs may be executed from source code form, by an interpreter. Theoretically, any language can be compiled or interpreted, so the term   generally refers to languages that are usually interpreted rather than compiled.\n Iterative languages are built around or offering  .\n \nGarbage Collection (GC) is a form of automatic memory management. The garbage collector attempts to reclaim memory that was allocated by the program but is no longer used.  List-based languages are a type of   that are based on the   data structure.\n  serve a specialized problem domain.\n  languages specify a set of attributes that a solution must-have, rather than a set of steps to obtain a solution.\n Notable languages following this   include:\n  are directly executable by a computer's CPU. They are typically formulated as bit patterns, usually represented in   or  . Each bit pattern causes the circuits in the CPU to execute one of the fundamental operations of the hardware. The activation of specific electrical inputs (e.g., CPU package pins for microprocessors), and logical settings for CPU state values, control the processor's computation. Individual machine languages are specific to a family of processors; machine-language code for one family of processors cannot run directly on processors in another family unless the processors in question have additional hardware to support it (for example, DEC VAX processors included a PDP-11 compatibility mode). They are (essentially) always defined by the CPU developer, not by 3rd parties.  The symbolic version, the processor's  , is also defined by the developer, in most cases. Some commonly used machine code   are:\n  languages transform one source code file into another. A \"macro\" is essentially a short piece of text that expands into a longer one (not to be confused with  ), possibly with parameter substitution. They are often used to   source code. Preprocessors can also supply facilities like  .\n Macro languages may be restricted to acting on specially labeled code regions (pre-fixed with a   in the case of the C preprocessor). Alternatively, they may not, but in this case it is still often undesirable to (for instance) expand a macro embedded in a  , so they still need a rudimentary awareness of syntax. That being the case, they are often still applicable to more than one language. Contrast with source-embeddable languages like  , which are fully featured.\n  such as   and   ( ,  ,  ,  ) have been embedded into applications. These are sometimes called \"macro languages\", although in a somewhat different sense to textual-substitution macros like  .\n  is the writing of programs that write or manipulate other programs, including themselves, as their data or that do part of the work that is otherwise done at   during  . In many cases, this allows programmers to get more done in the same amount of time as they would take to write all the code manually.\n  support more than one  . They allow a   to use more than one   style. The goal is to allow programmers to use the best tool for a job, admitting that no one paradigm solves all problems in the easiest or most efficient way.\n Several general-purpose programming languages, such as   and  , are also used for technical computing, this list focuses on languages almost exclusively used for technical computing.\n -based   languages support   defined by their class. Class definitions include member data.   is a key concept, if not the main concept, in object-oriented languages.\n Polymorphic functions parameterized by the class of some of their arguments are typically called  . In languages with  , classes typically also include method definitions. In languages with  , methods are defined by  . There are exceptions where   methods are   (e.g.  's object system).\n  are object-oriented languages where the distinction between classes and instances has been removed:\n  languages denote blocks of code by their  .\n  languages are based on the concept of the unit and scope (the data viewing range) of an executable code statement. A procedural program is composed of one or more units or modules, either user coded or provided in a code library; each module is composed of one or more procedures, also called a function, routine, subroutine, or method, depending on the language. Examples of procedural languages include:\n  languages let programs examine and possibly modify their high-level structure at runtime or compile-time. This is most common in high-level virtual machine programming languages like  , and less common in lower-level programming languages like  . Languages and platforms supporting reflection:\n Rule-based languages instantiate rules when activated by conditions in a set of data. Of all possible activations, some set is selected and the statements belonging to those rules execute. Rule-based languages include: \n Stack-based languages are a type of   that are based on the   data structure.\n  are optimized for programming reactive systems, systems that are often interrupted and must respond quickly. Many such systems are also called  , and are used often in  .\n Examples:\n A   is a graphics programming language adapted to programming shader effects. Such language forms usually consist of special data types, like \"color\" and \"normal\". Due to the variety of target markets for 3D computer graphics.\n They provide both higher hardware abstraction and a more flexible programming model than previous paradigms which hardcoded transformation and shading equations. This gives the programmer greater control over the rendering process and delivers richer content at lower overhead.\n Shading languages used in offline rendering produce maximum image quality. Processing such shaders is time-consuming. The computational power required can be expensive because of their ability to produce photorealistic results.\n These languages assist with generating   and   for  .\n The   are for low-level tasks like memory management or task management. A system programming language usually refers to a programming language used for system programming; such languages are designed for writing system software, which usually requires different development approaches when compared with application software.\n System software is computer software designed to operate and control the computer hardware, and to provide a platform for running application software. System software includes software categories such as operating systems, utility software, device drivers, compilers, and linkers. Examples of system languages include:\n  serve the purpose of transforming (translating) source code specified in a certain formal language into a defined destination format code. It is most commonly used in intermediate components of more complex super-systems in order to adopt internal results for input into a succeeding processing routine.\n  let users specify programs in a two-(or more)-dimensional way, instead of as one-dimensional text strings, via graphic layouts of various types. Some   languages are also visual languages.\n Computer scientist   designed and implemented several influential languages.\n These are languages based on or that operate on  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Timeline_of_programming_languages", "title": "Timeline of programming languages", "content": "\n \n This is a record of notable  , by decade. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Generational_list_of_programming_languages", "title": "Generational list of programming languages", "content": "\n This is a \"genealogy\" of  . Languages are categorized under the ancestor language with the strongest influence. Those ancestor languages are listed in alphabetic order. Any such categorization has a large arbitrary element, since programming languages often incorporate major ideas from multiple sources.\n JOSS also inspired features for several versions of BASIC, including  's   and  's  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Programming_language", "title": "Programming language", "content": "This is an accepted version of this page \n\n A   is a system of notation for writing  . \n Programming languages are described in terms of their   (form) and   (meaning), usually defined by a  . Languages usually provide features such as a  ,  , and mechanisms for  . An   of a programming language is required in order to   programs, namely an   or a  . An interpreter directly executes the source code, while a   produces an   program.\n  has strongly influenced the design of programming languages, with the most common type ( —which implement operations in a specified order) developed to perform well on the popular  . While early programming languages were closely tied to the  , over time they have developed more   to hide implementation details for greater simplicity.\n Thousands of programming languages—often classified as imperative,  ,  , or  —have been developed for a wide variety of uses. Many aspects of programming language design involve tradeoffs—for example,   simplifies error handling, but at a performance cost.   is the subfield of   that studies the design, implementation, analysis, characterization, and classification of programming languages.\n Programming languages differ from   in that natural languages are used for interaction between people, while programming languages are designed to allow humans to communicate instructions to machines. \n The term   is sometimes used interchangeably with \"programming language\".  However, usage of these terms varies among authors.\n In one usage, programming languages are described as a subset of computer languages.  Similarly, the term \"computer language\" may be used in contrast to the term \"programming language\" to describe languages used in computing but not considered programming languages  – for example,  .  Some authors restrict the term \"programming language\" to   languages.  Most practical programming languages are Turing complete,  and as such are equivalent in what programs they can compute.\n Another usage regards programming languages as theoretical constructs for programming   and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources.    emphasizes that   languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats. \n The first programmable computers were invented at the end of the 1940s, and with them, the first programming languages.  The earliest computers were programmed in   (1GLs),   (simple instructions that could be directly executed by the processor). This code was very difficult to debug and was not   between different computer systems.  In order to improve the ease of programming,   (or  —2GLs) were invented, diverging from the machine language to make programs easier to understand for humans, although they did not increase portability. \n Initially, hardware resources were scarce and expensive, while   were cheaper. Therefore, cumbersome languages that were time-consuming to use, but were closer to the hardware for higher efficiency were favored.  The introduction of   ( —3GLs)—revolutionized programming. These languages   away the details of the hardware, instead being designed to express algorithms that could be understood more easily by humans. For example, arithmetic expressions could now be written in symbolic notation and later translated into machine code that the hardware could execute.  In 1957,   (FORmula TRANslation) was invented. Often considered the first   high-level programming language,  Fortran has remained in use into the twenty-first century. \n Around 1960, the first  —general purpose computers—were developed, although they could only be operated by professionals and the cost was extreme. The data and instructions were input by  , meaning that no input could be added while the program was running. The languages developed at this time therefore are designed for minimal interaction.  After the invention of the  , computers in the 1970s became dramatically cheaper.  New computers also allowed more user interaction, which was supported by newer programming languages. \n , implemented in 1958, was the first   language.  Unlike Fortran, it supports   and  ,  and it also introduced   on a   and automatic  .  For the next decades, Lisp dominated   applications.  In 1978, another functional language,  , introduced   and polymorphic  . \n After   (ALGOrithmic Language) was released in 1958 and 1960,  it became the standard in computing literature for describing  . Although its commercial success was limited, most popular imperative languages—including  ,  ,  ,  ,  , and  —are directly or indirectly descended from ALGOL 60.  Among its innovations adopted by later programming languages included greater portability and the first use of  ,   grammar.   , the first language to support   (including  ,  , and  ), also descends from ALGOL and achieved commercial success.  C, another ALGOL descendant, has sustained popularity into the twenty-first century. C allows access to lower-level machine operations more than other contemporary languages. Its power and efficiency, generated in part with flexible   operations, comes at the cost of making it more difficult to write correct code. \n , designed in 1972, was the first   language, communicating with a computer using formal logic notation.  With logic programming, the programmer specifies a desired result and allows the   to decide how to achieve it. \n During the 1980s, the invention of the   transformed the roles for which programming languages were used.  New languages introduced in the 1980s included C++, a   of C that can compile C programs but also supports   and  .    and other new languages introduced support for  .  The Japanese government invested heavily into the so-called   that added support for concurrency to logic programming constructs, but these languages were outperformed by other concurrency-supporting languages. \n Due to the rapid growth of the   and the   in the 1990s, new programming languages were introduced to support   and  .   , based on C++ and designed for increased portability across systems and security, enjoyed large-scale success because these features are essential for many Internet applications.  Another development was that of    — ,  ,  , and  —designed to quickly produce small programs that coordinate existing  . Due to their integration with  , they have also been used for building web pages hosted on  . \n During the 2000s, there was a slowdown in the development of new programming languages that achieved widespread popularity.  One innovation was  , designed to exploit   whose components are connected by a network. Services are similar to objects in object-oriented programming, but run on a separate process.    and   cross-pollinated ideas between imperative and functional programming.  After 2010, several new languages— ,  ,  ,   and   —competed for the performance-critical software for which C had historically been used.  Most of the new programming languages uses   while a few numbers of new languages use   like   and  . \n Some of the new programming languages are classified as   like  ,   and  . Also, some of these languages mix between textual and visual programming usage like  .  Also, this trend lead to developing projects that help in developing new VPLs like   by  .  Many game engines like   and   added support for visual scripting too. \n Every programming language includes fundamental elements for describing data and the operations or transformations applied to them, such as adding two numbers or selecting an item from a collection. These elements are governed by syntactic and semantic rules that define their structure and meaning, respectively.\n A programming language's surface form is known as its  . Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, some programming languages are  , using visual relationships between symbols to specify a program.\n The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either   or hard-coded in a  ). Since most languages are textual, this article discusses textual syntax.\n The programming language syntax is usually defined using a combination of   (for   structure) and   (for   structure). Below is a simple grammar, based on  :\n This grammar specifies the following:\n The following are examples of well-formed token sequences in this grammar:  ,   and  .\n Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit  . Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.\n Using   as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:\n The following   fragment is syntactically correct, but performs operations that are not semantically defined (the operation   has no meaning for a value having a complex type and   is not defined because the value of   is the  ):\n If the   on the first line were omitted, the program would trigger an error on the undefined variable   during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.\n The grammar needed to specify a programming language can be classified by its position in the  . The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are  .  Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an  , and generally blur the distinction between parsing and execution.  In contrast to   and Perl's   blocks, which may contain general computations, C macros are merely string replacements and do not require code execution. \n The term   refers to the meaning of languages, as opposed to their form ( ).\n Static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms.  For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every   is declared before it is used (in languages that require such declarations) or that the labels on the arms of a   are distinct.  Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that   calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a   called a  . Other forms of   like   may also be part of static semantics. Programming languages such as   and   have  , a form of data flow analysis, as part of their respective static semantics.\n Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the   by which expressions are evaluated to values, or the manner in which   conditionally execute  . The   (also known as  ) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research goes into  , which allows execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.\n A   is a set of allowable values and operations that can be performed on these values.  Each programming language's   defines which data types exist, the type of an  , and how   and   function in the language. \n According to  , a language is fully typed if the specification of every operation defines types of data to which the operation is applicable.  In contrast, an untyped language, such as most  , allows any operation to be performed on any data, generally sequences of bits of various lengths.  In practice, while few languages are fully typed, most offer a degree of typing.  \n Because different types (such as   and  ) represent values differently, unexpected results will occur if one type is used when another is expected.   will flag this error, usually at   (runtime type checking is more costly).  With  ,   can always be detected unless variables are explicitly   to a different type.   occurs when languages allow implicit casting—for example, to enable operations between variables of different types without the programmer making an explicit type conversion. The more cases in which this   is allowed, the fewer type errors can be detected.   \n Early programming languages often supported only built-in, numeric types such as the   (signed and unsigned) and   (to support operations on   that are not integers). Most programming languages support multiple sizes of floats (often called   and  ) and integers depending on the size and precision required by the programmer. Storing an integer in a type that is too small to represent it leads to  . The most common way of representing negative numbers with signed types is  , although   is also used.   Other common types include  —which is either true or false—and  —traditionally one  , sufficient to represent all   characters.  \n  are a data type whose elements, in many languages, must consist of a single type of fixed length. Other languages define arrays as references to data stored elsewhere and support elements of varying types.  Depending on the programming language, sequences of multiple characters, called  , may be supported as arrays of characters or their own  .  Strings may be of fixed or variable length, which enables greater flexibility at the cost of increased storage space and more complexity.  Other data types that may be supported include  ,    accessed via keys,    in which data is mapped to names in an ordered structure,  and  —similar to records but without names for data fields.    store memory addresses, typically referencing locations on the   where other data is stored. \n The simplest   is an   whose values can be mapped onto the set of positive integers.  Since the mid-1980s, most programming languages also support  , in which the representation of the data and operations are  , who can only access an  .  The benefits of   can include increased reliability, reduced complexity, less potential for  , and allowing the underlying   to be changed without the client needing to alter its code. \n In  , all expressions have their types determined before a program executes, typically at compile-time.  Most widely used, statically typed programming languages require the types of variables to be specified explicitly. In some languages, types are implicit; one form of this is when the compiler can   types based on context. The downside of   is the potential for errors to go undetected.  Complete type inference has traditionally been associated with functional languages such as   and  .  \n With dynamic typing, the type is not attached to the variable but only the value encoded in it. A single variable can be reused for a value of a different type. Although this provides more flexibility to the programmer, it is at the cost of lower reliability and less ability for the programming language to check for errors.  Some languages allow variables of a   to which any type of value can be assigned, in an exception to their usual static typing rules. \n In computing, multiple instructions can be executed simultaneously. Many programming languages support instruction-level and subprogram-level concurrency.  By the twenty-first century, additional processing power on computers was increasingly coming from the use of additional processors, which requires programmers to design software that makes use of multiple processors simultaneously to achieve improved performance.    such as   and   do not support the concurrent use of multiple processors.  Other programming languages do support managing data shared between different threads by controlling the order of execution of key instructions via the use of  , controlling access to shared data via  , or enabling   between threads. \n Many programming languages include exception handlers, a section of code triggered by   that can deal with them in two main ways: \n Some programming languages support dedicating a block of code to run regardless of whether an exception occurs before the code is reached; this is called finalization. \n There is a tradeoff between increased ability to handle exceptions and reduced performance.  For example, even though array index errors are common  C does not check them for performance reasons.  Although programmers can write code to catch user-defined exceptions, this can clutter a program. Standard libraries in some languages, such as C, use their return values to indicate an exception.  Some languages and their compilers have the option of turning on and off error handling capability, either temporarily or permanently. \n One of the most important influences on programming language design has been  .  , the most commonly used type, were designed to perform well on  , the most common computer architecture.  In von Neumann architecture, the   stores both data and instructions, while the   that performs instructions on data is separate, and data must be piped back and forth to the CPU. The central elements in these languages are variables,  , and  , which is more efficient than   on these machines.   \n Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse.  The birth of programming languages in the 1950s was stimulated by the desire to make a universal programming language suitable for all machines and uses, avoiding the need to write code for different computers.  By the early 1960s, the idea of a universal language was rejected due to the differing requirements of the variety of purposes for which code was written.  \n Desirable qualities of programming languages include readability, writability, and reliability.  These features can reduce the cost of training programmers in a language, the amount of time needed to write and maintain programs in the language, the cost of compiling the code, and increase runtime performance.  \n Programming language design often involves tradeoffs.  For example, features to improve reliability typically come at the cost of performance.  Increased expressivity due to a large number of operators makes writing code easier but comes at the cost of readability. \n \n  has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate.   took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs.    was similarly dismissive of the idea.  \n The specification of a programming language is an artifact that the language   and the   can use to agree upon whether a piece of   is a valid   in that language, and if so what its behavior shall be.\n A programming language specification can take several forms, including the following:\n An implementation of a programming language is the conversion of a program into   that can be executed by the hardware. The machine code then can be executed with the help of the  .  The most common form of interpretation in   is by a  , which translates the source code via an intermediate-level language into machine code, known as an  . Once the program is compiled, it will run more quickly than with other implementation methods.  Some compilers are able to provide further   to reduce memory or computation usage when the executable runs, but increasing compilation time. \n Another implementation method is to run the program with an  , which translates each line of software into machine code just before it executes. Although it can make debugging easier, the downside of interpretation is that it runs 10 to 100 times slower than a compiled executable.  Hybrid interpretation methods provide some of the benefits of compilation and some of the benefits of interpretation via partial compilation. One form this takes is  , in which the software is compiled ahead of time into an intermediate language, and then into machine code immediately before execution. \n Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly   or internal   for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users. \n Some programming languages exist on the border between proprietary and open; for example,   asserts proprietary rights to some aspects of the  ,  and  's   programming language, which has open implementations of most parts of the system, also has   (CLR) as a closed environment. \n Many proprietary languages are widely used, in spite of their proprietary nature; examples include  ,  , and  . Some languages may make the transition from closed to open; for example,   was originally Ericsson's internal programming language. \n Open source programming languages are particularly helpful for   applications, enhancing the capacity for   and code sharing. \n Thousands of different programming languages have been created, mainly in the computing field. \nIndividual software projects commonly use five programming languages or more. \n Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers \"do exactly what they are told to do\", and cannot \"understand\" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using  , which interleaves natural language with code written in a programming language.\n A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A   uses the   present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called  ).    is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.\n Programs for a computer might be   in a   without human interaction, or a user might type   in an   of an  . In this case the \"commands\" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a   or other  ), without compiling, it is called a  . \n Determining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example,   is still strong in the corporate data center, often on large  ;    in scientific and engineering applications;   in aerospace, transportation, military, real-time, and embedded applications; and   in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.\n Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:\n Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages (in descending order by overall popularity):  ,  ,  ,  ,  ,  ,  ,  ,  , and  . \n As of June 2024, the top five programming languages as measured by   are  ,  ,  ,   and  . TIOBE provide a list of top 100 programming languages according to popularity and update this list every month. \n A   of a programming language or a   is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as   and  , standards may be considered insufficient, inadequate, or illegitimate by implementors, so often they will deviate from the standard, making a new  . In other cases, a dialect is created for use in a  , often a subset. In the   world, most languages that use basic   syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly as do, say,   and  . As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The   language has  .\n Programming languages are often placed into four main categories:  ,  ,  , and  . \n Although   are not programming languages, some have extensions that support limited programming. Additionally, there are special-purpose languages that are not easily compared to other programming languages. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_BASIC_dialects", "title": "List of BASIC dialects", "content": "\n This is an alphabetical   –   and   variants of the    . Each dialect's platform(s), i.e., the   models and  , are given in parentheses along with any other significant information.\n \n \n  (a.k.a.  ) extend a particular BASIC.\n \n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/BASIC", "title": "BASIC", "content": "\n  ( )  is a family of  ,   designed for ease of use.   was created by   and   at   in 1963. They wanted to enable students in non-scientific fields to use computers. At the time, nearly all computers required writing custom software, which only   and   tended to learn.\n In addition to the programming language, Kemeny and Kurtz developed the   (DTSS), which allowed multiple users to edit and run BASIC programs simultaneously on remote terminals. This general model became popular on   systems like the   and   in the late 1960s and early 1970s.   produced an entire computer line for this method of operation, introducing the   series in the late 1960s and continuing sales into the 1980s. Many early video games trace their history to one of these versions of BASIC.\n The emergence of   in the mid-1970s led to the development of multiple BASIC dialects, including   in 1975. Due to the tiny   available on these machines, often 4 KB, a variety of   dialects were also created. BASIC was available for almost any system of the era, and became the   programming language for   systems that emerged in the late 1970s. These   almost always had a   installed by default, often in the machine's   or sometimes on a   cartridge.\n BASIC declined in popularity in the 1990s, as more powerful microcomputers came to market and programming languages with advanced features (such as   and  ) became tenable on such computers. By then, most nontechnical personal computer users relied on pre-written applications rather than writing their own programs. In 1991,   released  , combining an updated version of BASIC with a  . This reignited use of the language and \"VB\" remains a major programming language  in the form of  , while a hobbyist scene for BASIC more broadly continues to exist. \n  was the chairman of the Dartmouth College Mathematics Department. Based largely on his reputation as an innovator in math teaching, in 1959 the college won an   award for $500,000 to build a new department building.    had joined the department in 1956, and from the 1960s Kemeny and Kurtz agreed on the need for programming literacy among students outside the traditional   fields. Kemeny later noted that \"Our vision was that every student on campus should have access to a  , and any faculty member should be able to use a computer in the classroom whenever appropriate. It was as simple as that.\" \n Kemeny and Kurtz had made two previous experiments with simplified languages,   (Dartmouth Simplified Code) and  . These did not progress past a single freshman class. New experiments using   and   followed, but Kurtz concluded these languages were too tricky for what they desired. As Kurtz noted, Fortran had numerous oddly formed commands, notably an \"almost impossible-to-memorize convention for specifying a loop:  . Is it '1, 10, 2' or '1, 2, 10', and is the comma after the line number required or not?\" \n Moreover, the lack of any sort of immediate feedback was a key problem; the machines of the era used   and took a long time to complete a run of a program. While Kurtz was visiting  ,   suggested that   offered a solution; a single machine could divide up its processing time among many users, giving them the illusion of having a (slow) computer to themselves.  Small programs would return results in a few seconds. This led to increasing interest in a system using time-sharing and a new language specifically for use by non-STEM students. \n Kemeny wrote the first version of BASIC. The     comes from the name of an unpublished paper by Thomas Kurtz.  The new language was heavily patterned on FORTRAN II; statements were one-to-a-line, numbers were used to indicate the target of loops and branches, and many of the commands were similar or identical to Fortran. However, the   was changed wherever it could be improved. For instance, the difficult to remember   loop was replaced by the much easier to remember  , and the line number used in the DO was instead indicated by the  .  Likewise, the cryptic   statement of Fortran, whose syntax matched a particular instruction of the machine on which it was originally written, became the simpler  . These changes made the language much less idiosyncratic while still having an overall structure and feel similar to the original FORTRAN. \n The project received a $300,000 grant from the  , which was used to purchase a   computer for processing, and a Datanet-30 realtime processor to handle the     used for input and output. A team of a dozen undergraduates worked on the project for about a year, writing both the DTSS system and the BASIC compiler.  The first version BASIC language was released on 1 May 1964. \n Initially, BASIC concentrated on supporting straightforward mathematical work, with   arithmetic support from its initial implementation as a batch language, and   functionality being added by 1965. Usage in the university rapidly expanded, requiring the main CPU to be replaced by a GE-235,  and still later by a GE-635. By the early 1970s there were hundreds of terminals connected to the machines at Dartmouth, some of them remotely.\n Wanting use of the language to become widespread, its designers made the compiler available free of charge. In the 1960s, software became a chargeable commodity; until then, it was provided without charge as a service with expensive computers, usually available only to lease. They also made it available to high schools in the  , area and regionally throughout New England on Teletype Model 33 and Model 35 teleprinter terminals connected to Dartmouth via dial-up phone lines, and they put considerable effort into promoting the language. In the following years, as other dialects of BASIC appeared, Kemeny and Kurtz's original BASIC dialect became known as  .\n New Hampshire recognized the accomplishment in 2019 when it erected a highway historical marker in Hanover describing the creation of \"the first user-friendly programming language\". \n The emergence of BASIC took place as part of a wider movement toward time-sharing systems. First conceptualized during the late 1950s, the idea became so dominant in the computer industry by the early 1960s that its proponents were speaking of a future in which users would \"buy time on the computer much the same way that the average household buys power and water from utility companies\". \n General Electric, having worked on the Dartmouth project, wrote their own underlying operating system and launched an online time-sharing system known as Mark I. It featured BASIC as one of its primary selling points. Other companies in the emerging field quickly followed suit;   introduced   in 1968,   had a version on the   at their launch in 1969, and by the early 1970s BASIC was largely universal on general-purpose  . Even   eventually joined the club with the introduction of VS-BASIC in 1973. \n Although time-sharing services with BASIC were successful for a time, the widespread success predicted earlier was not to be. The emergence of minicomputers during the same period, and especially low-cost microcomputers in the mid-1970s, allowed anyone to purchase and run their own systems rather than buy online time which was typically billed at dollars per minute. \n BASIC, by its very nature of being small, was naturally suited to porting to the   market, which was emerging at the same time as the time-sharing services. These machines had small  , perhaps as little as 4 KB in modern terminology,  and lacked high-performance storage like   that make compilers practical. On these systems, BASIC was normally implemented as an interpreter rather than a compiler due to its lower requirement for working memory. \n A particularly important example was  , which, like the original Dartmouth system, used two computers working together to implement a time-sharing system. The first, a low-end machine in the   series, was used to control user input and save and load their programs to tape or disk. The other, a high-end version of the same underlying machine, ran the programs and generated output. For a cost of about $100,000, one could own a machine capable of running between 16 and 32 users at the same time.  The system, bundled as the HP 2000, was the first mini platform to offer time-sharing and was an immediate runaway success, catapulting HP to become the third-largest vendor in the minicomputer space, behind   and   (DG). \n DEC, the leader in the minicomputer space since the mid-1960s, had initially ignored BASIC. This was due to their work with  , who had purchased a   to run their   language, which was conceptually very similar to BASIC.  This led DEC to introduce a smaller, cleaned up version of JOSS known as  , which they heavily promoted in the late 1960s. However, with timesharing systems widely offering BASIC, and all of their competition in the minicomputer space doing the same, DEC's customers were clamoring for BASIC. After management repeatedly ignored their pleas,   took it upon himself to buy a BASIC for the  , which was a major success in the education market. By the early 1970s, FOCAL and JOSS had been forgotten and BASIC had become almost universal in the minicomputer market.  DEC would go on to introduce their updated version,  , for use on the   time-sharing operating system.\n During this period a number of simple   were written in BASIC, most notably Mike Mayfield's  . David Ahl collected these, some ported from FOCAL, and published them in an educational newsletter he compiled. He later collected a number of these into book form,  , published in 1973.  During the same period, Ahl was involved in the creation of a small computer for education use, an early  . When management refused to support the concept, Ahl left DEC in 1974 to found the seminal computer magazine,  . The book remained popular, and was re-published on several occasions. \n The introduction of the first   in the mid-1970s was the start of explosive growth for BASIC. It had the advantage that it was fairly well known to the young designers and computer hobbyists who took an interest in microcomputers, many of whom had seen BASIC on minis or mainframes. Despite  's famous judgement in 1975, \"It is practically impossible to teach good programming to students that have had a prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of regeneration\",  BASIC was one of the few languages that was both high-level enough to be usable by those without training and small enough to fit into the microcomputers of the day, making it the   standard programming language on early microcomputers.\n The first   of BASIC was co-written by  ,   and   for their newly formed company, Micro-Soft.  This was released by MITS in   format for the   shortly after the machine itself,  immediately cementing BASIC as the primary language of early microcomputers. Members of the   began circulating copies of the program, causing Gates to write his  , complaining about this early example of  .\n Partially in response to Gates's letter, and partially to make an even smaller BASIC that would run usefully on 4 KB machines,    urged   to write their own variation of the language. How to design and implement a stripped-down version of an   for the BASIC language was covered in articles by Allison in the first three quarterly issues of the   newsletter published in 1975 and implementations with source code published in  . This led to a wide variety of   with added features or other improvements, with versions from Tom Pittman and   becoming particularly well known. \n Micro-Soft, by this time  , ported their interpreter for the  , which quickly become one of the most popular microprocessors of the 8-bit era. When new microcomputers began to appear, notably the \"1977 trinity\" of the  ,   and  , they either included a version of the MS code, or quickly introduced new models with it.   personal computers also joined this trend at that time. By 1978, MS BASIC was a   standard and practically every   of the 1980s included it in  . Upon boot, a BASIC interpreter in   was presented.\n  includes  , based on Microsoft BASIC. The Apple II and TRS-80 each have two versions of BASIC: a smaller introductory version with the initial releases of the machines and a Microsoft-based version introduced as interest in the platforms increased. As new companies entered the field, additional versions were added that subtly changed the BASIC family. The   use the 8 KB   which is not derived from Microsoft BASIC.   was introduced in 1980 with the Sinclair  , and was later extended for the Sinclair   and the Sinclair  . The   published  , developed by  , incorporates extra   keywords and floating-point features.\n As the popularity of BASIC grew in this period, computer magazines published complete source code in BASIC for video games, utilities, and other programs. Given BASIC's straightforward nature, it was a simple matter to   from the magazine and execute the program. Different magazines were published featuring programs for specific computers, though some BASIC programs were considered universal and could be used in machines running any variant of BASIC (sometimes with minor adaptations). Many books of type-in programs were also available, and in particular, Ahl published versions of the original 101 BASIC games converted into the Microsoft dialect and published it from   as  . This book, and its sequels, provided hundreds of ready-to-go programs that could be easily converted to practically any BASIC-running platform.  The book reached the stores in 1978, just as the   market was starting off, and it became the first million-selling computer book. Later packages, such as Learn to Program BASIC would also have gaming as an introductory focus. On the business-focused   computers which soon became widespread in small business environments,   ( ) was one of the leading applications. \n In 1978, David Lien published the first edition of  , documenting keywords across over 78 different computers. By 1981, the second edition documented keywords from over 250 different computers, showcasing the explosive growth of the microcomputer era. \n When IBM was designing the  , they followed the paradigm of existing home computers in having a built-in BASIC interpreter. They sourced this from Microsoft –   – but Microsoft also produced several other versions of BASIC for  /  including   (BASIC D),   (BASIC A),   (a BASICA-compatible version that did not need IBM's ROM)  and  , all typically bundled with the machine. In addition they produced the Microsoft BASIC Compiler aimed at professional programmers.  -publisher   published   1.0 in 1985 (successor versions are still being marketed under the name  ). On   systems, specialized implementations were created such as   and  .  XBasic was ported to   as  , and   variants such as  ,  ,  ,   ,   ,   ,   , and   emerged.   and   meanwhile targeted the  , while yab is a version of   optimized for  ,   and  . \n These later variations introduced many extensions, such as improved   and graphics support, access to the   and additional  . More important were the facilities for  , including additional   and proper   supporting  .  However, by the latter half of the 1980s, users were increasingly using pre-made applications written by others rather than learning programming themselves; while professional programmers now had a wide range of more advanced languages available on small computers.   and later   became the languages of choice for professional   application development. \n A niche that BASIC continued to fill was for hobbyist  , as   and readily available   were still in their infancy. The   had   while the   had   for this purpose. Microsoft first exhibited BASIC for game development with   for  , and later   and   for  .   maintained an active game development community,  which helped later spawn the   and   implementations.  In 2013 a game written in   and compiled with   for modern computers entitled   was released on  .   ,  ,  ,  ,   ,   ,   ,   ,    and   further filled this demand, right up to the modern  ,   ,   ,    and  . \n In 1991, Microsoft introduced  , an evolutionary development of  . It included constructs from that language such as block-structured control statements, parameterized subroutines and optional   as well as   constructs from other languages such as \"With\" and \"For Each\". The language retained some compatibility with its predecessors, such as the Dim keyword for declarations, \"Gosub\"/Return statements and optional line numbers which could be used to locate errors. An important driver for the development of Visual Basic was as the new   for  , a   program. To the surprise of many at Microsoft who still initially marketed it as a language for hobbyists, the language came into widespread use for small custom business applications shortly after the release of VB version 3.0, which is widely considered the first relatively stable version. Microsoft also spun it off as   and  .\n While many advanced programmers still scoffed at its use, VB met the needs of   efficiently as by that time, computers running Windows 3.1 had become fast enough that many business-related processes could be completed \"in the blink of an eye\" even using a \"slow\" language, as long as large amounts of data were not involved. Many small business owners found they could create their own small, yet useful applications in a few evenings to meet their own specialized needs. Eventually, during the lengthy lifetime of VB3, knowledge of Visual Basic had become a marketable job skill. Microsoft also produced   in 1996 and   in 2001. The latter has essentially the same power as   and   but with syntax that reflects the original Basic language, and also features some cross-platform capability through implementations such as  .  The  , with its    , was also influential on other   tools, most notably  's   for   and its own descendants such as  . \n Mainstream support for the final version 6.0 of the original Visual Basic ended on March 31, 2005, followed by extended support in March 2008.  Owing to its persistent remaining popularity,  third-party attempts to further support it exist.  On February 2, 2017, Microsoft announced that development on VB.NET would no longer be in parallel with that of C#,  and on March 11, 2020, it was announced that evolution of the VB.NET language had also concluded.  Even so, the language was still supported. \n Many other BASIC dialects have also sprung up since 1990, including the     and  , inspired by QBasic, and the Visual Basic-styled  ,  ,   and  .  Modern commercial incarnations include  ,  ,  ,   and   (the direct successor to Dartmouth BASIC from a company controlled by Kurtz).\n Several web-based simple BASIC interpreters also now exist, including Microsoft's   and  's wwwBASIC.  A number of compilers also exist that convert BASIC into  .  such as  .\n Building from earlier efforts such as  ,  many dialects are now available for   and tablets.\n On game consoles, an application for the   and   called   allows for programming in a slightly modified version of BASIC with DS button support. A version has also been released for  , which has also been supplied a version of the Fuze Code System,  a BASIC variant  first implemented as a custom   machine.  Previously BASIC was made available on consoles as   (for the  ) and     (for the original  ), while   was ported to the   and   to the original  .\n Variants of BASIC are available on graphing and otherwise   made by   ( ), HP ( ), Casio ( ), and others.\n , a version of Microsoft   without the linker to make EXE files, is present in the   and DOS-  streams of operating systems and can be obtained for more recent releases like   which do not have them. Prior to DOS 5, the Basic interpreter was  . QuickBasic is part of a series of three languages issued by Microsoft for the home and office power user and small-scale professional development; QuickC and QuickPascal are the other two. For   and 98, which do not have QBasic installed by default, they can be copied from the installation disc, which will have a set of directories for old and optional software; other missing commands like Exe2Bin and others are in these same directories.\n The various Microsoft, Lotus, and Corel office suites and related products are programmable with Visual Basic in one form or another, including  , which is very similar to VBA 6. The Host Explorer terminal emulator uses WWB as a macro language; or more recently the programme and the suite in which it is contained is programmable in an in-house Basic variant known as Hummingbird Basic. The VBScript variant is used for programming web content, Outlook 97, Internet Explorer, and the Windows Script Host. WSH also has a   (VBA) engine installed as the third of the default engines along with VBScript, JScript, and the numerous proprietary or open source engines which can be installed like  , a couple of Rexx-based engines, Python, Ruby, Tcl, Delphi, XLNT, PHP, and others; meaning that the two versions of Basic can be used along with the other mentioned languages, as well as LotusScript, in a WSF file, through the component object model, and other WSH and VBA constructions. VBScript is one of the languages that can be accessed by the 4Dos, 4NT, and Take Command enhanced shells. SaxBasic and WWB are also very similar to the Visual Basic line of Basic implementations. The pre-Office 97 macro language for Microsoft Word is known as  . Excel 4 and 5 use Visual Basic itself as a macro language.  , an old-school interpreter similar to BASICs of the 1970s, is available for  ,   and  .\n The ubiquity of BASIC interpreters on personal computers was such that textbooks once included simple \"Try It In BASIC\" exercises that encouraged students to experiment with mathematical and computational concepts on classroom or home computers. Popular computer magazines of the day typically included  .\n Futurist and sci-fi writer   mourned the loss of ubiquitous BASIC in a 2006   article  as have others who first used computers during this era. In turn, the article prompted Microsoft to develop and release  ;  it also inspired similar projects like   and the web based Quite Basic.    held a 50th anniversary celebration for BASIC on 1 May 2014.  The pedagogical use of BASIC has been followed by other languages, such as  ,   and particularly  . \n Dartmouth College celebrated the 50th anniversary of the BASIC language with a day of events  on April 30, 2014. A short documentary film was produced for the event. \n Minimal versions of BASIC had only integer variables and one- or two-letter variable names, which minimized requirements of limited and expensive memory (RAM). More powerful versions had floating-point arithmetic, and variables could be labelled with names six or more characters long. There were some problems and restrictions in early implementations; for example, Applesoft BASIC allowed variable names to be several characters long, but only the first two were significant, thus it was possible to inadvertently write a program with variables \"LOSS\" and \"LOAN\", which would be treated as being the same; assigning a value to \"LOAN\" would silently overwrite the value intended as \"LOSS\". Keywords could not be used in variables in many early BASICs; \"SCORE\" would be interpreted as \"SC\" OR \"E\", where OR was a keyword.   variables are usually distinguished in many microcomputer dialects by having $ suffixed to their name as a  , and values are often identified as strings by being delimited by \"double quotation marks\". Arrays in BASIC could contain integers, floating point or string variables.\n Some dialects of BASIC supported  , which can be used to solve sets of simultaneous linear algebraic equations. These dialects would directly support matrix operations such as assignment, addition, multiplication (of compatible matrix types), and evaluation of a determinant. Many microcomputer BASICs did not support this data type; matrix operations were still possible, but had to be programmed explicitly on array elements.\n New BASIC programmers on a home computer might start with a simple program, perhaps using the language's PRINT statement to display a message on the screen; a well-known and often-replicated example is  's  :\n An   could be used to fill the display with the message:\n Note that the   statement is optional and has no action in most dialects of BASIC. It was not always included, as is the case in this example. This same program can be modified to print a fixed number of messages using the common   statement:\n Most home computers BASIC versions, such as   and  , supported simple data types, loop cycles, and arrays. The following example is written for GW-BASIC, but will work in most versions of BASIC with minimal changes:\n The resulting dialog might resemble:\n The original Dartmouth Basic was unusual in having a matrix keyword, MAT.  Although not implemented by most later microprocessor derivatives, it is used in this example from the 1968 manual  which averages the numbers that are input:\n Second-generation BASICs (for example,  ,  ,  ,  ,  ,  ,  ,  ,   and (arguably)  ) introduced a number of features into the language, primarily related to structured and procedure-oriented programming. Usually,   is omitted from the language and replaced with   (for  ) and   to encourage easier and more flexible design.  In addition keywords and structures to support repetition, selection and procedures with local variables were introduced.\n The following example is in Microsoft QuickBASIC:\n Third-generation BASIC dialects such as  ,  ,  ,  ,   and   introduced features to support object-oriented and   paradigm. Most built-in procedures and functions are now represented as   of standard objects rather than  . Also, the   became increasingly accessible to the BASIC language.\n The following example is in  :\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Non-English-based_programming_languages", "title": "Non-English-based programming languages", "content": "\n  are   that do not use keywords taken from or inspired by   vocabulary.\n The use of the   in the inspiration for the choice of elements, in particular for   in computer programming languages and code libraries, represents a significant trend in the history of language design. According to the HOPL online database of languages,  out of the 8,500+ programming languages recorded, roughly 2,400 of them were developed in the  , 600 in the  , 160 in  , and 75 in  .\n Thus, over a third of all programming languages have been developed in countries where English is the primary language. This does not take into account the usage share of each programming language, situations where a language was developed in a non-English-speaking country but used English to appeal to an international audience (see the case of   from the  ,   from  , and   from  ), and situations where it was based on another programming language which used English.\n The concept of international-style programming languages was inspired by the work of British    ,  , and others. It represents a class of languages of which the line of the algorithmic languages   was exemplary.\n 's standard document was published in numerous  . The standard allowed the internationalization of the programming language. On December 20, 1968, the \"Final Report\" (MR 101) was adopted by the Working Group, then subsequently approved by the General Assembly of  's   for publication. Translations of the standard were made for  ,  ,  ,  , and then later  . The standard was also available in  . ALGOL 68 went on to become the  -27974-88 standard in the  .\n In English, Algol68's case statement reads   ~   ~   ~  . In  , this reads   ~   ~   ~  .\n Localization is the core feature of the  . Citrine is designed to be translatable to every written human language. For instance the   version is called Citrine/FY. Citrine features localized keywords, localized numbers and localized punctuation. Users can translate code files from one language into another using a string-based approach. At the time of writing, Citrine supports 111 human languages. Support is not limited to well-known languages; all natural human languages up to   are being accepted for inclusion.\n Hedy is an   programming language which was developed for programming education. It was designed to be as instructive as possible and as accessible as possible with a few unique features. As of September 2024  it supports 47 different languages,  meaning its keywords can be typed in any of those. It supports languages that do not use the   for their keywords and variable names and it also supports more numbering systems than  , like  . All of these can be used interchangeably. The error messages are quite verbose, explaining what is wrong and what might be a fix, just like the   compiler.\n While   is not a part of any   standard, the expressiveness and flexibility of the language allows for the addition of internationalization as a  .    is an   project to which anyone can contribute a translation.  Since translations of Scheme can be loaded as libraries, Scheme programs can be  .\n  is a block-based educational language. The text of the blocks is translated into many languages, and users can select different translations. Unicode characters are supported in variable and list names. (Scratch lists are not stored inside variables the way arrays or lists are handled in most languages. Variables only store strings, numbers, and, with workarounds, Boolean values, while lists are a separate data type that store sequences of these values.) Projects can be \"translated\" by simply changing the language of the editor, although this does not translate the variable names.\n  on  \n ,  \n \n Ceylonicus is an  ,  , and   programming language designed to bridge the gap between   and   syntax within a unified codebase. As a Sinhala Programming Language, it empowers developers to express their ideas in both languages seamlessly. Ceylonicus is implemented in  , and features a web-based environment, built using  .\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Shell_script", "title": "Shell script", "content": "A   is a   designed to be run by a  , a  .  The various dialects of shell scripts are considered to be  . Typical operations performed by shell scripts include file manipulation, program execution, and printing text. A script which sets up the environment, runs the program, and does any necessary cleanup or logging, is called a  .\n The term is also used more generally to mean the automated mode of running an operating system shell;  each operating system uses a particular name for these functions including batch files (MSDos-Win95 stream,  ), command procedures (VMS), and shell scripts (  stream and third-party derivatives like  —article is at  ), and mainframe operating systems are associated with a number of terms.\n Shells commonly present in Unix and Unix-like systems include the  , the  , and  . While a Unix operating system may have a different default shell, such as   on  , these shells are typically present for backwards compatibility.\n  are ignored by the shell. They typically begin with the hash symbol ( ), and continue until the end of the line. \n The  , or hash-bang, is a special kind of comment which the system uses to determine what interpreter to use to execute the file. The shebang must be the first line of the file, and start with \" \".  In Unix-like operating systems, the characters following the \" \" prefix are interpreted as a path to an executable program that will interpret the script. \n A shell script can provide a convenient variation of a system command where special environment settings, command options, or post-processing apply automatically, but in a way that allows the new script to still act as a fully normal  .\n One example would be to create a version of  , the command to list files, giving it a shorter command name of  , which would be normally saved in a user's   directory as  , and a default set of command options pre-supplied.\n Here, the first line uses a   to indicate which interpreter should execute the rest of the script, and the second line makes a listing with options for file format indicators, columns, all files (none omitted), and a size in blocks. The   sets the default collation order to not fold upper and lower case together, not intermix   with normal filenames as a side effect of ignoring punctuation in the names (dotfiles are usually only shown if an option like   is used), and the   causes any parameters given to   to pass through as parameters to ls, so that all of the normal options and other   known to ls can still be used.\n The user could then simply use   for the most commonly used short listing.\n Another example of a shell script that could be used as a shortcut would be to print a list of all the files and directories within a given directory.\n In this case, the shell script would start with its normal starting line of  . Following this, the script executes the command   which clears the terminal of all text before going to the next line. The following line provides the main function of the script. The   command lists the files and directories that are in the directory from which the script is being run. The   command attributes could be changed to reflect the needs of the user.\n Shell scripts allow several commands that would be entered manually at a command-line interface to be executed automatically, and without having to wait for a user to trigger each stage of the sequence. For example, in a directory with three C source code files, rather than manually running the four commands required to build the final program from them, one could instead create a script for  -compliant shells, here named   and kept in the directory with them, which would compile them automatically:\n The script would allow a user to save the file being edited, pause the editor, and then just run   to create the updated program, test it, and then return to the editor. Since the 1980s or so, however, scripts of this type have been replaced with utilities like   which are specialized for building programs.\n Simple batch jobs are not unusual for isolated tasks, but using shell loops, tests, and variables provides much more flexibility to users. A POSIX sh script to convert JPEG images to PNG images, where the image names are provided on the command-line—possibly via wildcards—instead of each being listed within the script, can be created with this file, typically saved in a file like  \n The   command can then be run on an entire directory full of JPEG images with just  \n Many modern shells also supply various features usually found only in more sophisticated  , such as control-flow constructs, variables,  , arrays,   and so on. With these sorts of features available, it is possible to write reasonably sophisticated applications as shell scripts. However, they are still limited by the fact that most shell languages have little or no support for data typing systems, classes, threading, complex math, and other common full language features, and are also generally much slower than compiled code or interpreted languages written with speed as a performance goal.\n The standard Unix tools   and   provide extra capabilities for shell programming;   can also be embedded in shell scripts as can other scripting languages like  . Perl and Tcl come with graphics toolkits as well.\n Scripting languages commonly found on UNIX, Linux, and POSIX-compliant operating system installations include:\n The C and Tcl shells have syntax quite similar to that of said programming languages, and the Korn shells and Bash are developments of the Bourne shell, which is based on the   language with elements of a number of others added as well.  On the other hand, the various shells plus tools like  ,  ,  , and  ,  ,   and so forth contributed to the   programming language. \n Other shells that may be available on a machine or for download and/or purchase include:\n Related programs such as shells based on  ,  ,  ,  ,  ,  ,   etc. in various forms are also widely available. Another somewhat common shell is   ( ), whose manual page states it \"is an enhanced, backward-compatible port of the standard command interpreter from Sixth Edition UNIX.\" \n So called remote shells such as \n are really just tools to run a more complex shell on a remote system and have no 'shell' like characteristics themselves.\n Many powerful scripting languages have been introduced for tasks that are too large or complex to be comfortably handled with ordinary shell scripts, but for which the advantages of a script are desirable and the development overhead of a full-blown, compiled programming language would be disadvantageous. The specifics of what separates scripting languages from   is a frequent source of debate, but, generally speaking, a scripting language is one which requires an interpreter.\n Shell scripts often serve as an initial stage in software development, and are often subject to conversion later to a different underlying implementation, most commonly being converted to  ,  , or  . The   allows the implementation detail to be fully hidden inside the script, rather than being exposed as a filename extension, and provides for seamless reimplementation in different languages with no impact on end users.\n While files with the \".sh\"   are usually a shell script of some kind, most shell scripts do not have any filename extension. \n Perhaps the biggest advantage of writing a shell script is that the commands and syntax are exactly the same as those directly entered at the command-line. The programmer does not have to switch to a totally different syntax, as they would if the script were written in a different language, or if a compiled language were used.\n Often, writing a shell script is much quicker than writing the equivalent code in other programming languages. The many advantages include easy program or file selection, quick start, and interactive debugging. A shell script can be used to provide a sequencing and decision-making linkage around existing programs, and for moderately sized scripts the absence of a compilation step is an advantage. Interpretive running makes it easy to write debugging code into a script and re-run it to detect and fix bugs. Non-expert users can use scripting to tailor the behavior of programs, and shell scripting provides some limited scope for multiprocessing.\n On the other hand, shell scripting is prone to costly errors. Inadvertent typing errors such as   (instead of the intended  ) are folklore in the Unix community; a single extra space converts the command from one that deletes all subdirectories contained in the current directory, to one which deletes everything from the file system's  . Similar problems can transform   and   into dangerous weapons, and misuse of the   redirect can delete the contents of a file. This is made more problematic by the fact that many UNIX commands differ in name by only one letter:  ,  ,  ,  , etc.\n Another significant disadvantage is the slow execution speed and the need to launch a new process for almost every shell command executed. When a script's job can be accomplished by setting up a   in which efficient   commands perform most of the work, the slowdown is mitigated, but a complex script is typically several orders of magnitude slower than a conventional compiled program that performs an equivalent task.\n There are also compatibility problems between different platforms.  , creator of  , famously wrote that \"It's easier to port a shell than a shell script.\" \n Similarly, more complex scripts can run into the limitations of the shell scripting language itself; the limits make it difficult to write quality code, and extensions by various shells to ameliorate problems with the original shell language can make problems worse. \n Many disadvantages of using some script languages are caused by design flaws within the   or implementation, and are not necessarily imposed by the use of a text-based command-line; there are a number of shells which use other shell programming languages or even full-fledged languages like   (which uses  ).\n Different scripting languages may share many common elements, largely due to being POSIX based, and some shells offer modes to emulate different shells. This allows a shell script written in one scripting language to be adapted into another.\n One example of this is Bash, which offers the same grammar and syntax as the Bourne shell, and which also provides a POSIX-compliant mode.  As such, most shell scripts written for the Bourne shell can be run in BASH, but the reverse may not be true since BASH has extensions which are not present in the Bourne shell. As such, these features are known as  . \n Interoperability software such as  , the  ,   (which is available in the Microsoft Windows Services for UNIX),  ,   (AT&T Unix for Windows) and others allow Unix shell programs to be run on machines running Windows NT and its successors, with some loss of functionality on the  -  branch, as well as earlier MKS Toolkit versions for OS/2. At least three DCL implementations for Windows type operating systems—in addition to  , a multiple-use scripting language package which is used with the command shell,   and   programming—are available for these systems as well. Mac OS X and subsequent are Unix-like as well. \n In addition to the aforementioned tools, some   and OS/2 functionality can be used with the corresponding environmental subsystems of the Windows NT operating system series up to Windows 2000 as well. A third,   subsystem often called the MS-DOS subsystem uses the Command.com provided with these operating systems to run the aforementioned MS-DOS batch files. \n The console alternatives  ,  ,  ,  's   and   which add functionality to the Windows NT-style cmd.exe, MS-DOS/Windows 95 batch files (run by Command.com), OS/2's cmd.exe, and 4NT respectively are similar to the shells that they enhance and are more integrated with the Windows Script Host, which comes with three pre-installed engines, VBScript,  , and   and to which numerous third-party engines can be added, with Rexx, Perl, Python, Ruby, and Tcl having pre-defined functions in 4NT and related programs.   is quite similar to MS-DOS, whilst   is more different. Earlier versions of Windows NT are able to run contemporary versions of 4OS2 by the OS/2 subsystem.\n Scripting languages are, by definition, able to be extended; for example, a MS-DOS/Windows 95/98 and Windows NT type systems allows for shell/batch programs to call tools like  ,  , various  ,  ,  , and   implementations, the   and its installed engines. On Unix and other  -compliant systems,   and   are used to extend the string and numeric processing ability of shell scripts.  , Perl, Rexx, and Python have graphics toolkits and can be used to code functions and procedures for shell scripts which pose a speed bottleneck (C, Fortran, assembly language &c are much faster still) and to add functionality not available in the shell language such as sockets and other connectivity functions, heavy-duty text processing, working with numbers if the calling script does not have those abilities, self-writing and self-modifying code, techniques like  , direct memory access, various types of   and more, which are difficult or impossible in the main script, and so on.   and   can be used to control and communicate with such things as spreadsheets, databases, scriptable programs of all types, telecommunications software, development tools, graphics tools and other software which can be accessed through the  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Unisys_MCP_programming_languages", "title": "Burroughs MCP", "content": "The   (Master Control Program) is the   of the     and the  , including the     systems.\n MCP was originally written in 1961 in   (Executive Systems Problem Oriented Language). In the 1970s, MCP was converted to   which was a better structured, more robust, and more secure form of ESPOL.\n The MCP was a leader in many areas, including: the first operating system to manage multiple processors, the first commercial implementation of virtual memory, and the first OS written exclusively in a  .\n In 1961, the MCP was the first OS written exclusively in a   (HLL). The   (  and successors) were unique in that they were designed with the expectation that all software, including system software, would be written in an HLL rather than in  , which was a unique and innovative approach in 1961.\n Unlike IBM, which faced hardware competition after the departure of  , Burroughs software only ever ran on Burroughs hardware due to a lack of compatible third party hardware. For this reason, Burroughs was free to distribute the source code of all software it sold, including the MCP, which was designed with this openness in mind. For example, upgrading required the user to recompile the system software and apply any needed local patches. At the time, this was common practice, and was necessary as it was not unusual for customers (especially large ones, such as the  ) to modify the program to fit their specific needs.  As a result, a Burroughs Users Group was formed, which held annual meetings and allowed users to exchange their own extensions to the OS and other parts of the system software suite. Many such extensions have found their way into the base OS code over the years, and are now available to all customers. As such, the MCP could be considered one of the earliest   projects.\n Burroughs was not the first manufacturer to distribute source code and was a late entry to electronic computing (compared to its traditional rivals NCR, IBM, and Univac). Now that MCP runs on commodity hardware, some elements of the MCP based software suite are no longer made available in source form by Unisys.\n The MCP was the first commercial OS to provide  , which has been supported by the   architecture since its inception. This scheme is unique in the industry, as it stores and retrieves compiler-defined objects rather than fixed-size memory pages, as a consequence of its overall non-von Neumann and uniformly stack-based architecture.\n Donald Knuth also had influence during this period, becoming consultant to Burroughs Corporation, joining the Product Planning Department from 1960 to 1968. He refers to “a control program” (presumably the MCP then under development) in his book   in section 2.5 on  , Knuth claims credit for “The “boundary-tag” method, introduced in Section 2.5, was designed by the author in 1962 for use in a control program for the B5000 computer.” \n Unisys stopped producing the hardware in the early 2010s, and the operating system is now run under emulation. \n The MCP provides a   with hierarchical directory structures. In early MCP implementations,   nodes were represented by separate files with directory entries, as other systems did. However, since about 1970, MCP internally uses a 'FLAT' directory listing all file paths on a volume. This is because opening files by visiting and opening each directory in a file path was inefficient and for a production environment it was found to be better to keep all files in a single directory, even though they retain the hierarchical naming scheme. Programmatically, this makes no difference. The only difference visible to users is that an entity file can have the same name as a directory. For example, \"A/B\" and \"A/B/C\" can both exist; \"B\" can be both a node in a file and a directory.\n Files are stored on named volumes, for example 'this/is/a/filename on myvol', 'myvol' being the volume name. This is device independent, since the disk containing 'myvol' can be moved or copied to different physical disk drives. Disks can also be concatenated so that a single volume can be installed across several drives, as well as mirrored for recoverability of sensitive data. For added flexibility, each program can make volume substitutions, a volume name may be substituted with a primary and secondary alternate name. This is referred to as the process’ FAMILY. For instance, the assignment “FAMILY DISK = USERPACK OTHERWISE SYSPACK” stores files logically designated on volume DISK onto the volume USERPACK and will seek files first on volume USERPACK. If that search has no success, another search for the file is done on volume SYSPACK. DISK is the default volume name if none is specified.\n Each file in the system has a set of file attributes. These attributes record all sorts of   about a file, most importantly its name and its type (which tells the system how to handle a file, like the more limited four-character file type code on the  ). Other attributes have the file's record size (if fixed for commercial applications), the block size (in multiples of records that tells the MCP how many records to read and write in a single physical IO) and an area size in multiples of blocks, which gives the size of disk areas to be allocated as the file expands.\n The file type indicates if the file is character data, or source code written in particular languages, binary data, or code files.\n Files are protected by the usual security access mechanisms such as public or private, or a file may have a guard file where the owner can specify complex security rules.\n Another security mechanism is that code files can only be created by trusted compilers. Malicious programmers cannot create a program and call it a compiler – a program could only be converted to be a compiler by an operator with sufficient privileges with the 'mc' make compiler operator command.\n The MCP implements a  , providing fault tolerance in case of disk failure, loss of power, etc. It is not possible to corrupt the file system (except by the operating system or other trusted system software with direct access to its lower layers)  .\n The file system is   and not   unless quotes are added around the name in which case it is case-sensitive and case-preserving.\n MCP   are called \" \" and \" .\" A Job contains one or more tasks. Tasks within a job can run sequentially or in parallel. Logic can be implemented at the Job level, typically in the MCP's job control language WFL, to control the flow of a job. Once all tasks in a job are complete, the job itself is completed.\n An MCP Process goes through a life cycle from the time it enters the system until it leaves. The initial state for a Job is \"Queued.\" There is a period of time while the Job resides in one of several user defined Job Queues. The next state is \"Scheduled\" as the Job moves from a queue into memory. Tasks within a job do not wait in queue; instead going directly to the 'Scheduled' state when initiated. Once a Job or Task is started, it can transition between \"Active,\" \"Waiting\" and \"Scheduled\" as it progresses. Once a Job or Task completes, it moves to the 'Completed' state.\n Running processes are those that use a processor resource and are marked as 'running'. Processes that are ready to be assigned to a processor, when there is no free processor are placed in the ready queue. Processes may be assigned a “Declared” or “Visible” priority, generally 50 as the default, but can be from 0 to 99 for user processes. System processes may be assigned the higher values. Note that this numerical priority is secondary to an overall priority, which is based on the task type. Processes that are directly part of the operating system, called Independent Runners, have the highest priority regardless of numeric priority value. Next come processes using an MCP lock, then Message Control Systems such as  . Then Discontinued processes. Then Work Flow Language jobs. Finally come user processes. At a lower level, there is a Fine priority intended to elevate the priority of tasks that do not use their full processor slice. This allows an IO bound task to get processor time ahead of a processor bound task on the same declared priority.\n Processes that are waiting on other resources, such as a file read, wait on the EVENT  . Thus all processes waiting on a single resource wait on a single event. When the resource becomes available, the event is caused, which wakes up all the processes waiting on it. Processes may wait on multiple events for any one of them to happen, including a time out. Events are fully user programmable – that is, users can write systems that use the generalized event system provided by the MCP.\n Processes that have terminated are marked as completed.\n Operationally, the status of all tasks in the system is displayed to the operator. All running and ready processes are displayed as 'Active' tasks (since the system implements  , the change from ready to running and back is so quick that distinguishing ready and running tasks is pointless because they will all get a slice of the processor within a second). All active tasks can be displayed with the 'A' command.\n Terminated tasks are displayed as completed tasks with the reason for termination, EOT for normal 'end of task', and DSed with a reason for a process failure. All processes are assigned a mix number, and operators can use this number to identify a process to control. One such command is the DS command (which stands for either Delete from Schedule, DiScontinue, or Deep Six, after the influence of Navy personnel on early computer projects, depending on who you talk to). Tasks terminated by the operator are listed in the complete entries as O-DS.\n Tasks can also terminate due to program faults, marked as F-DS or P-DS, for faults such as  ,  , etc. Completed entries can be listed by the operator with the 'C' command.\n Tasks waiting on a resource are listed under the waiting entries and the reason for waiting. All waiting tasks may be listed with the 'W' command. The reason for waiting is also listed and more information about a task may be seen with the 'Y' command. It may be that a task is waiting for operator input, which is sent to a task via the accept 'AX' command (note that operator input is very different from user input, which would be input from a network device with a GUI interface).\n Tasks waiting on user input or file reads would not normally be listed as waiting entries for operator attention. Another reason for a task to be waiting is waiting on a file. When a process opens a file, and the file is not present, the task is placed in the waiting entries, noting that it is waiting on a certain file. An operator (or the user that owns the process) has the opportunity either to copy the file to the expected place, or to redirect the task to read the file from another place, or the file might even be created by an independent process that hasn't yet completed.\n If the resource cannot be provided by the operator, the operator can DS the task as a last resort. This is different from other systems, which automatically terminate a task when a resource such as a file is not available. The MCP provides this level of operator recoverability of tasks. Other systems force programmers to add code to check for the presence of files before accessing them, and thus extra code must be written in every case to provide recoverability, or process synchronization. Such code may be written in an MCP program when it is not desirable to have a task wait, but because of the operator-level recoverability, this is not forced and therefore makes programming much simpler.\n In addition to the ability to dynamically remap file (or database) requests to other files (or databases), before or during program execution, several mechanisms are available to allow programmers to detect and recover from errors. One way, an 'ON' statement, has been around for many years. Specific faults (e.g., divide by zero) can be listed, or the catch-all 'anyfault' can be used. The statement or block following the 'ON' statement is recognized by the compiler as fault-handling code. During execution, if a recoverable fault occurs in scope of the 'on' statement, the stack is cut back and control transferred to the statement following it.\n One problem with the handling logic behind the ON statement was that it would only be invoked for program faults, not for program terminations having other causes. Over time, the need for guaranteed handling of abnormal terminations grew. In particular, a mechanism was needed to allow programs to invoke plug-ins written by customers or third parties without any risk should the plug-in behave badly. In addition to general plug-in mechanisms, the new form of dynamic library linkage ( ) allows programs to import and export functions and data, and hence one program runs code supplied by another.\n To accomplish such enhanced protection, a newer mechanism was introduced in the mid 1990s. In a misguided attempt at compatibility, it was named after the then-proposed C++ language construct of the same name. Because the syntax and behavior of the two differ to such a large extent, choosing the same name has only led to confusion and misunderstanding.\n Syntactically, 'try' statements look like 'if' statements: 'try', followed by a statement or block, followed by 'else' and another statement or block. Additional 'else' clauses may follow the first. During execution, if any recoverable termination occurs in the code following the 'try' clause, the stack is cut back if required, and control branches to the code following the first 'else'. In addition, attributes are set to allow the program to determine what happened and where (including the specific line number).\n Most events that would result in task termination are recoverable. This includes stack overflow, array access out-of-bounds, integer over/under flow, etc. Operator (or user) DS is not recoverable except by privileged tasks using an UNSAFE form of try.\n MCP thus provides a very fault-tolerant environment, not the crash-and-burn core-dump of other systems.\n As with file attributes, tasks have attributes as well, such as the task priority (which is assigned at compile time or execution time, or can be changed while the task is running), processor time, wait time, status, etc. These task attributes can be accessed programmatically as can file attributes of files. The parent task is available programmatically as a task attribute that is of type task. For example, 'myself.initiator.name' gives the name of the process that initiated the current process.\n  and   are the two main procedures handling memory allocation and deallocation. Memory needs to be allocated at process initiation and whenever a block is entered that uses arrays, files, etc.   and   not only handle memory space, they also allocate or deallocate the disk space where non memory resident data may be overlaid. Memory may be SAVE (i.e., memory resident), OVERLAYABLE (i.e., virtual memory) or STICKY (meaning memory resident, but movable). They are called upon e.g. by   when a process addresses an uninitialized array or by  .\n  handles hardware interrupts and may call upon  ,   or the like.\n  is called upon by a task exiting a block. BLOCKEXIT may in turn call  ,   or the like while cleaning up and releasing resources declared and used within that block.\n  is the main security guardian of the system, called upon at process start, file open, user log on, etc.\n  is the procedure that decides which process is the next one to receive CPU resources and is thus one of the few processes that uses the MoveStack instruction.\n A task goes through various states starting with NASCENT. At DELIVERY the event BIRTH is caused and the task's state changes to ALIVE. When PROCESSKILL is called upon, the state changes into DISEASED. When DEATH is caused the task gets put into the queue structure the MORGUE, after which all remaining resources are freed to the system by a process called PROCESSKILL.\n While the task is ALIVE, MCP functions are run on top of that particular process, thus CPU resources are automatically charged to the task causing the MCP overhead. Also, much of the MCP work is being performed with that particular stack's security rights. Only before BIRTH and after DEATH does the MCP need to be operating out of some other stack. If none is available, the system maintains an idle stack.\n MCP   provide a way of sharing data and code between processes. The article on   looks at the way dependent processes could be asynchronously run so that many processes could share common data (with the mechanisms to provide synchronized update). Such a family of related processes had to be written as a single program unit, processing procedures at higher lex levels as the asynchronous processes, which could still access global variables and other variables at lower lex levels.\n Libraries completely inverted this scenario with the following advantages:\n So clean and radical was the library mechanism that much system software underwent major rewrites resulting in a better structured systems and performance boosts.\n Libraries were introduced to MCP systems in the early 1980s, having been developed by Roy Guck and others at  . They are very much like  's monitors and provide the opportunity for controlled mutual exclusion and synchronization between client processes, using MCP EVENTs and the Dahm locking technique. Libraries offer procedural entry-points to the client, which are checked for a compatible interface (all parameters and return types of imported procedures checked) before the client is linked to the library. The library and its client may be written in different languages. The advantage is that all synchronization is provided in the library and client code does not need to worry about this level of programming at all. This results in robust code since clients can't undermine the synchronization code in the library. (Some would call this a '  Initiative'.)\n Libraries are more sophisticated forms of libraries on other systems such as  . MCP libraries can be 'shared by all', ‘shared by rununit’ or 'private'. The private case is closest to libraries on other systems – for each client a separate copy of the library is invoked and there is no data sharing between processes.\n Shared by all is more interesting. When a client starts up, it can run for a while until it requires the services in the library. Upon first reference of a library entry-point, the linkage is initiated. If an instance of the library is already running, the client is then linked to that instance of the library. All clients share the same instance.\n Shared by rununit is a sharing mechanism in between these two sharing schemes. It was designed specifically for COBOL, where a rununit is defined as the original initiating client program and all the libraries it has linked to. Each rununit gets one instance of the library and different rununits get a different instance. This is the only dynamic implementation of COBOL rununits.\n If this was the first invocation of the library, the library would run its main program (outer block in an ALGOL program) to initialize its global environment. Once initialization was complete, it would execute a freeze, at which point all exported entry points would be made available to clients. At this point, the library's stack was said to be frozen since nothing more would be run on this stack until the library became unfrozen, in which case clean-up and termination code would be run. When a client calls a routine in a library, that routine runs on top of the client stack, storing its locals and temporary variables there. This allows many clients to be running the same routine at the same time, being synchronized by the library routine, which accesses the data in the global environment of the library stack.\n Freeze could also be in three forms – temporary, permanent and controlled. Temporary meant that once the client count dropped to zero, the library would be unfrozen and terminated. Permanent meant that the library remained available for further clients even if the client count dropped to zero – permanent libraries could be unfrozen by an operator with a THAW command. A controlled freeze meant that the library actually kept running, so that it could execute monitoring functions and perform data initialization and cleanup functions for each linking client.\n Libraries could also be accessed 'by title' and 'by function'. In 'by title' the client specified the file name of the library. 'By function' was an indirect method where a client would just specify the function name of the library, for example 'system_support' and the actual location of the library is found in a table previously set up by an operator with 'SL' (system library) commands, for example 'SL system_support = *system/library/support'. MCP's fault tolerant attitude also works here – if a client tries accessing a library that is not present, the client is put in the 'waiting' tasks and the library could be made present, or the request redirected.\n Libraries can also be updated on the fly, all that needs to be done is to 'SL' the new version. Running clients will continue to use the old version until they terminate and new clients will be directed to the new version.\n Function libraries also implemented a very important security feature, linkage classes. All normal libraries have a linkage class of zero. Libraries used by the MCP or other privileged system modules may not be usable from normal programs. They are accessed by function and forced in linkage class one. A client in linkage class zero cannot link to linkage class one entry-points. A library with linkage class one that needs to offer entry-points to normal programs can do so if it is designated as ‘trusted’. It can offer selected entry-points in linkage class zero.\n The entire database system is implemented with libraries providing very efficient and tailored access to databases shared between many clients. The same goes for all networking functionality and system intrinsics.\n In the mid-1990s a new type of library was made available: Connection Libraries. These are programs in their own right that can execute independently as well as import and export data and functions to other programs in arrays of structure blocks. For example, the networking component of the operating system is available as a connection library, allowing other programs to use its services by exporting and importing functions. Upon linkage, each client gets a dedicated structure block to keep state information in. A program that uses the network might import a network-write function and export a network-read function. Thus, if you open a network connection (e.g., using  ), when data arrives for you to read, the networking component can directly call your function to consume it, without having to first copy the data to a buffer and do a context switch. Likewise, you can write data to the network by directly calling a network-write function.\n Connection Libraries allow a significant degree of control over linkages. Each side of a linkage can optionally approve a linkage and can sever the linkage as desired. State can be easily maintained per linkage as well as globally.\n Another technique for   is port files. They are like  , except that they are generalized to be multiway and bidirectional. Since these are an order of magnitude slower than other IPC techniques such as libraries, it is better to use other techniques where the IPC is between different processes on the same machine.\n The most advantageous use of port files is therefore for distributed IPC. Port files were introduced with BNA (Burroughs Network Architecture), but with the advent of standard networking technologies such as   and  / , port files can be used with these networks as well.\n A server listening for incoming connections declares a port file (a file with the KIND attribute equal to PORT). Each connection that is made from a client creates a subfile with an index, so each port file represents multiple connections to different clients around the network.\n A server process receives client requests from anywhere on the network by issuing a read on the port file (subfile = 0 to read from any subfile). It issues a response to the client that issued the request by writing to the particular subfile from which the request was read.\n The MCP also provides a sophisticated yet simple operator environment. For large installations, many operators might be required to make physical resources, such as printers (loading paper, toner cartridges, etc.) available. Low-end environments for small offices or single user may require an operator-free environment (especially the laptop implementation).\n Large systems have dedicated operations terminals called ODTs (Operator Display Terminals), usually kept in a secure environment. For small systems, machines can be controlled from any terminal (provided the terminal and user have sufficient privileges) using the MARC program (Menu Assisted Resource Control). Operator commands can also be used by users familiar with them.\n Operator commands are mostly two letters (as with Unix), and some are just one letter. This means that the operator interface must be learned, but it is very efficient for experienced operators who run a large mainframe system from day to day. Commands are case insensitive.\n Tasks are entered in the program 'mix' and identified by mix numbers, as are libraries. To execute a program, operators can use the 'EX' or 'RUN' command followed by the file name of the program. ODTs are run typically with ADM (Automatic Display Mode), which is a tailorable display of system status usually set up to display the active, waiting, and completed mix entries, as well as system messages to the operator for notifications or situations requiring operator action.\n Complete listing of these displays are given by the 'A' (active), 'W' (waiting), 'C' (completed), and 'MSG' (message commands).\n If a task becomes waiting on some operator action, the operator can find out what the task needs by entering its mix number followed by the 'Y' command. (Note the object-oriented style of commands, selecting the object first, followed by the command.) For example, '3456Y'.\n An operator can force a task into the waiting entries with the stop command '3456ST' and make it active again with OK: '3456OK'. The OK command can also be used when an operator has made a resource available for a task, although more frequently than not, the MCP will detect that resources have become available, CAUSE the EVENT that processes have been waiting on without further operator intervention. To pass textual information from an operator to a program, the accept command ‘3456AX MORE INFO’ can be used. Programs can pass information to operators using the DISPLAY mechanism, which causes DISPLAY messages to be added to the MSG display.\n As well as tasks and processes, operators also have control over files. Files can be listed using the FILE command, copied using COPY, removed using REMOVE, and renamed.\n The operating environment of the MCP is powerful, yet simple and usually only requires a fraction of the number of operators of other systems.\n An important part of the operations environment is the high-level  .\n All actions in the system are logged, for example all messages displayed to the operator, and all operator actions. All significant program actions are optionally logged in a system log and a program log, for example BOJ for beginning of a WFL job, BOT for beginning of a task within a WFL job, EOT and EOJ for end of tasks and jobs. As well, all file and database open and closes can be logged. Logging many events contributes to an apparent slowness of the MCP operating environment compared to systems like Unix, since everything is logged with forced physical writes to the program log after every record, which is what systems like Unix don't do, even though they too keep many things in the system logs.\n The logs can be used for forensics to find out why programs or systems may have failed, or for detecting attempts to compromise system security. System logs are automatically closed after a system-settable period and a new one opened. System logs contain a huge amount of information, which can be filtered and analyzed with programs such as LOGANALYZER.\n The DUMPANALYZER analyzes memory dumps that were originally written to tape. As all compilers added LINEINFO into the code-files, the DUMPANALYZER is able to pinpoint exactly which source statement was being executed at the time of error.\n Also a normal program dump, where just one program was dumped, contains information on source-code sequence number and variable names.\n The two analyzers are major diagnostic tools for all kinds of purposes.\n Beyond the many technical innovations in the MCP design, the Burroughs Large Systems had many management innovations now being used by the internet community at large. The system software was shipped to customers inclusive of source code and all the editing and compilation tools needed to generate new versions of MCP for customers. Many customers developed niche expertise on the inner workings of the MCP, and customers often sent in the 'patches' (fragment pieces of source code with sequence numbers) as suggestions of new enhanced features or fault corrections (FTR - field trouble reports). Many of the suggested patches were included by the systems developers and integrated into the next version of the MCP release. Including a community of voluntary, self-professed experts, into mainstream technical work, is now widely practised and is the essence of  . This management innovation of community development dated back to the 1970s.\n Unisys MCP has had several generations of compilers in its history supporting a wide variety of  , including:\n Other products include:\n Compilers previously existed for  , COBOL(68), Fortran(66),  , and  .\n There is no assembler on the Unisys MCP operating system.\n The MCP was the first OS developed exclusively in a high-level language. Over its 50-year history, it has had many firsts in a commercial implementation, including virtual memory, symmetric multiprocessing, and a high-level job control language (WFL). It has long had many facilities that are only now  appearing in other widespread operating systems, and together with the Burroughs large systems architecture, the MCP provides a  , high performance, multitasking and transaction processing environment.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/S2CID_(identifier)", "title": "Semantic Scholar", "content": " is a research tool for scientific literature powered by  . It is developed at the   and was publicly released in November 2015.  Semantic Scholar uses modern techniques in   to support the research process, for example by providing automatically generated summaries of scholarly papers.  The Semantic Scholar team is actively researching the use of artificial intelligence in  ,  ,  , and  . \n Semantic Scholar began as a database for the topics of  ,  , and  .  In 2017, the system began including   in its corpus.  As of September 2022 , it includes over 200 million publications from all fields of science. \n Semantic Scholar provides a one-sentence summary of  . One of its aims was to address the challenge of reading numerous titles and lengthy abstracts on mobile devices.  It also seeks to ensure that the three million scientific papers published yearly reach readers, since it is estimated that only half of this literature is ever read. \n Artificial intelligence is used to capture the essence of a paper, generating it through an \"abstractive\" technique.  The project uses a combination of  ,  , and   to add a layer of   to the traditional methods of  , and to extract relevant figures,  , entities, and venues from papers. \n Another key AI-powered feature is Research Feeds, an adaptive research recommender that uses AI to quickly learn what papers users care about reading and recommends the latest research to help scholars stay up to date. It uses a state-of-the-art paper embedding model trained using contrastive learning to find papers similar to those in each Library folder. \n Semantic Scholar also offers Semantic Reader, an augmented reader with the potential to revolutionize scientific reading by making it more accessible and richly contextual.  Semantic Reader provides in-line citation cards that allow users to see citations with   (short for Too Long, Didn't Read) automatically generated short summaries as they read and skimming highlights that capture key points of a paper so users can digest faster.\n In contrast with   and  , Semantic Scholar is designed to highlight the most important and influential elements of a paper.  The AI technology is designed to identify hidden connections and links between research topics.  Like the previously cited search engines, Semantic Scholar also exploits graph structures, which include the  , Springer Nature's  , and the Semantic Scholar Corpus (originally a 45 million papers corpus in computer science, neuroscience and biomedicine). \n Each paper hosted by Semantic Scholar is assigned a unique   called the Semantic Scholar Corpus ID (abbreviated S2CID). The following entry is an example:\n Semantic Scholar is free to use and unlike similar search engines (i.e.  ) does not search for material that is behind a  . \n One study compared the index scope of Semantic Scholar to Google Scholar, and found that for the papers cited by secondary studies in computer science, the two indices had comparable coverage, each only missing a handful of the papers. \n As of January 2018, following a 2017 project that added biomedical papers and topic summaries, the Semantic Scholar corpus included more than 40 million papers from   and  .  In March 2018, Doug Raymond, who developed   initiatives for the   platform, was hired to lead the Semantic Scholar project.  As of August 2019 , the number of included papers metadata (not the actual PDFs) had grown to more than 173 million  after the addition of the   records.  In 2020, a partnership between Semantic Scholar and the   made all articles published under the University of Chicago Press available in the Semantic Scholar corpus.  At the end of 2020, Semantic Scholar had indexed 190 million papers.   In 2020, Semantic Scholar reached seven million users per month. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Stephen_Wolfram", "title": "Stephen Wolfram", "content": "\n\n  (   ; born 29 August 1959) is a British-American  computer scientist, physicist, and businessman. He is known for his work in  , and  .  In 2012, he was named a fellow of the  .  \n As a businessman, he is the founder and CEO of the software company   where he works as chief designer of   and the   answer engine. \n Stephen Wolfram was born in London in 1959 to   and   Wolfram, both   refugees to the United Kingdom.   His maternal grandmother was British    .\n Wolfram's father,  , was a textile manufacturer and served as managing director of the Lurex Company—makers of the fabric  .  Wolfram's mother,  , was a Fellow and Tutor in Philosophy at   at   from 1964 to 1993. \n Stephen Wolfram is married to a mathematician. They have four children together. \n Wolfram was educated at  , but left prematurely in 1976.  As a young child, Wolfram had difficulties learning arithmetic.  He entered  , at age 17 and left in 1978  without graduating  to attend the   the following year, where he received a PhD  in particle physics in 1980.  Wolfram's   was composed of  ,  ,   and  , and chaired by  . \n Wolfram, at the age of 15, began research in applied   and   and published scientific papers in    ; by the time he had earned his undergraduate degree, he had published ten such papers.  Following his PhD, Wolfram joined the faculty at Caltech and became the youngest recipient  of a   in 1981, at age 21. \n In 1983, Wolfram left for the School of Natural Sciences of the   in Princeton. By that time, he was no longer interested in particle physics. Instead, he began pursuing investigations into  ,  mainly with computer simulations. He produced a series of papers investigating the class of  , conceiving the  , a naming system for one-dimensional cellular automata, and a   for the complexity of their behaviour.  He conjectured that the   cellular automaton might be  , which a research assistant to Wolfram,  , later proved correct.  Wolfram sued Cook and temporarily blocked publication of the work on Rule 110 for allegedly violating a   until Wolfram could publish the work in his controversial book  .  Wolfram's cellular-automata work came to be cited in more than 10,000 papers. \n In the mid-1980s, Wolfram worked on simulations of physical processes (such as  ) with cellular automata on the   alongside   and helped initiate the field of  .  In 1984, he was a participant in the Founding Workshops of the  , along with Nobel laureates  ,  , and  , and future laureate  .  In 1986, he founded the Center for Complex Systems Research (CCSR) at the  .  In 1987, he founded the journal  . \n Wolfram led the development of the   SMP ( ) in the Caltech physics department during 1979–1981. A dispute with the administration over the intellectual property rights regarding SMP—patents, copyright, and faculty involvement in commercial ventures—eventually led him to resign from Caltech.  SMP was further developed and marketed commercially by Inference Corp. of Los Angeles during 1983–1988.\n In 1986, Wolfram left the   for the  , where he had founded their Center for Complex Systems Research, and started to develop the computer algebra system  , which was first released on 23 June 1988, when he left academia. In 1987, he founded  , which continues to develop and market the program. \n From 1992 to 2002, Wolfram worked on his controversial book  ,  which presents an empirical study of simple computational systems. Additionally, it argues that for fundamental reasons these types of systems, rather than traditional mathematics, are needed to model and understand complexity in nature. Wolfram's conclusion is that the universe is discrete in its nature, and runs on fundamental laws which can be described as simple programs. He predicts that a realization of this within scientific communities will have a revolutionary influence on physics, chemistry, biology, and a majority of scientific areas in general, hence the book's title. The book was met with skepticism and criticism that Wolfram took credit for the work of others and made conclusions without evidence to support them. \n In March 2009, Wolfram announced Wolfram Alpha, an  . WolframAlpha later launched in May 2009,  and a paid-for version with extra features launched in February 2012 that was met with criticism for its high price that was later dropped from $50.00 to $2.00.  The engine is based on   and a large library of rules-based algorithms. The   allows other applications to extend and enhance Wolfram Alpha.  \n In 2010, Wolfram co-founded   along with  , Max Whitby, and John Cromie. The company specialised in creating in-depth premium apps and games covering a wide range of educational subjects designed for children, parents, students, and educators. Since the launch, Touchpress has published more than 100 apps.  The company is no longer active.\n In March 2014, at the annual   (SXSW) event, Wolfram officially announced the   as a new general  ,  though it was previously available through Mathematica and not an entirely new programming language. The documentation for the language was pre-released in October 2013 to coincide with the bundling of   and the Wolfram Language on every   computer with some controversy because of the proprietary nature of the Wolfram Language.  While the Wolfram Language has existed for over 30 years as the primary programming language used in  , it was not officially named until 2014, and is not widely used.  \n In April 2020, Wolfram announced the \"Wolfram Physics Project\" as an effort to reduce and explain all the laws of physics within a paradigm of a   that is transformed by minimal   that obey the  .   The effort is a continuation of the ideas he originally described in   Wolfram claims that \"From an extremely simple model, we're able to reproduce special relativity, general relativity and the core results of quantum mechanics.\"\n Physicists are generally unimpressed with Wolfram's claim, and state that Wolfram's results are non-quantitative and arbitrary.  This sentiment is not universal, however. Theoretical physicist  , while initially skeptical of the project, remarked, \"When I look at this today, I honestly think that this research program is going very well, and I think it's about time that physicists pay a little more attention to it.\" \n Wolfram has a log of personal analytics, including emails received and sent, keystrokes made, meetings and events attended, recordings of phone calls, and even physical movement dating back to the 1980s. In the preface of  , he noted that he recorded over 100 million keystrokes and 100 mouse miles. He has stated \"[personal analytics] can give us a whole new dimension to experiencing our lives.\" \n Stephen Wolfram was involved as a scientific consultant for the 2016 film  . He and his son Christopher Wolfram wrote some of the code featured on-screen, such as the code in graphics depicting an analysis of the alien logograms, for which they used the  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Wayback_Machine", "title": "Wayback Machine", "content": "\n The   is a   of the   founded by the  , an   based in  ,  . Created in 1996 and launched to the public in 2001, it allows users to go \"back in time\" to see how websites looked in the past. Its founders,   and  , developed the Wayback Machine to provide \"universal access to all knowledge\" by preserving archived copies of defunct web pages. \n Launched on May 10, 1996, the Wayback Machine had saved more than 38.2 billion web pages by the end of 2009. As of November 2024, the Wayback Machine has archived more than 916 billion web pages and well over 100   of data. \n The Internet Archive began archiving   web pages in 1996. One of the earliest known pages was archived on May 10, 1996, at   ( ). \n Internet Archive founders   and   launched the Wayback Machine in  ,  ,  in October 2001,  primarily to address the problem of web content vanishing whenever it gets changed or when a website is shut down.  The service enables users to see archived versions of   across time, which the archive calls a \"three-dimensional index\".  Kahle and Gilliat created the machine hoping to archive the entire Internet and provide \"universal access to all knowledge\".  The name \"Wayback Machine\" is a reference to a fictional time-traveling device in the animated cartoon   from the 1960s.  In a segment of the cartoon entitled \"Peabody's Improbable History\", the characters   and Sherman use the \" \" to travel back in time to witness and participate in famous historical events. \n From 1996 to 2001, the information was kept on digital tape, with Kahle occasionally allowing researchers and scientists to tap into the \"clunky\"  .  When the archive reached its fifth anniversary in 2001, it was unveiled and opened to the public in a ceremony at the  .  By the time the Wayback Machine launched, it already contained over 10 billion archived pages.  The data is stored on the Internet Archive's large cluster of   nodes.  It revisits and archives new versions of websites on occasion (see technical details below).  Sites can also be captured manually by entering a website's   into the search box, provided that the website allows the Wayback Machine to \" \" it and save the data. \n On October 30, 2020, the Wayback Machine began fact-checking content.  As of January 2022, domains of   are disabled from capturing. \n In May 2021, for Internet Archive's 25th anniversary, the Wayback Machine introduced the \"Wayforward Machine\" which allows users to \"travel to the Internet in 2046, where knowledge is under  \". \n The Wayback Machine's software has been developed to \" \" the Web and download all publicly accessible information and data files on webpages, the   hierarchy, the   (Usenet) bulletin board system, and downloadable software.  The information collected by these \"crawlers\" does not include all the information available on the Internet, since much of the data is restricted by the publisher or stored in databases that are not accessible. To overcome inconsistencies in partially cached websites, Archive-It.org was developed in 2005 by the Internet Archive as a means of allowing institutions and content creators to voluntarily harvest and preserve collections of digital content, and create digital archives. \n Crawls are contributed from various sources, some imported from third parties and others generated internally by the Archive.  For example, crawls are contributed by the   and  , crawls run by Internet Archive on behalf of   and the  , mirrors of  .  The \"Worldwide Web Crawls\" have been running since 2010 and capture the global Web.  In September 2020, the Internet Archive announced a partnership with   – an American   service provider – to automatically index websites served via its \"Always Online\" services. \n Documents and resources are stored with time stamp URLs such as  . Pages' individual resources such as images and style sheets and scripts, as well as outgoing  , are linked to with the time stamp of the currently viewed page, so they are redirected automatically to their individual captures that are the closest in time. \n The frequency of snapshot captures varies per website.  Websites in the \"Worldwide Web Crawls\" are included in a \"crawl list\", with the site archived once per crawl.  A crawl can take months or even years to complete, depending on size.  For example, \"Wide Crawl Number 13\" started on January 9, 2015, and completed on July 11, 2016.  However, there may be multiple crawls ongoing at any one time, and a site might be included in more than one crawl list, so how often a site is crawled varies widely. \n A \"Save Page Now\" archiving feature was made available in October 2013,  accessible on the lower right of the Wayback Machine's main page.  Once a target URL is entered and saved, the web page will become part of the Wayback Machine.  Through the Internet address web.archive.org,  users can upload to the Wayback Machine a large variety of contents, including   and   file formats. The Wayback Machine creates a permanent local URL of the upload content, that is accessible in the web, even if not listed while searching in the https://archive.org official website. \n Starting in October 2019, users were   to 15 archival requests and retrievals per minute. \n As technology has developed over the years, the storage capacity of the Wayback Machine has grown. In 2003, after only two years of public access, the Wayback Machine was growing at a rate of 12 terabytes per month. The data is stored on   rack systems custom designed by Internet Archive staff. The first 100TB rack became fully operational in June 2004, although it soon became clear that they would need much more storage than that. \n The Internet Archive migrated its customized storage architecture to   in 2009, and hosts a new data centre in a   on  ' California campus.  As of 2009 , the Wayback Machine contained approximately three   of data and was growing at a rate of 100   each month. \n A new, improved version of the Wayback Machine, with an updated interface and a fresher index of archived content, was made available for public testing in 2011, where captures appear in a calendar layout with circles whose width visualizes the number of crawls each day, but no marking of duplicates with asterisks or an advanced search page.  A top   was added to facilitate navigating between captures. A bar chart visualizes the frequency of captures per month over the years.  Features like \"Changes\", \"Summary\", and a graphical site map were added subsequently.\n In March that year, it was said on the Wayback Machine forum that \"the Beta of the new Wayback Machine has a more complete and up-to-date index of all crawled materials into 2010, and will continue to be updated regularly. The index driving the classic Wayback Machine only has a little bit of material past 2008, and no further index updates are planned, as it will be phased out this year.\"  Also in 2011, the Internet Archive installed their sixth pair of PetaBox racks which increased the Wayback Machine's storage capacity by 700 terabytes. \n In January 2013, the company announced a milestone of 240 billion URLs. \n In October 2013, the company introduced the \"Save a Page\" feature, which allows any Internet user to archive the contents of a URL, and quickly generates a   unlike the preceding   feature. \n In December 2014, the Wayback Machine contained 435   web pages—almost nine petabytes of data, and was growing at about 20 terabytes a week. \n In July 2016, the Wayback Machine reportedly contained around 15 petabytes of data.  In October 2016, it was announced that the way web pages are counted would be changed, resulting in the decrease of the archived pages counts shown. Embedded objects such as pictures, videos, style sheets, JavaScripts are no longer counted as a \"web page\", whereas HTML, PDF, and plain text documents remain counted. \n In September 2018, the Wayback Machine contained over 25 petabytes of data.  As of December 2020, the Wayback Machine contained over 70 petabytes of data. \n The Wayback Machine service offers three public APIs, SavePageNow, Availability, and CDX.  SavePageNow can be used to archive web pages. Availability API for checking the archive availability status for a web page,  checking whether an archive for the web page exists or not. CDX API is for complex querying, filtering, and analysis of captured data. \n Historically, the Wayback Machine has respected the   (robots.txt) in determining if a website would be crawled – or if already crawled, if its archives would be publicly viewable. Website owners had the option to opt out of Wayback Machine through the use of robots.txt. It applied robots.txt rules retroactively; if a site blocked the Internet Archive, any previously archived pages from the domain were immediately rendered unavailable as well. In addition, the Internet Archive stated that \"Sometimes, a website owner will contact us directly and ask us to stop crawling or archiving a site. We comply with these requests.\"  In addition, the website says: \"The Internet Archive is not interested in preserving or offering access to Web sites or other internet documents of persons who do not want their materials in the collection.\" \n On April 17, 2017, reports surfaced of sites that had gone defunct and became   that were using robots.txt to exclude themselves from search engines, resulting in them being inadvertently excluded from the Wayback Machine.  Following this, the Internet Archive changed the policy to require an explicit exclusion request to remove sites from the Wayback Machine. \n Wayback's retroactive exclusion policy is based in part upon  , known as  , published by the School of Information Management and Systems at   in 2002, which gives a website owner the right to block access to the site's archives.  Wayback has complied with this policy to help avoid expensive litigation. \n The Wayback retroactive exclusion policy began to relax in 2017, when it stopped honoring robots on U.S. government and military web sites for both crawling and displaying web pages. As of April 2017, Wayback is ignoring robots.txt more broadly, not just for U.S. government websites. \n From its public launch in 2001, the Wayback Machine has been studied by scholars both for the ways it stores and collects data as well as for the actual pages contained in its archive. As of 2013, scholars had written about 350 articles on the Wayback Machine, mostly from the  ,  , and   fields. Social science scholars have used the Wayback Machine to analyze how the development of websites from the mid-1990s to the present has affected the company's growth. \n When the Wayback Machine archives a page, it usually includes most of the hyperlinks, keeping those links active when they just as easily could have been broken by the Internet's instability. Researchers in India studied the effectiveness of the Wayback Machine's ability to save hyperlinks in online scholarly publications and found that it saved slightly more than half of them. \n \"Journalists use the Wayback Machine to view dead websites, dated news reports, and changes to website contents. Its content has been used to hold politicians accountable and expose battlefield lies.\"  In 2014, an archived social media page of  , a separatist rebel leader in Ukraine, showed him boasting about his troops having shot down a suspected Ukrainian military airplane before it became known that the plane actually was a civilian Malaysian Airlines jet ( ), after which he deleted the post and blamed Ukraine's military for downing the plane.  In 2017, the   originated from a discussion on   that indicated someone had visited Archive.org and discovered that all references to   had been deleted from the White House website. In response, a user commented, \"There needs to be a Scientists' March on Washington\". \n The site is used heavily for verification, providing access to references and content creation by  .  When new URLs are added to Wikipedia, the Internet Archive has been archiving them. \n In September 2020, a partnership was announced with   to automatically archive websites served via its \"Always Online\" service, which will also allow it to direct users to its copy of the site if it cannot reach the original host. \n In 2014, there was a six-month lag time between when a website was crawled and when it became available for viewing in the Wayback Machine.  As of 2024, the lag time is 3 to 10 hours.  The Wayback Machine offers only limited search facilities. Its \"Site Search\" feature allows users to find a site based on words describing the site, rather than words found on the web pages themselves. \n The Wayback Machine does not include every web page ever made due to the limitations of its web crawler. The Wayback Machine cannot completely archive web pages that contain interactive features such as Flash platforms and forms written in JavaScript and  , because those functions require interaction with the host website. This means that, since approximately July 9, 2013, the Wayback Machine has been unable to display YouTube comments when saving videos' watch pages, as, according to the Archive Team, comments are no longer \"loaded within the page itself.\"  The Wayback Machine's web crawler has difficulty extracting anything not coded in HTML or one of its variants, which can often result in broken hyperlinks and missing images. Due to this, the web crawler cannot archive \"orphan pages\" that are not linked to by other pages.  The Wayback Machine's crawler only follows a predetermined number of hyperlinks based on a preset depth limit, so it cannot archive every hyperlink on every page. \n In a 2009 case,  , defendant Chordiant filed a motion to compel Netbula to disable the   file on its website that was causing the Wayback Machine to retroactively remove access to previous versions of pages it had archived from Netbula's site, pages that Chordiant believed would support its case. \n Netbula objected to the motion on the ground that defendants were asking to alter Netbula's website and that they should have subpoenaed Internet Archive for the pages directly.  An employee of Internet Archive filed a sworn statement supporting Chordiant's motion, however, stating that it could not produce the web pages by any other means \"without considerable burden, expense and disruption to its operations.\" \n Magistrate Judge Howard Lloyd in the Northern District of California, San Jose Division, rejected Netbula's arguments and ordered them to disable the robots.txt blockage temporarily in order to allow Chordiant to retrieve the archived pages that they sought. \n In an October 2004 case,  , No. 02 C 3293, 65 Fed. R. Evid. Serv. 673 (N.D. Ill. October 15, 2004), a litigant attempted to use the Wayback Machine archives as a source of admissible evidence, perhaps for the first time. Telewizja Polska is the provider of   and   operates the  . Prior to the trial proceedings, EchoStar indicated that it intended to offer Wayback Machine snapshots as proof of the past content of Telewizja Polska's website. Telewizja Polska brought a motion   to suppress the snapshots on the grounds of   and unauthenticated source, but Magistrate Judge Arlander Keys rejected Telewizja Polska's assertion of hearsay and denied TVP's motion   to exclude the evidence at trial.  At the trial, however, District Court Judge Ronald Guzman, the trial judge, overruled Magistrate Keys' findings, and held that neither the affidavit of the Internet Archive employee nor the underlying pages (i.e., the Telewizja Polska website) were admissible as evidence. Judge Guzman reasoned that the employee's affidavit contained both hearsay and inconclusive supporting statements, and the purported web page, printouts were not self-authenticating. \n The   and the   will accept date stamps from the Internet Archive as evidence of when a given Web page was accessible to the public. These dates are used to determine if a Web page is available as   for instance in examining a patent application. \n There are technical limitations to archiving a website, and as a consequence, opposing parties in litigation can misuse the results provided by website archives. This problem can be exacerbated by the practice of submitting screenshots of web pages in complaints, answers, or expert witness reports when the underlying links are not exposed and therefore, can contain errors. For example, archives such as the Wayback Machine do not fill out forms and therefore, do not include the contents of non-  e-commerce databases in their archives. \n In Europe, the Wayback Machine could be interpreted as violating   laws. Only the content creator can decide where their content is published or duplicated so the Archive would have to delete pages from its system upon request of the creator.  The exclusion policies for the Wayback Machine may be found in the FAQ section of the site. \n Some cases have been brought against the Internet Archive specifically for its Wayback Machine archiving efforts. \n In late 2002, the Internet Archive removed various sites that were critical of   from the Wayback Machine.  An error message stated that this was in response to a \"request by the site owner\".  Later, it was clarified that lawyers from the   had demanded the removal and that the site owners did not want their material removed. \n In 2003, Harding Earley Follmer & Frailey defended a client from a trademark dispute using the Archive's Wayback Machine. The attorneys were able to demonstrate that the claims made by the plaintiff were invalid, based on the content of their website from several years prior. The plaintiff, Healthcare Advocates, then amended their complaint to include the Internet Archive, accusing the organization of copyright infringement as well as violations of the   and the  . Healthcare Advocates claimed that, since they had installed a   file on their website, even if after the initial lawsuit was filed, the Archive should have removed all previous copies of the plaintiff website from the Wayback Machine, however, some material continued to be publicly visible on Wayback.  The lawsuit was settled out of court after Wayback fixed the problem. \n Activist   filed suit in December 2005, demanding Internet Archive pay her US$100,000 for archiving her website profane-justice.org between 1999 and 2004.  Internet Archive filed a   action in the   on January 20, 2006, seeking a judicial determination that Internet Archive did not violate Shell's  . Shell responded and brought a   against Internet Archive for archiving her site, which she alleges is in violation of her  .  On February 13, 2007, a judge for the   dismissed all counterclaims except  .  The Internet Archive did not move to dismiss the   claims that Shell asserted arose out of its copying activities, which would also go forward. \n On April 25, 2007, Internet Archive and Suzanne Shell jointly announced the settlement of their lawsuit.  The Internet Archive said it \"...has no interest in including materials in the Wayback Machine of persons who do not wish to have their Web content archived. We recognize that Ms. Shell has a valid and enforceable copyright in her Web site and we regret that the inclusion of her Web site in the Wayback Machine resulted in this litigation.\" Shell said, \"I respect the historical value of Internet Archive's goal. I never intended to interfere with that goal nor cause it any harm.\" \n Between 2013 and 2016, a   named Daniel Davydiuk tried to remove archived images of himself from the Wayback Machine's archive, first by sending multiple   to the archive, and then by appealing to the  .  The images were removed from the website in 2017.\n In 2018, archives of   FlexiSpy's website were removed from the Wayback Machine. The company claimed to have contacted the Internet Archive, presumably to remove the archives of its website. \n Archive.org is  .  The Internet Archive was   in 2015–16, ostensibly for hosting a Jihad outreach video.  Since 2016, the website has been back, available in its entirety, although in 2016 Russian commercial lobbyists were suing the Internet Archive to ban it on copyright grounds. \n In March 2015, it was published that security researchers became aware of the threat posed by the service's unintentional   from archived sites. \n , director of the  , notes that \"while librarians deeply value individual privacy, we also strongly oppose censorship\". \n There is at least one case in which an article was removed from the archive shortly after it had been removed from its original website. A   reporter had written an article that outed several gay Olympian athletes in 2016 after the reporter had made a fake profile posing as a gay man on a dating app.   removed the article after it was met with widespread furor; not long after, the Internet Archive soon did as well, but emphatically stated that they did so for no other reason than to protect the safety of the outed athletes. \n Other threats include natural disasters,  destruction (both remote and physical),  manipulation of the archive's contents, problematic copyright laws,  and surveillance of the site's users. \n Alexander Rose, executive director of the  , suspects that in the long term of multiple generations \"next to nothing\" will survive in a useful way, stating, \"If we have continuity in our technological civilization, I suspect a lot of the bare data will remain findable and searchable. But I suspect almost nothing of the format in which it was delivered will be recognizable\" because sites \"with deep back-ends of content-management systems like Drupal and Ruby and Django\" are harder to archive. \n In 2016, in an article reflecting on the preservation of human knowledge,   has commented that the Internet Archive, which describes itself to be built for the long-term,  \"is working furiously to capture data before it disappears without any long-term infrastructure to speak of.\" \n In September 2024, the Internet Archive suffered a data breach that exposed 31 million records containing personal information, including email addresses and   passwords.  On October 9, 2024, the site went down due to a  .  On October 14, the site returned online, but it remained in read-only mode until November 4. \"Save Page Now\" was disabled, replaced with a \"Temporarily Unavailable\" banner. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Style_sheet_language", "title": "Style sheet language", "content": "A  , or  , is a   that expresses the presentation of  . One attractive feature of structured documents is that the content can be reused in many contexts and presented in various ways. Different style sheets can be attached to the logical structure to produce different presentations.\n One modern style sheet language with widespread use is   (CSS), which is used to style documents written in  ,  ,  ,  , and other  .\n For content in structured documents to be presented, a set of stylistic rules – describing, for example, colors, fonts and layout – must be applied. A collection of stylistic rules is called a style sheet. Style sheets in the form of written documents have a long history of use by editors and typographers to ensure consistency of presentation, spelling and punctuation. In electronic publishing, style sheet languages are mostly used in the context of visual presentation rather than spelling and punctuation.\n All style sheet languages offer functionality in these areas:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Turbo-BASIC_XL", "title": "Turbo-BASIC XL", "content": " is an enhanced version of the   programming language for  . It is a compatible superset of the   that shipped with the Atari 8-bit systems. Turbo-Basic XL was developed by   and published in the December 1985 issue of      . A version for the 400/800 models was released shortly after as  . Several modified versions working with different DOS systems have been released by other authors.\n Turbo-Basic XL greatly improves execution over Atari BASIC. An Atari BASIC program loaded into Turbo-BASIC, with no changes made, would generally run about three times as fast. A Turbo-Basic XL   created binary  , further speeding up program performance to about ten times faster than Atari BASIC. Turbo-Basic XL also includes an expanded editor, support for named procedures,   and similar block constructs, and added access to the underlying hardware, which, among other things, allowed operation of attached   without exiting to  .\n Ostrowski soon got a job with   (at the time known as  ) where he adapted Turbo-Basic XL into   for the  , which became one of the more popular BASICs on that platform.\n Since their release in 1979, the   family normally shipped with a version of Atari BASIC on a  , or built into the internal   on later machines. This version of BASIC had a number of custom commands that allowed partial access to the system's advanced features like graphics and sound. It was notoriously slow, appearing at the very bottom of the list of   BASICs in the original version of David Ahl's  . \n The poor performance of the official Atari BASIC led to a market for 3rd party   with better performance or more commands. Among them was an official port of   sold by Atari, several improved versions released by  , who had written the original Atari BASIC under contract, and many others. There were also several Atari BASIC compilers from a variety of vendors.\n Turbo-Basic XL was a late entry to this list, first published in December 1985 as  . It was unique in that it came in both interpreter and compiler versions. It included code to take advantage of the expanded memory available on the XL series machines, and later XE series. This meant that it could not run on the original 400/800 systems, which led Ostrowski to make a port known as Frost BASIC (short for \"Frank Ostrowski\") that was tied to   2.0.\n The internal disk-related commands were tied to particular versions of DOS.  A number of ports to different versions of DOS became available.\n The most notable feature of Turbo-Basic was its dramatically improved speed; an unmodified Atari BASIC program loaded into Turbo-Basic would normally run three to five times faster, and the speed advantage improved as the program size grew. This was due largely to a series of improvements on well-known problems in the original Atari BASIC code.\n In most BASICs,   was handled by reading the associated line number and then searching through the program for that line of code. In MS-derived BASICs the line numbers were stored as 16-bit   and numeric constants in the code in their original   format. When a line like   was encountered, the interpreter would use special code to convert the \"1000\" into 16-bit format and then search for it. Atari BASIC worked differently, converting all numeric constants to a 6-byte   format when the line was entered. This meant the \"1000\" was no longer in ASCII format and had to be converted from floating-point to integer format. The code for doing so was not well optimized and could take over 2 ms (average 1-1.5 ms).\n  are another common construct in BASIC programs. In most BASICs, when the FOR portion was encountered at runtime, its memory location in the   was pushed onto a   so it could easily return to that location when the associated NEXT was encountered. For unknown reasons, Atari BASIC pushed the line number of the FOR onto the stack and then looked through the entire code for that line when it encountered the NEXT. For programs that did significant looping, which is often the case in BASIC, this could cause a dramatic performance hit.\n Turbo-Basic implemented its   using the address, as was the case in MS BASIC, and thus ran loops with roughly the same performance as MS. It then went further and greatly improved GOTO performance as well. Line numbers were sent into a   that broke them into 256-line chunks. As the program was entered, the address of the first of each of these chunks was stored in a 128-value table. At runtime, when a line number lookup was needed, it would first pick the nearest-but-lower value in the table, retrieve the address, and then begin scanning for the line from that point on. The improvement was most notable in larger programs where the scanning time was increasingly expensive, which is why Turbo-Basic could hit a 5-times increase in larger programs.\n The other major source of poor performance in Atari BASIC was its very slow   (BCD)   code. The  , contained in a separate 2K ROM and considered part of the   as opposed to BASIC itself, had been written in a hurry and never optimized. Some of the routines, notably the multiply and exponents functions, were far slower than they could be.\n Turbo-Basic fixed this by including its own complete floating-point library, which not only fixed many of these issues but also further optimized the code by unrolling small loops. For programs that used math extensively, the new library resulted in dramatic performance improvements, sending the Atari from near the bottom of the   lists to near the top, beating a number of machines that were much faster in hardware.\n Among the extra features of Turbo-Basic XL, added to Atari BASIC, are the following:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/YouTube_video_(identifier)", "title": "YouTube", "content": "\n\n\n   is an American   platform owned by  . YouTube was founded on February 14, 2005, by  ,  , and  , three former employees of  . Headquartered in  , United States, it is the   in the world, after  . In January 2024, YouTube had more than 2.7 billion  , who collectively watched more than one billion hours of videos every day.  As of May 2019 , videos were being uploaded to the platform at a rate of more than 500 hours of   per minute,  and as of 2023 , there were approximately 14 billion videos in total. \n On the 9th of October 2006, YouTube was purchased by Google for $1.65 billion (equivalent to $2.31 billion in 2023).  Google expanded YouTube's business model of generating revenue from   alone, to offering paid content such as movies and   produced by and for YouTube. It also offers  , a paid subscription option for watching content without ads. YouTube incorporated   program, generating more revenue for both YouTube and approved content creators. In 2023, YouTube's advertising revenue totaled $31.7 billion, a 2% increase from the $31.1 billion reported in 2022.  From Q4 2023 to Q3 2024, YouTube's combined revenue from advertising and subscriptions exceeded $50 billion. \n Since its purchase by Google, YouTube has expanded beyond the core website into  , network television, and the   with other platforms. Video categories on YouTube include  ,  ,  ,   and  ,  ,  ,  ,  ,  ,  ,  , and more. Most content is  , including collaborations between \" \" and corporate sponsors. Established media, news, and entertainment corporations have also created and expanded their visibility to YouTube channels in order to reach greater audiences.\n YouTube has had  , influencing popular culture, internet trends, and creating multimillionaire celebrities. Despite its growth and success, the platform has been criticized for its facilitation of the spread of   and  ,  ,  , endangering  , and for its inconsistent implementation of platform guidelines.\n YouTube was founded by  ,  , and  . The trio were early employees of  , which left them enriched after the company was bought by  .  Hurley had studied design at the  , and Chen and Karim studied   together at the  . \n According to a story that has often been repeated in the media, Hurley and Chen developed the idea for YouTube during the early months of 2005, after they had experienced difficulty sharing videos that had been shot at a dinner party at Chen's apartment in  . Karim did not attend the party and denied that it had occurred, but Chen remarked that the idea that YouTube was founded after a dinner party \"was probably very strengthened by marketing ideas around creating a story that was very digestible\". \n Karim said the inspiration for YouTube came from the  , when  's breast was briefly exposed by   during the halftime show. Karim could not easily find video clips of the incident and the   online, which led to the idea of a video-sharing site.  Hurley and Chen said that the original idea for YouTube was a video version of an   and had been influenced by the website  .  They created posts on   asking attractive women to upload videos of themselves to YouTube in exchange for a $100 reward.  Difficulty in finding enough dating videos led to a change of plans, with the site's founders deciding to accept uploads of any video. \n YouTube began as a  –funded technology  . Between November 2005 and April 2006, the company raised money from various investors, with   and Artis Capital Management being the largest two.  YouTube's early headquarters were situated above a pizzeria and a Japanese restaurant in  .  In February 2005, the company activated  .  The first video was uploaded on April 23, 2005. Titled \" \", it shows co-founder Jawed Karim at the   and can still be viewed on the site.  The same day, the company launched a public   and by November, a Nike ad featuring   became the first video to reach one million total views.  The site launched officially on December 15, 2005, by which time the site was receiving 8 million views a day.  Clips at the time were limited to 100 megabytes, as little as 30 seconds of footage. \n YouTube was not the first video-sharing site on the Internet;   was launched in November 2004, though that site remained a side project of its developers from  .  The week of YouTube's launch, NBC-Universal's   ran a skit \" \" by  . Besides helping to bolster ratings and long-term viewership for  , \"Lazy Sunday\"'s status as an early   helped establish YouTube as an important website.  Unofficial uploads of the skit to YouTube drew in more than five million collective views by February 2006 before they were removed when   requested it two months later based on copyright concerns.  Despite eventually being taken down, these duplicate uploads of the skit helped popularize YouTube's reach and led to the upload of more third-party content.  The site grew rapidly; in July 2006, the company announced that more than 65,000 new videos were being uploaded every day and that the site was receiving 100 million video views per day. \n The choice of the name   led to problems for a similarly named website,  . That site's owner,  , filed a lawsuit against YouTube in November 2006, after being regularly overloaded by people looking for YouTube. Universal Tube subsequently changed its website to  . \n On October 9, 2006,   announced that they had acquired YouTube for $1.65 billion in Google stock.  The deal was finalized on November 13, 2006.  Google's acquisition launched newfound interest in video-sharing sites;  , which now owned Vimeo, focused on supporting the content creators to distinguish itself from YouTube.  It is at this time YouTube issued the slogan \"Broadcast Yourself\".\nThe company experienced rapid growth.   wrote that in 2007, YouTube consumed as much   as the entire Internet in 2000.  By 2010, the company had reached a   of around 43% and more than 14 billion views of videos, according to  .  That year, the company simplified its interface to increase the time users would spend on the site.  In 2011, more than three billion videos were being watched each day with 48 hours of new videos uploaded every minute.  However, most of these views came from a relatively small number of videos; according to a software engineer at that time, 30% of videos accounted for 99% of views on the site.  That year, the company again changed its interface and at the same time, introduced a new logo with a darker shade of red.  A subsequent interface change, designed to unify the experience across desktop, TV, and mobile, was rolled out in 2013.  By that point, more than 100 hours were being uploaded every minute, increasing to 300 hours by November 2014. \n During this time, the company also went through some organizational changes. In October 2006, YouTube moved to a new office in  .  Hurley announced that he would be stepping down as chief executive officer of YouTube to take an advisory role and that   would take over as head of the company in October 2010. \n In December 2009, YouTube partnered with  .  In April 2010, Lady Gaga's \" \" became the  , becoming the first video to reach 200 million views on May 9, 2010. \n YouTube   by   in 2011 that nearly resulted in the discontinuation of the website. The lawsuit was filed as a result of alleged   of Viacom's material by YouTube. However, the   ruled that YouTube was not liable, and thus YouTube won the case in 2012. \n  was appointed   of YouTube in February 2014.  In January 2016, YouTube expanded its headquarters in San Bruno by purchasing an office park for $215 million. The complex has 51,468 square metres (554,000 square feet) of space and can house up to 2,800 employees.  YouTube officially launched the \"polymer\" redesign of its user interfaces based on   language as its default, as well a redesigned logo that is built around the service's play button emblem in August 2017. \n Through this period, YouTube tried several new ways to generate revenue beyond advertisements. In 2013, YouTube launched a pilot program for content providers to offer premium, subscription-based channels.  This effort was discontinued in January 2018 and relaunched in June, with US$4.99 channel subscriptions.  These channel subscriptions complemented the existing Super Chat ability, launched in 2017, which allows viewers to donate between $1 and $500 to have their comment highlighted.  In 2014, YouTube announced a subscription service known as \"Music Key\", which bundled ad-free streaming of music content on YouTube with the existing   service.  The service continued to evolve in 2015 when YouTube announced  , a new premium service that would offer ad-free access to all content on the platform (succeeding the Music Key service released the previous year), premium original series, and films produced by YouTube personalities, as well as background playback of content on mobile devices. YouTube also released  , a third app oriented towards streaming and discovering the music content hosted on the YouTube platform. \n The company also attempted to create products appealing to specific viewers. YouTube released a mobile app known as   in 2015, designed to provide an experience optimized for children. It features a simplified user interface, curated selections of channels featuring age-appropriate content, and parental control features.  Also in 2015, YouTube launched YouTube Gaming—a  -oriented vertical and app for videos and live streaming, intended to compete with the  -owned  . \n The company was attacked on April 3, 2018, when   occurred at YouTube's headquarters in San Bruno, California, which wounded four and resulted in the death of the shooter. \n By February 2017, one billion hours of YouTube videos were being watched every day, and 400 hours worth of videos were uploaded every minute.  Two years later, the uploads had risen to more than 500 hours per minute.  During the  , when most of the world was under  , usage of services like YouTube significantly increased. One data firm  estimated that YouTube was accounting for 15% of all  , twice its pre-pandemic level.  In response to EU officials requesting that such services reduce bandwidth as to make sure medical entities had sufficient bandwidth to share information, YouTube and   stated they would reduce streaming quality for at least thirty days as to cut bandwidth use of their services by 25% to comply with the EU's request.  YouTube later announced that they would continue with this move worldwide: \"We continue to work closely with governments and network operators around the globe to do our part to minimize stress on the system during this unprecedented situation.\" \n Following a 2018 complaint alleging violations of the   (COPPA),  the company was fined $170 million by the FTC for collecting personal information from minors under the age of 13.  YouTube was also ordered to create systems to increase children's privacy.  Following criticisms of its implementation of those systems, YouTube started treating all videos designated as \"made for kids\" as liable under COPPA on January 6, 2020.  Joining the   app, the company created a supervised mode, designed more for  , in 2021.  Additionally, to compete with  , YouTube released  , a short-form video platform. \n During this period, YouTube entered disputes with other tech companies. For over a year, in 2018 and 2019, no YouTube app was available for   products.  In 2020,   removed the YouTube TV app from its streaming store after the two companies were unable to reach an agreement. \n After testing earlier in 2021, YouTube removed public display of dislike counts on videos in November 2021, claiming the reason for the removal was, based on its internal research, that users often used the dislike feature as a form of   and  .  While some users praised the move as a way to discourage  , others felt that hiding dislikes would make it harder for viewers to recognize   or unhelpful videos and that other features already existed for creators to limit bullying. YouTube co-founder   referred to the update as \"a stupid idea\", and that the real reason behind the change was \"not a good one, and not one that will be publicly disclosed.\" He felt that users' ability on a social platform to identify harmful content was essential, saying, \"The process works, and there's a name for it: the  . The process breaks when the platform interferes with it. Then, the platform invariably declines.\"  Shortly after the announcement, software developer Dmitry Selivanov created Return YouTube Dislike, an  , third-party   for   and   that allows users to see a video's number of dislikes.  In a letter published on January 25, 2022, by then YouTube CEO  , acknowledged that removing public dislike counts was a controversial decision, but reiterated that she stands by this decision, claiming that \"it reduced dislike attacks.\" \n In 2022, YouTube launched an experiment where the company would show users who watched longer videos on TVs a long chain of short un-skippable adverts, intending to consolidate all ads into the beginning of a video. Following public outrage over the unprecedented amount of un-skippable ads, YouTube \"ended\" the experiment on September 19 of that year.  In October, YouTube announced that they would be rolling out customizable user handles in addition to channel names, which would also become channel URLs. \n On February 16, 2023, Wojcicki announced that she would step down as CEO, with   named as her successor. Wojcicki took on an advisory role for Google and parent company  .  Wojcicki died a year and a half later, on August 9, 2024. \n In late October 2023, YouTube began cracking down on the use of   on the platform. Users of ad blockers may be given a pop-up warning saying \"Video player will be blocked after 3 videos\". Users of ad blockers are shown a message asking them to allow ads or inviting them to subscribe to the ad-free   subscription plan. YouTube says that the use of ad blockers violates its terms of service. \n In April 2024, YouTube announced it would be \"strengthening our enforcement on third-party apps that violate YouTube's Terms of Service, specifically ad-blocking apps\". \n YouTube has been led by a CEO since its founding in 2005, beginning with  , who led the company until 2010. After Google's acquisition of YouTube, the CEO role was retained.   took over Hurley's position and kept the job until 2014. He was replaced by  , who later resigned in 2023.  The current CEO is  , who was appointed on February 16, 2023. \n YouTube offers different features based on user verification, such as standard or basic features like uploading videos, creating playlists, and using  , with limits based on daily activity (verification via phone number or channel history increases feature availability and daily usage limits); intermediate or additional features like longer videos (over 15 minutes), live streaming, custom thumbnails, and creating podcasts; advanced features like content ID appeals, embedding live streams, applying for monetization, clickable links, adding chapters, and pinning comments on videos or posts. \n In January 2012, it was estimated that visitors to YouTube spent an average of 15 minutes a day on the site, in contrast to the four or five hours a day spent by a typical US citizen watching television.  In 2017, viewers on average watched YouTube on mobile devices for more than an hour every day. \n In December 2012, two billion views were removed from the view counts of Universal and   music videos on YouTube, prompting a claim by   that the views had been deleted due to a violation of the site's terms of service, which ban the use of automated processes to inflate view counts. This was disputed by  , which said that the two billion views had been moved to Vevo, since the videos were no longer active on YouTube.  On August 5, 2015, YouTube patched the formerly notorious behavior which caused a video's view count to freeze at \"301\" (later \"301+\") until the actual count was verified to prevent  .  YouTube view counts once again updated in real time. \n Since September 2019, subscriber counts are abbreviated. Only three leading digits of channels' subscriber counts are indicated publicly, compromising the function of third-party real-time indicators such as that of  . Exact counts remain available to channel operators inside YouTube Studio. \n On November 11, 2021, after testing out this change in March of the same year, YouTube announced it would start hiding dislike counts on videos, making them invisible to viewers. The company stated the decision was in response to experiments which confirmed that smaller YouTube creators were more likely to be targeted in dislike   and harassment. Creators will still be able to see the number of likes and dislikes in the YouTube Studio dashboard tool, according to YouTube. \n YouTube has an estimate 14 billion videos  with about 5% of those never have a view and just over 85% of them have fewer than 1,000 views. \n YouTube has faced numerous challenges and criticisms in its attempts to deal with copyright, including the site's first viral video,  , which had to be taken down, due to copyright concerns.  At the time of uploading a video, YouTube users are shown a message asking them not to violate copyright laws.  Despite this advice, many unauthorized clips of copyrighted material remain on YouTube. YouTube does not view videos before they are posted online, and it is left to copyright holders to issue a     pursuant to the terms of the  . Any successful complaint about copyright infringement results in a  . Three successful complaints for   against a user account will result in the account and all of its uploaded videos being deleted.  From 2007 to 2009 organizations including  ,  , and the English   have filed lawsuits against YouTube, claiming that it has done too little to prevent the uploading of copyrighted material. \n In August 2008, a US court ruled in   that copyright holders cannot order the removal of an online file without first determining whether the posting reflected   of the material.  YouTube's owner Google announced in November 2015 that they would help cover the legal cost in select cases where they believe fair use defenses apply. \n In the 2011 case of  , professional singer Matt Smith sued Summit Entertainment for the wrongful use of copyright takedown notices on YouTube.  He asserted seven  , and four were ruled in Smith's favor.  In April 2012, a court in Hamburg ruled that YouTube could be held responsible for copyrighted material posted by its users.  On November 1, 2016, the dispute with GEMA was resolved, with Google content ID being used to allow advertisements to be added to videos with content protected by GEMA. \n In April 2013, it was reported that   and YouTube have a contractual agreement that prevents content blocked on YouTube by a request from UMG from being restored, even if the uploader of the video files a DMCA counter-notice.  As part of YouTube Music, Universal and YouTube signed an agreement in 2017, which was followed by separate agreements other major labels, which gave the company the right to advertising revenue when its music was played on YouTube.  By 2019, creators were having videos taken down or demonetized when Content ID identified even short segments of copyrighted music within a much longer video, with different levels of enforcement depending on the record label.  Experts noted that some of these clips said qualified for fair use. \n In June 2007, YouTube began trials of a system for automatic detection of uploaded videos that infringe copyright. Google CEO Eric Schmidt regarded this system as necessary for resolving lawsuits such as the one from  , which alleged that YouTube profited from content that it did not have the right to distribute.  The system, which was initially called \"Video Identification\"  and later became known as Content ID,  creates an ID File for copyrighted audio and video material, and stores it in a database. When a video is uploaded, it is checked against the database, and flags the video as a copyright violation if a match is found.  When this occurs, the content owner has the choice of blocking the video to make it unviewable, tracking the viewing statistics of the video, or adding advertisements to the video.\n An independent test in 2009 uploaded multiple versions of the same song to YouTube and concluded that while the system was \"surprisingly resilient\" in finding copyright violations in the audio tracks of videos, it was not infallible.  The use of Content ID to remove material automatically has led to   in some cases, as the videos have not been checked by a human for fair use.  If a YouTube user disagrees with a decision by Content ID, it is possible to fill in a form disputing the decision. \n Before 2016, videos were not monetized until the dispute was resolved. Since April 2016, videos continue to be monetized while the dispute is in progress, and the money goes to whoever won the dispute.  Should the uploader want to monetize the video again, they may remove the disputed audio in the \"Video Manager\".  YouTube has cited the effectiveness of Content ID as one of the reasons why the site's rules were modified in December 2010 to allow some users to upload videos of unlimited length. \n YouTube has a set of community guidelines aimed to reduce abuse of the site's features. The uploading of videos containing defamation, pornography, and material encouraging criminal conduct is forbidden by YouTube's \"Community Guidelines\".  Generally prohibited material includes sexually explicit content, videos of animal abuse,  , content uploaded without the copyright holder's consent, hate speech, spam, and predatory behavior.  YouTube relies on its users to flag the content of videos as inappropriate, and a YouTube employee will view a flagged video to determine whether it violates the site's guidelines.  Despite the guidelines, YouTube has faced criticism over aspects of its operations,  its   perpetuating   and falsehoods,  hosting videos ostensibly targeting children but containing  ,  videos of minors attracting   activities in their comment sections,  and fluctuating policies on the types of content that is eligible to be monetized with advertising. \n YouTube contracts companies to hire content moderators, who view content flagged as potentially violating YouTube's content policies and determines if they should be removed. In September 2020, a class-action suit was filed by a former content moderator who reported developing   (PTSD) after an 18-month period on the job. \n Controversial moderation decisions have included material relating to  ,  the  ,   's death,  and the  .  In July 2008, the Culture and Media Committee of the House of Commons of the United Kingdom stated that it was \"unimpressed\" with YouTube's system for policing its videos, and argued that \"proactive review of content should be standard practice for sites hosting user-generated content\". \n In June 2022,  , a media watchdog group, reported that   and   content calling LGBT people   was becoming more common on YouTube.  The report also referred to common accusations in YouTube videos that LGBT people are  .  The report stated the content appeared to be in violation of YouTube's hate speech policy. \n An August 2022 report by the  , a British think tank, found that harassment against women was flourishing on YouTube.  In his 2022 book  ,   reporter Mark Bergen said that many female content creators were dealing with harassment, bullying, and stalking. \n YouTube has been criticized for using an algorithm that gives great prominence to videos that promote conspiracy theories, falsehoods and incendiary fringe discourse.  According to an investigation by  , \"YouTube's recommendations often lead users to channels that feature conspiracy theories, partisan viewpoints and misleading videos, even when those users haven't shown interest in such content. When users show a political bias in what they choose to view, YouTube typically recommends videos that echo those biases, often with more-extreme viewpoints.\"  After YouTube drew controversy for giving top billing to videos promoting falsehoods and conspiracy when people made breaking-news queries during the  , YouTube changed its algorithm to give greater prominence to mainstream media sources. \n In 2017, it was revealed that advertisements were being placed on extremist videos, including videos by rape apologists, anti-Semites, and hate preachers who received ad payouts.  After firms started to stop advertising on YouTube in the wake of this reporting, YouTube apologized and said that it would give firms greater control over where ads got placed. \n University of North Carolina professor   has referred to YouTube as \"The Great Radicalizer\", saying \"YouTube may be one of the most powerful radicalizing instruments of the 21st century.\"  Jonathan Albright of the Tow Center for Digital Journalism at Columbia University described YouTube as a \"conspiracy ecosystem\". \n Before 2019, YouTube took steps to remove specific videos or channels related to   content that had violated its acceptable use policies but otherwise did not have site-wide policies against  . \n In the wake of the March 2019  , YouTube and other sites like Facebook and Twitter that allowed user-submitted content drew criticism for doing little to moderate and control the spread of hate speech, which was considered to be a factor in the rationale for the attacks.  These platforms were pressured to remove such content, but in an interview with  , YouTube's then chief product officer Neal Mohan said that unlike content such as   videos which take a particular format and thus easy to detect through computer-aided algorithms, general hate speech was more difficult to recognize and handle, and thus could not readily take action to remove without human interaction. \n In May 2019, YouTube joined an initiative led by France and New Zealand with other countries and tech companies to develop tools to be used to block   and to develop regulations, to be implemented at the national level, to be levied against technology firms that failed to take steps to remove such speech, though the United States declined to participate.  Subsequently, on June 5, 2019, YouTube announced a major change to its terms of service and further stated it would \"remove content denying that well-documented violent events, like the Holocaust or  , took place.\" \n In June 2020, YouTube was criticized for allowing white supremacist content on its platform for years after it announced it would be pledging $1 million to fight racial injustice.  Later that month, it banned several channels associated with white supremacy, including those of  ,  , and  , asserting these channels violated their policies on hate speech. \n Multiple research studies have investigated cases of misinformation in YouTube. In a July 2019 study based on ten YouTube searches using the   related to climate and climate change, the majority of videos were videos that communicated views contrary to the  .  A May 2023 study found that YouTube was monetizing and profiting from videos that included misinformation about climate change.  A 2019 BBC investigation of YouTube searches in ten different languages found that YouTube's algorithm promoted health misinformation, including fake cancer cures.  In Brazil, YouTube has been linked to pushing pseudoscientific misinformation on health matters, as well as elevated far-right fringe discourse and conspiracy theories.  In the Philippines, numerous channels disseminated misinformation related to the  .  Additionally, research on the dissemination of   beliefs in social media, has shown that networks of YouTube channels form an echo chamber that polarizes audiences by appearing to confirm preexisting beliefs. \n In 2018, YouTube introduced a system that would automatically add information boxes to videos that its algorithms determined may present conspiracy theories and other  , filling the infobox with content from   and   as a means to inform users to minimize misinformation propagation without impacting freedom of speech.  In 2023, YouTube revealed its changes in handling content associated with  . This social media platform's Community Guidelines now prohibit content that could encourage emulation from at-risk users. \n In January 2019, YouTube said that it had introduced a new policy starting in the United States intended to stop recommending videos containing \"content that could misinform users in harmful ways.\" YouTube gave  , miracle cures, and   as examples.  Efforts within YouTube engineering to stop recommending borderline extremist videos falling just short of forbidden hate speech, and track their popularity were originally rejected because they could interfere with viewer engagement.  In July 2022, YouTube announced policies to combat misinformation surrounding  , such as videos with instructions to perform abortion methods that are considered unsafe and videos that contain misinformation about the  .  Google and YouTube implemented policies in October 2021 to deny monetization or revenue to advertisers or content creators that promoted  .  In January 2024, the   reported that climate change deniers were instead pushing other forms of climate change denial that have not yet been banned by YouTube. \n Following the dissemination via YouTube of   that   communications technology was responsible for the spread of   which led to multiple 5G towers in the United Kingdom being attacked by arsonists, YouTube removed all such videos linking 5G and the coronavirus in this manner. \n In September 2021, YouTube extended this policy to cover videos disseminating misinformation related to any vaccine, including those long approved against measles or Hepatitis B, that had received approval from local health authorities or the  .  The platform proceeded to remove the accounts of anti-vaccine campaigners such as   and  .  YouTube had extended this moderation to non-medical areas. In the weeks following the  , the site added policies to remove or label videos promoting election fraud claims;  however, it reversed this policy in June 2023, citing that the removal was necessary to \"openly debate political ideas, even those that are controversial or based on disproven assumptions\". \n Leading into 2017, there was a significant increase in the number of videos related to children, coupled between the popularity of parents vlogging their family's activities, and previous content creators moving away from content that often was criticized or demonetized into family-friendly material. In 2017, YouTube reported that time watching family vloggers had increased by 90%.  However, with the increase in videos featuring children, the site began to face several controversies related to  , including with popular channels   and  . \n Later that year, YouTube came under criticism for showing inappropriate videos targeted at children and often featuring popular characters in violent, sexual or otherwise disturbing situations, many of which appeared on   and attracted millions of views. The term \" \" was coined on the Internet and then used by various news outlets to refer to this controversy.  Following the criticism, YouTube announced it was strengthening site security to protect children from unsuitable content and the company started to mass delete videos and channels that made improper use of family-friendly characters. As part of a broader concern regarding child safety on YouTube, the wave of deletions also targeted channels that showed children taking part in inappropriate or dangerous activities under the guidance of adults. \n Even for content that appears to be aimed at children and appears to contain only child-friendly content, YouTube's system allows for anonymity of who uploads these videos. These questions have been raised in the past, as YouTube has had to remove channels with children's content which, after becoming popular, then suddenly include inappropriate content masked as children's content.  The anonymity of such channel raise concerns because of the lack of knowledge of what purpose they are trying to serve.  The difficulty to identify who operates these channels \"adds to the lack of accountability\", according to Josh Golin of the  , and educational consultant Renée Chernow-O'Leary found the videos were designed to entertain with no intent to educate, all leading to critics and parents to be concerned for their children becoming too enraptured by the content from these channels.  Content creators that earnestly make child-friendly videos have found it difficult to compete with larger channels, unable to produce content at the same rate as them, and lacking the same means of being promoted through YouTube's recommendation algorithms that the larger animated channel networks have shared. \n In January 2019, YouTube officially banned videos containing \"challenges that encourage acts that have an inherent risk of severe physical harm\" (such as the  ) and videos featuring pranks that \"make victims believe they're in physical danger\" or cause emotional distress in children. \n In November 2017, it was revealed in the media that many videos featuring children—often uploaded by the minors themselves, and showing innocent content such as the children playing with toys or performing gymnastics—were attracting comments from   with predators finding the videos through private YouTube playlists or typing in certain keywords in Russian.  Other child-centric videos originally uploaded to YouTube began propagating on the  , and uploaded or embedded onto forums known to be used by pedophiles. \n As a result of the controversy, which added to the concern about \"Elsagate\", several major advertisers whose ads had been running against such videos froze spending on YouTube.  In December 2018,   found more than 100 grooming cases in which children were manipulated into sexually implicit behavior (such as taking off clothes, adopting overtly sexual poses and touching other children inappropriately) by strangers. \n In February 2019, YouTube vlogger Matt Watson identified a \"wormhole\" that would cause the YouTube recommendation algorithm to draw users into this type of video content, and make all of that user's recommended content feature only these types of videos.  Most of these videos had comments from sexual predators commenting with timestamps of when the children were shown in compromising positions or otherwise making indecent remarks.  In the wake of the controversy, the service reported that they had deleted over 400 channels and tens of millions of comments, and reported the offending users to law enforcement and the  .  Despite these measures several large advertisers pulled their advertising from YouTube. \n Subsequently, YouTube began to demonetize and block advertising on the types of videos that have drawn these predatory comments.  YouTube also began to flag channels that predominantly feature children, and preemptively disable their comments sections. \n A related attempt to algorithmically flag videos containing references to the string \"CP\" (an abbreviation of  ) resulted in some prominent false positives involving unrelated topics using the same abbreviation. YouTube apologized for the errors and reinstated the affected videos. \n In June 2019,   cited researchers who found that users who watched erotic videos could be recommended seemingly innocuous videos of children. \n In 2021, two accounts linked to  , the German channel of the Russian   network were removed as well for breaching YouTube's policies relating to COVID-19.  Russia threatened to ban YouTube after the platform deleted two German RT channels in September 2021. \n Shortly after the   in 2022, YouTube removed all channels funded by the Russian state.  YouTube expanded the removal of Russian content from its site to include channels described as 'pro-Russian'. In June 2022, the   channel run by Russian military blogger and journalist   was deleted.  \n In July 2023, YouTube removed the channel of British journalist  , active in covering the   from 2014. \n In August 2023, a Moscow court fined Google 3 million rubles, around $35,000, for not deleting what it said was \"fake news about the war in Ukraine\". \n In October 2024, a Russian court has fined its parent company Google a grand total of 2 undecillion   (equivalent to US$20 decillion) for restricting Russian state media channels on YouTube.  The fine imposed by Russia is far greater than the world's total GDP, estimated at US$110 trillion by the  .  News agency   reported that Google is allowed to return to the Russian market only if it complies with the court’s decision.  Kremlin spokesperson   labeled the court decision as \"symbolic\" and warned Google that it “should not be restricting the actions of our broadcasters on its platform.” \n YouTube featured an   prank on the site on April 1 of every year from 2008 to 2016. In 2008, all links to videos on the main page were redirected to  's music video \" \", a prank known as \" \".  The next year, when clicking on a video on the main page, the whole page turned upside down, which YouTube claimed was a \"new layout\".  In 2010, YouTube temporarily released a \"TEXTp\" mode which rendered video imagery into   letters \"in order to reduce bandwidth costs by $1 per second.\" \n The next year, the site celebrated its \"100th anniversary\" with a range of sepia-toned silent, early 1900s-style films, including a parody of  .  In 2012, clicking on the image of a DVD next to the site logo led to a video about a purported option to order every YouTube video for home delivery on DVD. \n In 2013, YouTube teamed up with satirical newspaper company   to claim in an uploaded video that the video-sharing website was launched as a contest which had finally come to an end, and would shut down for ten years before being re-launched in 2023, featuring only the winning video. The video starred several  , including  . A video of two presenters announcing the nominated videos streamed live for 12 hours. \n In 2014, YouTube announced that it was responsible for the creation of all viral video trends, and revealed previews of upcoming trends, such as \"Clocking\", \"Kissing Dad\", and \"Glub Glub Water Dance\".  The next year, YouTube added a music button to the video bar that played samples from \" \" by  .  In 2016, YouTube introduced an option to watch every video on the platform in 360-degree mode with  . \n YouTube Premium (formerly YouTube Red) is YouTube's premium subscription service. It offers advertising-free streaming, access to  , and background and offline video playback on mobile devices.  YouTube Premium was originally announced on November 12, 2014, as \"Music Key\", a   service, and was intended to integrate with and replace the existing Google Play Music \"All Access\" service.  On October 28, 2015, the service was relaunched as YouTube Red, offering ad-free streaming of all videos and access to exclusive original content.  As of November 2016 , the service has 1.5 million subscribers, with a further million on a free-trial basis.  As of June 2017 , the first season of   had received 250 million views in total. \n YouTube Kids is an American children's video app developed by YouTube, a subsidiary of  . The app was developed in response to parental and government scrutiny on the content available to children. The app provides a version of the service-oriented towards children, with curated selections of content, parental control features, and filtering of videos deemed inappropriate viewing for children aged under 13, 8 or 5 depending on the age grouping chosen. First released on February 15, 2015, as an   and    , the app has since been released for  ,  , and    , as well as for  . On May 27, 2020, it became available on  . As of September 2019, the app is available in 69 countries, including Hong Kong and Macau, and one province. YouTube launched a web-based version of YouTube Kids on August 30, 2019.\n On September 28, 2016, YouTube named  , the co-founder of   and former   executive, the Global Head of Music. \n In early 2018, Cohen began hinting at the possible launch of YouTube's new subscription music streaming service, a platform that would compete with other services such as   and  .  On May 22, 2018, the music streaming platform named \"YouTube Music\" was launched. \n YouTube Movies & TV is a   service that offers movies and television shows for purchase or rental, depending on availability, along with a selection of movies (encompassing between 100 and 500 titles overall) that are free to stream, with interspersed ad breaks. YouTube began offering free-to-view movie titles to its users in November 2018; selections of new movies are added and others removed, unannounced each month. \n In March 2021, Google announced plans to gradually   the Google Play Movies & TV app, and eventually migrate all users to the YouTube app's Movies & TV store to view, rent and purchase movies and TV shows (first affecting Roku, Samsung, LG, and Vizio smart TV users on July 15).  Google Play Movies & TV formally shut down on January 17, 2024, with the web version of that platform migrated to YouTube as an expansion of the Movies & TV store to desktop users. (Other functions of Google Play Movies & TV were integrated into the   service.) \n On November 1, 2022, YouTube launched Primetime Channels, a channel store platform offering third-party subscription streaming add-ons sold a la carte through the YouTube website and app, competing with similar subscription add-on stores operated by  ,   and  . The add-ons can be purchased through the YouTube Movies & TV hub or through the official YouTube channels of the available services; subscribers of YouTube TV add-ons that are sold through Primetime Channels can also access their content via the YouTube app and website. A total of 34 streaming services (including  ,  ,  ,  ,   and  ) were initially available for purchase. \n , as part of a broader residential distribution deal with Google signed in December 2022 that also made it available to YouTube TV subscribers, was added to Primetime Channels as a standalone add-on on  .  The ad-free tier of   was added to Primetime Channels on December 12, 2023, coinciding with YouTube TV converting its separate HBO (for base plan subscribers) and HBO Max (for all subscribers) linear/VOD add-ons into a single combined Max offering. \n On February 28, 2017, in a press announcement held at YouTube Space Los Angeles, YouTube announced YouTube TV, an    -style subscription service that would be available for United States customers at a price of US$65 per month. Initially launching in five major markets ( ,  ,  ,   and  ) on April 5, 2017,  the service offers live streams of programming from the five major broadcast networks ( ,  ,  ,   and  , along with selected   affiliates and   in certain markets), as well as approximately 60 cable channels owned by companies such as  ,  ,  ,  ,   and   (including among others  ,  ,  ,  ,  ,  ,  ,  ,  ,   and  ). \n Subscribers can also receive premium cable channels (including   (via a combined   add-on that includes in-app and log-in access to the service),  ,  ,   and  ) and other subscription services (such as  ,  ,  ,   and  ) as optional add-ons for an extra fee, and can access   original content.  In September 2022, YouTube TV began allowing customers to purchase most of its premium add-ons (excluding certain services such as NBA League Pass and  ) without an existing subscription to its base package. \n In September 2016,   was announced,  as an   app created for making YouTube easier to access on mobile devices in  . It was distinct from the company's main Android app and allowed videos to be downloaded and shared with other users. It also allowed users to preview videos, share downloaded videos through  , and offered more options for mobile data control and  . \n In February 2017,   was launched in  , and expanded in November 2017 to 14 other countries, including  ,  ,  ,  ,  , the  ,  , and  .  On February 1, 2018, it was rolled out in 130 countries worldwide, including  ,  ,  , and  . Before it shut down, the app was available to around 60% of the world's population.  In May 2022, Google announced that they would be shutting down   in August 2022. \n In September 2020, YouTube announced that it would be launching a beta version of a new platform of 15-second videos, similar to  , called  .  The platform was first tested in India but as of March 2021 has expanded to other countries including the United States with videos now able to be up to 1 minute long.  The platform is not a standalone app, but is integrated into the main YouTube app. Like TikTok, it gives users access to built-in creative tools, including the possibility of adding licensed music to their videos.  The platform had its global beta launch in July 2021. \n In 2018, YouTube started testing a new feature initially called \"YouTube Reels\".  The feature was nearly identical to   and  . YouTube later renamed the feature \"YouTube Stories\". It was only available to creators who had more than 10,000 subscribers and could only be posted/seen in the YouTube mobile app.  On May 25, 2023, YouTube announced that they would be shutting down this feature on June 26, 2023. \n In November 2016, YouTube released YouTube VR, a dedicated version with an interface for VR devices, for   mobile VR platform on Android.  In November 2018, YouTube VR was released on the   for the   headset.  YouTube VR was updated since for compatibility with successive   devices, and was ported to  . \n YouTube VR allows for access to all YouTube-hosted videos, but particularly supports headset access for 360° and 180°-degree video (both in 2D and stereoscopic 3D). Starting with the  , the app was updated for compatibility with mixed-reality passthrough modes on VR headsets. In April 2024, YouTube VR was updated to support 8K SDR video on  . \n Private individuals  and large production corporations  have used YouTube to grow their audiences. Indie creators have built grassroots followings numbering in the thousands at very little cost or effort, while mass retail and radio promotion proved problematic.  Concurrently,   celebrities moved into the website at the invitation of a YouTube management that witnessed early content creators accruing substantial followings and perceived audience sizes potentially larger than that attainable by television.  While YouTube's revenue-sharing \"Partner Program\" made it possible to earn a substantial living as a video producer—its top five hundred partners each earning more than $100,000 annually  and its ten highest-earning channels grossing from $2.5 million to $12 million —in 2012   business editor characterized YouTube as \"a free-to-use ... promotional platform for the music labels.\"  In 2013   Katheryn Thayer asserted that digital-era artists' work must not only be of high quality, but must elicit reactions on the YouTube platform and social media.  Videos of the 2.5% of artists categorized as \"mega\", \"mainstream\" and \"mid-sized\" received 90.3% of the relevant views on YouTube and Vevo in that year.  By early 2013,   had announced that it was factoring YouTube streaming data into calculation of the   and related genre charts. \n Observing that face-to-face communication of the type that online videos convey has been \"fine-tuned by millions of years of evolution\",   curator   referred to several YouTube contributors and asserted that \"what   did for writing, online video can now do for face-to-face communication.\"  Anderson asserted that it is not far-fetched to say that online video will dramatically accelerate scientific advance, and that video contributors may be about to launch \"the biggest learning cycle in human history.\"  In education, for example, the   grew from YouTube video tutoring sessions for founder Salman Khan's cousin into what     called \"the largest school in the world,\" with technology poised to   how people learn.  YouTube was awarded a 2008  ,  the website being described as a   that \"both embodies and promotes democracy.\"    reported that a disproportionate share of YouTube's most subscribed channels feature minorities, contrasting with mainstream television in which the stars are largely white.  A   study reported the development of \"visual journalism\", in which citizen eyewitnesses and established news organizations share in content creation.  The study also concluded that YouTube was becoming an important platform by which people acquire news. \n YouTube has enabled people to more directly engage with government, such as in the   (2007) in which ordinary people submitted questions to U.S. presidential candidates via YouTube video, with a   co-founder saying that Internet video was changing the political landscape.  Describing the   (2010–2012), sociologist   quoted an activist's succinct description that organizing the political unrest involved using \"Facebook to schedule the protests, Twitter to coordinate, and YouTube to tell the world.\"  In 2012, more than a third of the U.S. Senate introduced a resolution condemning   16 days after the \" \" video was posted to YouTube, with resolution co-sponsor Senator   remarking that the video \"will do more to lead to (Kony's) demise than all other action combined.\" \n Conversely, YouTube has also allowed government to more easily engage with citizens, the  's official YouTube channel being the seventh top news organization producer on YouTube in 2012  and in 2013 a healthcare exchange commissioned Obama impersonator  's YouTube music video spoof to encourage young Americans to enroll in the  -compliant health insurance.  In February 2014, U.S. President Obama held a meeting at the White House with leading YouTube content creators not only to promote awareness of Obamacare  but more generally to develop ways for government to better connect with the \"YouTube Generation.\"  Whereas YouTube's inherent ability to allow presidents to directly connect with average citizens was noted, the YouTube content creators'   savvy was perceived necessary to better cope with the website's distracting content and fickle audience. \n Some YouTube videos have themselves had a direct effect on world events, such as   (2012) which spurred   internationally.  TED curator Chris Anderson described a phenomenon by which geographically distributed individuals in a certain field share their independently developed skills in YouTube videos, thus challenging others to improve their own skills, and spurring invention and evolution in that field.  Journalist   stated in   that such videos have \"surprising implications\" for the dissemination of culture and even the future of classical music. \n A 2017 article in   posited that YouTube had become \"the new  \" for the  .  Almost a year before YouTube's January 2019 announcement that it would begin a \"gradual change\" of \"reducing   of borderline content and content that could misinform users in harmful ways\",  Zeynep Tufekci had written in   that, \"(g)iven its billion or so users, YouTube may be one of the most powerful radicalizing instruments of the 21st century\".  Under YouTube's changes to its recommendation engine, the most recommended channel evolved from conspiracy theorist   (2016) to   (2019).  According to a 2020 study, \"An emerging journalistic consensus theorizes the central role played by the video 'recommendation engine', but we believe that this is premature. Instead, we propose the 'Supply and Demand' framework for analyzing politics on YouTube.\"  A 2022 study found that \"despite widespread concerns that YouTube's algorithms send people down 'rabbit holes' with recommendations to extremist videos, little systematic evidence exists to support this conjecture\", \"exposure to alternative and extremist channel videos on YouTube is heavily concentrated among a small group of people with high prior levels of gender and racial resentment.\", and \"contrary to the 'rabbit holes' narrative, non-subscribers are rarely recommended videos from alternative and extremist channels and seldom follow such recommendations when offered.\" \n  and the   selected their membership based on individual video performances.  Further, the cyber-collaboration charity video \" \" was formed by mixing performances of 57 globally distributed singers into a single musical work,  with   noting the \"We Pray for You\" YouTube cyber-collaboration video as an example of a trend to use crowdsourcing for charitable purposes. \nThe anti-bullying   expanded from a single YouTube video directed to discouraged or  ,  that within two months drew video responses from hundreds including U.S. President  , Vice President Biden, White House staff, and several cabinet secretaries.  Similarly, in response to fifteen-year-old  's video \"My story: Struggling, bullying, suicide, self-harm\", legislative action was undertaken almost immediately after her suicide to study the prevalence of bullying and form a national anti-bullying strategy.  In May 2018, after London   claimed that   videos glamorizing violence gave rise to  , YouTube deleted 30 videos. \n Prior to 2020, Google did not provide detailed figures for YouTube's running costs, and YouTube's revenues in 2007 were noted as \" \" in a regulatory filing.  In June 2008, a   magazine article projected the 2008 revenue at $200 million, noting progress in advertising sales.  In 2012, YouTube's revenue from its ads program was estimated at $3.7 billion.  In 2013, it nearly doubled and estimated to hit $5.6 billion according to e-Marketer,  while others estimated $4.7 billion.  The vast majority of videos on YouTube are free to view and supported by advertising.  In May 2013, YouTube introduced a trial scheme of 53 subscription channels with prices ranging from $0.99 to $6.99 a month.  The move was seen as an attempt to compete with other providers of online subscription services such as  ,  , and Hulu. \n Google first published exact revenue numbers for YouTube in February 2020 as part of Alphabet's 2019 financial report. According to Google, YouTube had made   in ad revenue in 2019, in contrast to   in 2017 and   in 2018. YouTube's revenues made up nearly 10% of the total Alphabet revenue in 2019.  These revenues accounted for approximately 20 million subscribers combined between YouTube Premium and YouTube Music subscriptions, and 2 million subscribers to YouTube TV. \n YouTube had $29.2 billion ads revenue in 2022, up by $398 million from the prior year.  In Q2 2024, ad revenue rose to $8.66 billion, up 13% on Q1. \n YouTube entered into a marketing and advertising partnership with   in June 2006.  In March 2007, it struck a deal with   for three channels with BBC content, one for news and two for entertainment.  In November 2008, YouTube reached an agreement with  ,  , and  , allowing the companies to post full-length films and television episodes on the site, accompanied by advertisements in a section for U.S. viewers called \"Shows\". The move was intended to create competition with websites such as Hulu, which features material from NBC,  , and  .  In November 2009, YouTube launched a version of \"Shows\" available to UK viewers, offering around 4,000 full-length shows from more than 60 partners.  In January 2010, YouTube introduced an online film rentals service,  which is only available to users in the United States, Canada, and the UK as of 2010.  The service offers over 6,000 films. \n In March 2017, the government of the United Kingdom pulled its advertising campaigns from YouTube, after reports that its ads had appeared on videos containing extremist content. The government demanded assurances that its advertising would \"be delivered safely and appropriately\".   newspaper, as well as other major British and U.S. brands, similarly suspended their advertising on YouTube in response to their advertising appearing near  . Google stated that it had \"begun an extensive review of our advertising policies and have made a public commitment to put in place changes that give brands more control over where their ads appear\".  In early April 2017, the YouTube channel   presented evidence claiming that a   article had fabricated screenshots showing major brand advertising on an offensive video containing   music overlaid on a   music video, citing that the video itself had not earned any ad revenue for the uploader. The video was retracted after it was found that the ads had been triggered by the use of copyrighted content in the video. \n On April 6, 2017, YouTube announced that to \"ensure revenue only flows to creators who are playing by the rules\", it would change its practices to require that a channel undergo a policy compliance review, and have at least 10,000-lifetime views, before they may join the Partner Program. \n In May 2007, YouTube launched its Partner Program (YPP), a system based on   which allows the uploader of the video to share the revenue produced by advertising on the site.  YouTube typically takes 45 percent of the advertising revenue from videos in the Partner Program, with 55 percent going to the uploader. \n There are over two million members of the YouTube Partner Program.  According to  , in 2013 a pre-roll advertisement on YouTube (one that is shown before the video starts) cost advertisers on average $7.60 per 1000 views. Usually, no more than half of the eligible videos have a pre-roll advertisement, due to a lack of interested advertisers. \n YouTube's policies restrict certain forms of content from being included in videos being monetized with advertising, including videos containing violence, strong language, sexual content, \"controversial or sensitive subjects and events, including subjects related to war, political conflicts, natural disasters and tragedies, even if graphic imagery is not shown\" (unless the content is \"usually newsworthy or comedic and the creator's intent is to inform or entertain\"),  and videos whose user comments contain \"inappropriate\" content. \n In 2013, YouTube introduced an option for channels with at least a thousand subscribers to require a paid subscription in order for viewers to watch videos.  In April 2017, YouTube set an eligibility requirement of 10,000 lifetime views for a paid subscription.  On January 16, 2018, the eligibility requirement for monetization was changed to 4,000 hours of watch-time within the past 12 months and 1,000 subscribers.  The move was seen as an attempt to ensure that videos being monetized did not lead to controversy, but was criticized for penalizing smaller YouTube channels. \n , a part of the YouTube Creator Rewards, are a recognition by YouTube of its most popular channels.  The trophies made of nickel plated copper-nickel alloy, golden plated brass, silver plated metal, ruby, and red tinted crystal glass are given to channels with at least one hundred thousand, a million, ten million, fifty million subscribers, and one hundred million subscribers, respectively. \n YouTube's policies on \" \" restrict what may be incorporated into videos being monetized; this includes strong violence, language,  sexual content, and \"controversial or sensitive subjects and events, including subjects related to war, political conflicts, natural disasters and tragedies, even if graphic imagery is not shown\", unless the content is \"usually newsworthy or comedic and the creator's intent is to inform or entertain\".  In September 2016, after introducing an enhanced notification system to inform users of these violations, YouTube's policies were criticized by prominent users, including   and  . DeFranco argued that not being able to earn advertising revenue on such videos was \"censorship by a different name\". A YouTube spokesperson stated that while the policy itself was not new, the service had \"improved the notification and appeal process to ensure better communication to our creators\".    reported in 2019 that LGBT keywords resulted in demonetization. \n As of November 2020 in the United States, and June 2021 worldwide,  YouTube reserves the right to monetize any video on the platform, even if their uploader is not a member of the YouTube Partner Program. This will occur on channels whose content is deemed \"advertiser-friendly\", and all revenue will go directly to Google without any share given to the uploader. \n The majority of YouTube's advertising revenue goes to the publishers and video producers who hold the rights to their videos; the company retains 45% of the ad revenue.  In 2010, it was reported that nearly a third of the videos with advertisements were uploaded without permission of the copyright holders. YouTube gives an option for copyright holders to locate and remove their videos or to have them continue running for revenue.  In May 2013,   began enforcing its copyright ownership and claiming the advertising revenue from video creators who posted screenshots of its games.  In February 2015, Nintendo agreed to share the revenue with the video creators through the Nintendo Creators Program.  On March 20, 2019, Nintendo announced on Twitter that the company will end the Creators program. Operations for the program ceased on March 20, 2019. \n YouTube has been censored, filtered, or banned for a variety of reasons, including: \n Access to specific videos is sometimes prevented due to copyright and intellectual property protection laws (e.g.  ), violations of hate speech, and preventing access to videos judged inappropriate for youth,  which is also done by YouTube with the   app and with \" \".  Businesses, schools, government agencies, and other private institutions often block social media sites, including YouTube, due to its bandwidth limitations  and the site's potential for distraction. \n As of 2018 , public access to YouTube is blocked in many countries, including  ,  ,  ,  ,   ,   ,  ,   and  . In some countries, YouTube is blocked for more limited periods of time such as during periods of unrest, the run-up to an election, or in response to upcoming political anniversaries. In cases where the entire site is banned due to one particular video, YouTube will often agree to remove or limit access to that video in order to restore service. \n Reports emerged that since October 2019, comments posted with Chinese characters insulting the   (  \"communist bandit\" or   \" \", referring to  ) were being automatically deleted within 15 seconds. \n Specific incidents where YouTube has been blocked include:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Subject-oriented_programming", "title": "Subject-oriented programming", "content": "In  ,   is an     in which the state (fields) and behavior (methods) of objects are not seen as intrinsic to the objects themselves, but are provided by various subjective perceptions (\"subjects\") of the objects. The term and concepts were first published in September 1993 in a conference paper  which was later recognized as being one of the three most influential papers to be presented at the conference between 1986 and 1996.  As illustrated in that paper, an analogy is made with the contrast between the philosophical views of   and   with respect to the characteristics of \"real\" objects, but applied to software ones. For example, while we may all perceive a tree as having a measurable height, weight, leaf-mass, etc., from the point of view of a bird, a tree may also have measures of relative value for food or nesting purposes, or from the point of view of a tax-assessor, it may have a certain taxable value in a given year. Neither the bird's nor the tax-assessor's additional state information need be seen as intrinsic to the tree, but are added by the perceptions of the bird and tax-assessor, and from Kant's analysis, the same may be true even of characteristics we think of as intrinsic.\n Subject-oriented programming advocates the organization of the   that describe   into \"subjects\", which may be composed to form larger subjects. At points of access to fields or  , several subjects' contributions may be composed. These points were characterized as the   of the subjects. For example, if a tree is cut down, the methods involved may need to join behavior in the bird and tax-assessor's subjects with that of the tree's own. It is therefore fundamentally a view of the compositional nature of software development, as opposed to the algorithmic (procedural) or representation-hiding (object) nature.\n The introduction of   in 1997  raised questions about its relationship to subject-oriented programming, and about the difference between subjects and aspects. These questions were unanswered for some time, but were addressed in the patent on Aspect-oriented programming filed in 1999  in which two points emerge as characteristic differences from earlier art:\n In the subject-oriented view, the cross-cut may be placed separately from the aspect (subject) and the behavior is not forced by the aspect, but governed by rules of composition. Hindsight  makes it also possible to distinguish aspect-oriented programming by its introduction and exploitation of the concept of a query-like   to externally impose the join-points used by aspects in general ways.\n In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension. The use of externally imposed pointcuts is an important linguistic capability, but remains one of the most controversial features of aspect-oriented programming. \n By the turn of the millennium, it was clear that a number of research groups were pursuing different technologies that employed the composition or attachment of separately packaged state and function to form objects.  To distinguish the common field of interest from Aspect-Oriented Programming with its particular patent definitions and to emphasize that the compositional technology deals with more than just the coding phase of software development, these technologies were organized together under the term  ,  and an organization and series on international conferences begun on the subject. Like aspect-oriented programming, subject-oriented programming, composition filters,   and adaptive methods are considered to be aspect-oriented software development approaches.\n The original formulation of subject-oriented programming deliberately envisioned it as a packaging technology – allowing the space of functions and data types to be extended in either dimension.  The first implementations had been for C++,  and Smalltalk.  These implementations exploited the concepts of software labels and composition rules to describe the joining of subjects.\n To address the concern that a better foundation should be provided for the analysis and composition of software not just in terms of its packaging but in terms of the various concerns these packages addressed,  an explicit organization of the material was developed in terms of a multi-dimensional \"matrix\" in which concerns are related to the software units that implement them. This organization is called  , and the paper describing it  has been recognized as the most influential paper of the ICSE 1999 Conference. \n This new concept was implemented for composing   software, using the name   for the tool. \n Composition and the concept of subject can be applied to software artifacts that have no executable semantics, like requirement specifications or documentation. A research vehicle for  , called the   (CME), has been described  in which tools for query, analysis, modelling,  and composition are applied to artifacts in any language or representation, through the use of appropriate plug-in adapters to manipulate the representation.\n A successor to the Hyper/J composition engine  was developed as part of CME which uses a general approach for the several elements of a composition engine:\n Both Hyper/J and CME are available, from alphaWorks  or sourceforge,  respectively, but neither is actively supported.\n Method dispatch in object oriented programming can be thought of as \"two dimensional\" in the sense that the code executed depends on both the method name and the object in question. This can be contrasted  with procedural programming, where a procedure name resolves directly, or one dimensionally, onto a subroutine, and also to subject oriented programming, where the sender or subject is also relevant to dispatch, constituting a third dimension.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Usenet_newsgroup", "title": "Usenet newsgroup", "content": "A   is a   usually within the   system, for messages   from users in different locations using the  . They are   and are not devoted to publishing  . Newsgroups are technically distinct from, but functionally similar to,   on the  .   software is used to read the content of newsgroups. Before the adoption of the  , Usenet newsgroups were among the most popular Internet services.\n Communication is facilitated by the   (NNTP) which allows connection to Usenet servers and data transfer over the internet.  Similar to another early (yet still used) protocol   which is used for email messages, NNTP allows both server-server and client-server communication.  This means that newsgroups can be replicated from   to server which gives the Usenet network the ability to maintain a level of robust data persistence as a result of built-in data redundancy.  However, most users will access using only the client-server commands of NNTP and in almost all cases will use a GUI for browsing as opposed to command line based client-server communication specified in the NNTP protocol. \n \nNewsgroups generally come in either of two types, binary or text. There is no technical difference between the two, but the naming differentiation allows users and servers with limited facilities to minimize network bandwidth usage. Generally, Usenet conventions and rules are enacted with the primary intention of minimizing the overall amount of network traffic and resource usage.\nTypically, the newsgroup is focused on a particular topic of interest. A message sent for publication on a newsgroup is called a \"post\". Some newsgroups allow posts on a wide variety of themes, regarding anything a member chooses to discuss as  , while others keep more strictly to their particular subject, frowning on   posts. The news admin (the administrator of a  ) decides how long posts are kept on their server before being expired (deleted), which is called  . Different servers will have different retention times for the same newsgroup; some may keep posts for as little as one or two weeks, others may hold them for many years.\n Back when the early community was the pioneering computer society, the common habit seen with many posts was a notice at the end that disclosed whether the author had (or was free of) a personal interest (financial, political or otherwise) in making the post. This is rarer now, and the posts must be read more skeptically, as with other media. Privacy and   issues have also risen in importance.\n Usenet newsgroups posters and operators usually do not make money from their occupations on the platform.\n The number of newsgroups grew from more than 100 as of 1983  to more than 110,000, but only 20,000 or so of those are active.  Newsgroups vary in popularity; some newsgroups receive fewer than a dozen posts per year while the most popular can get several thousand in under an hour.\n While newsgroups were not created with the intention of distributing files such as pictures, sound and video, they have proven to be quite effective for this. As of 2022, some remain popular as an alternative to   to share and download files. \n Because newsgroups are widely distributed, a file uploaded once will be spread to many other servers and can then be downloaded by an unlimited number of users. More useful is that users download from a local news server, rather than from a more distant machine with perhaps limited connectivity, as may be the case with   technology. In fact, this is another benefit of newsgroups: it is usually not expected that users share. If every user makes uploads then the servers would be flooded; thus it is acceptable and often encouraged for users to just  .\n There were originally a number of obstacles to the transfer of binary files over Usenet. Usenet was originally designed with the transmission of text in mind, and so the encoding of posts caused losses in binary data where the data was not part of the protocol's  . Consequently, for a long while, it was impossible to send binary data as such. As workarounds,   such as   and later   and   were developed which encoded the binary data from the files to be transmitted (e.g. sound or video files) to text characters which would survive transmission over Usenet. At the receiver's end, the data needed to be decoded by the user's  .\n Additionally, there was a limit on the size of individual posts so that large files could not be sent as single posts. To get around this, Newsreaders were developed which were able to split long files into several posts. Intelligent newsreaders at the other end could then automatically group such split files into single files, allowing the user to easily retrieve the file. These advances have meant that Usenet is used to send and receive many   of files per day.\n There are two main issues that pose problems for transmitting large files over newsgroups. The first is   and the other is  . The business of premium   is generated primarily on their ability to offer superior completion and retention rates, as well as their ability to offer very fast connections to users. Completion rates are significant when users wish to download large files that are split into pieces; if any one piece is missing, it is impossible to successfully download and reassemble the desired file. To work around the problem, a redundancy scheme known as   (PAR) is commonly used.\n Many major   have a retention time of more than seven years.  A number of websites exist to keep an index of files posted to binary newsgroups.\n Partly because of such long retention times, as well as growing   and   speeds, Usenet is also used by individuals to store   data in a practice called  , or uBackup.  While commercial providers offer    , storing data on Usenet is free of charge (although access to Usenet itself may not be). A user must  . Because anyone can download the backup files, the data is typically  . After the files are uploaded, the uploader has no control over them; they are automatically distributed to all Usenet providers that subscribe to the newsgroup they are uploaded to, so there will be copies of them spread all around the world.\n Most Newsgroups are not moderated. A moderated newsgroup has one or more individuals who must approve posts before they are published. A separate address is used to submit posts and the moderators then propagate those they approve of. The first moderated newsgroups appeared in 1984 under mod.* according to  , \"Hobbes' Internet Timeline\".\n \nTransmission within and at the bounds of the network uses the   (NNTP) (Internet standard RFC 3977 of 2006, updating RFC 977 of 1986).\n Newsgroup servers are hosted by various organizations and institutions. Most   host their own  , or rent access to one, for their subscribers. There are also a number of companies who sell access to premium news servers.\n Every host of a news server maintains agreements with other nearby news servers to synchronize regularly. In this way news servers form a   network. When a user posts to one news server, the post is stored locally. That server then shares posts with the servers that are connected to it for those newsgroups they both carry. Those servers do likewise, propagating the posts through the network. For newsgroups that are not widely carried, sometimes a carrier group is used for   to aid distribution. This is typically only useful for groups that have been removed or newer   groups. Crossposts between hierarchies, outside of the Big 8 and   hierarchies, are prone to failure.\n Newsgroups are often arranged into  , theoretically making it simpler to find related groups. The term   refers to the hierarchy defined by the prefix before the first dot.\n The most commonly known hierarchies are the  . So for instance newsgroup   would be in the   top-level Usenet hierarchy, where the asterisk (*) is defined as a  . There were seven original major hierarchies of Usenet newsgroups, known as the \"Big 7\":\n These were all created in the   of 1986–1987, before which all of these newsgroups were in the net.* hierarchy. At that time there was a great controversy over what newsgroups should be allowed. Among those that the   (who effectively ran the Big 7 at the time) did not allow were those concerning  ,  , and  .\n This situation resulted in the creation of an   (short for \"alternative\") Usenet hierarchy, under which these groups would be allowed. Over time, the laxness of rules on newsgroup creation in alt.* compared to the Big 7 meant that many new topics could, given time, gain enough popularity to get a Big 7 newsgroup. There was a rapid growth of alt.* as a result, and the trend continues to this day. Because of the anarchistic nature with which the groups sprang up, some jokingly referred to ALT standing for \" ,   and  \" (a  ).\n In 1995,   was created for the discussion of the humanities (e.g. literature, philosophy), and the Big 7 became the Big 8.\n The   has discussion of all kinds of topics, and many hierarchies for discussion specific to a particular geographical area or in a language other than English.\n Before a new Big 8 newsgroup can be created, an RFD (Request For Discussion) must be posted into the newsgroup  , which is then discussed in  . Once the proposal has been formalized with a name, description, charter, the   will vote on whether to create the group.  If the proposal is approved by the  , the group is created.  Groups are removed in a similar manner.\n Creating a new group in the alt.* hierarchy is not subject to the same rules; anybody can create a newsgroup, and anybody can remove it, but most news administrators will ignore these requests unless a local user requests the group by name.\n There are a number of newsgroup hierarchies outside of the Big 8 (and alt.*) that can be found on many news servers. These include non-English language groups, groups managed by companies or organizations about their products, geographic/local hierarchies, and even non-internet network boards routed into NNTP. Examples include (alphabetically):\n Additionally, there is the   hierarchy, which can be considered \"more alt than alt.*\".  There are many local sub-hierarchies within this hierarchy, usually for specific countries or cultures (such as   for Italy).\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/WAITS", "title": "WAITS", "content": " was a heavily modified variant of  's Monitor   (later renamed to, and better known as, \" \") for the   and   mainframe computers, used at the   (SAIL) from the mid-1960s up until 1991; the mainframe computer it ran on also went by the name of \"SAIL\".\n There was never an \"official\" expansion of WAITS, but a common variant was \"West-coast Alternative to  \"; another variant was \"Worst Acronym Invented for a Timesharing System\". The name was endorsed by the SAIL community in a public vote choosing among alternatives.  Two of the other contenders were SAINTS (\"Stanford AI New Timesharing System\") and SINNERS (\"Stanford Incompatible Non-New Extensively Rewritten System\"), proposed by the systems programmers. Though WAITS was less visible than ITS, there was frequent exchange of people and ideas between the two communities, and innovations pioneered at WAITS exerted enormous indirect influence.\n WAITS alumni at   and elsewhere also played major roles in the developments that led to the  , the  , and the   (later sold by  ).\n The early screen modes of  , for example, were directly inspired by WAITS' \"E\" editor – one of a family of editors that were the first to do  , in which the editing commands were invisible and where one typed text at the point of insertion/overwriting. The modern style of multi-region windowing is said to have originated there.\n The system also featured an unusual level of support for what is now called   computing, allowing analog audio and video signals (including TV and radio) to be switched to programming terminals. This switching capability for terminal video even allowed users in separate offices to view and type on the same virtual terminal, or a single user to instantly switch among multiple full virtual terminals.\n Also invented there were \" \" - thus, the \"Alt\" key on every   is a WAITS legacy. \n One WAITS feature very notable in pre-Web days was a news-wire search engine called NS (for News Service) that allowed WAITS   to instantly find, store and be notified about selected   and   news-wire stories by doing searches using arbitrary combinations of words.  News story retrieval by such search was instantaneous because each story was automatically indexed by all its words when it came in over the wire.\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_style_guides", "title": "List of style guides", "content": "\n A  , or style manual, is a set of standards for the writing and design of documents, either for general use or for a specific publication, organization or field. The implementation of a style guide provides uniformity in style and formatting within a document and across multiple documents. A set of standards for a specific organization is often known as \"house style\". Style guides are common for general and specialized use, for the general reading and writing audience, and for students and scholars of various   disciplines, medicine, journalism, the law, government, business, and industry.\n Several basic style guides for technical and scientific communication have been defined by international  . These are often used as elements of and refined in more specialized style guides that are specific to a subject, region, or organization. Some examples are:\n Other style guides that cover international usage:\n In the United Kingdom, major publications, academic institutions and companies have their own style guides, otherwise they would normally rely on   available in the  .\n In the United States, most journalistic forms of mass communication rely on styles provided in the   (AP).  Corporate publications typically follow either the AP style guide or the equally respected Chicago Manual of Style, often with entries that are additions or exceptions to the chosen style guide. \n A classic grammar style guide is  . Together, these two books are referenced more than any other general style book for US third-person writing used across most professions. \n \n  \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Ed_Pegg_Jr.", "title": "Ed Pegg Jr.", "content": "\n  (born December 7, 1963) is an expert on mathematical   and is a self-described recreational  . He wrote an online puzzle column called Ed Pegg Jr.'s   for the   during the years 2003–2007. His puzzles have also been used by   on the puzzle segment of    . He was a fan of   and regularly participated in   conferences. In 2009 he teamed up with   and   to edit two Gardner tribute books. \n Pegg received a master's degree in mathematics from the  ,  writing his thesis on the subject of fair dice.  In 2000, he left   to join  , where he collaborated on   (NKS). In 2004 he started assisting   at Wolfram  .  He has made contributions to several hundred MathWorld articles.  He was one of the chief consultants for  .\n \n This article about an American mathematician is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Hachette_v._Internet_Archive", "title": null, "content": "\n\n , No. 20-cv-4160 (JGK), 664 F.Supp.3d 370 (S.D.N.Y. 2023), WL 2623787 (S.D.N.Y. 2023), is a   in which the   determined that the  , a registered library, committed   by scanning and lending complete copies of books through   mechanisms. Stemming from the creation of the   (NEL) during the onset of the  , publishing companies  ,  ,  , and   alleged that the Internet Archive's   and National Emergency Library facilitated copyright infringement. The case primarily concerns the   of   (CDL) of complete copies of certain books. The case does not concern the display of short passages, limited page views, search results, books out of copyright or out of print, or books without an ebook version currently for sale. \n On March 25, 2023, the court ruled on the case.  In August 2023, the parties reached a negotiated judgment, including a permanent injunction barring the Internet Archive from lending complete copies through CDL of some of the plaintiffs' books.  The Internet Archive appealed the decision but it was upheld by the appellate court in September 2024.\n In December 2020,   included the lawsuit among its \"Top 10 Library Stories of 2020\". \n The   is a non-profit organization and legally a library; it is governed by copyright laws specific to libraries. It is based in  ,  ; the Archive maintains  , a digital library index and lending system.  As many of the works in the Internet Archive are under copyright, the Archive used a   (CDL) system, a practice that relies upon   (DRM) to prevent unauthorized downloading or copying of copyrighted works. Open Library can generate digitized material ( ) from print copy. The Open Library CDL system ensured that only one digital copy is in use for each print copy or otherwise authorized ebook copy available.\n However, on March 24, 2020, following shutdowns caused by the  , the Internet Archive opened the  , removing the waitlists used in Open Library and expanding access to these books for all readers. More than one user could borrow a book at the same time.  Two months later, on June 1, the National Emergency Library (NEL) was met with a lawsuit from four book publishers. Two weeks after that, on June 16, the Internet Archive closed the NEL,  and the prior Open Library CDL system resumed after the 12 weeks of NEL usage.\n On June 1, 2020,   and other publishers, including  ,  , and  , filed a lawsuit against the Internet Archive for the National Emergency Library.  The plaintiffs argued that the practice of CDL was illegal and not protected by the doctrine of fair use.  Furthermore, they argued that the Internet Archive was not abiding by CDL, as it had acknowledged that its partner libraries were not always withdrawing their physical copies from their shelves. \n By June 2022, both parties to the case requested   for the case, each favoring their respective sides, which Judge   approved of a summary judgment hearing to take place later in 2022.  No summary judgment was issued, and instead a first hearing was held on March 20, 2023.  Over the course of the hearing, Koeltl appeared unmoved by the IA's fair use claims and unconvinced that the publishers' market for library e-books was not impacted by their practice. \n The 127 publishers' books in the suit are also available as ebooks from the publishers. The Internet Archive said afterwards it would appeal this ruling, but otherwise would continue other digital book services which have been previously cleared under case law, such as books for reading-impaired users. \n Senator   of North Carolina, chairman of the intellectual property subcommittee on the Senate Judiciary Committee, said in a letter to the Internet Archive that he was \"concerned that the Internet Archive thinks that it—not Congress—gets to determine the scope of copyright law\". \n As part of its response to the publishers' lawsuit, in late 2020 the Archive launched a campaign called Empowering Libraries (hashtag #EmpoweringLibraries) that portrayed the lawsuit as a threat to all libraries. \n In a 2021   article, Argyri Panezi argued that the case \"presents two important, but separate questions related to the electronic access to library works; first, it raises questions around the legal practice of digital lending, and second, it asks whether emergency use of copyrighted material might be fair use\" and argued that libraries have a public service role to enable \"future generations to keep having equal access—or opportunities to access—a plurality of original sources\". \n Shortly before oral arguments, the Internet Archive held a press conference with comments from several people who implied that the issues in this case were much broader than the 127 books specifically named in the suit.  All presenters agreed that book publishers need to make money to pay their expenses including authors. The question is whether the National Emergency Library (NEL) actually harmed the publishers.\n Lila Bailey, Senior Policy Counsel for the Internet Archive,  noted that:\n In the past, publishers stood against microfilm and photocopiers, crying harm. They said they would be harmed by interlibrary loan. They lobbied for decades against libraries being allowed to provide access for the blind and print disabled. They were wrong. It took years, but eventually, the law affirmed each of these things, and the public benefitted.  With this lawsuit, publishers have repeated those same claims of massive harm from controlled digital lending. ... When asked under oath, their own executives admitted this. ... [They even] instructed their own 950 dollar per hour expert not to even try to measure economic harm. ... On the other hand, when we invited economists from Northeastern University and the University of Copenhagen to look at the sales and library lending data produced in this case, they came to a singular conclusion: The Internet Archive's digital lending had no measurable effect on the market whatsoever. Bailey's conclusion was supported by other speakers. \n Harvard Law School Professor   said that book publishers need to make a profit to serve the public, but the material available to the public should not be limited to what commercial enterprises find profitable.  , for example, offers subscribers access to thousands of movies and television shows but routinely stops offering content for which the demand is too low.  That doesn't happen with libraries. Without controlled digital lending, out-of-print books become essentially unavailable to the vast majority of humanity. \"We need access to our past, not just the part of our past that is economically or commercially viable.\" \n An expert report filed with the court by Northeastern Econ Prof. Imke Reimers also reported that \"sales in the first five years after an edition's publication account for up to 90% of lifetime sales.\" \n On the other side, University of Chicago computer science professor   reported that the Internet Archive's actual CDL practices sometimes violated their claims, lending out more copies than they physically had. \n Judge John G. Koeltl ruled on March 24, 2023, granting the publishers' request.   He held that the Internet Archive's scanning and lending of complete copies constituted copyright infringement and that the Internet Archive's fair use defense failed all four factors of the \"fair use test\". He rejected the Archive's argument that their use was \"transformative\" in the sense of copyright law.  He further stated that \"Even full enforcement of a one-to-one owned-to-loaned ratio, however, would not excuse IA's reproduction of the Works in Suit\". \n Internet Archive founder Brewster Kahle declared their intention to appeal the ruling. \n While Judge Koeltl issued a summary judgment in favor of the plaintiffs and against the defendant, he did not assess damages. Instead, he directed the parties to brief the court on how they thought the case should be resolved in a way that comports with the judge's decision.  The deadline for this was extended several times;  the final extension was granted on July 28, extending the deadline to August 11, 2023, with Judge Keoltl writing, \"No further extensions.\" \n On August 11, 2023, the parties reached a negotiated judgment. The agreement prescribes a permanent injunction preventing Internet Archive from loaning the plaintiffs' books in full through CDL, except those for which no e-book is currently available for sale from the publisher,  as well as an undisclosed payment to the plaintiffs.  The agreement also preserves the right for the Internet Archive to appeal the previous ruling.  As a result of the lawsuit, more than 500,000 books were made unavailable from loaning in full through CDL. The Internet Archive appealed to restore full CDL access to the affected books. \n On September 11, 2023, the Internet Archive filed a notice which appealed the ruling to the  .  On December 15, 2023, the Internet Archive filed its opening brief in its appeal.  Shortly afterwards, several other organizations filed   briefs. \n The   phase of the appeal occurred on June 28, 2024.  \n On September 4, 2024, the Second Circuit Court of Appeals affirmed the lower court rulings. The court stated \"On the one hand, eBook licensing fees may impose a burden on libraries and reduce access to creative work. On the other hand, authors have a right to be compensated in connection with the copying and distribution of their original creations. Congress balanced these 'competing claims upon the public interest' in the Copyright Act. We must uphold that balance here.\" \n The   released a press statement that said, \"In celebrating the opinion, we also thank the thousands of public libraries across the country that serve their communities everyday [ ] through lawful eBook licenses. We hope the opinion will prove educational to the defendant and anyone else who finds public laws inconvenient to their own interests.\"  The AAP has been critical of the Internet Archive for suggesting that libraries engage in the same practices that they do, arguing that only 13 public libraries in the US had cooperated with the Open Library. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Comparison_of_stylesheet_languages", "title": "Comparison of stylesheet languages", "content": "In  , the two primary   are   (CSS) and the   (XSL). While they are both called stylesheet languages, they have very different purposes and ways of going about their tasks.\n  is designed around styling a document, structured in a  ,   and   (including   and  ) documents. It was created for that purpose. The code CSS is non-XML syntax to define the style information for the various elements of the document that it styles.\n The language to structure a document ( ) is a prelimit to CSS.  A markup language, like HTML and less XUL, may define some primitive elements to style a document, for example <emphasis> to bold.  CSS post styles a document to \"screen media\" or \"paged media\".\n Screen media, displayed as a single page (possibly with hyperlinks), that has a fixed horizontal width but a virtually unlimited vertical height. Scrolling is often the method of choice for viewing parts of screen media. This is in contrast to \"paged media\", which has multiple pages, each with specific fixed horizontal and vertical dimensions.  To style paged media involves a variety of complexities that screen media does not. Since CSS was designed originally for screen media, its paged facilities lacked.\n CSS version 3.0 provides new features that allow CSS to more adequately style documents for paged display.\n  has evolved drastically from its initial design into something very different from its original purpose. The original idea for XSL was to create an XML-based styling language directed toward paged display media. The mechanism they used to accomplish this task was to divide the process into two distinct steps.\n First, the XML document would be transformed into an intermediate form. The process for performing this transformation would be governed by the XSL stylesheet, as defined by the XSL specification. The result of this transformation would be an XML document in an intermediate language, known as   (also defined by the XSL specification).\n However, in the process of designing the transformation step, it was realized that a generic XML transformation language would be useful for more than merely creating a presentation of an XML document. As such, a new working group was split off from the XSL working group, and the   (XSLT) language became something that was considered separate from the styling information of the XSL-FO document. Even that split was expanded when   became its own separate specification, though still strongly tied to XSLT.\n The combination of XSLT and XSL-FO creates a powerful styling language, though much more complex than CSS. XSLT is a   language, while CSS is not; this demonstrates a degree of power and flexibility not found in CSS. Additionally, XSLT is capable of creating content, such as automatically creating a table of contents just from chapters in a book, or removing/selecting content, such as   generating a glossary from a book. XSLT version 1.0 with the   extensions, or XSLT version 2.0 is capable of generating multiple documents as well, such as dividing the chapters in a book into their own individual pages. By contrast, a CSS can only selectively remove content by not displaying it.\n XSL-FO is unlike CSS in that the XSL-FO document stands alone. CSS modifies a document that is attached to it, while the XSL-FO document (usually the result of the transformation by XSLT of the original document) contains all of the content to be presented in a purely presentational format. It has a wide range of specification options with regard to paged formatting and higher-quality typesetting. But it does not specify the pages themselves. The XSL-FO document must be passed through an XSL-FO processor utility that generates the final paged media, much like HTML+CSS must pass through a   to be displayed in its formatted state.\n The complexity of XSL-FO is a problem, largely because implementing an FO processor is very difficult. CSS implementations in web browsers are still not entirely compatible with one another, and it is much simpler to write a CSS processor than an FO processor. However, for richly specified paged media, such complexity is ultimately required in order to be able to solve various   problems.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Input/output", "title": "Input/output", "content": "In  ,   ( ,  , or informally   or  ) is the communication between an information processing system, such as a  , and the outside world, such as another computer system, peripherals, or a human operator.   are the signals or data received by the system and outputs are the signals or   sent from it. The term can also be used as part of an action; to \"perform I/O\" is to perform an  .\n  are the pieces of   used by a human (or other system) to communicate with a computer. For instance, a   or   is an   for a computer, while   and   are  . Devices for communication between computers, such as   and  , typically perform both input and output operations. Any interaction with the system by an interactor is an   and the reaction the system responds is called the output.\n The designation of a device as either input or output depends on perspective. Mice and keyboards take physical movements that the human user outputs and convert them into input signals that a computer can understand; the output from these devices is the computer's input. Similarly, printers and monitors take signals that computers output as input, and they convert these signals into a representation that human users can understand. From the human  's perspective, the process of reading or seeing these representations is receiving output; this type of interaction between computers and humans is studied in the field of  . A further complication is that a device traditionally considered an input device, e.g., card reader, keyboard, may accept control commands to, e.g., select stacker, display keyboard lights, while a device traditionally considered as an output device may provide status data (e.g., low toner, out of paper, paper jam).\n In computer architecture, the combination of the   and  , to which the CPU can read or write directly using individual  , is considered the brain of a computer. Any transfer of information to or from the CPU/memory combo, for example by reading data from a  , is considered I/O.  The CPU and its supporting circuitry may provide   that is used in low-level  , such as in the implementation of  , or may provide access to  . An   is one designed to exploit locality and perform efficiently when exchanging data with a secondary storage device, such as a disk drive.\n An I/O interface is required whenever the I/O device is driven by a processor. Typically a CPU communicates with devices via a  . The interface must have the necessary logic to interpret the device address generated by the processor.   should be implemented by the interface using appropriate commands (like BUSY, READY, and WAIT), and the processor can communicate with an I/O device through the interface. If different data formats are being exchanged, the interface must be able to convert serial data to parallel form and vice versa. Because it would be a waste for a processor to be idle while it waits for data from an input device there must be provision for generating   and the corresponding type numbers for further processing by the processor if required. \n A computer that uses   accesses hardware by reading and writing to specific memory locations, using the same assembly language instructions that computer would normally use to access memory. An alternative method is via instruction-based I/O which requires that a CPU have specialized instructions for I/O.  Both input and output devices have a   rate that can vary greatly.  With some devices able to exchange data at very high speeds   to memory (DMA) without the continuous aid of a CPU is required. \n Higher-level   and programming facilities employ separate, more abstract I/O concepts and  . For example, most operating systems provide application programs with the concept of  . Most programming languages provide I/O facilities either as statements in the language or as   in a standard library for the language.\n An alternative to special primitive functions is the  , which permits programs to just describe I/O, and the actions are carried out outside the program. This is notable because the   functions would introduce   to any programming language, but this allows   to be practical.\n The I/O facilities provided by operating systems may be  , with files containing  , or stream-oriented, with the file containing a stream of bytes.\n  requires the use of instructions that are specifically designed to perform I/O operations. The I/O instructions address the channel or the channel and device; the channel asynchronously accesses all other required addressing and control information. This is similar to DMA, but more flexible.\n  also requires the use of special I/O instructions. Typically one or more ports are assigned to the device, each with a special purpose. The port numbers are in a separate address space from that used by normal instructions.\n  (DMA) is a means for devices to transfer large chunks of data to and from memory independently of the CPU.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Caffeine_(service)", "title": "Caffeine (service)", "content": " was a   platform for gaming, sports, and other entertainment content.  \n Caffeine secured a $100 million investment in September 2018 from 21st Century Fox with chairman   joining Caffeine's board, as well as the creation of a newly formed joint venture called Caffeine Studios. As of 2019, Caffeine had raised $146 million from investors in 3 rounds led by  ,  , and  .  \n Both Caffeine and   hosted pre-game events for  . Notable content creators who have used the platform include   and  . \n Caffeine ended their service on June 26, 2024, stating that they were not able to achieve profitability. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Lecture_Notes_in_Computer_Science", "title": null, "content": "\n  is a series of   books published by   since 1973.\n The series contains  , post- ,  , and  . In addition,  ,   surveys, and \"hot topics\" are increasingly being included. \n The series is indexed by  . \n \n This article about a computer book or series of books is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Tin_(newsreader)", "title": null, "content": " is an  , text-based,    , used to read and post messages on  , the worldwide distributed discussion system.\n Tin was initially used on text-only   connected via a slow   to a multi-user   central server, where graphics were generally not supported and when the   did not yet exist. At the time, tin was considered to be somewhat of a high-resource  program in this environment (similar to  ) due to its use of terminal cursor control and page-oriented text scrolling to make navigating Usenet easier. While it did not have graphics support it does provide a visually organized browser-oriented drill-down list of groups, subjects, and then articles, as opposed to simply scrolling endless pages and menus upward from the bottom of the screen.\n Tin is available for a variety of    . It is based on the TASS newsreader, whose   had been posted in 1991 on   by  . \nThe work on tin was begun shortly afterward by Iain Lea,  who provided information for the   RFC 2980. \nSince 1996, tin has been maintained by Urs Janßen.\n The program is generally compared with   or nn. \nThe latter is also based on TASS. \nSome note that tin has the most flexible threading support. \n Tin runs on any   or   platform. This is because tin was an early adopter of  , in 1996. Older versions of tin also ran on  ;  the newer versions which have   support do not.\n The original tin used  . Along with the portability improvements gained by using autoconf, its developers improved the adaptability by making it work with   or  —again improving portability. Other changes, such as localization using  , as well as   support have kept the application current.\n Unlike trn or nn, it is easy to follow the progress of changes since 1995 in tin because its   is detailed and dated.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/WPS-8", "title": "WPS-8", "content": " is a   sold by   for use with their   processors (including the  , VT278  , and PC238 DECmate II and PC24P DECmate III microcomputer systems).\n WPS-8 supports a variety of 24 row by 80 or 132 column terminals including the   family as well as the   family and all subsequent ANSI-compatible terminals. A series of hierarchical menus allow the user to command the system; the particular style of these menus became very-widely used by Digital, particularly within their \" \" office system. Once a document is opened for editing, near   editing is provided using a   to indicate the text alignment and tab stops for any given portion of the text. A typical editing session might look like this:\n Using these various rulers, complex formatting can be achieved, even using a simple input device like a 24x80 character terminal. On ANSI terminals, character attributes such as   and underline are shown on the screen. On the VT52 terminals (which can not display attributes), the operator can perform the same functions but only the printout will reveal the formatting.\n As text is typed, the system automatically word-wraps the text so that it conforms to the ruler currently in effect for that section of the document. Rulers can be added or modified and the text from that ruler forward to the next will automatically be adjusted to conform to the new ruler. Hyphenation can be semi-automatically performed (including \"hidden\" hyphens that will only be revealed if a line break exposed them).\n Specialized editing functions are provided using the terminal keypad.  A few functions can be commanded simply by pressing a keypad key, but a far wider range of functions can be commanded by prefixing them with the \" \" (the PF1 key on the keypad, colored gold on systems equipped with the WPS-8 custom keycaps).  This style of \"gold key\" editing also became standard at Digital, later showing up in mainstream general-purpose   such as KED and   as well as the \"ALL-IN-1\" office system.  The editing facilities include making a selection and then using cut and paste (much like today's word processors, but using keys marked for cut and paste, rather than a mouse).\n Printing is to any of several different letter-quality   including a DEC variant of the  .\n WPS-8 normally runs from a single floppy   and user data can be stored on the system diskette or additional data-only diskettes. Up to four diskette drives are supported in a single system.\n The system also supports the creation of data tables, the sorting of these data tables, arithmetic calculations using these data, and a mail-merge operation using these data and the arithmetic results. Through the extensive use of  , it manages all that on a 12- , 1.2-  processor with 16 KWords of memory and 256 KB of diskette storage. The limited resources of the system do not permit a spell-checker, though, primarily because there was no place with adequate storage to contain the   file.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/OSNews", "title": "OSNews", "content": " is a    . It originally focused on   and their related technologies that launched in 1997, but is now aggregating consumer electronics news. The content is managed by a group of editors and the owner.  As of 2014, its managing editor is Thom Holwerda, who joined in 2005. \n OSnews has been referenced by  ,   ,   ,   ,   ,   ,    and  .    described OSnews as \"an alternative operating system Web magazine\",  and in 2011 Holwerda noted that \"while the alternative operating systems scene might no longer be the prime focus of OSNews due to a lack of activity in that field, it's still where our heart lies.\" \n Besides its main site, OSNews previously detected hundreds of mobile browsers and handsets  and redirected them to a specially formatted cHTML version of the website at mobile.osnews.com. Eugenia Loli-Queru, the author of this script, open sourced it in 2008. \n The editors contribute original articles and manage the submissions of news bits, articles, editorial comments and reviews that are submitted by readers. OSNews serves daily 275,000 page views on average (as of October 2005). \n Like other technology news sites such as  , it has a free user/  model, and allows viewers to add commentary to articles. In 2005, OSNews published version 3 of its website, which includes an all-new commenting engine. Instead of reporting comments to moderators, this system now relies on votes. Readers can vote comments up or down, and readers can set a score threshold, which can eliminate the down-voted comments from view.\n In late 2007, version 4 was launched, which completely overhauled the backend of the website, and was followed by version 4.1  which added a brand new theme and look to the website.\n On February 12, 2007, managing editor Thom Holwerda published the 1.0 version of the OSNews Style Guide.  This   is licensed under a     so that other websites and publications can use and adapt the guide to their liking. OSNews is one of the few sites of its kind with such a style guide.\n In January 2008, Thom Holwerda launched  ,  a webcomic based on the various news items OSNews carries.   was updated tri-weekly, until it was discontinued in mid-2008.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Numb3rs", "title": null, "content": "\n\n  (stylized as  ) is an American   television series that originally aired on   from January 23, 2005, to March 12, 2010, with a total of six seasons consisting of  . The series was created by   and  , and follows     ( ) and his brother   ( ), a college mathematics professor and prodigy, who helps Don solve crimes for the FBI. Brothers   and   produced  ; its production companies are the Scott brothers'   and   (originally  , and later  ).\n The show focuses equally on the relationships among Don Eppes, his brother Charlie Eppes, and their father,   ( ), and on the brothers' efforts to fight crime, usually in Los Angeles. A typical episode begins with a crime, which is subsequently investigated by a team of FBI agents led by Don and   by Charlie, with the help of   ( ) and   ( ). The insights provided by Charlie's mathematics were always in some way crucial to solving the crime.\n On May 18, 2010, CBS canceled the series after six seasons. \n The show revolved around three intersecting groups of characters: the FBI, scientists at the fictitious California Institute of Science (CalSci), and the Eppes family.\n  (Voice-over by David Krumholtz) We all use math every day. To predict weather, to tell time, to handle money. Math is more than formulas and equations. It's logic; it's rationality. It's using your mind to solve the biggest mysteries we know.\n The first season aired between January 23, 2005, and May 13, 2005, at 10:00 pm on Fridays. It started the working relationship between Los Angeles'   and Charlie Eppes. The main FBI agents are Charlie's brother, Don Eppes, and  , as well as  . Don and Charlie's father, Alan Eppes, provides emotional support for the pair, while Professor Larry Fleinhardt and doctoral student Amita Ramanujan provide mathematical support and insights to Charlie. Season one was a half-season, producing only 13 episodes.   played Terry Lake, an agent, in this season; she was later replaced by  , who played Megan Reeves.\n The second season aired between September 23, 2005, and May 19, 2006, again at 10:00 pm on Fridays. Season two has several changes to Don's FBI team: Terry Lake is reassigned to   and two new members join Don and David Sinclair:   and  . Charlie is challenged on one of his long-standing mathematical workpieces and starts work on a new theory, cognitive emergence theory. Larry sells his home and assumes a   lifestyle while he becomes romantically involved with Megan. Amita receives an offer for an assistant professor position at  , but is plagued by doubt as her relationship with Charlie is challenged, and her career is in upheaval. Alan begins work and dating again, although he struggles with the loss of his wife and Charlie and his dream of her.\n  was renewed for a third season,  which began airing at 10:00 pm on Friday, September 22, 2006, and ended on May 18, 2007. Charlie and Amita intensify their relationship, as do Larry and Megan, especially after Megan's kidnapping. Amita has trouble adjusting to her new role as a CalSci professor, and Larry announces his  ; he will be on the   for six months, which greatly distresses Charlie. Charlie and his colleagues are troubled by Dr. Mildred Finch, the newly appointed chair of the CalSci Physics, Mathematics, and Astronomy Division, whom they learn has begun dating Alan.\nMeanwhile, Don dates Agent Liz Warner and questions his   and  , and receives counseling. Charlie sees Don's therapist, and the two understand one another more. Despite Don's concerns, Alan engages in some FBI consulting with his engineering knowledge, and Larry returns from the space station, disillusioned. The finale wraps up with a revelation that Colby was a double agent for the Chinese.\n Noticeable changes from previous seasons include removing the opening-credit sequence (credits are now done during the first segment of the show), the absence of Peter MacNicol's character for much of the season, and the absence of Diane Farr's character for a few episodes. Peter MacNicol appeared in the first 11 episodes before leaving for the television show  , but returned to   for the 21st episode of season three (\" \"). His character's absence was written into the show by becoming a   on the International Space Station. Diane Farr, pregnant for most of the season, left the show for   in episode 18 (\" \"); her character's absence is explained as a particular assignment to the  .\n The season premiere aired on September 28, 2007, in the same time slot as in previous seasons, 10:00 pm  .  Because of the  , only 12 episodes were initially produced. However, once the strike ended, CBS announced the show's return April 4, 2008, with six episodes.  The season ended on May 16, 2008.\n As this season starts,   escapes from jail and is revealed to be a  . He then rejoins the team. Don and Liz break up halfway through this season after Liz has trouble with Don's trust issues. Amita's parents come to visit, which becomes a secondary theme throughout most of the season. Due to her work at the DOJ, Megan is conflicted by her work and turns to Larry. Near the end of the season, Don's girlfriend from season two, Robin Brooks, returns. Don and Robin then continue their relationship. Charlie attends   because he has been working with Don for several years and wants to understand better what his brother does. In the season finale, Megan leaves the team to move back to Washington, DC, and Charlie goes head-to-head with Don about a case. This causes Charlie to send information to scientists in  . He is subsequently arrested and has his   revoked to no longer help Don on cases. At the end of the episode, Don drives away to another case, and Charlie admits that giving up FBI work will be more challenging than he expected.\n Several characters from previous seasons did not appear in season four, most notably   and  .\n The fifth season premiered on October 3, 2008, and the season finale aired on May 15, 2009. The season premiere was moved back one week to accommodate the  . \n Season five opens three weeks after \" \" (season four's finale), with the government dropping the charges against Charlie. Charlie gets his   back after Don and he fight FBI Security Officer Carl McGowan. Don begins to explore  . The team adds new agent Nikki Betancourt, who arrives shortly after Megan Reeves' departure. Robin is offered a promotion but turns it down. Buck Winters (from the episodes   and \" \") breaks out of prison and comes after Don. Alan suddenly finds himself coaching CalSci's basketball team. David becomes Don's primary relief supervisor.   tries to recruit Charlie, but he turns down their offer. Toward the end of the season, Don is stabbed, and Charlie blames himself for it. The aftermath of Don's stabbing causes Charlie to focus more on his FBI consultation work. Amita is kidnapped, and the team races to find her. After she is rescued, Charlie proposes to Amita. Her response is left undisclosed.\n  marked the 100th episode of  . \n The sixth and final season premiered Friday, September 25, 2009, at 10:00 pm   and the season finale aired on March 12, 2010, 3 days before Hirsch's 75th birthday.\n The season starts with the   of Charlie and Amita. Soon after, Larry turns down an opportunity to meet with mathematicians at  , in  , and drops his course load for the following semester. This leads Charlie to realize Larry is once again leaving and leaving all of his work to Charlie. Don learns that his former mentor is crooked, causing Don angst to shoot his mentor. Charlie and Don realize that Alan has lost a substantial amount of money in his  . After some delay, Larry leaves Los Angeles to find a vacant piece of land for sale within driving distance of the city. Alan decides to return to work and finds a job as a software technical consultant. David asks Don for advice about career paths within the FBI. Larry returns from the desert with a new theory about the universe's fate. Charlie and Amita begin planning their wedding and decide to join the   program to practice parenting skills. They get married before their move to   to teach at the  . Don loses his gun, recovers it after it is used in some   murders, and gets engaged to Robin. He also decides to leave the team, taking an administrative position within the FBI. Before leaving, Charlie and Amita decide that the family garage should be converted to a   so Alan can continue living with them. Leaving Colby, Liz, and Nikki behind, David departs for Washington, DC, to a position as an anti-corruption team leader.\n  (distributed by  ) has released all six seasons of   on DVD in Regions 1, 2, and 4.\n On June 2, 2017, CBS DVD released   on DVD in Region 1. \n  and  , the show's creators, have won several awards for the show, including the   in 2006,  and the  's Public Service Award in 2007.  They also won the   (JPBM) reward and encourage communicators who, on a sustained basis, bring mathematical ideas and information to non-mathematical audiences Communications Award in 2010.  Also, the show's  , Jim Vickers, was nominated for an   for   in 2006 for episode 14 of Season 2, \" \". \n We all use math every day. To predict weather, to tell time, to handle money. Math is more than formulas and equations. It's logic; it's rationality. It's using your mind to solve the biggest mysteries we know. Several mathematicians work as   for each episode.  Actual mathematics are presented in the show; the equations on the chalkboards are mathematically valid, and are somewhat applicable to the situations presented in each show. This mathematical validity and applicability of the equations have been asserted by professional mathematicians. \n A book entitled   (   ; published August 28, 2007), written by   and Dr. Gary Lorden, a consultant to the show along with Dr. Orara, a physics consultant, explains some of the mathematical techniques that have been used both in actual FBI cases and in other law-enforcement departments. \n Since the premiere season, the blog edited by Prof. Mark Bridger (Northeastern University) has commented on the mathematics behind each episode of the show. \n  (the developers of  ) is the chief math consultant, reviewing scripts and providing background mathematics for the show. Starting with season four, their website in collaboration with CBS is entitled \"The math behind  \". \n , a mathematician consultant to the show, expressed concern with its use of mathematics, asserting that the math is inserted after the initial script and written to provide plausible-sounding  , rather than having consultants involved at all stages of story development.  The same part-time consultant offered criticism of the show's portrayal of female mathematicians and expressed concern over the appropriateness of the relationship between Charlie Eppes and his graduate student Amita Ramanujan. \n The idea for   was generated in the late 1990s when Nick Falacci and Cheryl Heuton, the show's creators, attended a lecture given by  , a popular  .  The premise of the show is similar to that of author  's  ,  and to the \" \" segment on the children's television show  .\n  was originally cast to portray the character of Don Eppes.  Also, the original concept for the show had the events take place at  ;  this was later changed to the fictional California Institute of Science, commonly called CalSci. Scenes which take place at CalSci are filmed at   (Caltech)  and the  . One of the most frequent campus locations at Caltech is the vicinity of  , including the bridge over Millikan Pond, the Trustees room, and the arcades of nearby buildings. At USC, locations include Doheny Library and the Town and Gown dining room. Exteriors for the FBI offices are on the distinctive bridge at  . \n Another common location is the   of the Eppes family. The house shown in the first season is real; it is owned by David Raposa and Edward Trosper,  although a   set was used from the second season onwards. \n The show uses the number three in its title instead of the letter \"e\", in which is found in  . In the interviews with Tom Jicha of the   and with Alan Pergament of  , Heuton mentioned that the use of the number three in the title derives from  , a form of computer jargon that replaces letters with numbers.   Dr. Gary Lorden, a   mathematics professor who served as the show's mathematics consultant, told  's Ira Flatow that it was created on a normal computer keyboard.  Lorden also mentioned that the use of the number three in the title can serve as a restriction in Internet searches about the series. \n Both entertainment reporters and psychologists noticed the title's spelling.  Some reporters, such as Joanne Ostrow of the  ,  the staff members of  ,  the editors of  ,  the staff of the  ,  and Mike Hughes of   acknowledged the presence of the number three in the title.  Lynette Rice of   asked Krumholtz about the three in the title; his response was, \"Isn't that annoying? I think it should be the mathematical symbol for  , which looks like an E. I've been fighting that for weeks.\"   (The   (Σ) stands for  . )  Others used varying adjectives to describe the title.  The TV site   called it \"their typographical silliness, not ours\".   Brad Aspey of  , stated, \"No, that wasn't an ugly typo you just read - \"NUMB3RS\" (pronounced numbers) is the idiosyncratic title of filmmakers Ridley and Tony Scott's astute and crafty psychological drama which shows that even math can make for edge-of-your-seat entertainment.\"   Ellen Gray of  , said, \"Some of you may have noticed that in promoting \"Numb3rs,\" which premieres Sunday before moving to its regular 10 p.m. Friday slot, CBS has chosen to put a 3 in place of the \"e\" in the title....I won't be going along with this particular affectation, which slows down my typing and seems to be the graphic equivalent of the reversed \"R\" in Toys R Us.  So there.\" \n Still others had a more positive view of the title.  When NPR's Flatow asked both Lorden and Dr. Keith Devlin, NPR's mathematics reporter, about the title, both men denied creating the title; Devlin believed that executive producer Tony Scott originated the title.  Lorden stated that he initially thought that the title was \"kind of hokey\", but later saw it as \"brilliant\" and a \"catchy logo\".   Jonathan Storm of  , in his review of the series stated, \"You'd think CBS's new  , which premieres at 10 tonight after the Patriots-Steelers football game, is just another one of those shows with numskull titles trying to draw attention to themselves.  But the '3' substituting for the 'e' is actually based on a real thing\"....  He later said that the show was \"written by people familiar with the  \".   David Brooks of   devoted the majority of his entire review to the use of leet in the series title.   In addition, three psychologists, Manuel Perea, Jon Andoni Duñabeitia, and Manuel Carreiras mentioned the television series in their 2008 article for the  's  . \n Seasonal rankings (based on average total viewers per episode) of   on CBS. \n \n :  \n :  \n :  \n :  \n :  \n :  ,  ,  ,  \n :  \n :  \n :  \n :  \n :  \n :  \n :  \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/You_Wouldn%27t_Steal_a_Car", "title": "You Wouldn't Steal a Car", "content": "\n \" \" is the first sentence of a   that debuted on July 27, 2004, which was part of the anti-  campaign \" \" It was created by the   and the   (now the MPA) in cooperation with the  ,  and appeared in theaters internationally from 2004 until 2008, and on many commercial DVDs during the same period as an ad preceding the  , as either an unskippable or skippable video.\n The announcement depicts either a teenage girl trying to illegally download a movie or a gang attempting to buy movies from a bootlegger interwoven with clips of a man committing   of various objects, and equates these crimes to the   of copyrighted materials, such as films.  According to the  , the announcement was unsuccessful, and was largely a source of ridicule.  Likewise, a 2022   paper published in   found the PSAs may have increased piracy rates.  By 2009, over 100 parodies of the announcement had been created.  It was reported that the music in the announcement was stolen and used without permission.  However, one source disputes this, saying the reporting is the result of   regarding a different anti-piracy ad that used stolen music. \n The advertisement has been parodied in  , including those using the phrase \"You wouldn't download a car.\"  In 2007,   episode \" \" parodied the advertisement, mirroring its initial points before comparing copyright infringement to increasingly ludicrous crimes and consequences.  Finlo Rohrer of the   considered this version to be \"perhaps the best known\" of over 100 parodies of the ad that had been created by 2009.  In 2021, the old   used by the campaign (piracyisacrime.com) was purchased and   to a YouTube upload of the parody, possibly inspired by a   discussion.  An advertisement for the 2008 film   parodied the campaign by having   repeatedly interrupt the narrator to say he would do the crimes described. The advertisement was titled \"Downloading Often Is Terrible\", or \"D.O.I.T\". \n The  , in association with Rafilm, released their own parody version of the film to oppose the media industry and government views on existing copyright laws, as well as to educate the public on alternative views about intellectual property.  \n In 2017,   produced a controversial parody of the video for  . The video compared the celebration of Australia Day, which marks the arrival of the   and is often referred to as \"Invasion Day\" by Indigenous Australians, to celebrating the  '  , dropping the   and the  . \n \"You wouldn't screenshot an NFT\" is a variant of the \"You wouldn't steal a car\" meme that satirizes  ,  based on the idea that the ease of making digital copies of the work of art associated with an NFT undermines the value of purchasing the NFT.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Typesetting", "title": "Typesetting", "content": " is the composition of   for publication, display, or distribution by means of arranging   (or  ) in mechanical systems or   in digital systems representing   (letters and other symbols).  Stored types are retrieved and ordered according to a language's   for visual display. Typesetting requires one or more   (which are widely but erroneously confused with and substituted for  ). \nOne significant effect of typesetting was that authorship of works could be spotted more easily, making it difficult for copiers who have not gained permission. \n During much of the  , movable type was composed by hand for each   by workers called  . A tray with many dividers, called a case, contained cast metal  , each with a single letter or symbol, but backwards (so they would print correctly). The compositor assembled these sorts into words, then lines, then pages of text, which were then bound tightly together by a frame, making up a   or page. If done correctly, all letters were of the same height, and a flat surface of type was created. The form was placed in a press and inked, and then printed (an impression made) on paper.  Metal type read backwards, from right to left, and a key skill of the compositor was their ability to read this backwards text.\n Before computers were invented, and thus becoming computerized (or digital) typesetting, font sizes were changed by replacing the characters with a different size of type. In letterpress printing, individual letters and punctuation marks were cast on small metal blocks, known as \"sorts,\" and then arranged to form the text for a page. The size of the type was determined by the size of the character on the face of the sort. A compositor would need to physically swap out the sorts for a different size to change the font size.\n During typesetting, individual sorts are picked from a type case with the right hand, and set from left to right into a   held in the left hand, appearing to the typesetter as upside down. As seen in the photo of the composing stick, a lower case 'q' looks like a 'd', a lower case 'b' looks like a 'p', a lower case 'p' looks like a 'b' and a lower case 'd' looks like a 'q'. This is reputed to be the origin of the expression \"mind your p's and q's\". It might just as easily have been \"mind your b's and d's\". \n A forgotten but important part of the process took place after the printing: after cleaning with a solvent the expensive sorts had to be redistributed into the typecase - called   or   - so they would be ready for reuse. Errors in sorting could later produce   if, say, a p was put into the b compartment.\n The diagram at right illustrates a cast metal sort:   face,   body or shank,   point size,   shoulder,   nick,   groove,   foot.   were used for centuries in combination with metal type. Not shown, and more the concern of the casterman, is the \"set\", or width of each sort. Set width, like body size, is measured in points.\n In order to extend the working life of type, and to account for the finite sorts in a case of type, copies of forms were cast when anticipating subsequent printings of a text, freeing the costly type for other work. This was particularly prevalent in book and newspaper work where rotary presses required type forms to wrap an impression cylinder rather than set in the bed of a press. In this process, called  , the entire form is pressed into a fine matrix such as   or   to create a  , from which a positive form is cast in  .\n Advances such as the   and   would push the state of the art even farther ahead. Still, hand composition and   printing have not fallen completely out of use, and since the introduction of digital typesetting, it has seen a revival as an   pursuit. However, it is a small niche within the larger typesetting market.\n The time and effort required to manually compose the text led to several efforts in the 19th century to produce mechanical typesetting. While some, such as the  , met with limited success, by the end of the 19th century, several methods had been devised whereby an operator working a keyboard or other devices could produce the desired text. Most of the successful systems involved the in-house casting of the type to be used, hence are termed \"hot metal\" typesetting. The  , invented in 1884, used a keyboard to assemble the casting matrices, and cast an entire line of type at a time (hence its name). In the  , a keyboard was used to  , which was then fed to control a casting machine. The   involved hand-set matrices, but otherwise used hot metal. By the early 20th century, the various systems were nearly universal in large newspapers and publishing houses.\n  systems first appeared in the early 1960s and rapidly displaced continuous casting machines. These devices consisted of glass or film disks or strips (one per  ) that spun in front of a light source to selectively expose characters onto light-sensitive paper. Originally they were driven by  . Later they were connected to computer front ends.\n One of the earliest electronic photocomposition systems was introduced by  . The typesetter typed a line of text on a Fairchild keyboard that had no display. To verify correct content of the line it was typed a second time. If the two lines were identical a bell rang and the machine produced a punched paper tape corresponding to the text. With the completion of a block of lines the typesetter fed the corresponding paper tapes into a phototypesetting device that mechanically set type outlines printed on glass sheets into place for exposure onto a negative  . Photosensitive paper was exposed to light through the negative film, resulting in a column of black type on white paper, or a  .  The galley was then cut up and used to create a mechanical drawing or   of a whole page.  A large film negative of the page is shot and used to make   for  .\n The next generation of phototypesetting machines to emerge were those that generated characters on a   display. Typical of the type were the Alphanumeric APS2 (1963),  IBM 2680 (1967),   VideoComp (1973?), Autologic APS5 (1975),  and Linotron 202 (1978).  These machines were the mainstay of phototypesetting for much of the 1970s and 1980s. Such machines could be \"driven online\" by a computer front-end system or took their data from magnetic tape. Type fonts were stored digitally on conventional magnetic disk drives.\n Computers excel at automatically typesetting and correcting documents.  Character-by-character, computer-aided phototypesetting was, in turn, rapidly rendered obsolete in the 1980s by fully digital systems employing a   to   an entire page to a single high-resolution  , now known as imagesetting.\n The first commercially successful laser imagesetter, able to make use of a raster image processor, was the Monotype Lasercomp. ECRM,   (later purchased by  ) and others rapidly followed suit with machines of their own.\n Early  -based typesetting software introduced in the 1970s and early 1980s, such as   Pager, Penta,  , Miles 33, Xyvision,   from  , and IBM's   product with CRT terminals, were better able to drive these electromechanical devices, and used text   to describe   and other page formatting information. The descendants of these text markup languages include  ,   and  .\n The minicomputer systems output columns of text on film for paste-up and eventually produced entire pages and   of 4, 8, 16 or more pages using   software on devices such as the Israeli-made   Dolev. The data stream used by these systems to drive page layout on printers and imagesetters, often proprietary or specific to a manufacturer or device, drove development of generalized printer control languages, such as  '   and  's  .\n Computerized typesetting was so rare that   magazine (comparing itself to \"the proverbial shoemaker's children who went barefoot\") did not use any computers in production until its August 1979 issue used a Compugraphics system for typesetting and page layout. The magazine did not yet accept articles on floppy disks, but hoped to do so \"as matters progress\".  Before the 1980s, practically all typesetting for publishers and advertisers was performed by specialist typesetting companies. These companies performed keyboarding, editing and production of paper or film output, and formed a large component of the graphic arts industry. In the United States, these companies were located in rural Pennsylvania, New England or the Midwest, where labor was cheap and paper was produced nearby, but still within a few hours' travel time of the major publishing centers.\n In 1985, with the new concept of   (for What You See Is What You Get) in text editing and word processing on personal computers,   became available, starting with the  ,   (and later  ) and PostScript and on the PC platform with Xerox Ventura Publisher under DOS as well as Pagemaker under Windows. Improvements in software and hardware, and rapidly lowering costs, popularized desktop publishing and enabled very fine control of typeset results much less expensively than the minicomputer dedicated systems. At the same time, word processing systems, such as  ,   and  , revolutionized office documents. They did not, however, have the typographic ability or flexibility required for complicated book layout, graphics, mathematics, or advanced hyphenation and justification rules ( ).\n By 2000, this industry segment had shrunk because publishers were now capable of integrating typesetting and graphic design on their own in-house computers. Many found the cost of maintaining high standards of typographic design and technical skill made it more economical to outsource to freelancers and graphic design specialists.\n The availability of cheap or free fonts made the conversion to do-it-yourself easier, but also opened up a gap between skilled designers and amateurs. The advent of PostScript, supplemented by the   file format, provided a universal method of proofing designs and layouts, readable on major computers and operating systems.\n QuarkXPress had enjoyed a market share of 95% in the 1990s, but lost its dominance to   from the mid-2000s onward. \n IBM created and inspired a family of typesetting languages with names that were derivatives of the word \"SCRIPT\". Later versions of SCRIPT included advanced features, such as automatic generation of a table of contents and index,   page layout, footnotes, boxes, automatic hyphenation and spelling verification. \n NSCRIPT was a port of SCRIPT to OS and TSO from CP-67/CMS SCRIPT. \n Waterloo Script was created at the University of Waterloo (UW) later.  One version of SCRIPT was created at MIT and the AA/CS at UW took over project development in 1974. The program was first used at UW in 1975. In the 1970s, SCRIPT was the only practical way to word process and format documents using a computer. By the late 1980s, the SCRIPT system had been extended to incorporate various upgrades. \n The initial implementation of SCRIPT at UW was documented in the May 1975 issue of the Computing Centre Newsletter, which noted some the advantages of using SCRIPT:\n The article also pointed out SCRIPT had over 100 commands to assist in formatting documents, though 8 to 10 of these commands were sufficient to complete most formatting jobs.  Thus, SCRIPT had many of the capabilities computer users generally associate with contemporary word processors. \n  was a SCRIPT variant developed at IBM in the 1980s.\n DWScript is a version of SCRIPT for MS-DOS, named after its author, D. D. Williams,  but was never released to the public and only used internally by IBM.\n Script is still available from IBM as part of the   for the   operating system. \n The standard generalized markup language ( ) was based upon IBM   (GML). GML was a set of macros on top of IBM Script.   is an international standard developed to provide a stylesheets for SGML documents.\n  is a successor of SGML.   is most often used to generate PDF files from XML files.\n The arrival of SGML/XML as the document model made other typesetting engines popular.\nSuch engines include Datalogics Pager, Penta, Miles 33's OASYS, Xyvision's  ,  , and  . XSL-FO compatible engines include  ,  , and  's  .\nThese products allow users to program their SGML/XML typesetting process with the help of scripting languages.\n YesLogic's   is another one, which is based on CSS Paged Media.\n During the mid-1970s,  , working at  , wrote the troff typesetting program to drive a Wang C/A/T   owned by the Labs; it was later enhanced by   to support output to different equipment, such as  . While its use has fallen off, it is still included with a number of   and   systems, and has been used to typeset a number of high-profile technical and computer books. Some versions, as well as a   work-alike called  , are now  .\n The   system, developed by   at the end of the 1970s, is another widespread and powerful automated typesetting system that has set high standards, especially for typesetting mathematics.   and LuaLaTeX are variants of TeX and of   scriptable in  .  TeX is considered fairly difficult to learn on its own, and deals more with appearance than structure. The LaTeX macro package, written by   at the beginning of the 1980s, offered a simpler interface and an easier way to systematically encode the structure of a document. LaTeX markup is widely used in academic circles for published papers and books. Although standard TeX does not provide an interface of any sort, there are programs that do. These programs include   and  , which are graphical/interactive editors;  , while being an independent typesetting system, can also aid the preparation of TeX documents through its export capability.\n GNU   (whose name is a combination of TeX and  , although it is independent from both of these programs) is a typesetting system which is at the same time a    .\n  borrows some algorithms from TeX and relies on other libraries such as   and  , with an extensible core engine developed in  . \nBy default, SILE's input documents can be composed in a custom LaTeX-inspired markup (SIL) or in XML. Via the adjunction of 3rd-party modules, composition in   or Djot is also possible. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/I/O_bound", "title": "I/O bound", "content": "In  ,   refers to a condition in which the time it takes to complete a   is determined principally by the period spent waiting for   operations to be completed, which can be juxtaposed with being  . This circumstance arises when the rate at which   is requested is slower than the rate it is consumed or, in other words, more time is spent requesting data than processing it. \n The I/O bound state has been identified as a problem in computing almost since its inception. The  , which is employed by many computing devices, this involves multiple possible solutions such as implementing a logically separate   which along with storing the instructions of the program also retrieves actual data usually from   and makes use of this more accessible data for working. When the process is terminated it writes back the results to the original storage (usually the  ).\n Since data must be moved between the CPU and memory along a   which has a limited  , there exists a condition that is known as the  . Put simply, this means that the data   between the CPU and memory tends to limit the overall speed of computation. In terms of the actual technology that makes up a computer, the Von Neumann Bottleneck predicts that it is easier to make the CPU perform calculations faster than it is to supply it with data at the necessary rate for this to be possible.\n In recent history, the Von Neumann bottleneck has become more apparent. The design philosophy of modern computers is based upon a physically separate CPU and main memory. It is possible to make the CPU run at a high data transfer rate because data is moved between locations inside them across tiny distances. The physical separation between CPU and main memory, however, requires a data bus to move data across\ncomparatively long distances of centimetres or more. The problem of making this part of the system operate sufficiently fast to keep up with the CPU has been a great challenge to designers. \n The I/O bound state is considered undesirable because it means that the   must stall its operation while waiting for data to be loaded or unloaded from   or  . With faster computation speed being the primary goal of new computer designs and components such as the CPU and memory being expensive, there is a strong imperative to avoid I/O bound states and eliminating them can yield a more economic improvement in performance than upgrading the CPU or memory.\n \n Or in simpler terms:\n \n This means that I/O bound processes are slower than non-I/O bound processes, not faster. This is due to increases in the rate of data processing in the core, while the rate at which data is transferred from storage to the processor does not increase with it. As CPU clock speed increases, allowing more instructions to be executed in a given time window, the limiting factor of effective execution is the rate at which instructions can be delivered to the processor from storage, and sent from the processor to their destination. In short, programs naturally shift to being more and more I/O bound. \n Assume we have one CPU-bound process and many I/O-bound processes. As the processes flow around the system, the following scenario may result. The CPU-bound process will get and hold the CPU. During this time, all the other processes will finish their I/O and will move into the ready queue, waiting for the CPU. While the processes wait in the ready queue, the I/O devices are idle. Eventually, the CPU-bound process finishes its CPU burst and moves to an I/O device. All the I/O-bound processes, which have short CPU bursts, execute quickly and move back to the I/O queues. At this point, the CPU sits idle. The CPU-bound process will then move back to the ready queue and be allocated the CPU. Again, all the I/O processes end up waiting in the ready queue until the CPU-bound process is done. There is a   as all the other processes wait for the one big process to get off the CPU. This effect results in lower CPU and device utilization than might be possible if the shorter processes were allowed to go first. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Puffer_(research_study)", "title": "Puffer (research study)", "content": "\n  is a free and open-source live TV research study operated by   to improve video streaming algorithms. The study allows users across the United States to watch seven   stations broadcasting in the   for free. \n Puffer was launched on January 18, 2019. It was initially led by Francis Yan, a Stanford computer science doctoral student, with Hudson Ayers and Sadjad Fouladi from Stanford, and Chenzhi Zhu from  . The project's facility advisors are professors   and  .  The research study uses machine learning to improve video-streaming algorithms, such as those commonly used by services like  ,  , and  . The goal is to teach a computer to design new algorithms that reduce glitches and stalls in streaming video (especially over wireless networks and those with limited capacities, such as in rural areas), improve picture quality, and predict how the capacity of an Internet connection will change over time. \n The service is limited. Only those in the U.S. can sign up, and only up to 500 users can watch Puffer at a time. In addition, the service only re-transmits free   channels in the    , specifically the following ones picked up by an antenna located on the Stanford campus:   2 ( ),   5 ( ),   7 ( ),   9 ( ),   11 ( ),   54 ( ) (July 21, 2023 – August 1, 2023),  44 ( ) (returned August 4, 2023), and   14 ( ).    4 ( / ) was added in March 2024 after KPYX (then KBCW) changed its CW affiliate status.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/British_Computer_Society", "title": "British Computer Society", "content": "\n\n The   ( ), branded  , since 2009, is a   and a   that represents those working in   (IT),  ,  ,   and  , both in the   and internationally. Founded in 1957, BCS has played an important role in educating and nurturing IT professionals, computer scientists, software engineers, computer engineers, upholding the profession, accrediting   (CITP) and   (CEng) status, and creating a global community active in promoting and furthering the field and practice of computing.\n With a worldwide membership of 57,625 members as of 2021,  BCS is a registered   and was incorporated by   in 1984. Its objectives are to promote the study and application of communications technology and computing technology and to advance knowledge of education in ICT for the benefit of professional practitioners and the general public. \n BCS is a member institution of the  , through which it is licensed to award the designation of   and   and therefore is responsible for the regulation of ICT and computer science fields within the UK. The BCS is also a member of the  , the   for international tertiary degree recognition, and the European Quality Assurance Network for Informatics Education  . BCS was previously a member organisation of the  , through which it was licensed to award the designation of  .\n BCS has an office in London. The main administrative offices are in  ,  , west of London. It also has two overseas offices in   and  .\n Members are sent the quarterly IT professional magazine   (formerly  ).\n BCS is a member organisation of the Federation of Enterprise Architecture Professional Organizations (FEAPO), a worldwide association of professional organisations which have come together to provide a forum to standardise, professionalise, and otherwise advance the discipline of  .\n The forerunner of BCS was the \"London Computer Group\" (LCG), founded in 1956. BCS was formed a year later from the merger of the LCG and an unincorporated association of scientists into an unincorporated club. In October 1957, BCS was incorporated, by  , as \"The British Computer Society Ltd\": the first President of BCS was Sir   (1913–2010),  .\n In 1966, the BCS was granted charitable status and in 1970, the BCS was given   including the shield and crest.\nThe major ethical responsibilities of BCS are emphasised by the leopard's face, surmounting the whole crest and depicting eternal vigilance over the integrity of the Society and its members.\n The BCS patron is  ,  . He became patron in December 1976 and has been actively involved in BCS activities, particularly having been President in the   Year in 1982–1983.\n On 21 September 2009, the British Computer Society went through a transformation and re-branded itself as \"BCS, The Chartered Institute for IT\".  In 2010, an   was called to discuss the direction of the BCS.  The debate has been covered by the computing press. \n BCS is governed by a   Board comprising the President, the Deputy President, the immediate past President, up to nine Vice Presidents (including Vice-President Finance), and five Professional Members elected by the Advisory Council.  Sir  , Professor of Computer Science at Cambridge University, served as its first president. Each president serves for a 2-year term. A   can be found on the BCS website. \n The BCS Advisory Council elects the Honorary Officers – the President, the Deputy President and up to nine Vice-Presidents, together with the immediate past President and five members of Council.  Lists of Trust Board and Advisory Council members are maintained online. \n The Advisory Council provides advice to the Trustee Board on the direction and operation of BCS; in particular, it is consulted on strategic plans and the annual budget. The Council is a representative body of the membership, with members elected directly by the professional membership, and by the Branches, Groups and Forums. \n The   title is conferred on individuals to recognise their outstanding achievements and contributions to Information Technology (engineering, product management, business leadership, etc). Fellows are expected to give something back to the profession, by promoting and evangelising the profession to the\npublic and society, and contributing to debates in conferences, panels, meetings, etc. \nFellows are nominated to the society each year and have to be supported by one or more existing fellows. Criteria  for election to fellow include:\n \ninclude distinguished individuals from industries and universities. Some of the prominent fellows include:\n The society also awards Honorary Fellowships. Examples include:\n Since July 2021, Fellows are eligible to be appointed to the Fellows Technical Advisory Group (F-TAG).  F-TAG provides technical thought leadership governance for BCS, informing policy positions   and content.\n The BCS is the only professional body in the United Kingdom with the ability to grant chartered status to IT professionals under its  , granted to them by the  .  Thus having the ability to grant   status to both its   and Professional members. Known as  , they are entitled to use the    . The BCS keeps a register of current Chartered Members and Fellows. \n Other Professional membership bodies apply to the BCS for a licence that enables them to award CITP to their eligible members.\n BCS has different grades of membership:\n Members are encouraged to display the designatory letters to which they are entitled whenever appropriate. The order of designatory (post-nominal) letters is complex and open to a certain amount of interpretation. The accepted authority on this subject is  . Normally these should appear after decorations, degrees and chartered letters. Members holding CEng should also display the designatory letters of the institution through which they are registered immediately after the CEng. Conventionally, members holding Chartered status ( ) display this immediately after their membership letters (e.g., FBCS CITP or MBCS CITP). However, as CITP may now be awarded by other organisations it may also be displayed separately, following that of the awarding institution.\n The society provides several awards to recognise outstanding computer scientists, engineers, experienced and young IT professionals.\nThe awards include:\n BCS provides a range of qualifications both for users of computers and for   professionals.\n BCS offers qualifications that cover all areas of IT, including understanding Spreadsheets and Presentation Software, Animation, Video Editing and Social Networking safety. \n The current IT user qualifications are:\n BCS conducts its own BCS Higher Education Qualifications  in many countries. It was formerly known as BCS Professional Examinations which consisted of Parts 1 and 2 of which passing of Part 2 with the professional project was equivalent to a British honours degree. These programs had an early history of success, with participants coming from all parts of the world, including Asia. Many private computing schools outside the UK have hosted students in preparation for BCS Part 1 and 2 examinations. The level of current qualifications are:\n e-type is a qualification that allows individuals to improve and certify their typing skills. The average user can save up to 21 days a year by improving their typing speed as well as preventing repetitive strain injury (RSI). e-type comes with full support materials and computer-based courseware before allowing the user to assess their skills using a simple online test. \n Digital Creator is a set of engaging qualifications that teach digital media skills through creative projects. They are designed for all types and ages of learners – in schools from Key Stage 2 to Key Stage 4 and in all areas of adult learning.\n The BCS ITQ is a range of IT user qualifications made up of a combination of units available on the ITQ framework.\n The framework consists of a wide range of units covering all aspects of IT user applications, including word processing, spreadsheets, the internet, multimedia software and design software.\n BCS also offers professional qualifications via its Professional Certifications board, formerly known as ISEB ( ).\n Professional Certifications (ISEB) provides a wide range of qualifications for IT professionals covering major areas including Management, Development, Service Delivery and Quality. \n BCS via FEDIP \nprovides 4 different professional registration levels for health and care informatics professionals:\nPractitioner, Senior Practitioner, Advanced Practitioner, Leading Practitioner.\n FEDIPAdvPra – post-nominals for Advanced Practitioner.\n FEDIP is the Federation for Informatics Professionals in Health and Social Care, a collaboration between the leading professional bodies in health and care informatics supporting the development of the informatics profession.\n The e-Citizen qualification allows beginners to get online and start using the Internet. The qualification has been designed to provide a basic understanding of the Internet and to start using the web safely, from reading email to shopping online. \n M_o_R Foundation is suitable for any organisation or individual seeing the need for guidance on a controlled approach to identification, assessment and control risk at strategic, programme, project and operational perspectives.\n In common with many professional institutions, BCS has a number of regional branches and specialist groups.  Currently, there are 45 regional branches in the UK, 16 international sections and over 50 specialist groups.\n The UK branches are: \n In September 2010, BCS sponsored the one-off 'Digital Revolutions Film Workshop' for amateurs and professionals to \"hone their skills\", and in October 2010, in conjunction with  , sponsored the 'Digital Revolutions Film Competition'. \n BCS magazines include:\n Their journals are mostly published by   and include:\n  (eWiC) is a series for conference and workshop proceedings, published by the BCS, also available open access via  .\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Changelog", "title": "Changelog", "content": "A   (also spelled  ) is a log or record of all notable changes made to a project.  The project is often a   or software project, and the changelog usually includes records of changes such as bug fixes, new features, etc.  Some   projects include a changelog as one of the top-level files in their distribution.\n A changelog has historically included all changes made to a project.  The \"Keep a Changelog\" site instead advocates that a changelog   include   changes, but that it should instead contain \"a curated, chronologically ordered list of notable changes for each version of a project\" and should not be a \"dump\" of a git log \"because this helps nobody\". \n Although the   ( ) canonical naming convention for the file is  ,  it is sometimes alternatively named as   or   (  is usually a different file reflecting changes between releases, not between the commits).  Another convention is to call it a  .  Some   will append a   suffix to the file name if the changelog is  , a   suffix if it is in  , or a   suffix if it is in  .\n Some   systems are able to generate the relevant information for a changelog, if the goal is to include all changes. \n Changelog files are organized by paragraphs, which define a unique change within a function or file.\nThe GNU Coding standards recommend the following format: \n Between the date and the name, and again between the name and the email address, there are two spaces each. It is common to enclose the email address in < and >. The   creates such entries when creating additional changelog entries.\n Most   software includes   as a fundamental feature (often called   in this context). For example, the \"View history\" link at the top  of a   entry links to that page's changelog. This feature is vital for complying with the attribution requirements of some copyright licenses. \n A product changelog can keep customers in the loop about what's new. It helps to announce new features, latest releases, and relevant news directly in-app. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Wang_Laboratories", "title": "Wang Laboratories", "content": ", was an American computer company founded in 1951 by   and G. Y. Chu.  The company was successively headquartered in   (1954–1963),   (1963–1976), and finally in   (1976–1997). At its peak in the 1980s, Wang Laboratories had annual revenues of  3 billion and employed over 33,000 people. It was one of the leading companies during the time of the  . \n The company was directed by An Wang, who was described as an \"indispensable leader\" and played a personal role in setting business and product strategy until his death in 1990. The company went through transitions between different product lines,  beginning with typesetters, calculators, and word processors, then adding computers, copiers, and laser printers. \n Wang Laboratories filed for bankruptcy protection in August 1992.  After emerging from bankruptcy, the company changed its name to  . It was acquired by   of the Netherlands in 1999, becoming Getronics North America, then was sold to   in 2007 and   in 2008.\n Wang went public on August 26, 1967, with the issuance of 240,000 shares at $12.50 per share on the  . The stock closed the day above $40, valuing the company's equity at approximately $77 million, of which An Wang and his family owned about 63%. \n An Wang took steps to ensure that the Wang family would retain control of the company even after going public. He created a second class of stock, class B, with higher dividends but only one-tenth the voting power of class C. The public mostly bought class B shares; the Wang family retained most of the class C shares.  The letters B and C were used to ensure that brokerages would fill any Wang stock orders with class B shares unless class C was specifically requested. Wang stock had been listed on the  , but this maneuver was not quite acceptable under NYSE's rules, and Wang was forced to delist with NYSE and relist on the more liberal  .  After Wang's 1992 bankruptcy, holders of class B and C common stock were treated the same. \n The company's first major project was the Linasec  in 1964, an electronic special-purpose computer designed to justify paper tape for use on automated  . It was developed under contract to   manufacturer  , which retained the manufacturing rights of the Linasec. The success of the machine led Compugraphic to decide to manufacture it themselves, causing Wang to lose out on a million dollars in revenue. \n The   (Logarithmic Computing Instrument) desktop calculator  (the earlier   in September 1964 was not a real product) was introduced in January 1965. Using  , it was the first   capable of computing  , which was quite an achievement for a machine without any  .  The electronics included 1,275 discrete  . It performed multiplication by adding logarithms, and roundoff in the display conversion was noticeable: 2 × 2 yielded 3.999999999.\n From 1965 to about 1971, Wang was a well-regarded calculator company. The dollar price of Wang calculators  was in the mid-four-figures.  They used   readouts, performed  , had varying degrees of  , and used  . The 200 and 300 calculator models were available as time-shared simultaneous (SE) packages that  had a central processing unit the size of a small suitcase connected by cables leading to four individual desktop display/keyboard units. Competition included  , which introduced the   in 1968, and old-line calculator companies such as   and  .\n Wang calculators were at first sold to scientists and engineers, but the company later became established in financial services industries, which had relied on complicated printed tables for mortgages and annuities.\n In 1971, Wang believed that calculators would become unprofitable low-margin   and decided to leave the calculator business within a few years. \n Wang's first attempt at a   was the Wang 1200, announced in late 1971  but not available until 1972.  The design consisted of the logic of a Wang 500 calculator hooked up to an OEM-manufactured   typewriter for keying and printing, and dual cassette decks for storage.  , who had written the   for the Wang 700 and its derivative the Wang 500 rewrote the microcode to perform word processing functions instead of numerical calculations.\n The operator of a Wang 1200 typed text on a conventional IBM Selectric keyboard; when the Return key was pressed, the line of text was stored on a cassette tape. One cassette held roughly 20 pages of text and could be \"played back\" (e.g., the text retrieved) by printing the contents on   in the 1200 typewriter's \"print\" mode. The stored text could also be edited using keys on a simple, six-key array. Basic editing functions included Insert, Delete, Skip (character, line), and so on.\n The labor and cost savings of this device were immediate and remarkable: pages of text no longer had to be retyped to correct simple errors, and projects could be worked on, stored, and then retrieved for use later on. The rudimentary Wang 1200 machine was the precursor of the Wang Office Information System (OIS), which revolutionized the way typing projects were performed in the American workplace.\n Following the Wang 1200, Harold Koplow and David Moros made another attempt at designing a word processor. They started by first writing the user's manual for the product.  A 2002   article refers to Koplow as a \"wisecracking rebel\" who \"was waiting for dismissal when, in 1975, he developed the product that made computers popularly accessible.\"\n In Koplow's words, \"Dr. Wang kicked me out of marketing. I, along with Dave Moros, was relegated to Long Range Planning – 'LRPed'. This ... was tantamount to being fired: 'here is a temporary job until you find another one in some other company.'\"\n Although he and Moros perceived the assignment to design a word processing machine as busywork, they went ahead anyway. They wrote the manual and convinced An Wang to turn it into a real project.  The word processing machine – the Wang 1200 WPS – was introduced in June 1976 and was an instant success, as was its successor, the 1977 Wang OIS  (Office Information System).\n The OIS was a multi-user system. Each workstation looked like a typical   but contained its own   microprocessor (later versions used a  ) and 64 KB of RAM (less than the original 1981  ).   was centralized in a master unit and shared by the workstations, and the connection was via high-speed dual   \"928 Link\". \n Ahead of   and  , Wang captured the lead for \"the 'intelligent' printer: a high-speed office copier that can be linked electronically\" to PCs \"and other automated equipment\".  A year later,   described the     as \"closer to the standard envisioned\". \n Wang's first computer, the Wang 3300, was an 8-bit integrated circuit general-purpose minicomputer designed to be the central processor for a multi-terminal  . Byte-oriented, it also provided a number of double-byte operand memory commands. Core memory ranged from 4,096 to 65,536 bytes in 4,096-byte increments. \n Development began after hiring Rick Bensene in June 1968.   The product was announced in February 1969  and shipped to its first customer on March 29, 1971. \n Wang developed and marketed several lines of small computer systems for both word processing and data processing. Instead of a clear, linear progression, the product lines overlapped and, in some cases, borrowed technology from each other.\n The most identifiable Wang   performing recognizable data processing was the  , which appeared in May 1973. Unlike some other   such as the  , it had a   in a cabinet that also included an integrated computer-controlled   storage unit and keyboard. It was microcoded to run    . It was widely used in small- and medium-sized businesses worldwide; about 65,000 systems were shipped.\n The original 2200 was a single-user system. The improved VP model increased performance more than tenfold and enhanced the language (renamed  ). The 2200 VP evolved into a desktop computer and larger MVP system to support up to 16 workstations and utilized commercial disk technologies that appeared in the late 1970s and early 1980s. The disk subsystems could be attached to up to 15 computers giving a theoretical upper limit of 240 workstations in a single  .\n Unlike the other product lines, such as the VS and OIS (described below), Wang used   (VARs) to customize and market 2200 systems. One such creative solution deployed dozens of 2200 systems and was developed in conjunction with  - and  –based firm  . It provided   (beeper) services for much of the Hong Kong market in the early 1980s. \n Overshadowed by the Wang VS, the 2200 languished as a cost-effective but forgotten solution in the hands of the customers who had it. In the late 1980s, Wang revisited the 2200 series one last time, offering 2200 customers a new 2200 CS with bundled maintenance for less than customers were paying at the time just for maintenance of their aging 2200s. The 2200 CS had an  , updated disk units, and other peripherals. Most 2200 customers upgraded to the 2200 CS, after which Wang did not develop or market any new 2200 products. In 1997, Wang reported having about two hundred 2200 systems still under maintenance around the world. Throughout, Wang had always offered maintenance services for the 2200.\n The 2200 BASIC-2 language was ported to be compiled and run on non-Wang hardware and   by at least two companies. Niakwa Inc  created a product named NPL (originally named Basic-2C). Kerridge Computer,  now a part of  , created a product named KCML. Both products support  ,  , and various   systems. The BASIC-2 language was enhanced and extended by both companies to meet modern needs. Compared to the 2200 Wang hardware, the compiled solutions improved speed, disk space, memory, and user limits by tens to hundreds of times; although there is no Wang support for the 2200, many software applications continue to function.\n During the 1970s, about 2,000 Wang 2200T computers were shipped to the  . Due to the   in the 1980s, US and   export restrictions ended the shipment of Wang computers. The Soviets were in great need of computers. In 1981, Russian engineers at  's   factory in     the Wang 2200T and created a computer they named the  . The \"COCOM restrictions\" theory, though, while popular in the West, is challenged by some Russian computer historians on the basis that development for the Iskra-226 started in 1978, two years before the Afghan war. It is also different from the Wang 2200 in its internals, being more inspired by it rather than a direct clone.\n It used the same BASIC language (named T-BASIC) with a few enhancements.  Many research papers reference calculations done on the Iskra 226. The machine's designers were nominated for a 1985 State Prize.  Later, a somewhat scaled-down   implementation was created for Iskra-226, which was used in the  .\n Wang had a line called Alliance, which was based on the high-end OIS (140/145) hardware architecture. It had more powerful software than the OIS word processing and list processing packages. The system was  , leading to global deployment in American embassies after the Iran hostage crisis.  The Z80 platform on which Alliance ran forced it to remain as an   application in a 64 KB workstation.\n The first   computer was introduced in 1977, the same year as  's  ;  both continued for decades.  The VS   was compatible with the   series, but it did not run any System/360 system software.\n The VS operating system and all system software were built from the ground up to support interactive users as well as batch operations. The VS was aimed at the business data processing market in general and IBM in particular. While many programming languages were available, the VS was programmed in  . Other languages supported in the VS   included  , COBOL 74, COBOL 85, BASIC,  ,  , C,  ,  , Glossary, MABASIC, SPEED II, and Procedure (a scripting language).   was also supported for I/O co-processor development. The Wang PACE (Professional Application Creation Environment)   and database was used from the mid-1980s onward by customers and third-party developers to build complex applications, sometimes involving many thousands of screens, hundreds of distinct application modules, and serving many hundreds of users. Substantial   were developed for the Wang VS by third-party software houses throughout the 1980s in COBOL, PACE, BASIC, PL/I, and RPG II. The   family of applications and Wang WP were both popular applications on the VS. Word Processing ran on the VS through services that emulated the OIS environment and downloaded the WP software as \"microcode\" (in Wang terminology) to VS workstations.\n The press and the industry referred to the class of machines made by Wang, including the VS, as \"minicomputers,\"  and Kenney's 1992 book refers to the VS line as \"minicomputers\" throughout.  Although some argue that the high-end VS machines and their successors should qualify as  , Wang avoided this term. In his autobiography, An Wang, rather than calling the VS 300 a mainframe, said that it \"verges on mainframe performance.\"  He went on to draw the distinction between the \"mainframes\" at the high end of IBM's line (\"just as Detroit would rather sell large cars ... so IBM would rather sell mainframes\")—in which IBM had a virtual monopoly—with the \"mid-sized systems\" in which IBM had not achieved dominance: \"The minicomputer market is still healthy. This is good for the customer and good for minicomputer makers.\"  \n An Wang felt a personal sense of rivalry with IBM, partly due to heavy-handed treatment by IBM in 1955 to 1956 over the rights to his magnetic-core patents (this encounter formed the subject of a long chapter in Wang's own book,  ). According to Charles C. Kenney, \"  remembers being in Wang's office one day when the Doctor pulled out a chart on which he had plotted Wang's growth and projected that Wang Laboratories would overtake IBM sometime in the middle of the 1990s. 'He had kept it a long time,' says Connors. 'And he   it.'\"\n Wang was one of the first computer companies to advertise on television and the first to run an ad during the   in 1978. Their first ad literally cast Wang Laboratories as David and IBM as Goliath, several years before the famous 1984 Apple Computer ad.  A later ad depicted Wang Laboratories as a helicopter gunship taking aim at IBM. \n Wang wanted to compete against IBM as a computer company, selling to   departments. The calculators, word processing systems, and OIS were sold into individual departments, bypassing the corporate data-processing decision-makers. The chapter in Wang's book dealing with them shows that he saw them as \"a beachhead in the Fortune 1000.\" The Wang VS was Wang's entry into IT departments. In his book, An Wang notes that, to sell the VS, \"we aggressively recruited salesmen with strong backgrounds in   ... who had experience dealing with MIS executives, and who knew their way around   companies.\" As the VS took hold, the word processor and OIS lines were phased out. The word processing software continued, in the form of a loadable-  environment that allowed VS workstations to take on the behavior of traditional Wang WP terminals to operate with the VS and use it as a  .\n Wang made inroads into IBM and DEC markets in the 1980s, but did not have a serious impact on IBM's mainframe market due to self-limiting factors. Even though An Wang wanted to compete with IBM, too many Wang salespeople weren't trained enough on the DP capabilities of the VS. In many instances, the VS ran smaller enterprises up to about   and, in larger organizations, found use as a gateway to larger corporate mainframes, handling workstation pass-through and massive print services.\n At  , for instance, thirteen 1985 top-of-the-line   at the Houston headquarters were used in the 1980s and into the 1990s to receive mainframe reports and make them viewable online by executives.\n At  , 18 VS systems from the smallest to the largest were used as the enterprise mortgage origination, servicing, finance, documentation, hedge system and mainframe gateway services (for login and printing). Between Mellon Mortgage and parent Mellon Bank, their network contained 45 VS systems and the Bank portion of the network supported about 16,000 Wang Office users for email, report distribution, and scheduling.\n At Kent and KTec Electronics,  two related Houston companies, separate VS clusters were the enterprise systems, handling distribution, manufacturing, and accounting, with significant EDI capability for receiving customer forecasts, sending invoices, sending purchase orders, and receiving shipping notifications. Both systems ran the GEISCO EDI package. Kent, which grew to  , ran the Arcus distribution software in COBOL and KTec, which grew to  , ran the   MRP system for manufacturing in BASIC.\n In the late 1980s, a British television documentary accused the company of targeting a competitor, Canadian company  , in an attempt to take it out of the market. However, the documentary came to no conclusion regarding this.\n Wang's approach was called \"The Gas Cooker Program,\" named after similar programs to give discounts on new gas stoves by trading in an old one. Wang was accused of targeting Wordplex by offering a large discount on Wang OIS systems with a trade-in of Wordplex machines, regardless of the age or condition of the trade-in machine.\n Based on its good reputation with users and its program of aggressive discounts, Wang gained an increasing share of a shrinking market. Wordplex was taken over by  .\n The market for standalone word processing systems collapsed with the introduction of the personal computer.  , on the IBM PC, and MS-DOS PC clones, replicated the keyboard and screen interface and functions of the Wang word processor, and was actively marketed to Wang corporate users, while several other   also became popular.\n Wang did make one last play in this arena, producing a dedicated Intel-based word processor called the Wang Office Assistant in 1984. This was marketed and sold successfully in the UK to a specific few office equipment dealers who were able to upgrade their clients from electronic typewriters to the Office Assistant. They proved to be very reliable and fast when connected to the Wang bi-directional printer, providing cheap but very fast word processing to small companies (such as  ). The USA was surprised at the success of this machine in the UK, but could not supply a spell-check programme in time before the PC. The PC, with its flexibility of combining word processors with other programs such as spreadsheets, had rendered such a specific-task machine unsellable. The Wang Office Assistant had a short life span of four years.\n The   was one of the first integrated   and   systems. In the United Kingdom, it was selected for the     pilot schemes at the   in about 1980.\n Wang, which had added DVX Message Waiting in 1984,  named their 1989 announcement DVX II. \n Internal research on speech recognition was carried out and implemented for discrete word recognition but was never released to the field. At one point there were 50 members of the Voice Engineering Department.\n Lawrence E. Bergeron was instrumental in managing the Voice Engineering Department at Wang Labs.  He promoted the purchase of a VAX-11/780 for 'real-time' signal processing research and created the Peripheral Signal Processor board (PSP). The PSP was placed into 16 racks to handle 128 phone lines for the DVX (Digital Voice Exchange). Wang's Digital Voice Exchange supported the renting of voice mailboxes.  Voice prompts were created by a hired voice specialist to give a melodic presentation for the DVX. To avoid false triggering of touch-tones by the prompts (due to input/output cross talk), notch filters were created to remove the touch tone frequencies from the prompts. Prompt languages supported included German, Spanish, French, British English, American English, and Portuguese.\n Despite the release of the 2200 PCS (Personal Computer System) and 2200 PCS-II models in 1976, the history of computing regards the earliest PC as one which contained a  , which the 2200 PCS did not. However, the self-contained PCS-II  incorporated many of the innovations that would later be seen in PCs, including the first 5.25-inch floppy drives that were designed for the PCS-II by  . \n The original Wang PC was released in April 1982 to counter the IBM PC, which had been released the previous August and which had gained wide acceptance in the market for which Wang traditionally positioned the OIS system. It was based on the   microprocessor, a faster CPU than the IBM PC's 8088.  A hardware/software package that permitted the Wang PC to act as a terminal to the OIS and VS products was available. The first version of the hardware component was made of two large add-in boards called the WLOC (Wang Local Office Connection). It contained a Z-80 processor and 64 KB of memory. The original PC-VS hardware used the 928 terminal emulator board; the WLOC boards were used in the subsequent 80286 machines.\n These PCs later formed the basis for the system console on VS7000 and later series of the Wang mid-frame series, being used for the initialisation of the boot process. One of the distinguishing features of the Wang PC was the system software. Similar to the Wang VS minicomputer, the command line was not evident. Everything could be run from menus, including formatting a disk. Furthermore, each item on a menu could be explained by hitting a   on the keyboard. This software was later sold in MS-DOS-compatible form for non-Wang hardware. The Wang word processing software was also very graphical. The keyboard had 16 function-keys and, unlike   (the popular word processor of the day), control key combinations were not required to navigate the system. The F-keys had the word processing functions labeled on them. \n Despite being a compliant MS-DOS system, it was not   with the IBM PC at the hardware level, because MS-DOS was used as a simple program loader. Complex software (spreadsheets, Flight Simulator, etc.) could obtain acceptable performance by direct manipulation of the hardware. Wang used a 16-bit data bus instead of the 8-bit data bus used by IBM, arguing that applications would run much faster since most operations required I/O (disk, screen, keyboard, printer). With this 16-bit design, Wang used peripheral hardware devices, such as the Wang PC display adapter, that were not compatible with their counterparts in the IBM PC line. This meant that the vast library of software available for the IBM PC could not be directly run on the Wang PC. Only those programs that were either written for the Wang PC or ported from the IBM PC were available.   and   were also available. This lack of application software led to the original Wang PC's end, and it was replaced by an Intel 80286-based product that was   with the IBM PC. The unique system software was available at extra cost.\n Most Wang PCs were released with a monochrome graphics adapter that supported a single video mode with text and graphics planes that could be scrolled independently. A color graphics adapter and Wang-branded color monitor were also available.\n An ergonomic feature of the Wang PC was the monitor arm that clamped to the desk and held the monitor above and a system clamp that attached to the side of the desk and held the rather large computer box. By using these, there was nothing on the desktop except the keyboard.\n Wang released an emulation board for Wang PC that enabled operation of many PC-compatible software packages. The board accomplished this by monitoring all I/O and memory transactions (visible in those days before  /  bridge chips to any board plugged into a slot on the expansion bus) and generating a   (NMI) whenever an operation was deemed to involve an incompatible device, requiring emulation.\n For example, the floppy controller circuitry on the Wang PC was similar to that of the IBM PC but involved enough design differences that PC-compatible software attempting to manipulate it directly would fail. Wang's PC emulation hardware would detect I/O and memory operations involving the addresses associated with the floppy controller in the IBM PC and generate an NMI. The NMI handler would be activated (the exception vector having been appropriated during system init to point to ROM routines on the emulation board instead of the NMI routine in the PC BIOS) and would then update an internal representation of the IBM PC floppy controller and manipulate the real controller to reflect its state. Reads were satisfied in a similar way, by forcing an NMI, decoding the machine code indicated by the instruction pointer at the time of the fault, and then obtaining the desired info and updating the CPU registers accordingly before resuming the executing program.\n IBM PC-emulation on the 8086-based Wang PC was working well when IBM released their 80286-based PC-AT, so Wang made the 80286-based   (Advanced Professional Computer).\n Further iterations of the PC line were released commencing with the model number PC-240. They booted into MS-DOS or another compatible operating system, and supported  -standard expansion cards.\n This PC-240 was still not IBM PC-standard, as the keyboard, although a standard PC/AT device, supported VS-compatibility with 24 function keys rather than the normal 12, and had a number of Wang VS-specific keys. There was also a slight difference in CPU interrupts from IBM standard, so some software had compatibility issues.\n VS connectivity was via an ISA-based VS-terminal card, or via LightSpeed, the networked VS Terminal Emulator, over an  -based Ethernet connection. The PC-240 came with a Wang-specific   and compatible screen, which also acted as a keyboard extension, so that the base unit could be kept some distance from the screen. This was later replaced with an   card and screen.\n Around 1991, Wang released the PC350-16 and PC350-40, which were Intel  -based, clocked at 16 MHz and 40 MHz. They used the same VS-compatible keyboard as the PC-240, had a maximum of 4 megabytes of RAM, and came with VGA screens as standard. They were supplied by Microsoft with MS-DOS and Windows 3.0.\n The 350-16 had a bug where the machine would freeze and not boot up if power-cycled at the mains. Although it would power on, the BIOS would not start. The solution was to turn on the machine at the mains and hold down the power button for 30 seconds, at which point it would start. It was suggested  that this was due to an under-valued capacitor in the power circuit. This problem appeared to be resolved in the 350–40, which had a different  .\n In 1992, Wang marketed a PC-compatible based on the Intel   processor, which they called the Alliance 750CD. It was clocked at 25 MHz and had a socket for an   math coprocessor. It came with 2 megabytes of installed RAM, and was expandable to 16 megabytes using   memory cards. It had a 1.44 megabyte floppy disk drive, an internal 80 megabyte hard disk, and a CD-ROM drive. Five expansion slots were built-in. It came with MS-DOS and Windows 3.1 operating systems.\n In 1994, Wang released the slimline Alliance 750CD   based PC in the United Kingdom. These machines used standard PC/AT keyboards and were IBM compatible, shipping with MSDOS 5.0 and Windows 3.11 as standard. System   and the   were maintained by four standard   instead of a specialty battery pack or  . While offered with a 33 MHz  , the 750CD could be upgraded to later   processors such as the   through the use of third party CPU upgrade adapters or  . This allowed upgrading to speeds beyond 50 MHz without  , or more than 100 MHz with overclocking, dependent on the processor used.\n  was a 1988  product consisting of:\n The pricing of the low-end product at   precluded the important features such as \"facsimile and voice options\" (priced at  ).   was not a success in anything except marketing terms. A description of the system at the   (USC) shows the symptoms of the failure:\n \n25 of the stations were Freestyle stations. The Freestyle was only affordable for highly specialized or very senior staff in Wang Laboratories. It was sold as a C-Level  tool for C grades to communicate with other C Grades. This reduced the marketplace immediately from the mass market, where the system would have been effective. Wang Labs was one of a large number  of New England–based computer companies that faltered in the late 1980s and 1990s, marking the end of the  . For instance, the struggling   also downsized in the 1990s and was acquired by  . \n A common view within the PC community is that Wang Labs failed because it specialized in computers designed specifically for   and did not foresee and could not compete with general-purpose   with word-processing software in the 1980s. Word processing was not actually the mainstay of Wang's business by the time desktop computers began to gain in popularity. Although Wang manufactured desktops, its main business by the 1980s was its VS line of minicomputer and \"midframe\" systems. The market for these minicomputers was conquered by enhanced microcomputers like the   and the   PC and  ,  , and   servers.\n An Wang's insistence that his sons,   and Courtney, would succeed him contributed to the company's failure.  Fred Wang was a business school graduate, \"but by almost any definition\", wrote Charles C. Kenney, \"unsuited for the job in which his father had placed him.\"  His assignment, first as head of research and development, then as president of the company, led to resignations by key R&D and business personnel. Amid declining revenues, John F. Cunningham, an 18-year employee of the firm, resigned as president and   of Wang Labs to become chairman and chief executive of Computer Consoles Inc. Cunningham resigned due to disagreement with An Wang on how to pull the company out of the slump, as well as being upset that Fred Wang was positioned,  , as An Wang's successor. \n One turning point occurred when Fred Wang was head of R&D. On October 4, 1983, Wang Laboratories announced fourteen major hardware and software products and promised dates of delivery. The announcement was well received, but even at the time, there were warning signs. According to  , Wang announced \" . And if you could attach the kitchen sink to a personal computer, they would announce that too.\"  Very few of the products were close to completion, and many of them had not even been started. All were delivered late, if at all. In retrospect, this was referred to as the \"  announcement,\" and it hurt the credibility of Fred Wang and Wang Laboratories. \n In 1986, Fred Wang, then 36 years old, was installed as president and chief operating officer of Wang Laboratories. However, the company's fortunes continued to decline, although Charles Kenney \"did not lay the failure at Fred's feet, but his father's, saying his father leaned too hard on family considering the sophistication of the company\", as the market underwent great upheaval where minicomputers gave way to microcomputers.  Unlike most computer companies that funded their growth by issuing stock, An Wang had used debt to avoid further dilution of family control of the company. By August 1989, that debt was causing conflicts with its creditors. On August 4, 1989, An Wang requested Fred's resignation, although Fred remained a member of the board of directors. Harry H.S. Chou, a vice chairman and director of the international computer maker, became acting president and served in that role until  , who had been with the company since 1988, was named president of Wang Laboratories.  Fred went on to attend the   at Harvard, planning a new career in public service. While Courtney, An Wang's younger son, still remained with the company and had ambitions to eventually take over, he was only \"a 33-year-old branch manager in the Dallas office and hardly a major player\", plus Miller's contract \"stipulated that he would never be subordinate to anyone at Wang Labs other than Dr. Wang.\". \n Miller announced in December 1989 that the company would start to embrace established software standards rather than use traditional proprietary designs. An Wang died in March 1990, and Miller took on the additional posts of chairman and  . The company underwent massive restructuring and layoffs and eliminated its bank debt in August 1990, but it still ended the year with a record net loss. \n In November 1990, Wang announced their first personal computers running  . In 1987, Wang developed a new typesetting system in conjunction with Arlington, MA–based Texet Corp. The system used Xerox printers and UNIX workstations from Sun, but the product vanished before coming to market, because few Wang employees could use or support UNIX. UNIX ran on the VS – Interactive Systems first ported IN/ix (their IBM 360 version of SYS5 UNIX) to run in a VSOS Virtual machine circa 1985, and then Wang engineers completed the port so that it ran \"native\" on the VS hardware soon thereafter – but performance was always sub-par as UNIX was never a good fit for the batch-mode nature of the VS hardware, and the line-at-a-time processing approach taken by the VS workstations; indeed, the workstation code had to be rewritten to bundle up each keystroke into a frame to be sent back to the host when running UNIX so that \"tty\" style processing could be implemented. PACE, which offered its  , excellent  , and speedy application development, was in the process of being ported to UNIX under the name OPEN Pace. A client-server RDBMS model built on the original product's ideology, OPEN Pace was demonstrated at the North American PACE User Group Conferences in both Boston and Chicago. OPEN Pace, along with a new Windows-based word processor called UpWord (which was at the time considered a strong contender to retake Wang's original market leadership from Microsoft), were touted as their new direction. However, after a marketing study  suggested that it would require large capital investments in order to be viable competitors against Microsoft, both products were  abandoned.\n , who was brought in by Miller in 1990, proposed to take Wang out of the manufacture of computers altogether, and to go big into imaging software instead. In March 1991, the company introduced its Office 2000 marketing strategy, focusing on office productivity.\n In June 1991, Wang started reselling IBM computers, in exchange for IBM investing in Wang stock. Wang hardware strategy to re-sell IBM   also included further pursuit of UNIX software.\n In August 1991, Wang won a suit against   and   claiming violation of Wang's patents on   (SIMMs). The company still recorded a net loss for the 1991 fiscal year.\n Wang Laboratories filed for bankruptcy protection on August 18, 1992, at a time when the company's attempted concession from proprietary to open systems was deemed by some analysts as \"too little and too late.\" \n Wang Labs emerged from bankruptcy on September 20, 1993.  As part of its bankruptcy reorganization, the company's iconic headquarters,   in Lowell, was sold at auction. The complex, which cost $60 million to build and housed 4,500 workers in over a million square feet (100,000 m ) of office space, was sold in 1994 for $525,000.  The renovated complex, which is now known as Cross Point, was sold in 1998 to a joint venture of Yale Properties and Blackstone Real Estate Advisors for a price reported to be over $100 million. \n The company emerged from bankruptcy with $200 million in hand and embarked on a course of acquisition and self-reinvention, eschewing its former role as an innovative designer and manufacturer of computers and related systems. Later in the 1990s, and under the guidance of then CEO  , with the acquisition of the Olsy division of  , the company changed its name to Wang Global. By then, Wang had settled on \"network services\" as its chosen business.\n The most advanced VS system, capable of supporting over 1,000 users – the VS18000 Model 950 – was released in 1999, and smaller models based on the same CPU chip were released in 2000 – the VS6760 and the VS6780. These were the last VS-based hardware systems. \n  acquired the Wang Software arm in 1997, strengthening its position in the then-booming document imaging and workflow market. \n In 1999, Wang Global, by then back up to $3.5 billion in annual revenues, was acquired by   of The Netherlands, a $1.5 billion network services company active only in parts of Europe and Australia. Joe Tucci departed Wang after the acquisition. Wang Labs then became Getronics North America.\n In 2005, Getronics announced  New VS (VSGX), a product designed to run the VS operating system and all VS software on   and   machines under Linux or Unix, using a   layer. The product was a joint commercial effort of Getronics and  , developers of the Wang VS virtualization technology that makes the New VS possible. VS software can be run under New VS without program or data conversion. The New VS combines configured mainstream   or   server hardware running virtualization software. It is interoperable with SCSI-based Wang VS tape and disk drives, which provide a means of restoring VS files from standard backup tapes or copying VS disk drives. Wang networking and clustering are supported over TCP/IP.\n In 2007, Getronics operations worldwide were divided and sold to companies in respective local geographies. Dutch telecommunications operator   acquired Getronics in North America and some parts of Europe. In July 2008, Getronics North America (now an arm of KPN) announced the ending of support for the legacy VS line as existing contracts expired,  and that TransVirtual Systems would be exclusive reseller of the New VS platform. In August 2008, KPN sold Getronics North America to   of Dallas, Texas. \n The Wang VS product line, not actively marketed since the 1993 bankruptcy and a tiny portion of the Getronics business, survived in use into the 21st century; by 2006, about 1,000 to 2,000 systems remained in service worldwide. In 2014, CompuCom announced that all support for legacy VS systems would cease at the end of 2014, while support for New VS systems would continue through TransVirtual Systems. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/License", "title": "License", "content": "\n\n A   ( ) or   ( ) is an official permission or permit to do, use, or own something (as well as the document of that permission or permit). \n A license is granted by a party (licensor) to another party (licensee) as an element of an agreement between those parties. In the case of a license issued by a government, the license is obtained by applying for it. In the case of a private party, it is by a specific agreement, usually in writing (such as a   or other contract).  The simplest definition is \"A license is a promise not to sue\", because a license usually either permits the licensed party to engage in an illegal activity, and subject to prosecution, without the license (e.g.  ,  , or operating a  ), or it permits the licensed party to do something that would violate the rights of the licensing party (e.g. make copies of a  ), which, without the license, the licensed party could be sued, civilly, criminally, or both.\n In particular, a license may be issued by authorities, to allow an activity that would otherwise be forbidden. It may require paying a fee or proving a capability (or both). The requirement may also serve to keep the authorities informed on a type of activity, and to allow them to set conditions and limitations.\n A licensor may grant a license under   laws to authorize a use (such as copying software or using a   invention) to a licensee, sparing the licensee from a claim of   brought by the licensor.  A license under intellectual property commonly has several components beyond the grant itself, including a  ,  ,   provisions, and other limitations deemed vital to the licensor.\n  many licenses are valid for a particular length of time. This protects the licensor should the value of the license increase, or market conditions change. It also preserves enforceability by ensuring that no license extends beyond the term of the agreement.\n  a license may stipulate what territory the rights pertain to. For example, a license with a territory limited to \"North America\" (Mexico/United States/Canada) would not permit a licensee any protection from actions for use in Japan.\n Again, a shorthand definition of a license is \"a promise by the licensor not to sue the licensee\". That means without a license any use or exploitation of intellectual property by a third party would amount to copying or infringement. Such copying would be improper and could, by using the legal system, be stopped if the intellectual property owner wanted to do so. \n Intellectual property licensing plays a major role in business, academia and broadcasting. Business practices such as  ,  , publication and   entirely depend on the licensing of intellectual property. Land licensing (proprietary licensing) and IP licensing.\n A license provides one party with the authority to act on another's land, when such action would typically amount to trespass absent that license. A key distinction between licenses and leases is that a license grants the licensee a revocable non-assignable privilege to act upon the land of the licensor, without granting any possessory interest in the land.  Once a license is agreed upon, the licensee may occupy the land only so far as is necessary to complete the act. Another key distinction between a license and a lease is that leases are generally required to be in writing, where the statute of frauds requires it, while licenses can be made orally.\n A license is generally created by an express or implied agreement. The licensor must agree to the license which can be shown in writing or the licensors acquiescence in its exercise. Furthermore, unlike many other contractual agreements, a license does not require consideration, a license can be created with or without it. Moreover, whether an agreement is held to be a \"license\" and not a lease will depend on three essential characteristics of a license: (1) a clause allowing the licensor to revoke \"at will\"; (2) the retention by the licensor of absolute control over the premises; and (3) the licensor's supplying to the licensee all of the essential services required for the licensee's permitted use of the premises. \n Under a pure licensing agreement, the licensor, under its terms and by common-law, can cancel the agreement at will and without cause, unless it is coupled with an interest or made irrevocable by contract. A license that has been coupled with an interest is not revocable by the licensor without exposure to liability and potential damages. In the event a license is coupled with an interest, the licensor must provide reasonable time for the licensee to remove that interest from the property prior to termination. Additionally, because a license does not confer any possessory interest in the licensee, in the event of a sale of the property, the license is terminated and cannot be enforced against the new owners of that property. Moreover, the death of either the licensee or licensor will terminate the agreement.\n If a license is revocable at will by the licensor, courts will be unable to grant specific performance in favor of the licensee.  A licensee would be unsuccessful in bringing forcible entry claims or a detainer proceeding because the licensee was never granted any possessory interest. The Licensee would also not be able to recover damages for money spent unless they are able to show detrimental reliance on the license. In certain cases, however, licenses can be made irrevocable, and specific performance may be granted. Where a license is made with a set term period and valid consideration is transferred, revocation of the license prior to the terms expiration may raise breach of contract claims that could provide damages against the licensor. Furthermore, once the licensor terminates or revokes the license, notice is statutorily required prior to the commencement of any special proceeding to recover possession of the property (e.g., in NY that requirement is 10 days).\n Mass distributed software is used by individuals on personal computers under license from the developer of that software. Such license is typically included in a more extensive   (EULA)  entered into upon the installation of that software on a computer.\nTypically, a license is associated with a unique code, that when approved grants the end user access to the software in question.\n Under a typical end-user license agreement, the user may install the software on a limited number of computers. \n The enforceability of end-user license agreements is sometimes  .\n As of 2020, there are various ways to   with different kinds of licensing models, which allow software vendors to profit from their product offerings in flexible ways.\n Like other intellectual property, patent owners may grant permission to others to engage in conduct that would otherwise be within the scope of a patent.  For example, a patent owner may authorize a licensee to make, use, sell, offer for sale, or import a patented product. Such agreements are typically referred to as a   or a  . These agreements can last for a specific period of time (such as five years) or for the entire life of the patent (  until the patent expires).   Patent license agreements may also be exclusive (  the licensee is the only person or entity that is allowed to sell, make, use, offer to sell, or import the patented invention) or non-exclusive (  the licensee is simply one of several entities who has rights under the patent).  Finally, any rights given under the agreement may be limited to a particular \"field of use\" (  a licensee may be able to practice an invention in the field of consumer electronics, but not in the field of industrial electronics). \n Often, patent owners will require a licensee to pay money in exchange for granting a patent license.  Such payments are referred to as   and come primarily in two forms: lump sum or running royalty.  A lump sum royalty involves an upfront, one-time payment, while a running royalty typically involves periodic payments (  quarterly or annual) based on the number of patented products sold or imported.\n A licensor may grant permission to a licensee to distribute products under a  . With such a license, the licensee may use the trademark without fear of a claim of trademark infringement by the licensor.\nThe assignment of a license often depends on specific  . The most common terms are, that a license is only applicable for a particular geographic region, just for a certain period of time or merely for a stage in the  . Moreover, there are different types of fees within the trademark and brand licensing. The first form demands a fee independent of   and  , the second type of license fee is dependent on the productivity of the licensee.\n For example,   licenses their trademark such as the \" \" or the \" \", but the licenses gives McDonald's a right to impose strict quality standards to their franchisees as they can take back the right to the trademark if they do not meet McDonald's standards. \n When a licensor grants permission to a licensee to not only distribute, but manufacture a patented product, it is known as  .\n A licensor may grant a permission to a licensee to copy and distribute   works such as \"art\" (e.g.,  's painting  ) and characters (e.g.,  ). With such license, a licensee need not fear a claim of copyright infringement brought by the copyright owner.\n  is, however, not related to the aforementioned license. It is a   that denotes freedom of expression, the ability to make the subject appear more engaging or attractive, by   part of the subject.\n A   is an   that traditionally conferred the license to teach at a university or to practice a particular profession. The term survived despite the fact that nowadays a   is typically needed in order to teach at a university. The term is also used for a person who holds a licentiate.  In English, the degree has never been called a license. In France, the   is the first degree awarded in Universities.\n In  , Finland, and in some other European university systems, a 'licentiate' is a postgraduate degree between the master's degree and the doctorate.  The licentiate is a popular choice in those countries where a full   would take five or more years to achieve.\n A license to driving certain vehicles has been applied to many countries around the world. Being allowed to drive a certain vehicle requires a specific driving license, the type of license depending on the type of vehicle.\n In the United Kingdom prisoners serving a determinate sentence (a fixed time in prison) will be released prior to the completion of their full sentence \"on licence\".  The licence is the prisoner's agreement to maintain certain conditions, such as periodic reporting in to a probation officer and only living at an approved address, in exchange for their early release. If they break the conditions of the licence, they can be \"recalled\" (returned to prison). \n Offenders serving determinate sentences are released automatically at a set point in their sentence, whereas prisoners serving indeterminate sentences (e.g.  ) can only be released by the  . \n Patent licensing has been studied in formal economic models in the field of  . In particular, Katz and Shapiro (1986) have explored the optimal licensing strategy of a research lab selling to firms who are competitors on the product market.  It turns out that (compared to the welfare-maximizing solution) the licensor's incentives to develop innovations may be excessive, while the licensor's incentives to disseminate the innovation are typically too low. Subsequently, the seminal work of Katz and Shapiro (1986) has been extended in several directions. For example, Bhattacharya, Glazer, and Sappington (1992) have taken into account that the firms acquiring licenses must make further investments in order to develop marketable products.  Schmitz (2002, 2007) has shown that asymmetric information due to   or   may lead the research lab to sell more licenses than it would do under complete information.  Antelo and Sampayo (2017) have studied the optimal number of licenses in a   model. \n The provision of licenses and the agencies that mandate them are often criticised by American libertarians like   for creating an anticompetitive environment for occupations, which creates a   for more qualified and skilled individuals who may not have the resources to obtain the necessary licences. According to Friedman, licenses and permits have become so burdensome due to legislation that favors the current  establishment of wealthy occupants that they decrease the supply of such occupations, which raises prices for the average consumer. Libertarians and the anti-authoritarian left ( ) view competing guilds and other voluntary communes as being more beneficial for disseminating the skills and education required to perform a specified career.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Real_Genius", "title": null, "content": " is a 1985 American   film directed by  , written by  ,  , and  , and starring   and  . The film, set on the campus of Pacific Tech, a science and engineering university similar to  , follows Chris Knight (Kilmer), a genius in his senior year, who is paired with a new student on campus, Mitch Taylor (Jarret), to work on a  , only to learn it will be used for dangerous purposes.\n The film received positive   from  , and grossed $13 million at the  . \n The   has covertly hired Professor Jerry Hathaway at Pacific Tech University to develop the power source for \"Crossbow\", a   precise enough to commit illegal political assassinations from outer space. Hathaway uses his position to recruit brilliant students to do the work for him, diverting the CIA's funding into building his enormous house.\n Hathaway recruits high school student Mitch Taylor, a budding genius in  .  Mitch is roomed with Chris Knight, a legend in the \"National Physics Club\" and one of Mitch's idols. Mitch's ideal of Chris is shattered, however, when Chris turns out to be more of a slacker than a hard-working student. Meanwhile, Hathaway hopes Mitch will encourage Chris to straighten up his act and that their two exceptional minds can develop a proper power source for \"Crossbow\". Mitch also befriends Jordan Cochran, a hyperactive insomniac student for whom he gradually develops romantic feelings.\n Kent, Hathaway's   (and  ), reports Mitch for attending a   with Chris instead of working on the laser.  Hathaway lambasts Mitch, who breaks down and tearfully calls his parents. Kent secretly records the call and uses the recording to humiliate Mitch. As Mitch begins packing to leave, Chris explains the pressures of school and burdens of being highly intelligent by relating the history of genius and former Pacific Tech student Lazlo Hollyfeld. Hollyfeld suffered a   when he discovered his creations were being used to kill, and he now lives hidden in the university's tunnels, accessed from beneath Chris and Mitch's closet. Chris, fearing the same could happen to him, learned to lighten up and enjoy life. Mitch agrees to stay, and they exact revenge on Kent by disassembling his car, a 1972  , and reassembling it in his  .\n Hathaway, angry about the still-incomplete project and Chris's attitude, informs Chris that he intends to prevent him from earning a degree,   him, and give a coveted job, originally promised to Chris, to Kent instead. Chris is disheartened and Mitch must use Chris's same argument to convince him to stay. The two create a new laser, but Kent sabotages it, causing it to explode. Though initially despondent, the incident inspires Chris to design and build a six-megawatt   laser, which burns a hole through the campus when it is test-fired.  Hathaway reverses his position, giving Chris a degree and the job. As Chris and Mitch celebrate, Hollyfeld arrives and informs them that, with certain modifications, their laser could be used as a weapon. A panicked Chris returns to the lab to find the laser gone, as well as Kent's projects: a mirror and a tracking system which together can weaponize Chris's laser.\n Jordan and fellow project member \"Ick\" Ikagami surreptitiously implant a   in Kent's  , which Mitch uses to convince him he is speaking to  . Kent divulges the date of the test, and the group tails Hathaway to learn the location of the   base the CIA is using. Chris and Mitch sneak onto the     where their equipment has been installed and assist Hollyfeld in reprogramming the laser. \n Outside Hathaway's home, Chris, Mitch, Jordan, and Ick meet   Meredith and a  , to whom they had reported Hathaway's plan. Kent arrives unexpectedly and goes inside the house. The laser test begins and, instead of firing on the target, the laser fires on Hathaway's house, activating a gigantic  . Kent is launched out the front door on a popcorn wave. Hollyfeld arrives in an RV—which he has won using mathematics to rig a  —to tell them he is leaving. Hathaway, who hates popcorn, arrives afterwards to find his house destroyed by popcorn.\n To prepare for  , Martha Coolidge spent months researching laser technology and the policies of the  , and interviewed dozens of students at  .  The   was extensively rewritten, first by   and  , later by Coolidge and PJ Torokvei. \n    remembers that when Val Kilmer came in to   for the role of Chris Knight, he brought candy bars and performed tricks. Kilmer remembered it differently. \"The character wasn't polite, so when I shook Grazer's hand and he said, 'Hi, I'm the producer,' I said, 'I'm sorry. You look like you're 12 years old. I like to work with men.'\" \n To achieve the house filled with popcorn for the film's  , the production team popped popcorn continuously for three months. The popcorn was treated with   so it would not   and covered so that it would not be eaten by birds and possibly poison them. The popcorn was then shipped to a   under construction in  , northwest of  , and placed in the house. \n To   the film, the studio held what it billed as \"the world's first computer press conference\", with Coolidge and Grazer answering journalists' questions via   and relayed over the    . \n The dorm in the film is based on   at Caltech, and Caltech students served as   and played   in the film. \n  was released on August 9, 1985, in 990 theaters, grossing $2.5 million in its first weekend. It went on to make $12,952,019 in North America. \n On    , the film holds an approval rating of 77% based on 35 reviews with an average rating of 6.7/10. The website's critical consensus reads, \"It follows college tropes, but   has an optimistic streak that puts you on Val Kilmer's side all the way.\"  On  , the film received a score of 71 based on 15 reviews, indicating \"generally favorable reviews\". \n  reviewed the film for   #85, and stated that it was \"yet another celebration of the anxious wonder of growing up white, middle-class and heterosexual in America. The lovable weirdos squabble in the lab, play hi-tech pranks in the dorm and party in the lecture theater. Nerds just wanna have fun. Nerds have feelings too. Hug a Nerd today.\" \n In her review for  ,   wrote, \"the film is best when it takes [the students] seriously, though it does so only intermittently.\"    wrote in his review for  , \"When it's good, the dormitory high jinks feel like the genuine release of teen-age tensions and cruelty. Too bad the story isn't as smart as the kids in it.\"  In her review for  , Rita Kempley wrote, \"Many of the scenes, already badly written, fail to fulfill their screwball potential... [D]espite its enthusiastic young cast and its many good intentions, it doesn't quite succeed. I guess there's a leak in the think tank.\" \n  film critic   awarded the film three and a half stars out of four, saying that it \"contains many pleasures, but one of the best is its conviction that the American campus contains life as we know it.\"  In his review for  , Salem Alaton wrote, \"Producer Brian Grazer craved a feel-good picture, and she [Martha Coolidge] turned in the summer's best, and she didn't cheat to do it. There's heart in the kookiness.   has real people, real comedy and real fun.\"    of   praised the film for being \"a smart, no-nonsense movie that may actually teach its prime audience a valuable lesson: the best retort to an intolerable situation is not necessarily a food fight. Better results, and more fun, come from rubbing a few brains briskly together.\" \n In the   episode \"Car vs. Rain\", first broadcast on June 17, 2009, the   team tried to determine whether the final scene in the film, the destruction of Dr Hathaway's house with laser-popped popcorn, is actually possible. First they used a ten-watt laser to pop a single   wrapped in aluminum foil, showing that popping corn is possible with a laser. Then they tested a scaled-down model of a house. The popcorn was popped through   because a sufficiently large laser was not available. The result was that the popcorn was unable to expand sufficiently to break glass, much less break open a door or move the house off its  . Instead, it ceased to expand and then simply  . \n It was also specifically stated in the program that a five-megawatt laser still did not exist, even in military applications, and that the most powerful military laser they knew of was 100  . \n In January 2011, it was further demonstrated on video  in a home setting that a kernel of corn directly exposed to laser light from accessible consumer level lasers could be popped as reported by  . \n The solid   proposed and built by Chris in the latter half of the film, though in the realm of science fiction, was based on a theory of the time.  , through consultant Martin A. Gundersen, who played the math professor, was later cited in an academic publication that detailed the scientific basis behind the laser. \n Reports surfaced in September 2014 that a potential television series was in the works.    was set to produce the comedy series with  ,   and  .   As of December 2017  there were no updates on the production.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Dr._Karl", "title": "Karl Kruszelnicki", "content": "\n\n    (born 1948), often referred to as  ,  is an Australian   and populariser,  who is known as an author and a science commentator on Australian radio, television, and podcasts.\n Kruszelnicki is the Julius Sumner Miller Fellow in the Science Foundation for Physics at the  ,  . \n Kruszelnicki (   ) was born in  ,  , to   parents, Rina and Ludwik. Kruszelnicki's background was hidden from him for a long time, with his mother having told him that she was Swedish and a   but she was, in fact, Polish and  .  Both his parents were  .  His father Ludwik, a Polish  , was turned in to the   for smuggling Jews out of Poland and was imprisoned at  , a concentration camp used mainly for political prisoners. As the end of   approached, Ludwik avoided execution by swapping identities with a dead person.  Rina escaped the   when the Nazis ran out of   that was used to gas prisoners.  They separately fled to Sweden, where they met, and where Karl was born. \n When Kruszelnicki was two years old, his parents became concerned about the risk of Sweden being overrun by Russia and decided to flee the country. Before boarding a boat bound for America, Karl became ill with fever following a  . Worried for his health, his parents decided not to board the boat. \"Luck has it that the next ship went to Australia, so that is where we ended up. It is amazing how fate can take you in unexpected directions.\" \n On arrival in Australia, the family were tenanted at the   in  . They remained there for three years  before settling in the city of  ,  . Kruszelnicki said his childhood as a refugee in Wollongong was difficult, and he was bullied at school; he said \"anybody who was not an Irish Catholic was considered an outsider\".  He found an escape in the Wollongong Library, where he became interested in science fiction. \n Kruszelnicki attended Edmund Rice Christian Brothers College in  .  After high school, he attended the  , completing a Bachelor of Science degree majoring in physics in 1968.  In 1980, Kruszelnicki was awarded a Master of   degree at the  . He completed his Bachelor of Medicine and Bachelor of Surgery degrees at   in 1986. \n After primary school, Kruszelnicki's first job was ditch digger in the Wollongong suburb of  .  He also worked as a filmmaker, car mechanic, TV weatherman and as   for  ,   and  .  While working as a taxi driver in Sydney, he was beaten unconscious after picking up a passenger trying to escape a group of men. \n After graduating from university at age 19, Kruszelnicki took a job as a physicist working for a   in his home town of Wollongong. He designed a machine to test the strength of steel made for use in Melbourne's  , which was under construction at the time. After he was asked to fake the results of his tests, he resigned. \n In the early 1980s, Kruszelnicki worked for    . His Master of Biomedical Engineering degree allowed him to design and build a machine to pick up electrical signals off the human retina to diagnose certain eye diseases. \n Kruszelnicki commenced his degree in medicine at the   at the age of 32, graduating in 1986. From here he began work at a number of hospitals around Sydney, including the Children's Hospital in Camperdown.  He talks fondly of his time as a children's doctor, though he left this profession after witnessing the first child die from   in twenty years. This came about, he says, after a television program tried to create controversy by presenting the efficacy of vaccinations with a  . This caused a drop in  , and eventually the death of this child. \"That very strongly influenced me to go into the media, because I felt like I could do more good there (convincing people to vaccinate). And as a result, I gave up the best job of my life, which was being a doctor in a kids' hospital, so I could do more good in the community.\" \n Kruszelnicki presented the first series of   (replaced by  ) in 1985. As a science communicator and presenter, he appears on the Seven Network's   and on  . From early 2008 to 2010 he co-hosted a TV series called   with Adam Spencer.\n Kruszelnicki does a number of weekly radio shows and  . His hour-long show on   radio station   has been going on in one form or another since 1981; this weekly science   show,  , is broadcast on Thursday mornings from 11:00 am to midday and attracts up to 300,000 listeners; it is also available as a podcast. \n Kruszelnicki also often helps with other science and education   promotions such as the   roadshow with   and Caroline Pegram. He and Adam Spencer released the   podcast regularly until December 2015.  Also, Since 2016, he has hosted the podcast  \n For many years, until March 2020, Kruszelnicki appeared on a live weekly late-night link-up on  's  , usually with  , answering science questions.  In 2017, he hosted   on  . \n Kruszelnicki writes a regular column for   magazine, called 'Need to Know', which is republished as a   on the magazine's website.  He has also written for the     magazine. \n In 1981, he appeared on an     about death and near-death experiences that aired on the  ,   It was adapted into a book in 1987. \n Kruszelnicki was an unsuccessful candidate for the   in the  . He was placed number two on the   ticket in  . \n In 2015, Kruszelnicki appeared in an Australian Government advertising campaign for the recently published intergenerational report. He had previously agreed to do the campaign, believing it would be a \"non-political, bipartisan, independent report.\" After its publication, however, he backed away from the campaign, describing it as \"flawed\". \"How can you possibly have a report that looks at the next 40 years and doesn't mention climate change? It should have acknowledged that climate change is real and we cause it and it will be messy.\" \n Kruszelnicki met his wife Mary in his first year of medical school. They have three children together: Karl, Alice, and Lola. \n Kruszelnicki has  , meaning he lacks the ability to recognise faces. To help him recognise co-workers, he has been known to carry a seating map of familiar office spaces.  He puts the cause of his condition down to having an unhappy, lonely childhood, saying that it impeded the development of the part of his brain responsible for remembering faces. \n In 2000, the   Internet Awards awarded Kruszelnicki the Best Science and Technology Website. \n In the 2001  , he was awarded the   \"for major service in raising public awareness of the importance of science and technology\". \n One of Kruszelnicki's more notable undertakings was his part in a research project on  , for which he received the tongue-in-cheek   in 2002.\n He received the   award in 2003.\n In the 2006 honours list, he was made a Member of the  . \n In 2006, the   recognised him as the Australian Skeptic Of The Year. \n In 2012, Kruszelnicki was named as a   by the   (NSW). \n In 2012,   asteroid   was named in his honour. \n In 2014,   readers voted Kruszelnicki as the ninth-most-trusted person in Australia \n In 2016, he received an honorary doctorate from the  . \n Kruszelnicki won UNESCO's 2019   for science communication. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Papermaking", "title": "Papermaking", "content": " is the manufacture of   and  , which are used widely for printing, writing, and packaging, among many other purposes. Today almost all paper is  , while handmade paper survives as a specialized craft and a medium for  .\n In papermaking, a dilute suspension consisting mostly of separate cellulose fibres in water is drained through a sieve-like screen, so that a mat of randomly interwoven fibres is laid down. Water is further removed from this sheet by pressing, sometimes aided by suction or vacuum, or heating. Once dry, a generally flat, uniform and strong sheet of paper is achieved.\n Before the invention and current widespread adoption of automated machinery, all paper was made by hand, formed or laid one sheet at a time by specialized laborers. Even today those who make paper by hand use tools and technologies quite similar to those existing hundreds of years ago, as originally developed in China and other regions of Asia, or those further modified in Europe. Handmade paper is still appreciated for its distinctive uniqueness and the skilled craft involved in making each sheet, in contrast with the higher degree of uniformity and perfection at lower prices achieved among industrial products.\n  paper had been used in   for wrapping and padding since the eighth century BC.  Paper with legible Chinese writings on it has been dated to 8 BC. \nThe traditional inventor attribution is of  , an official attached to the Imperial court during the   (202 BC – 220 CE), said to have invented paper about 105 CE using   and other   along with fishnets, old rags, and   waste.  Paper used as a writing medium had become widespread by the 3rd century  and, by the 6th century,   was starting to be used in China as well.  During the   (618–907 CE) paper was folded and sewn into square   to preserve the flavour of tea,  while the later   (960–1279 CE) was the first government to issue paper-printed money.\n In the 8th century, papermaking spread to the  , where the process was refined, and machinery was designed for bulk manufacturing. Production began in  ,  ,  ,  ,  , and then  .  In  , papermaking was under the supervision of the    . Muslims invented a method to make a thicker sheet of paper. This innovation helped transform papermaking from an art into a major industry.  The earliest use of   in paper production, specifically the use of   for preparing the pulp for papermaking, dates back to   in the 8th century.  The earliest references to   also come from the  , where they were first noted in the 9th century by   in  . \n Traditional   uses the inner bark fibers of plants. This fiber is soaked, cooked, rinsed and traditionally hand-beaten to form the paper pulp. The long fibers are layered to form strong, translucent sheets of paper. In Eastern Asia, three traditional fibers are  ,   and  . In the Himalayas,   is made from the   plant.  This paper is used for calligraphy, printing, book arts, and three-dimensional work, including  .  \n In  ,   using metallic wire were developed, and features like the   were well established by 1300 CE, while   and   rags were the main source of pulp, cotton eventually taking over after Southern plantations made that product in large quantities.  Papermaking was originally not popular in Europe due to not having many advantages over   and  . It was not until the 15th century with the invention of the movable type of printing and its demand for paper that many paper mills entered production, and papermaking became an industry. \n Modern papermaking began in the early 19th century in   with the development of the  . This machine produces a continuous roll of paper rather than individual sheets. These machines are large. Some produce paper 150 meters in length and 10 meters wide. They can produce paper at a rate of 100 km/h. In 1844, Canadian   and German   had invented the machine and associated process to make use of wood pulp in papermaking.  This innovation ended the nearly 2,000-year use of pulped rags and start a new era for the production of   and eventually almost all paper was made out of pulped wood.\n Papermaking, regardless of the scale on which it is done, involves making a dilute suspension of   in water, called \"furnish\", and forcing this suspension to drain through a screen, to produce a mat of interwoven fibres. Water is removed from this mat of fibres using a press. \n The method of manual papermaking changed very little over time, despite advances in technologies. The process of manufacturing handmade paper can be generalized into five steps:\n Screening the fibre involves using a mesh made from non-corroding and inert material, such as brass, stainless steel or a synthetic fibre, which is stretched in a paper mould, a wooden frame similar to that of a window. The size of the paper is governed by the open area of the frame. The mould is then completely submerged in the furnish, then pulled, shaken and drained, forming a uniform coating on the screen. Excess water is then removed, the wet mat of fibre laid on top of a damp cloth or felt in a process called \"couching\". The process is repeated for the required number of sheets. This stack of wet mats is then pressed in a hydraulic press. The fairly damp fibre is then dried using a variety of methods, such as vacuum drying or simply air drying. Sometimes, the individual sheet is rolled to flatten, harden, and refine the surface. Finally, the paper is then cut to the desired shape or the standard shape (A4, letter, legal, etc.) and packed. \n The wooden frame is called a \" \". The deckle leaves the edges of the paper slightly irregular and wavy, called \" \", one of the indications that the paper was made by hand. Deckle-edged paper is occasionally mechanically imitated today to create the impression of old-fashioned luxury. The impressions in paper caused by the wires in the screen that run sideways are called \"laid lines\" and the impressions made, usually from top to bottom, by the wires holding the sideways wires together are called \"chain lines\".   are created by weaving a design into the wires in the mould. Handmade paper generally folds and tears more evenly along the laid lines.\n The International Association of Hand Papermakers and Paper Artists (IAPMA) is the world-leading association for handmade paper artists.\n Handmade paper is also prepared in laboratories to study papermaking and in paper mills to check the quality of the production process. The \"handsheets\" made according to   Standard T 205\n  are circular sheets 15.9 cm (6.25 in) in diameter and are tested for paper characteristics such as brightness, strength and degree of  . \nPaper made from other fibers, cotton being the most common, tends to be valued higher than wood-based paper. \n A modern paper mill  is divided into several sections, roughly corresponding to the processes involved in making handmade paper. Pulp is refined and mixed in water with other additives to make a pulp slurry. The head-box of the paper machine called   distributes the slurry onto a moving continuous screen, water drains from the slurry by gravity or under vacuum, the wet paper sheet goes through presses and dries, and finally rolls into large rolls. The outcome often weighs several tons. \n Another type of paper machine, invented by John Dickinson in 1809, makes use of a cylinder   that rotates while partially immersed in a vat of dilute pulp. The pulp is picked up by the wire mesh and covers the mould as it rises out of the vat. A couch roller is pressed against the mould to smooth out the pulp, and picks the wet sheet off the mould. \n Papermaking continues to be of  , due to its use of harsh chemicals, its need for large amounts of water, and the resulting contamination risks, as well as the   lost by   caused by clearcutting the trees used as the primary source of  . \n While papermaking was considered a lifework, exclusive profession for most of its history, the term \"notable papermakers\" is often not strictly limited to those who actually make paper. Especially in the hand papermaking field there is currently an overlap of certain celebrated paper art practitioners with their other artistic pursuits, while in academia the term may be applied to those conducting research, education, or conservation of books and paper artifacts. In the industrial field it tends to overlap with science, technology and engineering, and often with management of the pulp and paper business itself.\n Some well-known and recognized papermakers have found fame in other fields, to the point that their papermaking background is almost forgotten. One of the most notable examples might be that of the first humans that achieved flight, the  , where many accounts barely mention the paper mill their family owned, although paper used in their balloons did play a relevant role in their success, as probably did their familiarity with this light and strong material.\n Key inventors include  ,  ,   and  , among others.\n By the mid-19th century, making paper by hand was extinct in the United States.  By 1912, fine book printer and publisher,   had reestablished the craft of fine hand paper making but by the 1930s the craft had lapsed in interest again.  When artist Douglass Howell returned to New York City after serving in  , he established himself as a fine art   and discovered that art paper was in short supply.  During the 1940s and 1950s, Howell started reading Hunter's books on paper making, as well as he learned about hand paper making history, conducted paper making research, and learned about printed books. \n 24. Longwood L.C. \"Science and practice of hand made paper\": (2004). \n25. Westerlund L.C. \"Fibre options for the sustainable development of the Australian Paper and Pulp Industry\": (2004)\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Memory-bound_function", "title": "Memory-bound function", "content": " refers to a situation in which the time to complete a given   is decided primarily by the amount of free   required to hold the working  . This is in contrast to algorithms that are  , where the number of elementary computation steps is the deciding factor.\n Memory and computation boundaries can sometimes be traded against each other, e.g. by saving and reusing preliminary results or using  .\n Memory-bound   and memory functions are related in that both involve extensive memory access, but a distinction exists between the two.\n Memory functions use a   technique called   in order to relieve the inefficiency of   that might occur. It is based on the simple idea of calculating and storing solutions to subproblems so that the solutions can be reused later without recalculating the   again. The best known example that takes advantage of memoization is an   that computes the  . The following   uses recursion and memoization, and runs in  :\n Compare the above to an algorithm that uses only recursion, and runs in   CPU time:\n While the recursive-only algorithm is simpler and more elegant than the algorithm that uses recursion and memoization, the latter has a significantly lower   than the former.\n The term \"memory-bound function\" has surfaced only recently and is used principally to describe a function that uses XOR and consists of a series of computations in which each computation depends on the previous computation. Whereas memory functions have long been an important actor in improving time complexity, memory-bound functions have seen far fewer applications. Recently , however, scientists have proposed a method using memory-bound functions as a means to discourage spammers from abusing resources, which could be a major breakthrough in that area.\n Memory-bound functions might be useful in a   that could deter  , which has become a problem of epidemic proportions on the  .\n In 1992, IBM research scientists   and   published a paper at CRYPTO 1992 titled  ,  suggesting a possibility of using   functions to deter abusers from sending spam. The scheme was based on the idea that computer users are much more likely to abuse a resource if the cost of abusing the resource is negligible: the underlying reason spam has become so rampant is that sending an   has minuscule cost for spammers.\n Dwork and Naor proposed that spamming might be reduced by injecting an additional cost in the form of an expensive   computation: CPU-bound functions would consume CPU resources at the sender's machine for each message, thus preventing huge amounts of spam from being sent in a short period.\n The basic scheme that protects against abuses is as follows: \nGiven a Sender, a Recipient, and an email Message. If Recipient has agreed beforehand to receive e-mail from Sender, then Message is transmitted in the usual way. Otherwise, Sender computes some function   and sends   to Recipient. Recipient checks if what it receives from Sender is of the form  . If yes, Recipient accepts Message. Otherwise, Recipient rejects Message.\n The function   is selected such that the verification by Recipient is relatively fast (e.g., taking a millisecond) and such that the computation by Sender is somewhat slow (involving at least several seconds). Therefore, Sender will be discouraged from sending Message to multiple recipients with no prior agreements: the cost in terms of both time and computing resources of computing   repeatedly will become very prohibitive for a spammer who intends to send many millions of e-mails.\n The major problem of using the above scheme is that fast CPUs compute much faster than slow CPUs. Further, higher-end computer systems also have sophisticated pipelines and other advantageous features that facilitate computations. As a result, a spammer with a state-of-the-art system will hardly be affected by such deterrence while a typical user with a mediocre system will be adversely affected. If a computation takes a few seconds on a new  , it may take a minute on an old PC, and several minutes on a  , which might be a nuisance for users of old PCs, but probably unacceptable for users of PDAs. The disparity in client CPU speed constitutes one of the prominent roadblocks to widespread adoption of any scheme based on a CPU-bound function. Therefore, researchers are concerned with finding functions that most computer systems will evaluate at about the same speed, so that high-end systems might evaluate these functions somewhat faster than low-end systems (2–10 times faster, but not 10–100 times faster) as CPU disparities might imply. These ratios are \" \" enough for the intended applications: the functions are effective in discouraging abuses and do not add a prohibitive delay on legitimate interactions, across a wide range of systems.\n The new egalitarian approach is to rely on memory-bound functions. As stated before, a memory-bound function is a function whose computation time is dominated by the time spent accessing memory. A memory-bound function accesses locations in a large region of memory in an unpredictable way, in such a way that using caches are not effective. In recent years, the speed of CPU has grown drastically, but there has been comparatively small progress in developing faster main memory. Since the   of   of machines built in the last five years is typically no greater than two, and almost always less than four, the memory-bound function will be egalitarian to most systems for the foreseeable future.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Dolphin_Browser", "title": "Dolphin Browser", "content": "10.0.6 (November 24, 2020 )\n The   is a   for the   and   operating systems developed by  . It was one of the first alternative browsers for the Android platform  that introduced support for   gestures.  Dolphin Browser uses its native platform's default  .\n Dolphin Browser supports most  . The browser also supports  ,  , and  . It can cache web content for offline use and synchronize data across devices. It supports   on Android only.\n Both iOS and Android versions are   with optional in-app purchases.  There was an updated version called   for   or later.  Dolphin Browser Beta  was released in May 2012 with the in-house   engine Jet pack.  In December 2013, Dolphin Zero, a version of the app that claims to be private by automatically deleting browser data, was released. \n In October 2011, privacy concerns were raised about Dolphin browser after it was discovered that all   loaded in Dolphin HD were being relayed as plain text to a remote server,  a process described by   as \"an unambiguous  \".  This breach was patched in the next update. \n In 2011, Steve Kovach of   compared Dolphin Browser favorably to Safari and claimed \"Dolphin Browser blows Safari out of the water.\"  In 2011, Dolphin Browser was recognized on  s list of the best free iPhone and iPad Apps of the year,  and received a   Editors Choice award in 2012. \n However, in the years since its release it has not had enough users to compete with competitor mobile browsers.  As of March 2024, the browser holds a rating of 2.7 out of 5 on the Apple App Store. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Network_World", "title": "International Data Group", "content": " ( )  is a   and   company  focused on the technology industry. IDG, Inc.'s mission is centered around supporting the technology industry through research, data, marketing technology, and insights that help create and sustain relationships between businesses. \n IDG, Inc. is wholly owned by   and is led by Genevieve Juillard, who was appointed CEO of the company in 2023.   Juillard serves on IDG, Inc.'s leadership team along with IDC President Crawford Del Prete and IDG, Inc.'s Chief Financial Officer Tiziana Figliolia. \n IDG, Inc. is headquartered in   and is parent company to both International Data Corporation (IDC) and Foundry (formerly IDG Communications). \n International Data Group was initially founded as International Data Corporation (IDC) in 1964 by  , shortly after he had graduated from the   (MIT). Based in Massachusetts, the company produced a computer installation database, and published a newsletter, \"EDP Industry and Market Report\" (modeled on \"ADP Newsletter\", which was published by the Diebold Group). Companies such as  ,  ,  , and   paid IDC for use of the data base. During this time, McGovern continued to work as a writer for \"Computers and Automation\" magazine, the first computer magazine, published by  . \n By IDG's third year, McGovern was considering liquidating the company when he hit on the idea of launching   in 1967,  which was a continuation of the monthly newsletter, published weekly instead of monthly, in a different format, with advertising, and which would become a cornerstone of IDG's subsequent publishing arm.  \n In 1969, IDG made its first overseas expansion when it opened IDC UK and launched its first European publication. In 1974, the company launched its first international publication,  , in Germany, its first fully translated publication. International publications in Japan, China, the then Soviet Union, Vietnam, and other countries would follow throughout the 1990s. \n In 1984, the company launched   in the same week that the Macintosh computer was debuted, and featured Steve Jobs on its cover. In the 1991, IDG Books launched its   series with  ,  and published many instructional/reference books under the series until Hungry Minds (the new name for IDG Books) was acquired by  . in 2001. \n In 2007, IDG ceased print publication of   and made the content available online only, signaling the company's transition to a web-centric model for publication. \n Throughout the 1970s and 1980s, IDG would break into the events and research spaces. In the early 1970s, it launched its   trade show in the US, reaching nine US cities in 11 weeks.  By 1972, the   had a European presence as well. \n In the 1980s, IDG launched   via its subsidiary IDC, which would come to represent the company's technology research and analyst arm.  The company still maintains an   team of analysts today that publish regular findings on the state of the worldwide technology industry. \n In 1991, the first IDG DEMO Conference was held in La Quinta, CA as a live forum where companies could debut their latest technology live on stage in front of crowds of technology consumers, business decision makers, and investors. The event, which would go on to be held as conferences across the US, Asia, South America, and other countries through 2015, served as the site of notable product and software launches such as  ,  ,   Virtual Hardware,  , and  . \n By the mid-2000s the company had established a rich online and print publication business, a trusted market research and analyst division, and a large global trade show presence – all which contributed to the growth of a database of over six million technology buyers and professionals. In 2006, IDG made this database of readers, website visitors, and event attendees available to technology marketers via its demand generation division IDG Connect.  In 2010, IDG introduced the \"Nanosite\", an advertising tool designed as an alternative to a  . \n Following McGovern's death in 2014, ownership of the corporate passed to the Patrick J. McGovern Foundation,  until 2017 when it was purchased by  .  IDG, Inc. changed ownership again in May 2021 when   acquired the corporation from China Oceanwide Holdings Group for $1.3 billion. \n IDG, Inc. serves as the parent company of two major company divisions, IDC and Foundry. \n IDC is a wholly-owned subsidiary of IDG, Inc. and is a global provider of market intelligence, advisory services, and events for the information technology, telecommunications, and consumer technology markets.  IDC employs over 2,500 people globally including more than 1,300 analysts worldwide to offer expertise and insights on technology and industry trends. \n In 2019, Crawford Del Prete was named president of IDC after serving as its Chief Operating Officer (COO). \n In May 2021, IDC acquired Dutch IT intelligence consultancy Metri,  bolstering its presence in the Benelux region and strengthening IDC's reach and insight into Europe's IT industry.\n Foundry is a wholly-owned subsidiary of IDG, Inc. and is a global provider of media & event services, marketing technology, and intent data for B2B technology marketers. Formerly known as IDG Communications, the IDG Inc. subsidiary company rebranded from IDG Communications to Foundry in February 2022 as part of its strategic transformation from publisher to data and martech company.  Foundry employs over 1,400 people globally  and operates in over 140 countries around the world. \n Between 2020 and 2022, Foundry acquired leading data and marketing technology (MarTech) companies Triblio, Kickfire, Leadsift, and Selling Simplified as part of its strategy to transform from legacy media network to integrated marketing technology and data provider. Through both homegrown and acquired data and technologies, Foundry continues to leverage their established media brands to gather and provide insights about global technology buyers to marketers in the same space. \n Foundry owns and operates various editorial brands that publish relevant content for technology buyers in both the B2B and consumer spaces across over 90 countries.  With some like   and   dating back to McGovern's early ownership, the editorial brands remain central to Foundry's operations in media and technology marketing, though many of the editorial brands have transitioned from print to digital. \n In 2000, Salesforce was launched at IDG's DEMO Event the premier launch venue for new technologies from 1991 to 2015.\n In 2001,   Magazine named IDG, Inc. to its list of \"The 100 Best Companies to Work For\", ranking the company at number 58.\n IDG Books launched the popular reference book series   in 1991, which it owned for 10 years until selling to John Wiley & Sons, Inc. in 2001. \n The first ever iPhone was revealed by   at a MacWorld conference in 2007. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Technology_roadmap", "title": "Technology roadmap", "content": "A   is a flexible   schedule to support strategic and long-range planning, by matching short-term and long-term goals with specific   solutions.  It is a plan that applies to a new product or process and may include using   or   to identify suitable  .  It is a known technique to help manage the   of innovation.  It is also expected that roadmapping techniques may help companies to survive in turbulent environments  and help them to plan in a more holistic way to include non-financial goals and drive towards a more sustainable development.  Here roadmaps can be combined with other corporate foresight methods to facilitate  . \n Developing a roadmap has three major uses.  It helps reach a consensus about a set of needs and the technologies required to satisfy those needs, it provides a mechanism to help forecast technology developments, and it provides a framework to help plan and coordinate technology developments.  It may also be used as an analysis tool to map the development and emergence from new industries.\n The technology roadmapping process may be conducted in three phases: preliminary activities, the development of the roadmap, and the follow-up activities phase.  Because the process is too big for one model, the phases are modeled separately. In the models no different roles are made; this is because everything is done by the   as a group. \n The first phase, the preliminary phase (see figure 2), consists of three steps:\n In this phase the key decision makers must identify that they have a problem and that technology roadmapping can help them in solving the problem.\n In this step it must become clear what the conditions are (they must be identified) and if they are not met, who takes actions to meet them. These conditions include, for example:  \n All conditions should be satisfied (or an agreed-on party takes necessary actions) to continue to the next step. The participants can have zero or more conditions of their own. It applies to all conditions that have the attribute to be met or not.\n Committed leadership is needed because of the time and effort involved in creating a technology roadmap. Additionally the   should come from one of the participants, one of them provides leadership and sponsorship. This means that the line organization must drive the process and use the roadmap to make   decisions. \n In this step the context for the roadmap is specified. In the company a   should exist and it must be clear that the roadmap can support that vision. If the vision does not exist one should be developed and clearly stated. When that is done the boundaries and the   of the roadmap should be specified. Furthermore, the   and the level of details should be set. The scope can be further divided into the technology scope and the participation scope.\n In table 1 all the different sub-activities of the preliminary activity phase can be seen. All the sub-activities have concepts as end products (marked in  ). These concepts are the actual  , which is an adjusted  . \n The second phase, the development of the technology roadmap phase (see figure 3.), consists of 7 steps:\n 1. Identify the \"product\" that is the focus of the roadmap, \n 2. Identify the critical system requirements and their targets, \n3. Specify the major technology areas, \n4. Specify the technology drivers and their targets, \n5. Identify technology alternatives and their timelines, \n6. Recommend the technology alternatives that should be pursued, and \n \n7. create the technology roadmap report. In this step the common product needs are identified and are agreed on by all the participants. This is important to get the acceptance of all groups for the process. In case of uncertainty of the product needs   can be used to determine the common product needs. In figure 3, the participants and possibly the scenario-based planning provide the common product needs.\n Once it is decided what must be roadmapped, the critical   can be identified; they provide the overall framework for the technology roadmap. The requirements can have targets (as an attribute in figure 3) like reliability and costs.\n These are the areas that help achieve critical system requirements. For each technology area several   can be found. Example technology areas are: market assessment, crosscutting technology, component development, and system development.\n In this step the critical system requirements from the second step are transformed into technology drivers (with targets) for the specific technology area. These drivers are the critical variables that select the technology alternatives. Drivers depend on the technology areas but they relate to how the technology addresses the critical system requirements.\n At this point the technology drivers and their targets are specified and the technology alternatives that can satisfy those targets should be specified. For each of the alternatives a timeline should be estimated for how it will mature with respect to the technology driver targets.\n The time factor can be adapted suitable for the particular situation. The time horizons for   and   related sectors are usually short. Other distinctions can be made on scale and intervals.\n Because the alternatives may differ in costs, timeline, etc., a selection must be made of the alternatives. These are the alternatives to pursue in figure 3. In this step a lot of   must be made between different alternatives for different targets: for example, performance over costs and even target over target.\n At this point the technology roadmap is finished. In figure 3, it can be seen that the technology roadmap report consists of 5 parts:\n The report can also include additional information. In table 2 all the different sub-activities of the development phase can be seen.\n This is the moment when the roadmap must be critiqued, validated and hopefully accepted by the group involved in any implementation. This requires a plan developed using the technology roadmap. Next, there must be a periodical review and update point, because needs from the participants and the technologies evolve.\n Given the potential complexity and organisational inertia surrounding the creation of roadmaps, researchers at the University of Cambridge  focused on developing a fast-start approach to roadmapping.  This approach, called T-Plan, was created in the late 1990s primarily to help organisations take the first step into roadmapping with minimal resource and time commitment. It has been influential in the propagation and uptake of roadmapping internationally including translations of the T-Plan workbook  into Chinese (traditional & modern), German, Japanese and Spanish. The approach (as well as its counterpart for innovation and strategy roadmapping, S-Plan) is flexible and scalable, and therefore can be easily customised for efficient application.  Fast and lean approaches are particularly important for small and medium enterprises (SME) and have been shown to work in particularly to give directions to clusters of SMEs. \n The process of technology roadmapping fits into  , corporate  , technology planning and the   context. Three critical elements should be connected: needs, products, and technology.\n Creating a technology roadmap requires certain knowledge and skills. Some of the participants must know the purpose of technology roadmapping. Next to this group-process and interpersonal skills are required since the process includes a lot of discussions and finding out what the common need is. If the number of participants is really large there might be need for a   or facilitator.\n This is the most common type of a technology roadmap: linking the insertion of technologies into products.\n This type is more directed to the implementation of strategy and related to project planning. Figure 5 shows the relationships between technology development phases, programme phases and milestones.\n Documented case studies include:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Elsevier_Science", "title": "Elsevier", "content": "\n  (   ) is a Dutch   company specializing in scientific, technical, and medical content. Its products include journals such as  ,  , the   collection of  ,  , the   series, the online citation database  , the SciVal tool for measuring research performance, the ClinicalKey search engine for clinicians, and the ClinicalPath evidence-based cancer care service. Elsevier's products and services include digital tools for  , instruction, research analytics, and assessment.  Elsevier is part of the  , known until 2015 as Reed Elsevier, a publicly traded company. According to RELX reports, in 2022 Elsevier published more than 600,000 articles annually in over 2,800 journals;  as of 2018 its archives contained over 17 million documents and 40,000  , with over one billion annual downloads. \n Researchers have criticized Elsevier for its high profit margins and  .  The company had a reported profit before tax of £2,295 million with an adjusted   of 33.1% in 2023.  Much of the research that Elsevier publishes is publicly funded; its high costs have led to accusations of  ,  boycotts, and the rise of alternate avenues for publication and access, such as   servers and  . \n Elsevier was founded in 1880  and adopted the name and logo from the   publishing house   that was an inspiration but has no connection to the contemporary Elsevier.  The Elzevir family operated as booksellers and publishers in the  ; the founder,   (1542–1617), lived in   and established that business in 1580. As a company logo, Elsevier used the Elzevir family's  , a tree entwined with a vine and the words  , which is   for \"not alone\".  According to Elsevier, this logo represents \"the symbiotic relationship between publisher and scholar\". \n The expansion of Elsevier in the scientific field after 1945 was funded with the profits of the newsweekly  , which published its first issue on 27 October 1945. The weekly was an instant success and very profitable.  The weekly was a continuation, as is stated in its first issue, of the monthly  , which was founded in 1891 to promote the name of the publishing house and had to stop publication in December 1940 because of the  . \n In May 1939 Klautz established the Elsevier Publishing Company Ltd. in London to distribute these academic titles in the   (except Canada). When the   for the duration of five years from May 1940, he had just founded a second international office, the Elsevier Publishing Company Inc. in  . \n In 1947, Elsevier began publishing its first English-language journal,  . \n In 1971 the firm acquired  ,a small medical abstract publisher based in  .  As the first and only company in the world that employed a database for the production of journals, it introduced computer technology to Elsevier.  In 1978 Elsevier merged with Dutch newspaper publisher NDU, and devised a strategy to broadcast textual news to people's television sets through   and   technology. \n In 1979 Elsevier Science Publishers launched the Article Delivery Over Network Information System (ADONIS) project in conjunction with four business partners. The project aims to find a way to deliver scientific articles to libraries electronically, and would continue for over a decade.  In 1991, in conjunction with nine American universities, Elsevier's The University Licensing Project (TULIP) was the first step in creating published, copyrighted material available over the Internet. It formed the basis for  , launched six years later.  In 1997, after almost two decades of experiments, ScienceDirect was launched as the first online repository of electronic (scientific) books and articles. Though librarians and researchers were initially hesitant regarding the new technology, more and more of them switched to e-only subscriptions. \n In 2004 Elsevier launched   - a multidisciplinary metadata database of scholarly publications, only the second of such kind (after the  , although free   was also launched in 2004).   covers journals, some conference papers and books from various publishers, and measures performance on both author and publication levels.  In 2009 SciVal Spotlight was released. This tool enabled research administrators to measure their institution's relative standing in terms of productivity, grants, and publications . \n In 2013, Elsevier acquired  , a UK company making software for managing and sharing research papers. Mendeley, previously an open platform for sharing of research, was greatly criticized for the sale, which users saw as acceding to the \" \" approach to research literature. Mendeley's previously open-sharing system now allows exchange of paywalled resources only within private groups.    described Elsevier's reasons for buying Mendeley as two-fold: to acquire its user data, and to \"destroy or coöpt an   icon that threatens its  \". \n During 2018 , researchers submitted over 1.8 million   to Elsevier-based publications. Over 20,000 editors managed the peer review and selection of these papers, resulting in the publication of more than 470,000 articles in over 2,500 journals.  Editors are generally unpaid volunteers who perform their duties alongside a full-time job in academic institutions,  although exceptions have been reported. In 2013, the five editorial groups Elsevier,  ,  ,  , and   published more than half of all academic papers in the peer-reviewed literature.  At that time, Elsevier accounted for 16% of the world market in science, technology, and medical publishing.  In 2019, Elsevier accounted for the review, editing and dissemination of 18% of the world's scientific articles.  About 45% of revenue by geography in 2019 derived from North America, 24% from Europe, and the remaining 31% from the rest of the world. Around 84% of revenue by format came from electronic usage and 16% came from print. \n The firm employs 8,100 people.  The CEO is Kumsal Bayazit, who was appointed on 15 February 2019.  In 2018, it reported a mean 2017   of 29.1% for its UK workforce, while the median was 40.4%, the highest yet reported by a publisher in UK. Elsevier attributed the result to the under-representation of women in its senior ranks and the prevalence of men in its technical workforce.  The UK workforce consists of 1,200 people in the UK, and represents 16% of Elsevier's global employee population.  Elsevier's parent company, RELX, has a global workforce that is 51% female to 49% male, with 43% female and 57% male managers, and 29% female and 71% male senior operational managers. \n In 2018, Elsevier accounted for 34% of the revenues of RELX group (£2.538 billion of £7.492 billion). In  , it represented 40% (£942 million of £2,346 million). Adjusted operating profits (with constant currency) rose by 2% from 2017 to 2018.  Profits grew further from 2018 to 2019, to a total of £982 million.  the first half of 2019, RELX reported the first slowdown in revenue growth for Elsevier in several years: 1% vs. an expectation of 2% and a typical growth of at least 4% in the previous 5 years.  Overall for 2019, Elsevier reported revenue growth of 3.9% from 2018, with the underlying growth at constant currency at 2%.  In 2019, Elsevier accounted for 34% of the revenues of RELX (£2.637billion of £7.874billion). In adjusted  , it represented 39% (£982m of £2.491bn). Adjusted operating profits (with constant currency) rose by 2% from 2018 to 2019. \n In 2019, researchers submitted over two million   to Elsevier-based publications. Over 22,000 editors managed the peer review and selection of these papers, resulting in the publication of about 500,000 articles in over 2,500 journals. \n In 2020 Elsevier was the largest academic publisher, with approximately 16% of the academic publishing market and more than 3000 journals. \n Products and services include electronic and print versions of journals, textbooks and  , and cover the  , life, physical, and  .\n The target markets are academic and government research institutions, corporate research labs, booksellers, librarians, scientific researchers, authors, editors, physicians, nurses, allied health professionals, medical and nursing students and schools, medical researchers,  , hospitals, and research establishments. It publishes in 13 languages including English, German, French, Spanish, Italian, Portuguese, Polish, Japanese, Hindi, and Chinese.\n Flagship products and services include VirtualE,  ,  ,  ,  , Engineering Village,  ,  , Knovel, SciVal, Pure, and Analytical Services, The Consult series (FirstCONSULT, PathCONSULT, NursingCONSULT, MDConsult, StudentCONSULT), Virtual Clinical Excursions, and major reference works such as  ,  ,  ,  , and online versions of many journals  including  .\n ScienceDirect is Elsevier's platform for online electronic access to its journals and over 40,000 e-books, reference works, book series, and handbooks. The articles are grouped in four main sections:  ,  ,  , and  . For most articles on the website, abstracts are freely available; access to the full text of the article (in PDF, and also HTML for newer publications) often requires a subscription or pay-per-view purchase. \n In 2019, Elsevier published 49,000 free   articles and 370 full open access journals. Moreover, 1,900 of its journals sold   options. \n The subscription rates charged by the company for its journals have been criticized; some very large journals (with more than 5,000 articles) charge subscription prices as high as £9,634, far above average,  and many British universities pay more than a million pounds to Elsevier annually.  The company has been criticized not only by advocates of a switch to the   publication model, but also by universities whose library budgets make it difficult for them to afford current journal prices.\n For example, in 2004, a resolution by  's senate singled out Elsevier's journals as being \"disproportionately expensive compared to their educational and research value\", which librarians should consider dropping, and encouraged its faculty \"not to contribute articles or editorial or review efforts to publishers and journals that engage in exploitive or exorbitant pricing\".  Similar guidelines and criticism of Elsevier's pricing policies have been passed by the  ,  , and  . \n In July 2015, the    threatened to boycott Elsevier, which refused to negotiate on any   policy for Dutch universities.  After a year of negotiation, Elsevier pledged to make 30% of research published by Dutch researchers in Elsevier journals open access by 2018. \n In October 2018, a complaint against Elsevier was filed with the European Commission, alleging anticompetitive practices stemming from Elsevier's confidential subscription agreements and market dominance. The European Commission decided not to investigate. \n The elevated pricing of field journals in economics, most of which are published by Elsevier, was one of the motivations that moved the   to launch the   in 2009. \n RELX Group has been   in  . Elsevier has incorporated other businesses that were either complementing or competing in the field of research and publishing and that reinforce its  ,  such as   (after the closure of  ),  ,   / ,  , Hivebench, Newsflo, Science-Metrix,  and  . \n Elsevier also conducts conferences, exhibitions, and workshops around the world, with over 50 conferences a year covering life sciences, physical sciences and engineering, social sciences, and health sciences. \n According to the  , in 2009, the firm [Elsevier] offered a £17.25 Amazon voucher to academics who contributed to the textbook   if they would go on   and   (a large US books retailer) and give it five stars. Elsevier responded by stating \"Encouraging interested parties to post book reviews isn't outside the norm in scholarly publishing, nor is it wrong to offer to nominally compensate people for their time. But in all instances the request should be unbiased, with no incentives for a positive review, and that's where this particular e-mail went too far\", and that it was a mistake by a marketing employee. \n Elsevier seeks to regulate   with private licenses,  claiming that reading requires extra permission if automated and that the publisher holds copyright on  . The conflict on research and copyright policy has often resulted in researchers being blocked from their work.  In November 2015, Elsevier blocked a scientist from performing   research at scale on Elsevier papers, even though his institution already pays for access to Elsevier journal content.  The data was collected using the   package \"statcheck\". \n Elsevier is one of the most prolific publishers of books aimed at expanding the production of  . Since at least 2010 the company has worked with the fossil fuel industry to optimise fossil fuel extraction. It commissions authors, journal advisory board members and editors who are employees of the largest oil firms. In addition it markets data services and research portals directly to the fossil fuel industry to help \"increase the odds of exploration success\". \n In 2013, one of Elsevier's journals was caught in the sting set up by  , published in  , called \"Who's Afraid of Peer Review?\"  The journal   accepted an obviously bogus paper made up by Bohannon that should have been rejected by any good peer-review system.  Instead,   was among many open-access journals that accepted the fake paper for publication. As of 2014, this journal had been transferred to a different publisher. \n At a 2009 court case in Australia where   was being sued by a user of  , the plaintiff alleged that Merck had paid Elsevier to publish the  , which had the appearance of being a peer-reviewed   but in fact contained only articles favourable to Merck drugs.  Merck described the journal as a \"complimentary publication\", denied claims that articles within it were   by Merck, and stated that the articles were all reprinted from peer-reviewed medical journals.  In May 2009, Elsevier Health Sciences CEO Hansen released a statement regarding Australia-based sponsored journals, conceding that they were \"sponsored article compilation publications, on behalf of pharmaceutical clients, that were made to look like journals and lacked the proper disclosures.\" The statement acknowledged that it \"was an unacceptable practice.\"    reported that, according to an Elsevier spokesperson, six sponsored publications \"were put out by their Australia office and bore the   imprint from 2000 to 2005,\" namely the   ( ), the   ( ), the   ( ), the   ( ), the   ( ), and the   ( ).  Excerpta Medica was a \"strategic medical communications agency\" run by Elsevier, according to the imprint's web page.  In October 2010, Excerpta Medica was acquired by Adelphi Worldwide. \n There was speculation  that the editor-in-chief of Elsevier journal  ,  , misused his power to publish his own work without appropriate peer review. The journal had published 322 papers with El Naschie as author since 1993. The last issue of December 2008 featured five of his papers.  The controversy was covered extensively in blogs.  The publisher announced in January 2009 that El Naschie had retired as editor-in-chief.  As of November 2011  the co-Editors-in-Chief of the journal were Maurice Courbage and Paolo Grigolini.  In June 2011, El Naschie sued the journal   for libel, claiming that his reputation had been damaged by their November 2008 article about his retirement, which included statements that   had been unable to verify his claimed affiliations with certain international institutions.  The suit came to trial in November 2011 and was dismissed in July 2012, with the judge ruling that the article was \"substantially true\", contained \"honest comment\", and was \"the product of responsible journalism\". The judgement noted that El Naschie, who represented himself in court, had failed to provide any documentary evidence that his papers had been peer-reviewed.  Judge   also found \"reasonable and serious grounds\" for suspecting that El Naschie used a range of false names to defend his editorial practice in communications with  , and described this behavior as \"curious\" and \"bizarre\". \n Elsevier's 'Duties of Authors' states that authors should ensure they have written entirely original works, and that proper acknowledgement of others' work must always be given. Elsevier claims plagiarism in all its forms constitutes unethical behaviour.  Some Elsevier journals automatically screen submissions for plagiarism,  but not all. \n Albanian politician Taulant Muka claimed that Elsevier journal   had plagiarized in the abstract of one of its articles. It is unclear whether or not Muka had access to the entirety of the article. \n  has criticized the two Elsevier journals   and   for having included on their editorial boards such well-known proponents of   as   and  ; in response to her inquiries, Elsevier defended their presence as editors.  The journal   has been criticized for having \"occasionally included papers with pseudoscientific findings about intelligence differences between races.\"  It is the official journal of the  , which organizes the controversial series of conferences  , described by the   as a forum for scientific racism. \n In response to a 2019 open letter, efforts by   and a petition signed by over 1000 people, on 17 June 2020 Elsevier announced it was retracting an article that   and   published in 2012 in the Elsevier journal  .  The article had claimed that there was scientific evidence that skin color was related to aggression and sexuality in humans. \n One of their journals,  , was involved in the manipulation of the peer review report. \n According to the signatories of the   (see also  ), commercial academic publishers benefit from manipulation of   and  , such as the  . The impact factor, which is often used as a   of  , can influence revenues, subscriptions, and academics' willingness to contribute unpaid work.  However, there's evidence suggesting that reliability of published research works in several fields may   with increasing journal rank. \n Nine Elsevier journals, which exhibited unusual levels of  , had their journal impact factor of 2019 suspended from   in 2020, a sanction which hit 34 journals in total. \n In 2023, the International Journal of Hydrogen Energy, which is published by Elsevier, was criticized for desk-rejecting a submitted article for the main reason that it did not cite enough articles from the same journal. \n The editorial boards of a number of journals have resigned because of disputes with Elsevier over pricing:\n Editorial boards have also resigned over open access policies or other issues:\n In 2003, various university librarians began coordinating with each other to complain about Elsevier's \" \" journal bundling packages, in which the company offered a group of journal subscriptions to libraries at a certain rate, but in which librarians claimed no economical option was available to subscribe to only the popular journals at a rate comparable to the bundled rate.  Librarians continued to discuss the implications of the pricing schemes, many feeling pressured into buying the Elsevier packages without other options. \n On 21 January 2012, mathematician   publicly announced he would boycott Elsevier, noting that others in the field have been doing so privately. The reasons for the   are high subscription prices for individual journals, bundling subscriptions to journals of different value and importance, and Elsevier's support for  ,  , and the  , which would have prohibited open-access mandates for U.S. federally-funded research and severely restricted the sharing of scientific data. \n Following this, a petition advocating noncooperation with Elsevier (that is, not submitting papers to Elsevier journals, not refereeing articles in Elsevier journals, and not participating in journal editorial boards), appeared on the site \"The Cost of Knowledge\". By February 2012, this petition had been signed by over 5,000 academics,  growing to over 17,000 by November 2018.  The firm disputed the claims, claiming that their prices are below the industry average, and stating that bundling is only one of several different options available to buy access to Elsevier journals.  The company also claimed that its profit margins are \"simply a consequence of the firm's efficient operation\".  The academics replied that their work was funded by public money, thus should be freely available.\n On 27 February 2012, Elsevier issued a statement on its website that declared that it has withdrawn support from the Research Works Act.  Although the Cost of Knowledge movement was not mentioned, the statement indicated the hope that the move would \"help create a less heated and more productive climate\" for ongoing discussions with research funders. Hours after Elsevier's statement, the sponsors of the bill,     and  , issued a joint statement saying that they would not push the bill in Congress. \n The   open-access initiative, which began in Europe and has since spread to some US research funding agencies, would require researchers receiving some grants to publish in open-access journals by 2020.  A spokesman for Elsevier said \"If you think that information should be free of charge, go to  \".  In September 2018,   advised to sell Elsevier (RELX) stocks, noting that Plan S could affect 5-10% of scientific funding and may force Elsevier to reduce pricing. \n In 2015, Finnish research organizations paid a total of 27 million euros in subscription fees. Over one-third of the total costs went to Elsevier. The information was revealed after successful court appeal following a denied request on the subscription fees, due to confidentiality clauses in contracts with the publishers.  Establishing of this fact lead to creation of tiedonhinta.fi petition demanding more reasonable pricing and open access to content signed by more than 2800 members of the research community.  While deals with other publishers have been made, this was not the case for Elsevier, leading to the nodealnoreview.org boycott of the publisher signed more than 600 times. \n In January 2018, it was confirmed that a deal had been reached between those concerned. \n The French   agreed in 2019 to a 4-year contract with Elsevier,  despite criticism from the scientific community. \n The French   has stopped having Elsevier publish the journal   (as of 2008). \n Effective on 1 January 2020, the   stopped publishing its 7 journals   with Elsevier and switched to  . \n Since 2018 and as of 2023,  almost no academic institution in Germany is subscribed to Elsevier. \n Germany's DEAL project ( ), which includes over 60 major research institutions, has announced that all of its members are cancelling their contracts with Elsevier, effective 1 January 2017. The boycott is in response to Elsevier's refusal to adopt \"transparent business models\" to \"make publications more openly accessible\".  Horst Hippler, spokesperson for the DEAL consortium states that \"taxpayers have a right to read what they are paying for\" and that \"publishers must understand that the route to open-access publishing at an affordable price is irreversible\".  In July 2017, another 13 institutions announced that they would also be cancelling their subscriptions to Elsevier journals.  In August 2017, at least 185 German institutions had cancelled their contracts with Elsevier.  In 2018, whilst negotiations were ongoing, around 200 German universities that cancelled their subscriptions to Elsevier journals were granted complimentary open access to them until this ended in July of the year. \n On 19 December 2018, the   (MPS) announced that the existing subscription agreement with Elsevier would not be renewed after the expiration date of 31 December 2018. MPS counts 14,000 scientists in 84 research institutes, publishing 12,000 articles each year. \n In 2023 Elsevier and DEAL reached a tentative agreement on a  , which would take effect until 2028 if at least 70% of the eligible institutions opt into it. \n In March 2018, the Hungarian   entered negotiations on its 2019 Elsevier subscriptions, asking for a read-and-publish deal.  Negotiations were ended by the Hungarian consortium in December 2018, and the subscription was not renewed. \n In 2013, Elsevier changed its policies in response to sanctions announced by the US   that year. This included a request that all Elsevier journals avoid publishing papers by Iranian nationals who are employed by the Iranian government.  Elsevier executive Mark Seeley expressed regret on behalf of the company, but did not announce an intention to challenge this interpretation of the law. \n CRUI (an association of Italian universities) sealed a 5-year-long deal for 2018–2022,  despite protests from the scientific community, protests focused on aspects such as the lack of prevention of cost increases by means of the  . \n In 2015, a consortium of all of Netherlands' 14 universities threatened to boycott Elsevier if it could not agree that articles by Dutch authors would be made open access and settled with the compromise of 30% of its Dutch papers becoming open access by 2018. Gerard Meijer, president of   in   and lead negotiator on the Dutch side noted, \"it's not the 100% that I hoped for\". \n In March 2019, the Norwegian government on behalf of 44 institutions — universities, university colleges, research institutes, and hospitals — decided to break negotiations on renewal of their subscription deal with Elsevier, because of disagreement regarding open-access policy and Elsevier's unwillingness to reduce the cost of reading access. \n In 2017, over 70 university libraries confirmed a \"contract boycott\" movement involving three publishers including Elsevier. As of January 2018, whilst negotiations remain underway, a decision will be made as to whether or not continue the participating libraries will continue the boycott.  It was subsequently confirmed that an agreement had been reached. \n In May 2018, the  , which negotiates license agreements on behalf of all Swedish universities and research institutes, decided not to renew their contract with Elsevier,  alleging that the publisher does not meet the demands of transition towards a more open-access model, and referring to the rapidly increasing costs for publishing.  Swedish universities will still have access to articles published before 30 June 2018. Astrid Söderbergh Widding, chairman of the Bibsam Consortium, said, \"the current system for scholarly communication must change and our only option is to cancel deals when they don't meet our demands for a sustainable transition to open access\".  Sweden has a goal of open access by 2026.  In November 2019 the negotiations concluded, with Sweden paying for reading access to Elsevier journals and open access publishing for all its researchers' articles. \n In Taiwan, more than 75% of universities, including the country's top 11 institutions, have joined a collective boycott against Elsevier. On 7 December 2016, the Taiwanese consortium, CONCERT, which represents more than 140 institutions, announced it would not renew its contract with Elsevier. \n In March 2018,  's faculty elected to cancel its $2 million subscription to a bundle of several journals. Starting in 2019, it will instead buy access to titles . \n In February 2019, the   said it would terminate subscriptions \"in [a] push for open access to publicly funded research.\"  After months of negotiations over open access to research by UC researchers and prices for subscriptions to Elsevier journals, a press release by the UC Office of the President issued Thursday, 28 February 2019 stated \"Under Elsevier's proposed terms, the publisher would have charged UC authors large publishing fees on top of the university's multimillion dollar subscription, resulting in much greater cost to the university and much higher profits for Elsevier.\"  On 10 July 2019, Elsevier began restricting access to all new paywalled articles and approximately 5% of paywalled articles published before 2019. \n In April 2020, the   elected not to renew its bundled Elsevier package, citing a failure \"to provide an affordable path\".  Rather than extend the license, which was stated to cost $2.6 million annually, the university decided to continue subscribing to a smaller set of individual journals. The   Libraries Consortium also announced similar outcome,  with the help of estimates from  .  Similarly,   announced in June 2020 that it would no longer pay for access to new Elsevier articles. \n In 2022 Elsevier and the   established an agreement to support authors who wish to publish open access. \n In June 2020 the Ukrainian government cancelled subscriptions for all universities in the country after failed negotiations. The Ministry of Education stated that Elsevier indexes journals in its register which call themselves Russian but are from occupied territories. \n Elsevier have been known to be involved in lobbying against open access.  These have included the likes of:\n In 2014, 2015, 2016, and 2017,  Elsevier was found to be selling some articles that should have been open access, but had been put behind a paywall.  A related case occurred in 2015, when Elsevier charged for downloading an open-access article from a journal published by  . However, whether Elsevier was in violation of the license under which the article was made available on their website was not clear. \n In 2013,  , a company representing Elsevier, told the   to remove articles published by faculty authors on university web pages; although such   of academic articles may be legal under the   provisions in Canadian  ,  the university complied.   and the   also received   for self-archived academic articles, a first for Harvard, according to  . \n Months after its acquisition of   rival  , Elsevier sent thousands of takedown notices to Academia.edu, a practice that has since ceased following widespread complaint by academics, according to Academia.edu founder and chief executive Richard Price. \n After Elsevier acquired the repository   in May 2016, academics started complaining that some of their work has been removed without notice. The action was explained as a technical error. \n In 2015, Elsevier filed a lawsuit against the sites   and  , which make copyright-protected articles available for free. Elsevier also claimed illegal access to institutional accounts. \n Among the major academic publishers, Elsevier alone declined to join the  . In the context of the resignation of the   editorial board, the firm stated: \"Elsevier invests significantly in citation extraction technology. While these are made available to those who wish to license this data, Elsevier cannot make such a large corpus of data, to which it has added significant value, available for free.\" \n Elsevier finally joined the initiative in January 2021 after the data was already available with an   license in  . \n A chamber of the Munich Regional Court has ruled that the research networking site ResearchGate has to take down articles uploaded without consent from their original publishers and   must take down Elsevier articles. A case was brought forward in 2017 by the  , a group of publishers that includes Elsevier and the  . \n In September 2024,  , a neuroscience professor at  , sued Elsevier along with five other   publishers in a proposed   lawsuit, alleging that the publishers violated   law by agreeing not to compete against each other for manuscripts and by denying scholars payment for   services. \n Elsevier has partnered with a number of organisations and lent its name to several awards.\n Since 1987, Elsevier has partnered with the academic journal   to award the Elsevier / Spectrochimica Acta Atomic Spectroscopy Award. This award is given each year for a jury-selected best paper of the year. The award is worth $1000. \n Starting in 1987, the   was awarded in 1992, 1995, 1998, 2001, 2003, 2005, 2007 by the   in partnership with Elsevier, \"for outstanding research and teaching throughout their career by an IBMS member in the fields of bone and mineral metabolism\". \n From 2007, the   (CAPES) in Brazil partnered with Elsevier to award the CAPES Elsevier Award, the award being restricted to women from 2013 to encourage more women to pursue scientific careers. Several awards were awarded each year, as of 2014. \n From 2011, the   (OWSD-Elsevier Foundation Awards) have been awarded annually to early-career women scientists in selected developing countries in four regions:   and the  ,   and     and the  ,   and   Asia, and  . The   (OWSD), the Elsevier Foundation, and   first partnered to recognize achievements of early-career women scientists in developing countries in 2011. \n In 2016, the Elsevier Foundation awarded the Elsevier Foundation-ISC3 Green and Sustainable Chemistry Challenge. From 2021 and as of 2024 , the annual award is known as the Elsevier Foundation Chemistry for Climate Action Challenge. Two prizes have been awarded each year; until 2020, the first prizewinner was awarded €50,000, and the second prize was €25,000. Since then, €25,000 has been awarded to each winner, usually an entrepreneur who has created a project or proposal that aids the fight against  . \n Elsevier uses its   (that is,   used in publishing) to market to different consumer segments. Many of the imprints have previously been the names of publishing companies that were purchased by Reed Elsevier.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Richard_Raysman", "title": "Richard Raysman", "content": " (born October 9, 1946), is a   and a founding practitioner of American  , later expanded to become  .\n Raysman was born in  , the son of Victor Raysman, a businessman, and Irene Davies Raysman, a professor.  He grew up in  , a suburb of New York City, attending  .  Raysman received a B.S. in 1968 from the  , where he majored in   at the   and minored in computer science.\n After graduation from  , Raysman worked for the   as a   for six years, based in New York City.  In that capacity he guided the   departments of major corporations in implementing new computer systems and upgrading to more advanced  .  He programmed in   such as Assembler,  ,   and  .\n While working for IBM Raysman attended   at night.  During that time he joined the  , where he served in the   for six years, doing his basic training at Fort Gordon, in Augusta, Georgia.\n Being a systems engineer as well as a lawyer, Raysman realized that the law relating to the purchase and use of computer hardware and   was as yet undeveloped.  Although academic articles relating to computer law were starting to appear in  , there were no law firms professing to practice in it.  Since the use of computers in a business context was increasing exponentially, Raysman decided, in 1978, to start his own firm in New York City specifically to counsel companies in those transactions.  As part of his effort to distinguish the acquisition of software and hardware as an area of the law requiring specific knowledge and expertise, in the following years Raysman wrote articles for the  ,  the  ,  and the  , where in 1981 he became \"co-author\" of the first monthly column on Computer Law, written by associates under his byline.  The New York Times twice cited Raysman as a legal expert on patents and software . \n During the last two decades of the 20th century computer law expanded to include issues relating to  , protection of intellectual property on the internet,   law and information technology employment issues such as  .  These areas of the law are now encompassed in the term Intellectual Property Law.\n Raysman's firm, known as Brown, Raysman & Millstein, ultimately grew to 250 lawyers with offices in New York,  ,  ,   and  .  In 2006 Brown Raysman Millstein Felder & Steiner, as it was then known, merged with the San Francisco law firm of   and became known as Thelen Reid Brown Raysman & Steiner, having 650 attorneys and offices worldwide.  In 2008 Raysman left Thelen, when the firm disbanded.  He then practiced at the New York office of   until December 2020.\n Raysman concentrates his practice in international outsourcing transactions.  Raysman has litigated numerous reported cases for the New York State and Federal courts.  He has been selected by Chambers as one of America's leading outsourcing lawyers. \n Raysman continues to publish extensively on the topic of Intellectual Property Law, including three ghost-written treatises as well as newsletters and the monthly column that appears under his byline in the New York Law Journal.  He is also a regular speaker in this field at numerous conferences, including those sponsored by the  , the Outsourcing Interests Group and the Intellectual Technology Law Forum in Europe.\n Raysman is admitted to the New York and Connecticut State bars, the  , the   for the Second Circuit and the   for the Eastern and Southern Districts of New York.\n Raysman is married to the former Georgia M. Urbano, a graduate of the Columbia University School of Law and Connecticut College, who is also the former President and Chairman of the Nantucket Preservation Trust.  He has four children. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Ron_Howard", "title": "Ron Howard", "content": "\n\n  (born March 1, 1954) is an American director, producer, screenwriter, and actor. Howard started his career as a   before transitioning to directing films. Over his six-decade career, Howard has received  , including two  , six  , two  , and a  . He was awarded the   in 2003 and was inducted into the   in 2013.  He has two stars on the   for his contributions in film and television.\n Howard first came to prominence as a child actor, acting in several television series before gaining national attention for playing young  , the son of Sheriff   (played by  ) in the sitcom   from 1960 through 1968. During this time, he also appeared in the musical film   (1962), a critical and commercial success. Howard was cast in one of the lead roles in the influential coming-of-age film   (1973), and became a household name for playing   in the sitcom   (1974–1980).  He starred in the films   (1974),   (1976), and   (1977), the latter being his directorial film debut. \n In 1980, Howard left   to focus on directing, producing, and sometimes writing a variety of films and television series. His films included the comedies   (1982),   (1984), and   (1985) as well as the fantasy   (1988), the thriller   (1991), and the newspaper     (1994). Howard went on to win the   and   for   (2001) and was nominated again for the same awards for   (2008).  Howard also directed other historical dramas such as   (1995),   (2005),   (2013),   (2015) and   (2022).\n He also directed the children's     (2000), the comedy   (2011), and   (2018), as well as the  :   (2006),   (2009), and   (2016). Howard has gained recognition for directing numerous documentary films such as   (2016),   (2019), and   (2022).\n Ron Howard was born on March 1, 1954, in  , the elder of the two sons of  , a director, writer, and actor and  , an actress. He is of German, English, Scottish, Irish, and Dutch ancestry.  His father was born with the surname \"Beckenholdt\" and took the stage name \"Howard\" in 1948 for his acting career.  Rance Howard was serving three years in the   at the time of Ron's birth. \n Howard was tutored at   in his younger years but continued his schooling at Robert Louis Stevenson Elementary and David Starr Jordan Junior High in   when not working in television, eventually graduating from Burbank's  . He later attended the  's   but did not graduate.  Howard has said he knew from a young age he might want to go into directing, thanks to his early experience as an actor. \n In 1959, Howard had his first credited film role in  . He appeared in  's       in the episode \"Child Lost\"; in   episode \" \"; a few episodes of the first season of the sitcom  , as Stewart, one of Dennis's friends; and several first- and second-season episodes of  . Howard played \"Timmy\" (uncredited) in \"Counterfeit Gun\", Season 4, Episode 2 (1960) of the TV series,  .\n In 1960, Howard was cast as   in  . Credited as \"Ronny Howard\", he portrayed the son of the main character (played by  ) for all eight seasons of the show. Recalling his experiences as a child actor on set, he commented\n I was five years old. And I was preoccupied with the prop that was in my hand, because it was a toy turtle. But I had to pretend it was a real turtle that the audience just wasn't seeing, and it was dead, so I was supposed to be crying and very emotional, and I remember him looking at that little turtle and talking to me about how it was kind of funny to have to pretend that was dead. So I recall just a very relaxed first impression. The sitcom was known for its old-fashioned wholesome quality. Even though it was set in a contemporary time period it evoked a mood of a different era from that of the 1960s. The series also starred  ,   and  . It received numerous nominations for the   including three   nominations which it lost to   in 1961,   in 1962, and   in 1967.\n A role in an installment of series  , titled \"Love and the Television Set\",  led to his being cast as   in the TV series   (for syndication, the segment was re-titled \"Love and the Happy Days\"). Beginning in 1974, he played the likable \"buttoned-down\" boy, in contrast to  's \" \"  . On the   set, he developed an on- and off-screen chemistry with Winkler.  Howard left   to become a film director just before the start of its eighth season in 1980, but returned for guest appearances in the show's eleventh season (1983–1984). \n In the 1962 film version of  , Howard played  , the child with the lisp; the film starred  ,  , and  . The film was based on the   by  . The film was directed by   who previously helmed the 1958 film   starring  . The film was a critical and commercial success becoming the  . The film went on to receive six   nominations including for  .\n He also starred in the 1963 film   with   and Jones. He guest-starred as Tommy in the twelfth episode of the first season of   and he appeared as Barry Stewart on   in 1965; on   in the 1966 episode \"Little Boy Lost\"; as  's son in an ABC series,  , in 1968; as Jodah in   in 1969; as a boy whose father was shot on   in 1971–72; and as an underage   on   in the episode \" \" in 1973. In the 1970s, he appeared in at least one episode of  , as a teenage tennis player with an illness.\n Howard appeared on the 1969   album  . It featured the story of two teenagers, Mike (Howard) and Karen ( ), who get trapped inside the  .   plays the Narrator, Pete Reneday plays the Ghost Host, and Eleanor Audley plays Madame Leota. Some of the effects and ideas that were planned but never permanently made it to the attraction are mentioned here: the Raven speaks in the Stretching Room, and the Hatbox Ghost is mentioned during the Attic scene. It was reissued in 1998 as a cassette tape titled   and on CD in 2009.\n Howard played Steve Bolander in  's coming-of-age film   in 1973,  which was the inspiration for the sitcom   starring Howard. Howard starred in the film alongside  ,  , and  . Critic   of the   praised the film in his four star review writing, \"  is not only a great movie but a brilliant work of historical fiction; no sociological treatise could duplicate the movie's success in remembering exactly how it was to be alive at that cultural instant.\"  Howard reprised his role in the sequel   (1979).\n In 1974, Howard guest-starred as Seth Turner, the best friend of Jason Walton ( ), in   episode, \"The Gift\". Featured in the cast as Dr. McIvers is Ron Howard's father  .  In 1976, Howard starred alongside   and   in  's  , the story of a   gunfighter dying of cancer. (The movie was Wayne's last.)\n Howard was the narrator for   and also appeared as a cameo in later seasons.\n Before leaving   in 1980, Howard made his directing debut with the 1977   comedy/action film  , based on a script he co-wrote with his father, Rance.  This came after cutting a deal with  , wherein Corman let Howard direct a film in exchange for Howard starring in  , with  .  Howard went on to direct several TV movies for NBC between 1978 and 1982, including the 1980 TV movie,  , starring  .  His big directorial break came in 1982, with  , featuring  ,  , and Howard's   co-star  . \n Following  , Howard directed a number of major films, including the fantasy     (1984) starring  ,  ,  , and  . The film was a box office and critical success. He also directed the science fiction     (1985) starring  ,  ,  , and  . This film was also a critical and financial hit and won a Best Supporting Actor award for Don Ameche. In 1988, he reunited with George Lucas on the     film   starring   and  . Howard's final work as a director for the 1980s was the family comedy film   (1989) starring an ensemble cast that includes  ,  ,  ,  ,  ,  ,  ,  , and  . The film opened at  1 in its opening weekend, earning $10 million. It eventually grossed over $100 million domestically and $126 million worldwide.  The film was a critical hit and received two   nominations.\n Howard continued directing through the 1990s, including the American drama   revolving around firefighters. The film starred  ,  , and  . Film critics   of the   and   of the   gave the film a positive review.  In 1992, he directed the western film epic   starring   and  . Despite receiving mixed reviews from critics the film was a financial success, earning 137 million against its budget of 60 million. In 1994, Howard directed the newspaper comedy drama   with an ensemble starring  ,  ,  ,  ,  , and  . The film received rave reviews with many praising Keaton's leading performance.\n Howard's direction for the 1995   film   received praise from critics.  The film stars  ,  , and   as the three   members of the   flight crew, with supporting performances from  ,  , and  . The film was a massive financial success earning $335 million off a budget of $52 million. The film received widespread critical acclaim with   of the   praising the film in his review saying: \"A powerful story, one of the year's best films, told with great clarity and remarkable technical detail, and acted without pumped-up histrionics.\"  The film went on to receive nine   nominations including Best Picture.\n In 2000, he directed the live action children's fantasy film,   based on the   children's book. The film starred   as the titular character and featured performances from  ,  , and  , with   serving as the film's narrator. Despite the film receiving mixed reviews from critics, it was a financial success and earned $345 million at the box office. Howard's followup film was the   film   starring   as the American mathematician   who struggled with  . The film featured performances from  ,  ,  , and  . The film received positive reviews from critics who praised Crowe's and Connelly's performances. The film went on to receive eight   nominations including a win for   and a nomination and win for Howard as  . Howard was nominated alongside  ,  ,  , and  .\n In 2005, Howard directed the biographical     based on the true story of       played by Russell Crowe. The film also starred   as his wife Mae Braddock, and   as his trainer  .   gave it an approval rating of 80% based on reviews from 214 critics with an average score of 7.4/10. Its consensus states, \"With grittiness and an evocative sense of time and place,   is a powerful underdog story. And Ron Howard and Russell Crowe prove to be a solid combination.\"  Howard is also known for directing the  . The series began with   (2006) with   as Langdon, featuring performances by  ,  , and  . The sequel was   (2009) with Hanks reprising his role and performances by   and  . In 2016,   was released with Hanks continuing the role with performances by  ,  , and  . All three films received mixed reviews but were popular among audiences.\n Howard showcased the world premiere of his   film   at the   in October 2008.  The film is based on the taped conversations known as the   interviews between former United States President   and British talk show host  .   portrayed Nixon opposite   as Frost. The film was based on the   by  . The film also featured performances from  ,  ,  ,  ,  , and  . Despite losing money at the box office, the film was a critical success with website   giving the film an approval rating of 93% with the critical consensus reading, \"  is weighty and eloquent; a cross between a boxing match and a ballet with Oscar worthy performances.\"    gives the film an average score of 80 out of 100, based on 38 critics, indicating \"generally favorable reviews\".  The film received five   nominations with Howard receiving a nomination for Best Director.   praised the film declaring, \"Frost/Nixon is a riveting film, sharper, more intense than the play\". Howard was the recipient of the  's 2009 Extraordinary Contribution to Filmmaking Award.   presented him the Award.\n In 2013, Howard directed sports drama  , based on the   between two  , the British   and the Austrian   during the   motor-racing season. It was written by   and starred   as Hunt,   as Lauda, and   as  . The film premiered at the   and received positive reviews from critics. In 2015, Howard directed the film   about the sinking of the American     in 1820, an event that inspired  's 1851 novel  . The film featured performances by  ,  ,  ,  , and  . The film was a financial failure and received mixed reviews.\n Howard took over directing duties on  , a film featuring   character   in his younger years. The film was released on May 23, 2018. Howard officially replaced directors   on June 22, 2017; they were let go from their position two days earlier, reportedly due to their refusal to compromise with   over the direction of the film; reportedly the directors encouraged significant improvisations by the actors, which was believed by some at Lucasfilm to be \"shifting the story off-course\".  At the time, the film was nearly completed, with three and a half weeks left to film and another five weeks of reshoots scheduled.  Howard posted on Twitter, \"I'm beyond grateful to add my voice to the   Universe after being a fan since  . I hope to honor the great work already done & help deliver on the promise of a Han Solo film.\" \n In November 2017, Howard announced that he would be teaching his first directing class.  On November 24, 2020, Howard's drama film   was released on  . The film is   by   and was adapted for the screen by  . The film stars Academy Award nominees   and  . The film has received widespread negative reception from critics. \n In March 2021, Howard began filming the survival drama  , a film based on the   in 2018.  It was released in select theaters on July 29, 2022, by  , and began streaming on   on August 5, 2022. The film received generally positive reviews from critics. In 2022,   acquired from    , which will mark Howard's first time directing an animated feature.  and survival thriller   starting Jude Law and Ana de Amas. \n Howard is a co-chairman, with  , of  , a film and television production company. Imagine has produced several films including     and   as well as the television series       and   which Howard also narrated and later appeared in as himself.\n In July 2012, it was announced that Imagine had put into development   for  , a period drama based on the   by Spanish  . To be directed by Howard, the series was originally planned as a feature film before it was decided that the project was more suited to television. \n As part of Imagine Entertainment, he appeared in a 1997 print ad for  , in which he wore a cap for Imagine Entertainment and sported a milk mustache. Earlier versions show a younger Ronny Howard on the other side. In 2009, he appeared in the   music video \" \".\n Howard married Cheryl Alley (born December 23, 1953) on June 7, 1975.  They have four children: daughters   (born March 2, 1981),   and   (twins born February 5, 1985), and son   (born April 13, 1987).\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_ABC_radio_stations", "title": "List of ABC radio stations", "content": "\n \n\n The   (ABC) operates four national  , over 50 local  ,  the international service   and several digital stations. Most of the stations, as well as  , are available on the  ,  and ten radio stations are available via the  . \n As of 2019  there are 53   stations, including 45 regional stations and 8 capital city stations. \n The capital city (formerly: metropolitan) stations including their   are:\n The regional stations are:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Beverage_carton", "title": "Carton", "content": "\n A   is a box or container usually made of  ,   and sometimes of  .\nMany types of cartons are used in  . Sometimes a carton is also called a  .\n A carton is a type of   typically made from paperboard that is suitable for food, pharmaceuticals, hardware, and many other types of products.    are usually combined into a tube at the manufacturer and shipped flat (knocked down) to the packager. Tray styles have a solid bottom and are often shipped as flat blanks and assembled by the packager. Some also are self-erecting. High-speed equipment is available to set up, load, and close the cartons.\n  or trays are designed to protect whole eggs while in transit. Traditionally, these have been made of  . This uses recycled newsprint which is molded into a shape which protects the eggs. More recently, egg cartons have also been made from   and  .\n Cartons for liquids can be fabricated from laminates of  , foil, and polyethylene. Most are based on either   or   systems.  One option is to have the printed laminate supplied on a roll. The carton is cut, scored, and formed at the packager. A second option is to have the pre-assembled tubes delivered to the packaging plant for completion and filling. These are suited for   and are used for milk, soup, juice, etc. Paperboard-based cartons are lighter compared to a similarly sized steel can, but are harder to recycle.  Some open-loop recycling operations pelletize or flatten ground-up cartons for use in building materials; closed-loop recycling is possible by separating the layers before processing, though some recyclers only recycle the cardboard fibers. \n Perga cartons entered production in 1932 as a   during World War I. Jagenberg Werke AG, in Düsseldorf, Germany, patented the design. The carton had a ribbed texture and paper sleeves covered in paraffin material, which provided a seamed structure from base to lid. Most cartons had a capacity of 200 mL. Development of the carton slowed during World War II, but the design would see a revival within European markets in the 1960s.\n Gable top cartons are often used for liquid products such as milk, juice, etc. These use  -coated paperboard  or other   and sometimes a foil laminate. Most are opened by pushing open the gables at the top back and pulling the top (spout) out. Some have fitments to assist in opening and eating the contents. \n Cuboid waxed paperboard beverage, a formed waxed paperboard plug crimped and sealed, preceded gabled polyethylene-coated paperboard cartons.    were used to drink.    distributed milk in this way. \n Robert Gair was a Brooklyn printer and paper-bag maker during the 1870s. While he was printing an order of seed bags, a metal rule normally used to crease bags shifted in position and cut the bag. Gair concluded that cutting and creasing paperboard in one operation would have advantages; the first automatically made carton, now referred to as \"semi-flexible packaging\", was created. In 1817, the first commercial cardboard box production began in England.  In 1879,  , in Brooklyn, New York, operated a factory that die-ruled, cut, and scored   into a single impression of a folded carton.  By 1896, the   was the first to use cartons to package  . \n During the first decade of the 1900s, G. W. Maxwell developed the first paper milk carton. In 1908, Dr. Winslow, of Seattle, Washington, described paper   containers that were commercially sold in   and   as early as 1906.  The inventor of this carton was G.W. Maxwell.  Later, in 1915 John Van Wormer of Toledo, Ohio, received the a   for the gable-topped, wax-coated, \"paper bottle,\" a folded blank box for holding milk, calling it the \"Pure-Pak.\"  The milk carton could be folded, glued, filled with milk, and sealed at a dairy farm.  In 1953, Seok-kyun Shin introduced the gable-topped milk carton to Korea.  In the 1960s, Mario Lepore, a Detroit engineer designed a machine to fold and seal a gable top paper carton. \n In 1957 paper milk carton company   merged with the   Timber Company of  . \n Although quite often shaped like a  , it is not uncommon to find cartons lacking   and straight edges, as in   used for  .\n  and other shapes are available.  Cartons with a hexagonal or octagonal cross sections are sometimes used for specialty items.\n Cartons can be made from many materials:  , duplex, white kraft, recycled and many more various plastics, or a  .  Some are \"food grade\"  for direct contact with foods. Many cartons are made out of a single piece of paperboard. Depending on the need, this paperboard can be   or coated with   to form a moisture barrier. This may serve to contain a liquid product or keep a powder dry.\n \n In art history, the   (pronounced the French way) was a drawing on heavy pasteboard or paperboard, used as life-size design for the manufacture in an   of a valuable  , such as a  . During the weaving it hung behind the tapestry in the making, a time-consuming process thus in a creative sense simplified to 'mechanical' painting-by-numbers.\n As these were extremely valuable, often commanded by the very richest art-buyers, including princes who hung them in their palaces and even took them on their travels as prestigious displays of wealth, often with a visual message, especially the world-famous Flemish ateliers were deemed worthy to have cartons made by some of the greatest graphic artists of the time, including such celebrated painters as Rubens.\n In the 1980s, milk cartons in the United States often   with the hope that someone would recognize the photograph and provide information to police.\n Many milk cartons also included advertisements and sponsors. These images and sponsors ranged from DVDs, Cereal, Cartoons, Frozen Dinners, and Albums. \n  was a material used for the making of raised ornaments for wall and ceiling decoration. It is composed of the pulp of paper mixed with whiting (ground  ) and glue, this being forced into plaster moulds backed with paper, and then removed to a drying room to harden. It is much stronger and lighter than common plaster-of-Paris ornaments, and is not so liable to chip or break if struck with anything.\n There's a plethora of beverages and snacks found within carton-packaging. This includes milk, juices, egg whites, coffee, protein shakes, water, and even snacks like   and  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Memory_bottleneck", "title": "Random-access memory", "content": "\n  ( ;  ) is a form of   that can be read and changed in any order, typically used to store working   and  .  A   memory device allows data items to be   or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as   and  ), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement.\n In today's technology, random-access memory takes the form of   (IC) chips with   (metal–oxide–semiconductor)  . RAM is normally associated with   types of memory where stored information is lost if power is removed. The two main types of volatile random-access   are   (SRAM) and   (DRAM).\n Non-volatile RAM has also been developed  and other types of   allow random access for read operations, but either do not allow write operations or have other kinds of limitations. These include most types of   and  .\n The use of semiconductor RAM dates back to 1965 when IBM introduced the monolithic (single-chip) 16-bit SP95 SRAM chip for their   computer, and   used bipolar DRAM memory cells for its 180-bit Toscal BC-1411  , both based on  . While it offered higher speeds than  , bipolar DRAM could not compete with the lower price of the then-dominant magnetic-core memory.  In 1966, Dr.   invented modern DRAM architecture in which there's a single MOS transistor per capacitor.  The first commercial DRAM IC chip, the 1K  , was introduced in October 1970.   (SDRAM) was reintroduced with the   KM48SL2000 chip in 1992.\n Early computers used  ,   or   for main memory functions. Ultrasonic delay lines were   which could only reproduce data in the order it was written.   could be expanded at relatively low cost but efficient retrieval of memory items requires knowledge of the physical layout of the drum to optimize speed. Latches built out of  , and later, out of  , were used for smaller and faster memories such as  . Such registers were relatively large and too costly to use for large amounts of data; generally only a few dozen or few hundred bits of such memory could be provided.\n The first practical form of random-access memory was the  . It stored data as electrically charged spots on the face of a  . Since the electron beam of the CRT could read and write the spots on the tube in any order, memory was random access. The capacity of the Williams tube was a few hundred to around a thousand bits, but it was much smaller, faster, and more power-efficient than using individual vacuum tube latches. Developed at the   in England, the Williams tube provided the medium on which the first electronically stored program was implemented in the   computer, which first successfully ran a program on 21 June, 1948.  In fact, rather than the Williams tube memory being designed for the Baby, the Baby was a   to demonstrate the reliability of the memory. \n  was invented in 1947 and developed up until the mid-1970s. It became a widespread form of random-access memory, relying on an array of magnetized rings. By changing the sense of each ring's magnetization, data could be stored with one bit stored per ring. Since every ring had a combination of address wires to select and read or write it, access to any memory location in any sequence was possible. Magnetic core memory was the standard form of   until displaced by   in   (ICs) during the early 1970s. \n Prior to the development of integrated   (ROM) circuits,   (or  ) random-access memory was often constructed using   driven by  , or specially wound   planes. \n  appeared in the 1960s with bipolar memory, which used  . Although it was faster, it could not compete with the lower price of magnetic core memory. \n In 1957, Frosch and Derick manufactured the first silicon dioxide field-effect transistors at Bell Labs, the first transistors in which drain and source were adjacent at the surface.  Subsequently, in 1960, a team demonstrated a working   at Bell Labs.  This led to the development of   (MOS) memory by John Schmidt at   in 1964.  In addition to higher speeds, MOS   was cheaper and consumed less power than magnetic core memory.  The development of     (MOS IC) technology by   at Fairchild in 1968 enabled the production of MOS  .  MOS memory overtook magnetic core memory as the dominant memory technology in the early 1970s. \n Integrated bipolar   (SRAM) was invented by Robert H. Norman at   in 1963.  It was followed by the development of MOS SRAM by John Schmidt at Fairchild in 1964.  SRAM became an alternative to magnetic-core memory, but required six MOS transistors for each   of data.  Commercial use of SRAM began in 1965, when   introduced the SP95 memory chip for the  . \n  (DRAM) allowed replacement of a 4 or 6-transistor latch circuit by a single transistor for each memory bit, greatly increasing memory density at the cost of volatility. Data was stored in the tiny capacitance of each transistor, and had to be periodically refreshed every few milliseconds before the charge could leak away. \n 's Toscal BC-1411  , which was introduced in 1965,  used a form of capacitor-bipolar DRAM, storing 180-bit data on discrete  , consisting of   bipolar transistors and capacitors.  While it offered higher speeds than magnetic-core memory, bipolar DRAM could not compete with the lower price of the then dominant magnetic-core memory.  Capacitors had also been used for earlier memory schemes, such as the drum of the  , the   and the  .\n In 1966,   invented modern DRAM architecture for which there is a single MOS transistor per capacitor.  While examining the characteristics of MOS technology, he found it was capable of building  , and that storing a charge or no charge on the MOS capacitor could represent the 1 and 0 of a bit, while the MOS transistor could control writing the charge to the capacitor. This led to his development of a single-transistor DRAM memory cell.  In 1967, Dennard filed a patent under IBM for a single-transistor DRAM memory cell, based on MOS technology.  The first commercial DRAM IC chip was the  , which was   on an   MOS process with a capacity of 1 , and was released in 1970. \n The earliest DRAMs were often synchronized with the CPU clock (clocked) and were used with early microprocessors. In the mid-1970s, DRAMs moved to the asynchronous design, but in the 1990s returned to synchronous operation.  In 1992 Samsung released KM48SL2000, which had a capacity of 16 .  and mass-produced in 1993.  The first commercial   (  SDRAM) memory chip was Samsung's 64 Mbit DDR SDRAM chip, released in June 1998.    (graphics DDR) is a form of DDR   (synchronous graphics RAM), which was first released by Samsung as a 16 Mbit memory chip in 1998. \n The two widely used forms of modern RAM are   (SRAM) and   (DRAM). In SRAM, a   is stored using the state of a six-   , typically using six MOSFETs. This form of RAM is more expensive to produce, but is generally faster and requires less dynamic power than DRAM. In modern computers, SRAM is often used as  . DRAM stores a bit of data using a transistor and   pair (typically a MOSFET and  , respectively),  which together comprise a DRAM cell. The capacitor holds a high or low charge (1 or 0, respectively), and the transistor acts as a switch that lets the control circuitry on the chip read the capacitor's state of charge or change it. As this form of memory is less expensive to produce than static RAM, it is the predominant form of computer memory used in modern computers.\n Both static and dynamic RAM are considered  , as their state is lost or reset when power is removed from the system. By contrast,   (ROM) stores data by permanently enabling or disabling selected transistors, such that the memory cannot be altered. Writable variants of ROM (such as   and  ) share properties of both ROM and RAM, enabling data to   without power and to be updated without requiring special equipment.   (which can be either SRAM or DRAM) includes special circuitry to detect and/or correct random faults (memory errors) in the stored data, using   or  .\n In general, the term   refers solely to solid-state memory devices (either DRAM or SRAM), and more specifically the main memory in most computers. In optical storage, the term   is somewhat of a misnomer since, it is not random access; it behaves much like a hard disc drive if somewhat slower. Aside, unlike   or  , DVD-RAM does not need to be erased before reuse. \n The memory cell is the fundamental building block of  . The memory cell is an   that stores one   of binary information and it must be set to store a logic 1 (high voltage level) and reset to store a logic 0 (low voltage level). Its value is maintained/stored until it is changed by the set/reset process. The value in the memory cell can be accessed by reading it.\n In SRAM, the memory cell is a type of   circuit, usually implemented using  . This means that SRAM requires very low power when not being accessed, but it is expensive and has low storage density.\n A second type, DRAM, is based around a capacitor. Charging and discharging this capacitor can store a \"1\" or a \"0\" in the cell. However, the charge in this capacitor slowly leaks away, and must be refreshed periodically. Because of this refresh process, DRAM uses more power, but it can achieve greater storage densities and lower unit costs compared to SRAM.\n To be useful, memory cells must be readable and writable. Within the RAM device, multiplexing and demultiplexing circuitry is used to select memory cells. Typically, a RAM device has a set of address lines  , and for each combination of bits that may be applied to these lines, a set of memory cells are activated. Due to this addressing, RAM devices virtually always have a memory capacity that is a power of two.\n Usually several memory cells share the same address. For example, a 4 bit \"wide\" RAM chip has four memory cells for each address. Often the width of the memory and that of the microprocessor are different, for a 32 bit microprocessor, eight 4 bit RAM chips would be needed.\n Often more addresses are needed than can be provided by a device. In that case, external multiplexors to the device are used to activate the correct device that is being accessed. RAM is often byte addressable, although it is also possible to make RAM that is word-addressable. \n One can read and over-write data in RAM. Many computer systems have a memory hierarchy consisting of  , on-    caches, external  ,  ,   systems and   or   on a hard drive. This entire pool of memory may be referred to as \"RAM\" by many developers, even though the various subsystems can have very different  , violating the original concept behind the   term in RAM. Even within a hierarchy level such as DRAM, the specific row, column, bank,  , channel, or   organization of the components make the access time variable, although not to the extent that access time to rotating   or a tape is variable. The overall goal of using a memory hierarchy is to obtain the fastest possible average access time while minimizing the total cost of the entire memory system (generally, the memory hierarchy follows the access time with the fast CPU registers at the top and the slow hard drive at the bottom).\n In many modern personal computers, the RAM comes in an easily upgraded form of modules called   or DRAM modules about the size of a few sticks of chewing gum. These can be quickly replaced should they become damaged or when changing needs demand more storage capacity. As suggested above, smaller amounts of RAM (mostly SRAM) are also integrated in the   and other   on the  , as well as in hard-drives,  , and several other parts of the computer system.\n In addition to serving as temporary storage and working space for the operating system and applications, RAM is used in numerous other ways.\n Most modern operating systems employ a method of extending RAM capacity, known as \"virtual memory\". A portion of the computer's   is set aside for a   or a  , and the combination of physical RAM and the paging file form the system's total memory. (For example, if a computer has 2 GB (1024  B) of RAM and a 1 GB page file, the operating system has 3 GB total memory available to it.) When the system runs low on physical memory, it can \" \" portions of RAM to the paging file to make room for new data, as well as to read previously swapped information back into RAM. Excessive use of this mechanism results in   and generally hampers overall system performance, mainly because hard drives are far slower than RAM.\n Software can \"partition\" a portion of a computer's RAM, allowing it to act as a much faster hard drive that is called a  . A RAM disk loses the stored data when the computer is shut down, unless memory is arranged to have a standby battery source, or changes to the RAM disk are written out to a nonvolatile disk. The RAM disk is reloaded from the physical disk upon RAM disk initialization.\n Sometimes, the contents of a relatively slow ROM chip are copied to read/write memory to allow for shorter access times. The ROM chip is then disabled while the initialized memory locations are switched in on the same block of addresses (often write-protected). This process, sometimes called  , is fairly common in both computers and  .\n As a common example, the   in typical personal computers often has an option called \"use shadow BIOS\" or similar. When enabled, functions that rely on data from the BIOS's ROM instead use DRAM locations (most can also toggle shadowing of video card ROM or other ROM sections). Depending on the system, this may not result in increased performance, and may cause incompatibilities. For example, some hardware may be inaccessible to the   if shadow RAM is used. On some systems the benefit may be hypothetical because the BIOS is not used after booting in favor of direct hardware access. Free memory is reduced by the size of the shadowed ROMs. \n The '  is the growing disparity of speed between CPU and the response time of memory (known as  ) outside the CPU chip. An important reason for this disparity is the limited communication bandwidth beyond chip boundaries, which is also referred to as  . From 1986 to 2000,   speed improved at an annual rate of 55% while off-chip memory response time only improved at 10%. Given these trends, it was expected that memory latency would become an overwhelming   in computer performance. \n Another reason for the disparity is the enormous increase in the size of memory since the start of the PC revolution in the 1980s. Originally, PCs contained less than 1 mebibyte of RAM, which often had a response time of 1 CPU clock cycle, meaning that it required 0 wait states. Larger memory units are inherently slower than smaller ones of the same type, simply because it takes longer for signals to traverse a larger circuit. Constructing a memory unit of many gibibytes with a response time of one clock cycle is difficult or impossible. Today's CPUs often still have a mebibyte of 0 wait state cache memory, but it resides on the same chip as the CPU cores due to the bandwidth limitations of chip-to-chip communication. It must also be constructed from static RAM, which is far more expensive than the dynamic RAM used for larger memories. Static RAM also consumes far more power.\n CPU speed improvements slowed significantly partly due to major physical barriers and partly because current CPU designs have already hit the memory wall in some sense.   summarized these causes in a 2005 document. \n First of all, as chip geometries shrink and clock frequencies rise, the transistor   increases, leading to excess power consumption and heat... Secondly, the advantages of higher clock speeds are in part negated by memory latency, since memory access times have not been able to keep pace with increasing clock frequencies. Third, for certain applications, traditional serial architectures are becoming less efficient as processors get faster (due to the so-called  ), further undercutting any gains that frequency increases might otherwise buy. In addition, partly due to limitations in the means of producing inductance within solid state devices,   (RC) delays in signal transmission are growing as feature sizes shrink, imposing an additional bottleneck that frequency increases don't address. The RC delays in signal transmission were also noted in \"Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures\"  which projected a maximum of 12.5% average annual CPU performance improvement between 2000 and 2014.\n A different concept is the processor-memory performance gap, which can be addressed by   that reduce the distance between the logic and memory aspects that are further apart in a 2D chip.  Memory subsystem design requires a focus on the gap, which is widening over time.  The main method of bridging the gap is the use of  ; small amounts of high-speed memory that houses recent operations and instructions nearby the processor, speeding up the execution of those operations or instructions in cases where they are called upon frequently. Multiple levels of caching have been developed to deal with the widening gap, and the performance of high-speed modern computers relies on evolving caching techniques.  There can be up to a 53% difference between the growth in speed of processor and the lagging speed of main memory access. \n  have continued to increase in speed, from ~400 Mbit/s via   in 2012 up to ~7 GB/s via  /  in 2024, closing the gap between RAM and hard disk speeds, although RAM continues to be an order of magnitude faster, with single-lane   8000MHz capable of 128 GB/s, and modern   even faster. Fast, cheap,   solid state drives have replaced some functions formerly performed by RAM, such as holding certain data for immediate availability in   - 1   of SSD storage can be had for $200, while 1 TB of RAM would cost thousands of dollars. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_web_browsers", "title": "List of web browsers", "content": "\n \n The following is a   that are notable.\n This is a table of personal computer web browsers by year of release of major version. The increased growth of the Internet in the 1990s and 2000s means that current browsers with small market shares have more total users than the entire market early on. For example, 90% market share in 1997 would be roughly 60 million users, but by the start of 2007 9% market share would equate to over 90 million users. \n \n Other software publishers have built browsers and other products around Microsoft's Trident engine. The following browsers are all based on that rendering engine:\n Browsers that use both   and   include:\n Browsers that can use  ,   and   include:\n Browsers created for enhancements of specific browsing activities.\n  was the first widely used web browser. The   (NCSA) licensed the technology and many companies built their own web browser on Mosaic. The best known are the first versions of Internet Explorer and Netscape.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Top_Ryde_City", "title": "Top Ryde City", "content": "\n\n , previously known as  , is a large shopping centre in  , a suburb of  , Australia. It is owned by  .\n The original Top Ryde Shopping Centre was opened on the current 3.5 hectare site on 14 November 1957 by the    .  It was the first post-war major open-air shopping centre built in New South Wales  and the second post war and open-air mall-type complex built in Australia after   in  .  \n The centre was the dream of Peter Benjamin from the retailing family who opened A.J. Benjamin's in the suburb of  .  Benjamin had travelled to the United States in 1953 where he visited about 20 shopping centres in the new American style and met up with friend Peter Yeoman who was completing postgraduate studies in Detroit on the subject of American shopping centres. Together they devised a design for such a shopping centre in Sydney. Yeoman came up with the idea of the apricot brick and the windowless building with vertical divisions, while Benjamin sketched the layout for retailing. \n Top Ryde was anchored by Sydney-based A.J. Benjamin & Co department store,   supermarket, a chain variety store and 45 other shops grouped around a pedestrian mall, with 400 parking spaces. The centre feature modern sculpture centre which was a focal point designed by artist Gordon Andrews, a personal friend of Peter Yeoman. Top Ryde was established with the motto \"come as you are...shop in comfort\" offering a new experience for the shopper who until this time would have needed to travel to Sydney or Parramatta to gain access to a major department store and such a wide range of variety shopping. \n In 1962, Top Ryde was sold to   who undertook expansion of the centre.    was opened in 1963 in addition to the expansion of the centre which also included a variety store, several speciality shops and another 200 car parking spaces. The A.J. Benjamin store closed and was taken over by   in 1964. As regional shopping centres became the focus of community activities and associated recreational activities a Ten Pin   opened in the 1970s known as BowlAustralia's WondABowl- Top Ryde which was rebranded in 2003 to  . \n The centre underwent refurbishment and redevelopment in 1986 and changed its name to Top Ryde Shopping Square. A new multi-storey carpark was constructed, along with new entrances, roofing of the mall area and a general upgrade.   then moved into the space vacated by Grace Bros. \n With the opening of   in 1981 and the continual growth of centres such as  ,  ,   and most recently the opening   in 2004 severely affected the retail trade of Top Ryde.  The centre lost a lot of stores including Target which closed around 2005–2006.\n Towards the end of the centre's life, it was almost a   featuring  ,  , a   and around 90 stores which were predominantly banks and service stores.  The centre was situated over 2 floors. The lower level had direct access to the bottom carpark level and featured Woolworths and a small food court. It was connected to the upper level via a travelator. The upper level contained Franklins and access to Blaxland Road and Devlin Street, as well as access to bus services. \n In July 2007, the centre was demolished, and shortly thereafter, construction began on redeveloping the site. The new centre was renamed to Top Ryde City after it was a chosen name from   Council. \n Stage 1 was opened on 5 November 2009, consisting of around 115 stores including Woolworths,  ,   and  . This is on the Tucker Street side of the development. Other stages progressively opened throughout 2010, each stage next to the previous moving progressively towards Pope Street. \n Stage 2 was completed and opened in March 2010 and included the opening of  ,   and 60 speciality stores. This also saw the first section of La Strada (fashion precinct) opened. \n Stage 3 was completed which consisted of the   department store and additional fashion outlets within the La Strada opened on 4 August 2010. \n Top Ryde City had its official opening on 20 August 2010 which was presided over by    .  \n The final works which included  , a childcare centre, medical centre, Gymnasium, The new Ryde Library and The Ryde Planning and Business Centre all opened in February 2011.  There were plans for   to open in February 2011, but the plans were cancelled and the bowling alley never opened.\n The southern pedestrian overpass opened in December 2009 and the northern pedestrian overpass was opened in August 2010.\n The development of the project encountered a number of problems, including issues of worker safety in the surrounding roads \nand a near fatal workplace accident.  In addition to this, the local Chamber of Commerce raised some concerns with the project managers about the movement of trucks near the site, although these seem to have been dealt with by the project managers with the termination of contracts with trucking companies. \n The original owners of Top Ryde City entered   in 2011 with McGrathNicol appointed administrator.  Top Ryde was sold to   in November 2012. \n In 2014 property developer   completed the final apartments in its 653-apartment development, Top Ryde City Living. The seven-tower residential complex is home to more than 600 residents and positioned above Top Ryde City Shopping Centre with views to the  ,   and  . \n The development was awarded the NSW President's award in 2014 by the  . \n On 5 May 2015, Myer has closed its Top Ryde store due to poor sales with many customers increasingly shopping at other Myer stores such as  ,  ,   and  .  The redevelopment began in June 2015 which saw many stores closed or relocated during the redevelopment including   and   which have both closed. This development consists of\n Top Ryde City has 78,125m² of floor space.  The major retailers include  ,  ,  ,  ,  ,  ,  ,  ,  ,   &   and  . \n Top Ryde has bus connections to the  ,   and  , as well as local surrounding suburbs operated by  . The majority of bus services depart from Devlin Road in front of the shopping centre's main entrance and Blaxland Road. There is no railway station at Ryde, the nearest stations are located at   and  .\n  Media related to   at Wikimedia Commons\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Project_network", "title": "Project network", "content": "A   is a   that displays the order in which a project’s activities are to be completed. Derived from the  , the   of a project are organized sequentially based on the relationship among them. It is typically drawn from left to right to reflect project chronology. \n The Activity-on-Node (AON) technique uses nodes to represent individual project activities and path arrows to designate the sequence of activity completion.  Nodes are labelled using information pertaining to the activity. According to Project Management, nodes should at least display the following information: \n \nStart and finish times are used to determine the   of a project.  , or slack, time is used in project crashing.\n \n The condition for a valid project network is that it doesn't contain any  .\n Project dependencies can also be depicted by a predecessor table. Although such a form is very inconvenient for human analysis,   often offers such a view for data entry.\n An alternative way of showing and analyzing the sequence of project work is the design structure matrix or  .\n \n This business-related article is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Star_Wars_Celebration", "title": null, "content": "\n  is a large fan   held to celebrate the   franchise. The event is usually held annually (with a few exceptions) in varying locations around the world, and commonly features a host of   project announcements,   featuring actors, producers and writers, screenings, exhibits, cosplay and merchandise sales. It began in 1999, when   held the first   Celebration in   to celebrate the upcoming release of  .\n The   Celebration was held from April 30 to May 2, 1999, at the   in Denver, Colorado, just three weeks before the release of  .  An event \"for the fans, by the fans,\" the event took place in the hometown of the Official   Fan Club, headed by Dan Madsen.  \"The Fan Club is based here in Denver,\" says Madsen, \"so we thought it would only be appropriate that the Celebration be held here.\" \n The first   convention since 1987, the Celebration held activities including actor panels,   theater demonstrations, behind the scenes footage from  , and the world premiere of the \" \" music video.  The grounds boasted a vendors tent, and the museum hosted an exhibition consisting of props from the official   archives, including a full-scale model of Anakin Skywalker's podracer and a life-size X-wing model (a 3/4 scale replica made in 1996 for the Special Edition release, and still residing at Wings Over the Rockies Air and Space Museum). \n From May 3 to 5, 2002, Celebration II was held to celebrate the upcoming release of  .  The convention was moved to  , to make use of the larger  . \n Downtown Indianapolis was invaded by multitudes of   fans.  The initial projection of 15–20,000 people per day based on advance ticket sales was well surpassed and reached critical mass on Saturday. The estimated final tally was a little over 75,000 people  for the three-day event.  The two busiest spots were the Fan Club store and the autograph section, specifically for  . Highlights of the event included the   and the   25th Anniversary Concert on Saturday night, performed by the  . \n The   Celebration returned to Indianapolis from April 21 to 24, 2005, to commemorate the release of what was then thought to be the final film in the saga,  .  With over 34,000 fans in attendance over the course of four days, Celebration III brought actor panels, costume contests, fan films, and diorama building to the Indiana Convention Center.  The Lucasfilm archive provided many important props and costumes for display. One of this Celebration's most noteworthy events was the unprecedented Q&A session with   creator  , his first such appearance since the   10th Anniversary Convention in 1987. With approximately 10,000 fans in attendance (over the course of 3 half-hour sessions), Lucas personally answered several dozen fans' questions about the saga.\n On May 26, 2006, StarWars.com announced   Celebration IV (C4) to be held from May 24 to 28, 2007, to commemorate the 30th anniversary of the     film.  C4 was located at the   in  .  The convention offered a record number of celebrities in the autograph hall, multiple exhibitors, a   art show, a   helmet and Lucasfilm archive exhibits and many fan oriented activities. In addition, there were collector and costuming panels, including sneak peeks of the upcoming   animated series. Fans were the first to see the footage of this series on Sunday morning as well.   Other highlights included conversations with   and  , a visit from   and   for special   episodes of   and   respectively, and an efficiently organized Celebration Store. An estimated 35,000 people walked through the doors for Celebration IV over the Memorial Day weekend. \n After the event, Lucasfilm sued the hosting entity, GenCon, for a variety of reasons, forcing GenCon into Chapter 11 bankruptcy. \n On September 25, 2006, StarWars.com announced   Celebration Europe (CE) to be held from July 13 to 15, 2007, to commemorate the 30th anniversary of the first   film.  CE was to be located at   in  .  But on November 22, 2006, StarWars.com announced due to Advance interest in Celebration Europe the event would be moved to the larger venue located at the   in London.  The event also had on display some of the largest restored   Arcade collection, estimated at around 30 to 40 machines,  many of them now rarely seen in the USA or in other parts of Europe. An estimated 30,000 people attended this convention. \n On February 23, 2008, Lucasfilm Ltd. and the Lewis Daniel Group announced a three-day event known as \"Celebration Japan\", to be held at the   near Tokyo from July 19 to 21. The convention celebrated the 30th anniversary of the June 24, 1978, Japanese premiere of  . Celebration Japan included live entertainment,   celebrities, exclusive merchandise, special presentations, unique   exhibits, costume contests, and other activities. \n Lucasfilm announced in 2008 that a US-based four-day   convention called \"Celebration V\" would be held in the summer of 2010. In July 2008,  , director of content management and head of fan relations for Lucasfilm, announced that  ,  ,  , Indianapolis, Los Angeles,  , and   were competing to host this event. Organizers anticipated that 30,000   fans would attend no matter which city was selected. \n  and Lucasfilm announced on December 3, 2009, that Orlando would host the event.  Celebration V took place at the   from August 12 to 15, 2010. The convention celebrated the 30th anniversary of the second   movie,  . It also included many features of previous Celebrations (such as   celebrity appearances, costume contests, and other fan events) as well as a special one-hour interview between Jon Stewart and George Lucas called \"The Main Event\".  Celebration V marked the first American Celebration appearance for   ( ) and the last American appearance for   (Mon Mothma). Attendance was estimated at 32,000. \n Lucas also made an appearance at the nearby   to take part in the \" \", which provided special entertainment for those individuals who attended \"Celebration V\".\n StarWarsCelebration.com announced on June 2, 2011, that Celebration VI would be held in Orlando, FL at the Orange County Convention Center (OCCC) from August 16 to 19, 2012.  The event was later delayed by a week.  The convention was held in the same hall of the OCCC as was Celebration V, with a very similar format. Several celebrities returned for appearances at this Celebration (including Mark Hamill, Carrie Fisher, and Anthony Daniels), and this event marked the first American Celebration attended by  . George Lucas had not been scheduled to attend, but made a \"surprise\" appearance.  The event hosted the announcement of  . Attendance was estimated at 35,000 people. \n It was announced at the Closing Ceremonies of Celebration VI (and confirmed on StarWarsCelebration.com) that Celebration Europe II would be held in Essen, Germany, at the   fair venue from July 26 to 28, 2013.  Major panels were  's inaugural   Celebration appearance and the first look at  . Over 20,000 people attended the event from 40 different countries.  The convention celebrated the 30th anniversary of the third   movie,  .\n It was announced at the closing ceremonies of Celebration Europe II that Celebration Anaheim would be held in Anaheim, California, at the  , from April 16 to 19, 2015, with an anticipated turnout of about 50,000 fans. \n This event was one of the most anticipated due to the December 2015 release of   with most news and info on the film being kept secretive prior to the event. The entire celebration was broadcast live online free via www.starwars.com and the  '   channel. The long-awaited second teaser trailer for the   premiered on April 16, 2015, during the opening panel of the event which also included many of the stars of the upcoming film, new and old, director   along with producer and president of  ,  .  The following day, fans were treated to the trailer for the upcoming videogame,   while on the third day the trailer for the second season of   made its debut. The Celebration closed out its fourth and final day with fans being shown an exclusive teaser trailer for  , which was released in December 2016. This is the first of two anthology films, which are also known as the stand-alone or origin story films.\n Celebration Europe III took place from July 15 to 17, 2016, at the ExCel center in London, England. \"Jedi Master VIP Tickets\" sold out immediately.  Original trilogy stars   and   died in 2016.\n Celebration Orlando took place from April 13 to 16, 2017, in Orlando, Florida. The convention celebrated the 40th Anniversary of   and the upcoming film,  . This was the first   Celebration that   attended. He made an appearance during the opening panel celebrating the 40 years of   held on April 13 which also included other stars and people important to the franchise including   (president of  ) and a surprise appearance by   and   with the Orlando Philharmonic Orchestra, who performed parts of the soundtrack.  A special tribute to   was held by   on Friday, April 14.  A teaser trailer of   premiered on Friday, April 14.  On Saturday, April 15 it was announced that season 4 of   would be the last season of the series.  The celebration was once again streamed live and free via StarWars.com and the     channel.\n The thirteenth   Celebration was held from April 11 to 15, 2019 inside  's  . A teaser trailer and title reveal for   occurred on April 12;  a franchise mural including art from the upcoming film was also unveiled.  A trailer for the upcoming game   was also showcased as well as teaser reels for   Season 7 and the new   exclusive show,  . It was announced in June 2019 that Celebration Chicago drew an estimated 65,000 fans. \n Also during   Celebration Chicago, Lucasfilm sound editor   teased that there would be a new  .\n It was announced on April 15, 2019, the last day of Celebration Chicago 2019, that in 2020, the next   Celebration would be held for the second time at the Anaheim Convention Center in Anaheim, California.  On June 15, 2020, it was announced that the 2020 Celebration had been cancelled due to the  , with the next event scheduled to be held from August 18 to 21, 2022. The event was later moved forward by three months.  Several new  -exclusive   series were promoted, including  ,  ,  ,   and  . \n The fifteenth   Celebration was held at the ExCel Centre in London, England for a third time from April 7 to 10, 2023, which was part of The Walt Disney Company's centennial celebration. This celebration promoted several new   series including  ,   and  , and upcoming video game sequel,  .   was also promoted,  and it was announced that   would return for a second season, and three new   films were in development after a long film hiatus, including a film set 15 years after the events of   with   returning as  .  Additionally, the celebration commemorated the 40th anniversary of  , with the film receiving a limited theatrical rerelease from April 28 to May 1 (in the United Kingdom) and from April 28 to May 4 (in the United States). \n \nIt was announced on April 10, 2023 during the Celebration Europe 2023 closing ceremony, that there would be no celebration in 2024. Instead, the next Celebration would be held in Japan in 2025. This three-day event will be held at the   near Tokyo for a second time from April 18 to 20.  ", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/U.S._District_Courts", "title": "United States district court", "content": "\n   \n The   are the   of the  .  There is one district court for each  .  Each district covers one   or a portion of a state. There is at least one federal courthouse in each district, and many districts have more than one. District court decisions are appealed to the   for the circuit in which they reside, except for certain specialized cases that are appealed to the   or directly to the  .\n District courts are courts of  ,  , and  , and can hear both   and   cases. But unlike  , federal district courts are courts of  , and can only hear cases that involve disputes between  ,  , or federal crimes.\n Unlike the U.S. Supreme Court, which was expressly established by  , the district courts were established by Congress pursuant to authority delegated by Article III  through the enacting of a federal statute, the  . There is no constitutional requirement that district courts exist at all. \n During the drafting and ratification of the  , some opponents of a strong federal judiciary argued that the federal courts ought to be limited to the Supreme Court, which would hear appeals only from state courts.  In other words, the state courts would be treated as   under Article I of the Constitution for the purpose of hearing disputes under federal law, but their judges would not become officers of the federal government.     advocated this position in a letter to  , and it was also discussed by   in  .   However, this view did not prevail, and the first Congress created the district court system that is still in place today.   Pursuant to the Constitution, nonetheless,   retain the power of   in most federal matters. \n When the Act was first passed, there were thirteen districts created among the eleven states which had ratified the Constitution by that point. When North Carolina and Rhode Island voted to ratify, a district was created for each of them, bringing the number of districts to fifteen.\n The   ( ) of  , the  , and the   each have one territorial court; these courts are called \"district courts\" and exercise the same jurisdiction as district courts,  but differ from district courts in that territorial courts are  , with judges who serve ten-year terms rather than the   of judges of  , such as the district court judges. \n  does not have a district court or a federal territorial court, and so federal matters there are sent to either the   or  .  The   were previously part of the United States but were never part of the U.S. federal court system. \n There are 89 districts in the 50 states, with a total of 94 districts including territories.  There is at least one judicial district for each  , the  , and  .\n Each state has between one and four districts.  For states with multiple districts, they are named geographically.  States with two districts all give them either Northern–Southern or Western–Eastern designations.  Most states with three districts add a Middle District, with two exceptions: Illinois has a Central District instead of a Middle District, and Oklahoma has Northern, Western, and Eastern Districts.  Of the three states with four districts, New York and Texas use all four directional designations, while California has a Central District and no Western District.\n There are other federal trial courts that have nationwide   over certain types of cases, but the district court also has   over many of those cases, and the district court is the only one with jurisdiction over civilian criminal cases.\n The   addresses cases involving international trade and customs issues. The   has   over most claims for money damages against the United States, including disputes over federal contracts, unlawful   of private property by the federal government, and suits for injury on federal property or by a federal employee. The   has jurisdiction over contested pre-assessment determinations of  .\n A judge of a United States district court is officially titled a \"United States District Judge\". Other  , including   and  , can also sit in a district court upon assignment by the chief judge of the circuit or by the  . The number of judges in each district court (and the structure of the judicial system generally) is set by   in the  . The   appoints the federal judges for terms of good behavior (subject to the   of the  ), so the nominees often share at least some of his or her convictions. In states represented by a senator of the president's party, the senator (or the more senior of them if both senators are of the president's party) has substantial input into the nominating process, and through a tradition known as   can exercise an unofficial veto over a nominee unacceptable to the senator.\n Federal magistrate judges are appointed by each district court pursuant to statute. They are appointed for an eight-year term and may be reappointed for additional eight-year terms. A magistrate judge may be removed \"for incompetency, misconduct, neglect of duty, or physical or mental disability\".  A magistrate judgeship may be a stepping stone to a district judgeship nomination.\n District judges usually concentrate on managing their court's overall caseload, supervising trials, and writing opinions in response to important motions like the motion for  . Since the 1960s, routine tasks like resolving discovery disputes can, in the district judge's discretion, be referred to  . Magistrate judges can also be requested to prepare reports and recommendations on contested matters for the district judge's consideration or, with the consent of all parties, to assume complete jurisdiction over a case including conducting the trial.\n With the exception of the   ( , the  , and the  ), federal district judges are   appointed for life, and can be removed involuntarily only when they violate the standard of \"good behavior\". The sole method of involuntary removal of a judge is through   by the   followed by a trial in the   and a conviction by a two-thirds vote. Otherwise, a judge, even if convicted of a   criminal offense by a jury, is entitled to hold office until retirement or death. In the history of the United States, twelve judges have been impeached by the House, and seven have been removed following conviction in the Senate. (For a table that includes the twelve impeached judges, see  .)\n A judge who has reached the age of 65 (or has become disabled) may retire or elect to go on   and keep working. Such senior judges are not counted in the quota of active judges for the district and do only whatever work they are assigned by the chief judge of the district, but they keep their offices (called \"chambers\") and staff, and many of them work full-time.\n As of 2010, there were 678 authorized district court judgeships. \n A federal judge is addressed in writing as \"  John/Jane Doe\" or \"Hon. John/Jane Doe\" and in speech as \"Judge\" or \"Judge Doe\" or, when presiding in court, \"Your Honor\".\n Each district court appoints a clerk, who is responsible for overseeing filings made with the court, maintaining the court's records, processing fees, fines, and restitution, and managing the non-judicial work of the court, including information technology, budget, procurement, human resources, and financial. Clerks may appoint deputies, clerical assistants, and employees to carry out the work of the court. The clerk of each district court must reside in the district for which the clerk is appointed, except that the clerk of the District of Columbia and the clerk of the Southern District of New York may reside within twenty miles of their respective districts.\n The Judiciary Act of 1789 authorized the Supreme Court and the judge of each U.S. District Court to appoint a clerk to assist with the administration of federal judicial business in those courts. The clerk for each district court was to also serve as clerk of the corresponding circuit court. The Judiciary Act required each clerk to issue the writs summoning jurors and \"to record the decrees, judgments and determinations of the court of which he is clerk.\"\n The Judicial Code (28 U.S.C. § 751) provides that the clerk is appointed, and may be removed, by the court. The clerk's duties are prescribed by the statute, by the court's customs and practices, and by policy established by the  . The clerk is appointed by order of the court   to serve the entire court. The role of the clerk and deputies or assistants should not be confused with the judges'  , who assist the judges by conducting research and preparing drafts of opinions.\n To be eligible to serve as a clerk, a person must have a minimum of 10 years of progressively responsible administrative experience in public service or business that provides a thorough understanding of organizational, procedural, and human aspects of managing an organization, and at least 3 of the 10 years must have been in a position of substantial management responsibility. An attorney may substitute the active practice of law on a year-for-year basis for the management or administrative experience requirement. Clerks do not have to be licensed attorneys, but some courts specify that a law degree is a preference for employment.\n Unlike some state courts, the power of federal courts to hear cases and controversies is strictly limited. Federal courts may not decide every case that happens to come before them.  In order for a district court to entertain a lawsuit, Congress must first grant the court subject matter jurisdiction over the type of dispute in question.\n The district courts exercise original jurisdiction over—that is, they are empowered to conduct trials in—the following types of cases:\n For most of these cases, the jurisdiction of the federal district courts is concurrent with that of the state courts. In other words, a plaintiff can choose to bring these cases in either a federal district court or a state court. Congress has established a procedure whereby a party, typically the defendant, can \"remove\" a case from state court to federal court, provided that the federal court also has original jurisdiction over the matter (meaning that the case could have been filed in federal court initially).  If the party that initially filed the case in state court believes that removal was improper, that party can ask the district court to \"remand\" the case to the state court system. For certain matters, such as patent and copyright infringement disputes and prosecutions for federal crimes, the jurisdiction of the district courts is exclusive of that of the state courts, meaning that only federal courts can hear those cases. \n In addition to their original jurisdiction, the district courts have appellate jurisdiction over a very limited class of judgments, orders, and decrees. \n In order to represent a party in a case in a district court, a person must be an   and generally must be admitted to the bar of that particular court. The United States usually does not have a separate   for federal practice (except with respect to patent practice before the  ).   of a district court is generally available to any attorney who is admitted to practice law in the state where the district court sits. \n 56 districts (around 60% of all district courts) require an attorney to be admitted to practice in the state where the district court sits. The other 39 districts (around 40% of all district courts) extend admission to certain lawyers admitted in other states, although conditions vary from court to court. For example, the district courts in   (  and  ) extend admission to attorneys admitted to the bar in Connecticut or Vermont and to the district court in that state, but otherwise require attorneys to be admitted to the New York bar. Only 13 districts extend admission to attorneys admitted to any U.S. state bar. \n The attorney generally submits an application with a fee and takes the oath of admission. Local practice varies as to whether the oath is given in writing or in open court before a judge of the district. A \"sponsor\" admitted to the court's bar is often required. Several district courts require attorneys seeking admission to their bars to take an additional bar examination on federal law, including the following: the Southern District of Ohio,  the Northern District of Florida,  and the  . \n  admission is also available in most federal district courts on a case-by-case basis. Most district courts require   attorneys to associate with an attorney admitted to practice before the court. \n Generally, a final ruling by a district court in either a civil or a criminal case can be appealed to the   in the   in which the district court is located, except that some district court rulings involving patents and certain other specialized matters must be appealed instead to the  , and in a very few cases the appeal may be taken directly to the  .\n The   is the largest federal district by population;  it includes all five counties that make up  . By contrast,   and the surrounding   are divided between the   (which includes  ,   and  ) and the   (which includes  ,  ,  ,   and  ). New York suburbs in   and   are covered by the   and  , respectively.\n The Southern District of New York and the Central District of California are the largest federal districts by number of judges, with 28 judges each. \n In 2007, the busiest district courts in terms of criminal federal felony filings were the  ,  ,  , and the  . These four districts all share the  .  A crackdown on illegal immigration resulted in 75 percent of the criminal cases filed in the 94 district courts in 2007 being filed in these four districts and the other district that borders Mexico, the  .  The busiest patent litigation court is the  , with the most patent lawsuits filed there nearly every year. \n Most extinct district courts have disappeared by being divided into smaller districts.  The following courts were subdivided out of existence:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  .\n On rare occasions, an extinct district court was extinguished by merging it with other district courts. In every case except one, this has restored a district court that had been subdivided:\n There are a few additional extinct district courts that fall into neither of the above two patterns.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Dick_Wolf", "title": "Dick Wolf", "content": "\n\n  (born December 20, 1946 ) is an American film and  , best known for his  . Since 1990, the franchise has included six police/courtroom dramas and four international spinoffs. He is also co-creator and executive producer of the  , which since 2012, has included four  -based dramas, and the co-creator and executive producer of the  , which since 2018, has also become a franchise after spinning off two additional series.\n Wolf has also written four books. The first, the non-fiction volume  , is a companion to the   television series.      and   are works of fiction in a   series featuring an   detective named Jeremy Fisk. \n Wolf has won numerous awards, including an  , being inducted into the  , and receiving a star on the  .\n Wolf was born in   to a   father and a Catholic mother of  .  As a boy, he was an   at the local Catholic parish. \n Wolf attended  ,  ,  and  .  He subsequently attended the   (class of 1969), where he was a member of the   fraternity. \n Wolf worked as an   at   creating   for  , including the slogan \"You can't beat Crest for fighting cavities.\" He is also credited with the campaign \"I'm Cheryl, fly me\" for  . Yet despite his success in copywriting, all the while he was writing   in the hopes of a film career. It was at this time that he briefly collaborated on a screenplay with  , who was a struggling   at the time.\n He moved to   after a few years and had three screenplays produced; one of these films,  , featuring Rob Lowe and Meg Tilly, gained notable acclaim.  He started his television career as a staff writer on   and was nominated for his first   for the episode \"What Are Friends For?\", on which he was the only writer. While working on  , Wolf became close friends with  , then writing for the series  , produced in the same building, at the same time.  Wolf moved from   to  , where he was a writer and co-producer for the third and fourth seasons. \n Wolf's original series   ran from 1990 to 2010, and was revived in 2022. It has surpassed   as longest-running dramatic show in American television history, making it one of television's most successful franchises. It has been nominated for the most consecutive   of any primetime drama series. Wolf serves as creator and executive producer of the current   drama series from   and   Television –   (which as of September 5, 2024 is the longest-running scripted primetime drama, having aired 551 episodes, breaking the original   count of 456 (now 501 through the twenty-third season), and beating both the original   and   in number of seasons).  \n Wolf also was creator and executive producer for the four spinoff shows in the franchise that have been canceled –  ,  ,  , and  .  Along with Kevin Arkadie, he co-created the police drama  , which ran on the   Network from 1994 to 1999. He also served as executive producer of the series. He was the creator and executive producer of NBC's courtroom reality series  , which chronicled real-life cases prosecuted by the   District Attorney's office. Many of Wolf's series have intersected with the   in some fashion, and the   series have been adapted into several foreign versions. Wolf's company also produced  , the 2003  –winning Short Documentary about two brothers, one a policeman and the other a fireman, who were killed in the line of duty on  . Wolf was also involved with  , the production of a theatrical documentary about the rock band  . \n On March 31, 2020, Wolf announced that a spin-off series was ordered by   to launch in the 2020–21 season, with   reprising his role as   from   after a nine-year absence. The initial series order was for 13 episodes.  On June 2, 2020, it was announced that the series would be called   and that showrunner Craig Gore had been fired. \n Wolf announced that NBC placed an order of 13 episodes for  , a new installment of the franchise.  On March 4, 2019, NBC announced that the series would be redeveloped to flesh out the concept and would not be spun out of   as announced.  On June 5, 2020, the series of   was moved to NBC's streaming service,  , at least partly due to language concerns. \n On May 3, 2021, Wolf announced that NBC ordered yet another installment of the franchise,  , and that its showrunner would be  .  It was later announced that the show would not move forward.\n Wolf developed   a drama about a group of men and women working at the  . The series was picked up by NBC in May 2012,  and premiered on October 10, 2012, with meek numbers in the ratings and minimal reviews in the first few weeks before spiking to NBC's #2 scripted drama series, under   In March 2013, NBC announced intentions for a spin-off of   revolving around the Chicago Police Department.  When that series   premiered,  ,  , and   became executive producers, under Wolf.  Two subsequent shows,   which premiered in 2015, and   whose one season began and ended in 2017, followed in   wake.\n In 2018, Wolf became executive producer of the   drama  , starring   cast members   and   and also  .    has since had two spinoffs ( , and  ), giving Wolf his third franchise.\n Beginning in the  , all three of Wolf's franchises have their own night of programming:   Tuesdays on CBS (original series,  ,  ),   Wednesdays on NBC ( ,  ,  ), and   Thursdays on NBC (original series revival,   and  ). \n In 2012, Wolf developed the unscripted show  , a documentary drama, for  .  He also has written three novels whose central character is NYPD Detective Jeremy Fisk:  ,  , and  .  In 2024, Wolf released a documentary miniseries with Netflix called  .  \n In May 2021, NBC ordered a docuseries  . The series followed the firefighters of the   and will be executive produced by Wolf.  This series was cancelled by NBC after one season. \n Wolf's future projects for NBC are an American adaption of the United Kingdom psychological   series   as well as a drama series revolving around a  , tentatively titled  . Wolf is writing the latter project with  .  Wolf also has an untitled pilot about an insurance investigator on  . \n With Wolf pursuing projects other than  , he and current   showrunner/executive producer   sometimes discuss the future of the   franchise and revitalizing it; Leight commenting \"(Dick Wolf and I) sometimes talk in general terms of where (the franchise) could go. I'm curious to see if there's another iteration somewhere down the line.\" \n In December 2023, the Metropolitan Museum of Art announced the promised gift of over 200 works of art from Wolf, including Old Master paintings, sculptures and drawings, as well as funds to endow two galleries with his name.  Wolf reported that his appreciation for art started when he was a child visiting Met on his way home from school. \n Wolf's personal honors include the Award of Excellence from the  , the 2002 Creative Achievement Award from  ; the  's Distinguished Entertainment Industry Award, the Leadership and Inspiration Award from the Entertainment Industries Council, the Governor's Award by the New York Chapter of the  , the 1997 achievement award from the Caucus for Producers, Writers, and Directors, the 1998 Television Showman of the Year Award from the Publicists Guild of America, the 2002 Tribute from the  , and a 2003 Special   from the  . On March 29, 2007, Wolf received a star on the   at 7040 Hollywood Boulevard.  In 2013, Wolf was inducted into the  . Wolf is also an Honorary   of   and is actively involved in the principality's prestigious annual Television Festival.\n It was reported that Wolf contributed to  's  . The two had worked together since 2002, when Thompson joined the cast of   playing a  . \n , a   on   from 2009 to 2014 had an episode which parodied Dick Wolf's  , with the title \" \" being a play on his name. Wolf is given a special thanks credit at the end of the episode. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Australian_Capital_Territory", "title": "Australian Capital Territory", "content": "\n\n The   ( ), known as the   ( ) until 1938, is a   of Australia.  , the capital city of Australia, is situated within the territory, and serves as the territory's  . It is located in southeastern   as an   within the state of  . Founded after   as the   for the new nation, the territory hosts the headquarters of all important institutions of the  , most notably  .\n On 1 January 1901,   of Australia was achieved. Section 125 of the new   provided that land, situated in New South Wales and at least 100 miles (160 km) from  , would be ceded to the new  . Following discussion and exploration of various areas within New South Wales, the   was passed in 1908 which specified a capital in the Yass-Canberra region. The territory was transferred to the federal government by   in 1911, two years prior to the capital city being founded and formally named as Canberra in 1913.\n While the overwhelming majority of the population resides in the city of   in the ACT's north-east, the territory also includes some towns such as  ,  ,  ,   and  . The ACT also includes the  , which comprises the majority of land area of the territory. Despite a common misconception, the   is not part of the ACT, although the laws of the Australian Capital Territory apply as if Jervis Bay did form part of the ACT.  The territory has a relatively dry, continental climate, experiencing warm to hot summers and cool to cold winters.\n The Australian Capital Territory is home to many important institutions of the federal government, national monuments and museums. These include the  , the  , the   and the  . It also hosts the majority of foreign embassies in Australia, as well as regional headquarters of many international organisations, not-for-profit groups, lobbying groups and professional associations. Several major universities also have campuses in the ACT, including the  , the  , the  ,   and the  .\n  has governed the territory since 1988. However, the Commonwealth maintains authority over the territory and may overturn local laws. It still maintains control over the area known as the   through the  . Residents of the territory elect three members of the   and two  .\n With 453,324 residents, the Australian Capital Territory is the second smallest mainland state or territory by population. At the  , the median weekly income for people in the territory aged over 15 was $998, significantly higher than the national median of $662.  The average level of degree qualification in the ACT is also higher than the national average. Within the ACT, 37.1% of the population hold a bachelor's degree level or above education compared to the national figure of 20%.  The Australian Capital Territory had the equal fourth highest   score (0.976)   in 2022, coming close to a perfect score of 1.\n  have long inhabited the area.  Evidence indicates habitation dating back at least 25,000 years,  and it is possible that the area was inhabited for considerably longer, with   dating back around 40,000–62,000 years.   The principal group occupying the region were the  , with the   and   living immediately to the south, the   to the east, the   to the north and the   to the north-west. \n Following European settlement, the growth of the new colony of New South Wales led to an increasing demand for  .  Governor   supported expeditions to open up new lands to the south of  .  The 1820s saw further exploration in the Canberra area associated with the construction of a road from Sydney to the   plains. While working on the project,   learned of a nearby lake and river from the local Indigenous peoples and he accordingly sent Wild to lead a small party to investigate the site. The search was unsuccessful, but they did discover the  , and it is surmised that they would have set foot on part of the future territory. \n A second expedition was mounted shortly thereafter, and they became the first Europeans to camp at the   (Ngambri) and   (Jullergung) Rivers.  However, they failed to find the  .  The issue of the Murrumbidgee was solved in 1821 when Throsby mounted a third expedition and successfully reached the watercourse, on the way providing the first detailed account of the land where the Australian Capital Territory now resides.  The last expedition in the region before settlement was undertaken by   in 1824.  He reported that the region was suitable for grazing and the settlement of the Limestone Plains followed immediately thereafter. \n The first land grant in the region was made to Joshua John Moore in 1823, and European settlement in the area began in 1824 with the construction of a homestead by his stockmen on what is now the  .  Moore formally purchased the site in 1826 and named the property   or  . \n A significant influx of population and economic activity occurred around the 1850s  .  The gold rushes prompted the establishment of communication between Sydney and the region by way of the   coaches, which transported mail and passengers.  The first post offices opened in   in 1859 and at Lanyon in 1860. \n During colonial times, the European communities of Ginninderra,   and Tuggeranong settled and farmed the surrounding land. The region was also called the  -  district, after the two largest towns in the area. The villages of Ginninderra and Tharwa developed to service the local agrarian communities.\n During the first 20 years of settlement, there was only limited contact between the settlers and Aboriginal people. Over the succeeding years, the Ngunnawal and other local indigenous people effectively ceased to exist as cohesive and independent communities adhering to their traditional ways of life.  Those who had not succumbed to disease and other predations either dispersed to the local settlements or were relocated to more distant   set up by the New South Wales government in the latter part of the 19th century. \n In 1898, a referendum on a proposed Constitution was held in four of the colonies –  ,  ,  , and  . Although the referendum achieved a majority in all four colonies, the New South Wales referendum failed to gain the minimum number of votes needed for the bill to pass. Following this result, a meeting of the four Premiers in 1898 heard from  , the  , who argued that locating the future capital in New South Wales would be sufficient to ensure the passage of the Bill. The 1899 referendum on this revised bill was successful and passed with sufficient numbers.  Section 125 of the   thus provided that, following Federation in 1901, land would be ceded freely to the new  . \n This, however, left open the question of where to locate the capital. In 1906 and after significant deliberations, New South Wales agreed to cede sufficient land on the condition that it was in the  -  region,  this site being closer to Sydney.  Initially,   remained at the forefront, but Yass-Canberra prevailed after voting by federal representatives.  The   was passed in 1908, which repealed the 1904 Act and specified a capital in the Yass-Canberra region.  Government surveyor   was deployed to the region in the same year to map out a specific site and, after an extensive search, settled upon the present location,  basing the borders primarily on the need to secure a stable water supply for the planned capital. \n The Australian Capital Territory was transferred to the Commonwealth by   on 1 January 1911, two years before the naming of Canberra as the national capital on 20 March 1913. \n The Commonwealth gained control of all land within the borders of the new territory but ownership only of NSW Crown land, with significant parcels of extant freehold remaining in the hands of their pre-existing owners. Much of this was acquired during  , though a few titles were not transferred until the late 20th Century.\n Land within the territory is granted under a   system, with   sold to buyers as new suburbs are planned, surveyed, and developed. The current policy is for these leases to be extended for another 99-year period on expiry, subject to payment of an administrative fee.  In an arrangement inspired by  , the ideas of 19th-century American economist  , leaseholders had to pay 5% of the unimproved value of the underlying land in rent until the   abolished it in 1970. \n In 1911, an international competition to design the future capital was held; it was won by the Chicago architect   in 1912.  The official naming of Canberra occurred on 12 March 1913 and construction began immediately. \n After Griffin's departure following difficulty in implementing his project,  the   was established in 1920 to advise the government of the construction efforts.  The committee had limited success meeting its goals. However, the chairman,  , was instrumental in applying the ideas of the   to Griffin's plan. The committee was replaced in 1925 by the  . \n In 1930, the ACT Advisory Council was established to advise the minister for territories on the community's concerns. In 1934, the   was established. \n From 1938 to 1957, the   continued to plan the further expansion of Canberra. However, it did not have executive power, and decisions were made on the development of Canberra without consulting the committee.  During this time, Prime Minister   regarded the state of the national capital as an embarrassment. \n After World War II, there was a shortage of housing and office space in Canberra.  A Senate Select Committee hearing was held in 1954 to address its development requirements. This Committee recommended the creation of a single planning body with executive power. Consequently, the   was replaced by the   in 1957.  The   ended four decades of disputes over the shape and design of   and construction was completed in 1964 after four years of work. The completion of the centrepiece of Griffin's design finally laid the platform for the development of Griffin's  . \n In 1978, an advisory referendum was held to determine the views of ACT citizens about whether there should be self-government. Just under 64 percent of voters rejected devolved government options, in favour of the status quo.  Nevertheless, in 1988, the new minister for the Australian Capital Territory   received a report recommending the abolition of the   and the formation of a locally elected government. Punch recommended that the   accept the report's recommendations and subsequently   introduced legislation to grant self-government to the territory in October 1988. \n The enactment on 6 December 1988 of the   established the framework for self-government.  The   for the 17-member   was held on 4 March 1989. \n The initial years of self-government were difficult and unstable.  A majority of ACT residents had opposed self-government and had it imposed upon them by the federal parliament. At the first election, 4 of the 17 seats were won by anti-self-government single-issue parties due to a protest vote by disgruntled Canberrans and a total of 8 were won by minor parties and independents. \n In 1992, Labor won eight seats and the minor parties and independents won only three. Stability increased, and in 1995,   became the first elected Liberal chief minister. In 1998, Carnell became the first chief minister to be re-elected.\n The Australian Capital Territory is the smallest mainland territory (aside from the  ) and covers a total land area of 2,280 km  (880 sq mi), slightly smaller than Luxembourg.\n It is bounded by the   in the east, the   of   in the south, the watershed of the   in the west and the watershed of the   in the north-east. These boundaries were set to give the ACT an adequate water supply.  The ACT extends about 88.5 km (55.0 mi) north-south between 35.124°S and 35.921°S, and 57.75 km (35.88 mi) west-east between 148.763°E and 149.399°E.  The city area of   occupies the north-eastern corner of this area.\n The Australian Capital Territory includes the city of   and some towns such as  ,  ,  ,   and  . The Australian Capital Territory also contains agricultural land ( ,  ,   and small amounts of crops) and a large area of national park ( ), much of it mountainous and forested.\n Tidbinbilla is a locality to the south-west of Canberra that features the   and the  , operated by the United States'   as part of its  . The   straddles the state.\n The territory includes a large range of mountains, rivers and creeks, largely contained within the  . These include the Naas and Murrumbidgee Rivers.\n In September 2022, it was announced that the border between NSW and the ACT would change for the first time since it was created in 1911.  ACT chief minister   said NSW premier   had agreed to a proposed border change of 330 ha (1.3 sq mi) in the   watershed. \n The territory has a relatively dry, continental climate, experiencing warm to hot summers and cool to cold winters.  Under the  , the territory has an   ( ). \n January is the hottest month with an average high of 27.7 °C.  July is the coldest month when the average high drops to 11.2 °C (52.2 °F).  The highest maximum temperature recorded in the territory was 44.0 °C on 4 January 2020. The lowest minimum temperature was −10.0 °C on 11 July 1971. \n Rainfall varies significantly across the territory.  Much higher rainfall occurs in the mountains to the west of Canberra compared to the east.  The mountains act as a barrier during winter with the city receiving less rainfall.  Average annual rainfall in the territory is 629mm and there is an average of 108 rain days annually.  The wettest month is October, with an average rainfall of 65.3mm, and the driest month is June, with an average of 39.6mm. \n Frost is common in the winter months.   is rare in Canberra's city centre, but the surrounding areas get annual snowfall through winter and often the snow-capped mountains can be seen from the city. The last significant snowfall in the city centre was in 1968. \n Smoke haze became synonymous with the 2019/2020 Australian summer. On 1 January 2020 Canberra had the worst air quality of any major city in the world, with an AQI of 7700 (USAQI 949). \n source 2 = Special climate statements and climate summaries for more recent extremes \n Notable geological formations in the Australian Capital Territory include the  , the  ,   and  .\n In the 1840s   of   and   from the   period were discovered at Woolshed Creek near  . At the time, these were the oldest fossils discovered in Australia, though this record has now been far surpassed.  Other specific geological places of interest include the State Circle cutting and the Deakin  . \n The oldest rocks in the ACT date from the   around 480 million years ago. During this period the region along with most of Eastern Australia was part of the ocean floor; formations from this period include the   formation and the   consisting largely of  -rich  ,   and  . These formations became exposed when the ocean floor was raised by a major   in the   forming much of the east coast of Australia.\n The environments range from   area on the higher mountains, to   forest and to  . Much of the ACT has been cleared for grazing and is also burnt off by   several times per century. The kinds of plants can be grouped into  , that include  , flowering plants, and  , as well as  ,  , fungi and freshwater  . Four flowering plants are endemic to the ACT. Several lichens are unique to the territory. Most plants in the ACT are characteristic of the   and include well known plants such as  ,   trees and  .\n The native forest in the Australian Capital Territory was almost wholly   species and provided a resource for fuel and domestic purposes. By the early 1960s, logging had depleted the eucalypt, and concern about water quality led to the forests being closed. Interest in forestry began in 1915 with trials of a number of species including   on the slopes of Mount Stromlo. Since then, plantations have been expanded, with the benefit of reducing erosion in the Cotter catchment, and the forests are also popular recreation areas. \n The fauna of the territory includes representatives from most major  . This includes kangaroos, wallabies, koalas, platypus, echidna, emu, kookaburras and dragon lizards.\n Unlike the States of Australia which have their own constitutions, territories like the ACT are governed under a Commonwealth statute —for the ACT, the  .  The   constitutes a democratic government for the Territory consisting of a popularly elected   which elects a   from among its membership who, in turn, appoints an Executive consisting of a number of Ministers.\n The executive power of the Territory rests with the  , led by the Executive. The Executive is chaired by the Chief Minister (currently the  's  ) and consists of Ministers appointed by them. The Executive are supported by the ACT Public Service, which is arranged into directorates, and a number of public authorities.  The Chief Minister is the equivalent of a   and sits on the National Cabinet.  Unlike the States and the Northern Territory, there is no   who chairs the Executive. The Chief Minister performs many of the roles that a state governor normally holds in the context of a state; however, the Speaker of the Legislative Assembly gazettes the laws and summons meetings of the Assembly.\n The   has held Government since 2001.\n The legislative power of the Territory is vested in the unicameral  . The Assembly consists of 25   who are elected from   using the   single transferable voting system.  The Assembly is presided over by the Speaker (currently the Labor Party's  ). The Assembly has almost all of the same powers as the state parliaments, the power to \"make laws for the peace, order, and good government of the Territory\", with limited exceptions relating to the Territory's unique relationship with the Commonwealth.  The Hare-Clark voting system was adopted after   and was entrenched by another referendum in 1995.  The electoral system cannot be changed except by a two-thirds majority in the Assembly or a majority vote of support at a public referendum. \n There is no level of   below the Territory government as in the States and the functions associated with local government are carried out principally by the  .  There is an indigenous voice to the ACT Government, called the  . \n Despite the wide powers of the Territory government, the federal government continues to have power over the Territory. This includes an unused power to dissolve the Assembly and appoint a caretaker government in extraordinary circumstances.  The federal and territory governments share some officers, such as the  .  The federal parliament also retains the power to make any law for the Territory under   and an exclusive power to legislate for the \"seat of government\".  Territory laws which conflict with federal law are inoperable to the extent of the inconsistency.  Land in the Territory that is designated to be \"National Land\" under federal law remains under the control of the federal government, usually represented by the  .  The federal parliament can disallow laws enacted by the Assembly by a joint resolution of both houses of Parliament, a power which replaced a federal executive veto in 2011. \n The judicial power of the Territory is exercised by the territory courts. These courts are the  , the   and the  . It is unique in that the territory does not have an intermediary court like other mainland states and territories; there is only the superior court and a court of summary jurisdiction. From 2001, appeals from the Supreme Court are heard by a panel of Supreme Court judges sitting as the Court of Appeal.  The current Chief Justice is   and the current Chief Magistrate is  .\n The   has concurrent jurisdiction over civil matters arising under Territory law, a fact which has become increasingly important to the practice of   across Australia. \n Policing services are provided by the   unit of the   under agreements between the territory government, the federal government, and the police force.    had the lowest rate of crime of any capital city in Australia as of February 2019 .  \n In Australia's  , the ACT is represented by five federal members: three members of the   represent the  , the   and the  , and it is one of only two territories to be represented in the Senate, with two   (the other being the Northern Territory). The Member for Bean and the ACT Senators also represent the constituents of  . The Member for Fenner and the ACT Senators also represent the constituents of the  .\n In 1915, the   created the   as an annex to the Federal Capital Territory. While the Act's use of the language of \"annexed\" is sometimes interpreted as implying that the Jervis Bay Territory was to form part of the Federal Capital Territory, the accepted legal position is that it has been a legally distinct territory from its creation despite being subject to ACT law and, prior to ACT self-government in 1988, being administratively treated as part of the ACT. \n In 1988, when the ACT gained self-government, Jervis Bay was formally pronounced as a separate territory administered by the Commonwealth known as the Jervis Bay Territory. However, the laws of the ACT continue to apply to the Jervis Bay Territory.  Magistrates from the ACT regularly travel to the Jervis Bay Territory to conduct court. \n Another occasional misconception is that the ACT retains a small area of territory on the coast on the  , consisting of a strip of coastline around the northern headland of Jervis Bay. While the land is owned by the Commonwealth Government, that area itself is still considered to be under the jurisdiction of New South Wales government, not a separate territory nor a part of the ACT. \n The   estimates that the population of the territory was 453,324 on 31 December 2021, with an annual growth in 2021 of 0.4%.  A 2019 projection estimated the population would reach to approximately 700,000 by 2058. \n The overwhelming majority of the population reside in the city of Canberra. \n At the  , the median weekly income for people in the territory aged over 15 was $998 while the national average was $662. \n The average level of degree qualification in the ACT is higher than the national average. Within the ACT, 37.1% of the population hold a bachelor's degree level or above education compared to the national figure of 20%. \n The Australian Capital Territory consists of the city of   and some towns including  ,  ,  ,   and  .\n The urban areas of the Australian Capital Territory are organised into a hierarchy of districts, town centres, group centres, local suburbs as well as other industrial areas and villages. There are seven districts (with an eighth currently under construction), each of which is divided into smaller suburbs, and most of which have a town centre which is the focus of commercial and social activities. The districts were settled in the following chronological order:\n The North and South Canberra districts are substantially based on Walter Burley Griffin's designs.  In 1967, the then   adopted the \"Y Plan\" which laid out future urban development in the Australian Capital Territory a series of central shopping and commercial area known as the 'town centres' linked by freeways, the layout of which roughly resembled the shape of the letter Y,  with Tuggeranong at the base of the Y and Belconnen and Gungahlin located at the ends of the arms of the Y. \n At the  , the most commonly nominated ancestries were: \n The   showed that 32.5% of the ACT's inhabitants were  .  Of inhabitants born outside of Australia, the most prevalent countries of birth were India, England, China, Nepal and New Zealand. \n 2.0% of the population, or 8,949 people, identified as   (  and  ) in 2021. \n At the  , 71.3% of people spoke only English at home. The other languages most commonly spoken at home were   (3.2%),   (1.3%),   (1.1%),   (1.1%),   (1.0%). \n The most common responses in the   for religion in the territory were No Religion (43.5%), Catholic (19.3%), Anglican (8.2%), Not stated (5.2%) and Hinduism (4.5%). \n Almost all educational institutions in the Australian Capital Territory are located within  . The ACT public education system schooling is normally split up into  , Primary School (K-6), High School (7–10) and   (11–12) followed by studies at University or Institute of Technology. Many private high schools include years 11 and 12 and are referred to as colleges. Children are required to attend school until they turn 17 under the  's \"Learn or Earn\" policy. \n In February 2004 there were 140   in ACT; 96 were operated by the Government and 44 are non-Government.  In 2005, there were 60,275 students in the ACT school system. 59.3% of the students were enrolled in government schools with the remaining 40.7% in non-government schools. There were 30,995 students in primary school, 19,211 in high school, 9,429 in college and a further 340 in special schools. \n As of May 2004, 30% of people in the ACT aged 15–64 had a level of educational attainment equal to at least a bachelor's degree, significantly higher than the national average of 19%.  The two main tertiary institutions are the   (ANU) in   and the   (UC) in  . There are also two religious university campuses in Canberra: Signadou is a campus of the   and St Mark's Theological College is a campus of  . Tertiary level vocational education is also available through the multi-campus   (CIT).\n The   (ADFA) and the   (RMC) are in the suburb of   in Canberra's inner northeast. ADFA teaches military undergraduates and   and is officially a campus of the   while Duntroon provides      .\n The   (AIE) offers courses in computer game development and 3D animation.\n The Australian Capital Territory is home to a number of major professional sports league franchise teams including the   (Rugby Union),   (Soccer),   (Rugby League),   (Basketball) and the   (Field Hockey).\n The   (Cricket), started by   in the 1950s and revived by   in 1984, has been played every year at   against an overseas touring team.\n The   (Football) play three regular season matches a year and one pre-season match in Canberra at Manuka Oval.\n The territory is home to many national monuments and institutions such as the  , the  , the  , the  ,  the  ,  the  ,  the   and the  .  Many Commonwealth government buildings in the Australian Capital Territory are open to the public, including  , the   and the  . \n Lake Burley Griffin is the site of the   and the  .  Other sites of interest include the  , the  , the  , the   and  . \n The   in   is a repository of local history and art, housing a permanent collection and visiting exhibitions.  Several historic homes are open to the public: Lanyon and Tuggeranong Homesteads in the  ,  Mugga-Mugga in  ,  and Blundells' Cottage in   all display the lifestyle of the early European settlers.  Calthorpes' House in   is a well-preserved example of a 1920s house from Canberra's very early days. \n The Australian Capital Territory has many venues for live music and theatre: the   which hosts many major concerts and productions;  and   (within the  ), a world-class concert hall are two of the most notable.    was Canberra's first performing arts venue, opened in 1928. It was the original performance venue for theatre groups such as the Canberra Repertory Society. \n There are numerous bars and nightclubs which also offer live entertainment, particularly concentrated in the areas of  ,   and  .  Most town centres have facilities for a community theatre and a cinema, and all have a library.  Popular cultural events include the  , the  , the   car festival,   festival and the   in February. \n The Australian Capital Territory has a daily newspaper,  , which was established in 1926.  There are also several free weekly publications, including news magazines   and  \n Major daily newspapers such as the   and   from Sydney,   and   from Melbourne as well as national publications   and the   are also available for purchase via retail outlets or via home delivery in the Australian Capital Territory.\n There are a number of AM and FM stations broadcasting throughout the ACT ( ). The main commercial operators are the   (  and  ), and  /  (  and  ). There are also several community operated stations as well as the local and national stations of the  .\n A DAB+ digital radio trial is also in operation, it simulcasts some of the AM/FM stations, and also provides several digital only stations ( ).\n Five free-to-air television stations service the territory:\n Each station broadcasts a primary channel and several  .\n  services are available from   (via satellite) and telecommunications company   (via cable). \n The Australian Capital Territory has two large public hospitals both located in Canberra: the approximately 600-bed   in   and the 174-bed Calvary Public Hospital in  . Both are teaching institutions.  The largest private hospital is the Calvary John James Hospital in  .  Calvary Private Hospital in Bruce and  's National Capital Private Hospital in Garran are also major healthcare providers. \n The Australian Capital Territory has 10 aged care facilities. ACT's hospitals receive emergency cases from throughout southern New South Wales,  and   is one of four operational agencies of the  .    provides a dedicated ambulance service for inter-hospital transport of sick newborns within the ACT and into surrounding New South Wales. \n The automobile is by far the dominant form of transport in the Australian Capital Territory.  The city is laid out so that arterial roads connecting inhabited clusters run through undeveloped areas of open land or forest, which results in a low population density;  this also means that idle land is available for the development of future transport corridors if necessary without the need to build tunnels or acquire developed residential land. In contrast, other capital cities in Australia have substantially less green space. \n  are generally connected by  —limited access   roads  with speed limits generally set at a maximum of 100 km/h (62 mph).  An example is the   which links Canberra's CBD and Tuggeranong, and bypasses Weston Creek.  In most districts, discrete residential suburbs are bounded by main arterial roads with only a few residential linking in, to deter non-local traffic from cutting through areas of housing. \n , the government-operated bus service, provides public transport throughout the Australian Capital Territory.    provides bus services between the Australian Capital Territory and nearby areas of New South Wales (  and  )  and as Qcity Transit ( ).  A   that opened in April 2019 links the CBD with the northern district of  . At the 2016 census, 7.1% of the journeys to work involved public transport while 4.5% were on foot. \n There are two local taxi companies.   enjoyed monopoly status until the arrival of Cabxpress in 2007.  In October 2015, the ACT Government passed legislation to regulate ride sharing, allowing ride share services including   to operate legally in the Australian Capital Territory.  The ACT Government was the first jurisdiction in Australia to enact legislation to regulate the service. \n An interstate   railway service connects Canberra to Sydney.    is in the inner south suburb of  .  Train services to Melbourne are provided by way of a NSW TrainLink bus service which connects with a rail service between Sydney and Melbourne in Yass, about a one-hour drive from Canberra. \n Canberra is about three hours by road from Sydney on the   (National Highway 23),  which connects with the   (National Highway 31) near  , and seven hours by road from Melbourne on the   (National Highway 25), which joins the Hume Highway at Yass.  It is a two-hour drive on the   (National Highway 23) to the ski fields of the   and the  .   , a popular holiday spot on the New South Wales coast, is also two hours away via the  . \n  provides direct domestic services to  ,  ,  ,  ,  ,   and  , with connections to other domestic centres.  There are also direct flights to regional cities:   and   in New South Wales. Regular direct international flights operate to Singapore and   from the airport daily, but both with a stopover in Sydney before Canberra.  Canberra Airport is, as of September 2013, designated by the   as a restricted use designated international airport.  Until 2003, the civilian airport shared runways with  . In June of that year, the Air Force base was decommissioned and from that time the airport was fully under civilian control. \n The government-owned  , formerly ACTEW, manages the territory's water and sewerage infrastructure.    is a joint venture between Icon and  , and is the retail provider of Australian Capital Territory's utility services including water, natural gas, electricity, and also some telecommunications services via a subsidiary  . \n Australian Capital Territory's water is stored in four reservoirs, the Corin, Bendora and Cotter dams on the   and the Googong Dam on the Queanbeyan River. Although the Googong Dam is located in New South Wales, it is managed by the ACT government.  Icon Water owns Australian Capital Territory's two wastewater treatment plants, located at   and on the lower reaches of the  . \n  mainly comes from the national power grid through substations at   and   (via  ).  Power was first supplied from a thermal plant built in 1913, near the Molonglo River, but this was finally closed in 1957.  The ACT has four solar farms, which were opened between 2014 and 2017:   (rated output of 20 megawatts, 2014),    (2.3 MW, 2016),    (13 MW, 2017)  and   (11 MW, 2017).  In addition numerous houses in Canberra have photovoltaic panels or solar hot water systems. In 2015 and 2016, rooftop solar systems supported by the ACT government's feed-in tariff had a capacity of 26.3 megawatts, producing 34,910 MWh. In the same year, retailer-supported schemes had a capacity of 25.2 megawatts and exported 28,815 MWh to the grid (power consumed locally was not recorded). \n The ACT has the highest rate with internet access at home (94 per cent of households in 2014–15). \n The economic activity of the Australian Capital Territory is heavily concentrated around the city of Canberra.\n A stable housing market, steady employment and rapid population growth in the 21st century have led to economic prosperity and, in 2011,   ranked the ACT as the second best performing economic region in the country.  This trend continued into 2016, when the territory was ranked the third best performing out of all of Australia's states and territories. \n In 2017–18, the ACT had the fastest rate of growth in the nation due to a rapid growth in population, a strongly performing higher education sector as well as a significant housing and infrastructure investment. \n Higher education is the territory's largest export industry.  The ACT is home to a significant number of universities and higher education providers. The other major services exports of the ACT in 2017–18 were government services and personal travel.  The major goods exports of the territory in 2017–18 were gold coin, legal tender coin, metal structures and fish, though these represent a small proportion of the economy compared to services exports. \n The economy of the ACT is largely dependent on the public sector with 30% of the jobs in the territory being in the public sector.  Decisions by the federal government regarding the public service can have a significant impact on the territory's economy. \n The ACT's gross state product in 2017–18 was $39.8 billion which represented 2.2% of the overall gross domestic product of Australia.  In 2017–18 the ACT economy grew by 4.0 per cent, the highest growth rate of any jurisdiction in Australia. This brought real economic growth over the three years to June 2018 to 12 per cent. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Waste_management", "title": "Waste management", "content": "\n  or   includes the processes and actions required to manage   from its inception to its final  . \nThis includes the  ,  ,  , and disposal of waste, together with monitoring and regulation of the waste management process and waste-related  , technologies, and economic mechanisms.\n Waste can either be  ,  , or   and each type has different methods of disposal and management. Waste management deals with all types of waste, including  ,  , household, municipal, organic,  ,   In some cases, waste can pose a threat to human health.  Health issues are associated with the entire process of waste management. Health issues can also arise indirectly or directly: directly through the handling of solid waste, and indirectly through the consumption of water, soil, and food.  Waste is produced by human activity, for example, the extraction and processing of raw materials.  Waste management is intended to reduce the adverse effects of waste on human  , the  , planetary resources, and  .\n The aim of waste management is to reduce the dangerous effects of such waste on the environment and human health. A big part of waste management deals with  , which is created by industrial, commercial, and household activity. \n Waste management practices are not the same across countries (  and  ); regions (  and  ), and   and   sectors can all take different approaches. \n Proper management of waste is important for building sustainable and liveable cities, but it remains a challenge for many developing countries and cities. A report found that effective waste management is relatively expensive, usually comprising 20%–50% of municipal budgets. Operating this essential municipal service requires integrated systems that are efficient, sustainable, and socially supported.  A large portion of waste management practices deal with   (MSW) which is the bulk of the waste that is created by household, industrial, and commercial activity.  According to the   (IPCC), municipal solid waste is expected to reach approximately 3.4 Gt by 2050; however, policies and lawmaking can reduce the amount of waste produced in different areas and cities of the world.  Measures of waste management include measures for integrated techno-economic mechanisms  of a  , effective disposal facilities, export and import control  and optimal   of products that are produced.\n In the first   of the scientific evidence around global waste, its management, and its impact on human health and life, authors concluded that about a fourth of all the municipal solid terrestrial waste is not collected and an additional fourth is mismanaged after collection, often being burned in open and uncontrolled fires – or close to one billion tons per year when combined. They also found that broad priority areas each lack a \"high-quality   base\", partly due to the absence of \"substantial  \", which motivated scientists often require.  Electronic waste (ewaste) includes discarded computer monitors, motherboards, mobile phones and chargers, compact discs (CDs), headphones, television sets, air conditioners and refrigerators. According to the Global E-waste Monitor 2017, India generates ~ 2 million tonnes (Mte) of e-waste annually and ranks fifth among the e-waste producing countries, after the  , the  ,   and  . \n Effective 'Waste Management' involves the practice of '7R' - 'R'efuse, 'R'educe', 'R'euse, 'R'epair,  , 'R'ecycle and 'R'ecover. Amongst these '7R's, the first two ('Refuse' and 'Reduce') relate to the non-creation of waste - by refusing to buy non-essential products and by reducing consumption. The next two ('Reuse' and 'Repair') refer to increasing the usage of the existing product, with or without the substitution of certain parts of the product. 'Repurpose' and 'Recycle' involve maximum usage of the materials used in the product, and 'Recover' is the least preferred and least efficient waste management practice involving the recovery of embedded energy in the waste material. For example, burning the waste to produce heat (and electricity from heat). Certain non-biodegradable products are also dumped away as 'Disposal', and this is not a \"waste-'management'\" practice. \n The   refers to the \"3 Rs\"  ,   and  , which classifies waste management strategies according to their desirability in terms of  . The waste hierarchy is the bedrock of most waste minimization strategies. The aim of the waste hierarchy is to extract the maximum practical benefits from products and to generate the minimum amount of end waste; see:  .  The waste hierarchy is represented as a pyramid because the basic premise is that policies should promote measures to prevent the generation of waste. The next step or preferred action is to seek alternative uses for the waste that has been generated, i.e., by re-use. The next is recycling which includes composting. Following this step is material recovery and  . The final action is disposal, in landfills or through incineration without  . This last step is the final resort for waste that has not been prevented, diverted, or recovered.  The waste hierarchy represents the progression of a product or material through the sequential stages of the pyramid of waste management. The hierarchy represents the latter parts of the life-cycle for each product. \n The life-cycle of a product, often referred to as the  , encompasses several key stages that begin with the design phase and proceed through manufacture, distribution, and primary use. After these initial stages, the product moves through the waste hierarchy's stages of reduce, reuse, and recycle. Each phase in this lifecycle presents unique opportunities for policy intervention, allowing stakeholders to rethink the necessity of the product, redesign it to minimize its waste potential, and extend its useful life.\n During the design phase, considerations can be made to ensure that products are created with fewer resources, are more durable, and are easier to repair or recycle. This stage is critical for embedding sustainability into the product from the outset. Designers can select materials that have lower environmental impacts and create products that require less energy and resources to produce.\n Manufacturing offers another crucial point for reducing waste and conserving resources. Innovations in production processes can lead to more efficient use of materials and energy, while also minimizing the generation of by-products and emissions. Adopting cleaner production techniques and improving manufacturing efficiency can significantly reduce the environmental footprint of a product.\n Distribution involves the logistics of getting the product from the manufacturer to the consumer. Optimizing this stage can involve reducing packaging, choosing more sustainable transportation methods, and improving supply chain efficiencies to lower the overall environmental impact. Efficient logistics planning can also help in reducing fuel consumption and greenhouse gas emissions associated with the transport of goods.\n The primary use phase of a product's lifecycle is where consumers interact with the product. Policies and practices that encourage responsible use, regular maintenance, and the proper functioning of products can extend their lifespan, thus reducing the need for frequent replacements and decreasing overall waste.\n Once the product reaches the end of its primary use, it enters the waste hierarchy's stages. The first stage, reduction, involves efforts to decrease the volume and toxicity of waste generated. This can be achieved by encouraging consumers to buy less, use products more efficiently, and choose items with minimal packaging.\n The reuse stage encourages finding alternative uses for products, whether through donation, resale, or repurposing. Reuse extends the life of products and delays their entry into the waste stream.\n Recycling, the final preferred stage, involves processing materials to create new products, thus closing the loop in the material lifecycle. Effective recycling programs can significantly reduce the need for virgin materials and the environmental impacts associated with extracting and processing those materials.\n Product life-cycle analysis (LCA) is a comprehensive method for evaluating the environmental impacts associated with all stages of a product's life. By systematically assessing these impacts, LCA helps identify opportunities to improve environmental performance and resource efficiency. Through optimizing product designs, manufacturing processes, and end-of-life management, LCA aims to maximize the use of the world's limited resources and minimize the unnecessary generation of waste.\n In summary, the product lifecycle framework underscores the importance of a holistic approach to product design, use, and disposal. By considering each stage of the lifecycle and implementing policies and practices that promote sustainability, it is possible to significantly reduce the environmental impact of products and contribute to a more sustainable future.\n  reflects the understanding that global economic growth and development can not be sustained at current production and consumption patterns. Globally, humanity extracts more resources to produce goods than the planet can replenish. Resource efficiency is the reduction of the environmental impact from the production and consumption of these goods, from final raw material extraction to the last use and disposal.\n The   mandates that the polluting parties pay for the impact on the environment. With respect to waste management, this generally refers to the requirement for a waste generator to pay for appropriate disposal of the unrecoverable materials. \n Throughout most of history, the amount of   generated by humans was insignificant due to low levels of   and  . Common waste produced during pre-modern times was mainly ashes and human  , and these were released back into the ground locally, with minimum  . Tools made out of   or   were generally reused or passed down through the generations.\n However, some civilizations have been more profligate in their waste output than others. In particular, the   of   had a fixed monthly ritual, in which the people of the village would gather together and burn their rubbish in large dumps. \n Following the onset of the  , industrialisation, and the sustained urban growth of large population centres in  , the buildup of waste in the cities caused a rapid deterioration in levels of   and the general quality of urban life. The streets became choked with filth due to the lack of waste clearance regulations.  Calls for the establishment of municipal authority with waste removal powers occurred as early as 1751, when   in London proposed that \"... as the preservation of the health of the people is of great importance, it is proposed that the cleaning of this city, should be put under one uniform public management, and all the filth be...conveyed by the   to proper distance in the country\". \n However, it was not until the mid-19th century, spurred by increasingly devastating   outbreaks and the emergence of a public health debate that the first legislation on the issue emerged. Highly influential in this new focus was the report   in 1842  of the  ,  , in which he argued for the importance of adequate waste removal and management facilities to improve the health and wellbeing of the city's population.\n In the UK, the Nuisance Removal and Disease Prevention Act of 1846 began what was to be a steadily evolving process of the provision of regulated waste management in London.  The   was the first citywide authority that centralized sanitation regulation for the rapidly expanding city, and the   made it compulsory for every household to deposit their weekly waste in \"moveable receptacles\" for disposal—the first concept for a  .  In the   by the 19th century, there existed a Public Works Department that was responsible for sanitation in   and its suburbs. They kept the streets clean daily and commanded civilians to keep their compounds clean and weeded. \n The dramatic increase in waste for disposal led to the creation of the first   plants, or, as they were then called, \"destructors\". In 1874, the first incinerator was built in   by   to the design of Alfred Fryer.  However, these were met with opposition on account of the large amounts of ash they produced and which wafted over the neighbouring areas. \n Similar municipal systems of waste disposal sprung up at the turn of the 20th century in other large cities of   and  . In 1895,   became the first U.S. city with public-sector garbage management. \n Early   were simply open-bodied   pulled by a team of horses. They became motorized in the early part of the 20th century and the first closed-body trucks to eliminate odours with a dumping lever mechanism were introduced in the 1920s in Britain.  These were soon equipped with 'hopper mechanisms' where the scooper was loaded at floor level and then hoisted mechanically to deposit the waste in the truck. The   was the first truck in 1938, to incorporate a hydraulic compactor.\n Waste collection methods vary widely among different countries and regions. Domestic waste collection services are often provided by local government authorities, or by private companies for industrial and commercial waste. Some areas, especially those in less developed countries, do not have formal waste-collection systems.\n  is the most common method of disposal in most European countries, Canada, New Zealand, the United States, and many other parts of the developed world in which waste is collected at regular intervals by specialised trucks. This is often associated with curb-side waste segregation. In rural areas, waste may need to be taken to a transfer station. Waste collected is then transported to an appropriate disposal facility. \nIn some areas, vacuum collection is used in which waste is transported from the home or commercial premises by vacuum along small bore tubes. Systems are in use in Europe and North America.\n In some jurisdictions, unsegregated waste is collected at the curb-side or from waste transfer stations and then sorted into recyclables and unusable waste. Such systems are capable of sorting large volumes of solid waste, salvaging recyclables, and turning the rest into bio-gas and soil conditioners. \nIn  , the local government established its   in support of its goal of \"Zero waste by 2020\", requiring everyone in the city to keep recyclables and compostables out of the landfill. The three streams are collected with the curbside \"Fantastic 3\" bin system – blue for recyclables, green for compostables, and black for landfill-bound materials – provided to residents and businesses and serviced by San Francisco's sole refuse hauler, Recology. The city's \"Pay-As-You-Throw\" system charges customers by the volume of landfill-bound materials, which provides a financial incentive to separate recyclables and compostables from other discards. The city's Department of the Environment's Zero Waste Program has led the city to achieve 80% diversion, the highest diversion rate in North America.  Other businesses such as   use a variety of colors to distinguish between trash and recycling cans. In addition, in some areas of the world the disposal of municipal solid waste can cause environmental strain due to official not having benchmarks that help measure the   of certain practices. \n This is the separation of wet waste and dry waste. The purpose is to recycle dry waste easily and to use wet waste as compost. When segregating waste, the amount of waste that gets landfilled reduces considerably, resulting in lower levels of air and water pollution. Importantly, waste segregation should be based on the type of waste and the most appropriate treatment and disposal. This also makes it easier to apply different processes to the waste, like composting, recycling, and incineration. It is important to practice waste management and segregation as a community. One way to practice waste management is to ensure there is awareness. The process of waste segregation should be explained to the community. \n Segregated waste is also often cheaper to dispose of because it does not require as much manual sorting as mixed waste. There are a number of important reasons why waste segregation is important such as legal obligations, cost savings, and protection of human health and the environment. Institutions should make it as easy as possible for their staff to correctly segregate their waste. This can include labelling, making sure there are enough accessible bins, and clearly indicating why segregation is so important.  Labeling is especially important when dealing with nuclear waste due to how much harm to human health the excess products of the nuclear cycle can cause. \n There are multiple facets of waste management that all come with hazards, both for those around the disposal site and those who work within waste management. Exposure to waste of any kind can be detrimental to the health of the individual, primary conditions that worsen with exposure to waste are   and  .  The exposure to waste on an average individual is highly dependent on the conditions around them, those in less developed or lower income areas are more susceptible to the effects of waste product, especially though chemical waste.  The range of hazards due to waste is extremely large and covers every type of waste, not only chemical. There are many different guidelines to follow for disposing different types of waste. \n The hazards of   are a large risk to many variable communities, including underdeveloped countries and countries or cities with little space for landfills or alternatives. Burning waste is an easily accessible option for many people around the globe, it has even been encouraged by the   when there is no other option.  Because burning waste is rarely paid attention to, its effects go unnoticed. The release of hazardous materials and CO2 when waste is burned is the largest hazard with incineration. \n In most developed countries, domestic waste disposal is funded from a national or local tax which may be related to income, or property values. Commercial and industrial waste disposal is typically charged for as a commercial service, often as an integrated charge which includes disposal costs. This practice may encourage disposal contractors to opt for the cheapest disposal option such as landfill rather than the environmentally best solution such as re-use and recycling.\n Financing solid waste management projects can be overwhelming for the city government, especially if the government see it as an important service they should render to the citizen. Donors and grants are a funding mechanism that is dependent on the interest of the donor organization. As much as it is a good way to develop a city's waste management infrastructure, attracting and utilizing grants is solely reliant on what the donor considers important. Therefore, it may be a challenge for a city government to dictate how the funds should be distributed among the various aspect of waste management. \n An example of a country that enforces a waste tax is  . The tax is based on two rates: fixed and variable. The fixed rate is based on the size of the house while the variable is determined by the number of people living in the house. \n The World Bank finances and advises on solid waste management projects using a diverse suite of products and services, including traditional loans, results-based financing, development policy financing, and technical advisory. World Bank-financed waste management projects usually address the entire lifecycle of waste right from the point of generation to collection and transportation, and finally treatment and disposal. \n A   is a site for the disposal of   materials. It is the oldest and most common form of  , although the systematic burial of waste with daily, intermediate and final covers only began in the 1940s. In the past, waste was simply left in piles or thrown into pits (known in   as  ).\n Incineration is a disposal method in which solid organic wastes are subjected to combustion so as to convert them into residue and gaseous products. This method is useful for the disposal of both   and solid residue from wastewater treatment. This process reduces the volume of solid waste by 80 to 95 percent.  Incineration and other high-temperature waste treatment systems are sometimes described as \" \". Incinerators convert waste materials into  ,  ,  , and  .\n Incineration is carried out both on a small scale by individuals and on a large scale by industry. It is used to dispose of solid, liquid, and gaseous waste. It is recognized as a practical method of disposing of certain   materials (such as biological  ). Incineration is a controversial method of waste disposal, due to issues such as the emission of gaseous   including substantial quantities of  .\n Incineration is common in countries such as   where land is more scarce, as the facilities generally do not require as much area as landfills.   (WtE) or energy-from-waste (EfW) are broad terms for facilities that burn waste in a furnace or boiler to generate heat, steam, or electricity. Combustion in an incinerator is not always perfect and there have been concerns about pollutants in gaseous emissions from incinerator stacks. Particular concern has focused on some very persistent   such as  ,  , and  , which may be created and which may have serious environmental consequences and some heavy metals such as   and   which can be volatilised in the combustion process..\n Recycling is a   practice that refers to the collection and reuse of waste materials such as empty beverage containers. This process involves breaking down and reusing materials that would otherwise be gotten rid of as trash. There are numerous benefits of recycling, and with so many new technologies making even more materials recyclable, it is possible to clean up the Earth.  Recycling not only benefits the environment but also positively affects the economy. The materials from which the items are made can be made into new products.  Materials for recycling may be collected separately from general waste using dedicated bins and collection vehicles, a procedure called  . In some communities, the owner of the waste is required to separate the materials into different bins (e.g. for paper, plastics, metals) prior to its collection. In other communities, all recyclable materials are placed in a single bin for collection, and the sorting is handled later at a central facility. The latter method is known as \" \". \n The most common consumer products recycled include   such as beverage cans,   such as wire,   from food and aerosol cans, old steel furnishings or equipment, rubber  ,   and   bottles,   bottles and jars,    ,  , magazines and light paper, and   boxes.\n ,  ,  , and   (see  ) are also recyclable. These items are usually composed of a single type of material, making them relatively easy to recycle into new products. The recycling of complex products (such as computers and electronic equipment) is more difficult, due to the additional dismantling and separation required.\n The type of material accepted for recycling varies by city and country. Each city and country has different recycling programs in place that can handle the various types of recyclable materials. However, certain variation in acceptance is reflected in the resale value of the material once it is reprocessed. Some of the types of recycling include waste paper and cardboard,  ,  , electronic devices,  ,  , cloth and textile and so many more.  In July 2017, the Chinese government announced an import ban of 24 categories of recyclables and  , including  , textiles and mixed paper, placing tremendous impact on developed countries globally, which exported directly or indirectly to China. \n Recoverable materials that are organic in nature, such as  , food scraps, and paper products, can be recovered through   and digestion processes to   the organic matter. The resulting organic material is then recycled as   or   for agricultural or landscaping purposes. In addition, waste gas from the process (such as methane) can be captured and used for generating electricity and heat (CHP/cogeneration) maximising efficiencies. There are different types of composting and digestion methods and technologies. They vary in complexity from simple home compost heaps to large-scale industrial digestion of mixed domestic waste. The different methods of biological decomposition are classified as aerobic or anaerobic methods. Some methods use the hybrids of these two methods. The anaerobic digestion of the organic fraction of solid waste is more environmentally effective than landfill, or incineration.  The intention of biological processing in waste management is to control and accelerate the natural process of decomposition of organic matter. (See  ).\n Energy recovery from waste is the conversion of non-recyclable waste materials into usable heat, electricity, or fuel through a variety of processes, including combustion, gasification, pyrolyzation, anaerobic digestion, and   recovery.  This process is often called waste-to-energy. Energy recovery from waste is part of the non-hazardous waste management hierarchy. Using energy recovery to convert non-recyclable waste materials into electricity and heat, generates a renewable energy source and can reduce carbon emissions by offsetting the need for energy from fossil sources as well as reduce methane generation from landfills.  Globally, waste-to-energy accounts for 16% of waste management. \n The energy content of waste products can be harnessed directly by using them as a direct combustion fuel, or indirectly by processing them into another type of fuel. Thermal treatment ranges from using waste as a fuel source for cooking or heating and the use of the gas fuel (see above), to fuel for   to generate steam and electricity in a  .   and   are two related forms of thermal treatment where waste materials are heated to high temperatures with limited   availability. The process usually occurs in a sealed vessel under high  . Pyrolysis of solid waste converts the material into solid, liquid, and gas products. The liquid and gas can be burnt to produce energy or refined into other chemical products (chemical refinery). The solid residue (char) can be further refined into products such as  . Gasification and advanced   are used to convert organic materials directly into a synthetic gas ( ) composed of   and  . The gas is then burnt to produce electricity and  .\nAn alternative to pyrolysis is high-temperature and pressure supercritical water decomposition (hydrothermal monophasic oxidation).\n Pyrolysis is often used to convert many types of domestic and industrial residues into a recovered fuel. Different types of waste input (such as plant waste, food waste, tyres) placed in the pyrolysis process potentially yield an alternative to fossil fuels.  Pyrolysis is a process of thermo-chemical decomposition of organic materials by heat in the absence of stoichiometric quantities of  ; the decomposition produces various hydrocarbon gases.  During pyrolysis, the molecules of an object vibrate at high frequencies to the extent that molecules start breaking down. The rate of pyrolysis increases with  . In industrial applications, temperatures are above 430 °C (800 °F). \n Slow pyrolysis produces gases and solid charcoal.  Pyrolysis holds promise for conversion of   into useful liquid fuel. Pyrolysis of waste wood and plastics can potentially produce fuel. The solids left from pyrolysis contain metals, glass, sand, and pyrolysis coke which does not convert to gas. Compared to the process of incineration, certain types of pyrolysis processes release less harmful by-products that contain alkali metals, sulphur, and chlorine. However, pyrolysis of some waste yields gases which impact the environment such as HCl and SO . \n Resource recovery is the systematic diversion of waste, which was intended for disposal, for a specific next use.  It is the processing of recyclables to extract or recover materials and resources, or convert to energy.  These activities are performed at a resource recovery facility.  Resource recovery is not only environmentally important, but it is also cost-effective.  It decreases the amount of waste for disposal, saves space in landfills, and conserves natural resources. \n Resource recovery, an alternative approach to traditional waste management, utilizes life cycle analysis (LCA) to evaluate and optimize waste handling strategies. Comprehensive studies focusing on mixed municipal solid waste (MSW) have identified a preferred pathway for maximizing resource efficiency and minimizing environmental impact, including effective waste administration and management, source separation of waste materials, efficient collection systems, reuse and recycling of non-organic fractions, and processing of organic material through anaerobic digestion.\n As an example of how resource recycling can be beneficial, many items thrown away contain metals that can be recycled to create a profit, such as the components in circuit boards. Wood chippings in pallets and other packaging materials can be recycled into useful products for horticulture. The recycled chips can cover paths, walkways, or arena surfaces.\n Application of rational and consistent waste management practices can yield a range of benefits including:\n  or waste reclamation  is the process of   products or   from an economic process being   (given economic value), by   or   in order to create economically useful materials.  The term comes from practices in   and  ,   and waste management. The term is usually applied in industrial processes where residue from creating or processing one good is used as a raw material or energy feedstock for another industrial process.    in particular are good candidates for valorization because they tend to be more consistent and predictable than other waste, such as  . \n Liquid waste is an important category of waste management because it is so difficult to deal with. Unlike solid wastes, liquid wastes cannot be easily picked up and removed from an environment. Liquid wastes spread out, and easily pollute other sources of liquid if brought into contact. This type of waste also soaks into objects like soil and groundwater. This in turn carries over to pollute the plants, the animals in the ecosystem, as well as the humans within the area of the pollution. \n  describes the processes used for   that is produced by industries as an undesirable by-product. After treatment, the treated industrial wastewater (or effluent) may be reused or released to a   or to a   in the environment. Some industrial facilities generate wastewater that can be treated in  . Most industrial processes, such as  , chemical and   plants have their own specialized facilities to treat their wastewaters so that the pollutant concentrations in the treated wastewater comply with the regulations regarding disposal of wastewaters into   or into rivers, lakes or  .  This applies to industries that generate wastewater with high concentrations of organic matter (e.g. oil and grease), toxic pollutants (e.g. heavy metals,  ) or nutrients such as  .  Some industries install a pre-treatment system to remove some pollutants (e.g., toxic compounds), and then discharge the partially treated wastewater to the municipal sewer system. \n  describes the processes used to manage and dispose of   produced during  . Sludge treatment is focused on reducing sludge weight and volume to reduce transportation and disposal costs, and on reducing potential health risks of disposal options. Water removal is the primary means of weight and volume reduction, while   destruction is frequently accomplished through heating during thermophilic digestion,  , or  . The choice of a sludge treatment method depends on the volume of sludge generated, and comparison of treatment costs required for available disposal options. Air-drying and composting may be attractive to rural communities, while limited land availability may make aerobic digestion and mechanical dewatering preferable for cities, and   may encourage   alternatives in metropolitan areas.\n Sludge is mostly water with some amounts of solid material removed from liquid sewage. Primary sludge includes   removed during primary treatment in primary  . Secondary sludge is sludge separated in secondary clarifiers that are used in     or processes using inorganic  . In intensive sewage treatment processes, the sludge produced needs to be removed from the liquid line on a continuous basis because the volumes of the tanks in the liquid line have insufficient volume to store sludge.  This is done in order to keep the treatment processes compact and in balance (production of sludge approximately equal to the removal of sludge). The sludge removed from the liquid line goes to the sludge treatment line. Aerobic processes (such as the   process) tend to produce more sludge compared with anaerobic processes. On the other hand, in extensive (natural) treatment processes, such as   and  , the produced sludge remains accumulated in the treatment units (liquid line) and is only removed after several years of operation. \n Sludge treatment options depend on the amount of solids generated and other site-specific conditions. Composting is most often applied to small-scale plants with aerobic digestion for mid-sized operations, and anaerobic digestion for the larger-scale operations. The sludge is sometimes passed through a so-called pre-thickener which de-waters the sludge. Types of pre-thickeners include centrifugal sludge thickeners,  rotary drum sludge thickeners and belt filter presses.  Dewatered sludge may be incinerated or transported offsite for disposal in a landfill or use as an agricultural soil amendment. \n An important method of waste management is the prevention of waste material being created, also known as  . Waste Minimization is reducing the quantity of hazardous wastes achieved through a thorough application of innovative or alternative procedures.  Methods of avoidance include reuse of second-hand products, repairing broken items instead of buying new ones, designing products to be refillable or reusable (such as cotton instead of plastic shopping bags), encouraging consumers to avoid using   (such as disposable  ), removing any food/liquid remains from cans and packaging,  and designing products that use less material to achieve the same purpose (for example, lightweighting of beverage cans). \n The   is the   of   between countries for further  ,  , or  . Toxic or   are often imported by   from developed countries.\n The   Report  , describes the amount of solid waste produced in a given country. Specifically, countries which produce more solid waste are more economically developed and more industrialized.  The report explains that \"Generally, the higher the economic development and rate of urbanization, the greater the amount of solid waste produced.\"  Therefore, countries in the  , which are more economically developed and urbanized, produce more solid waste than   countries. \n Current international trade flows of waste follow a pattern of waste being produced in the Global North and being exported to and disposed of in the Global South. Multiple factors affect which countries produce waste and at what magnitude, including geographic location, degree of  , and level of integration into the global economy.\n \"Neoliberalism ...removes economics and markets from the discourse of social obligations and social costs. ...As a policy and political project, neoliberalism is wedded to the privatization of public services, selling off of state functions, deregulation of finance and labor, elimination of the welfare state and unions, liberalization of trade in goods and capital investment, and the marketization and   of society.\" Areas with developing economies often experience exhausted waste collection services and inadequately managed and uncontrolled dumpsites. The problems are worsening.  Problems with governance complicate the situation. Waste management in these countries and cities is an ongoing challenge due to weak institutions, chronic under-resourcing, and rapid urbanization.  All of these challenges, along with the lack of understanding of different factors that contribute to the hierarchy of waste management, affect the treatment of waste. \n In developing countries, waste management activities are usually carried out by the poor, for their survival. It has been estimated that 2% of the population in Asia, Latin America, and Africa are dependent on waste for their livelihood. Family organized, or individual manual scavengers are often involved with waste management practices with very little supportive network and facilities with increased risk of health effects. Additionally, this practice prevents their children from further education. The participation level of most citizens in waste management is very low, residents in urban areas are not actively involved in the process of waste management. \n Traditionally, the   has been a late adopter of new technologies such as   (Radio Frequency Identification) tags, GPS and integrated software packages which enable better quality data to be collected without the use of estimation or manual data entry.  This technology has been used widely by many organizations in some industrialized countries. Radiofrequency identification is a tagging system for automatic identification of recyclable components of municipal solid waste streams. \n Smart waste management has been implemented in several cities, including San Francisco, Varde or Madrid.  Waste containers are equipped with  . When the container is almost full, the sensor warns the pickup truck, which can thus trace its route servicing the fullest containers and skipping the emptiest ones. \n The \"Global Waste Management Outlook 2024,\" supported by the Environment Fund -  ’s core financial fund, and jointly published with the   (ISWA), provides a comprehensive update on the trajectory of global waste generation and the escalating costs of waste management since 2018. The report predicts municipal solid waste to rise from 2.3 billion tonnes in 2023 to 3.8 billion tonnes by 2050. The direct global cost of waste management was around USD 252 billion in 2020, which could soar to USD 640.3 billion annually by 2050 if current practices continue without reform. Incorporating life cycle assessments, the report contrasts scenarios from maintaining the status quo to fully adopting   and   principles. It indicates that effective waste prevention and management could cap annual costs at USD 270.2 billion by 2050, while a circular economy approach could transform the sector into a net positive, offering a potential annual gain of USD 108.5 billion. To prevent the direst outcomes, the report calls for immediate action across multiple sectors, including development banks, governments, municipalities, producers, retailers, and citizens, providing targeted strategies for waste reduction and improved management practices. \n Municipal solid waste generation shows spatiotemporal variation. In spatial distribution, the point sources in eastern coastal regions are quite different. Guangdong, Shanghai and Tianjin produced MSW of 30.35, 7.85 and 2.95 Mt, respectively. In temporal distribution, during 2009–2018, Fujian province showed a 123% increase in MSW generation while Liaoning province showed only 7% increase, whereas Shanghai special zone had a decline of −11% after 2013. MSW composition characteristics are complicated. The major components such as kitchen waste, paper and rubber & plastics in different eastern coastal cities have fluctuation in the range of 52.8–65.3%, 3.5–11.9%, and 9.9–19.1%, respectively. Treatment rate of consumption waste is up to 99% with a sum of 52% landfill, 45% incineration, and 3% composting technologies, indicating that landfill still dominates MSW treatment. \n  has seen benefits from implementing a $300 million sanitary   system. While it might appear to be a costly investment, the country's government predicts that it has saved them another $440 million in damages, or consequences of failing to dispose of waste properly. \n  started to make changes to their waste management policies in 2009 with the expectation to be zero waste by 2030.  Council made changes such as making recycling and composting a mandatory practice for businesses and individuals, banning   and plastic bags, putting charges on paper bags, and increasing garbage collection rates.  Businesses are fiscally rewarded for correct disposal of recycling and composting and taxed for incorrect disposal. Besides these policies, the waste bins were manufactured in various sizes. The compost bin is the largest, the recycling bin is second, and the garbage bin is the smallest. This encourages individuals to sort their waste thoughtfully with respect to the sizes. These systems are working because they were able to divert 80% of waste from the landfill, which is the highest rate of any major U.S. city.  Despite all these changes, Debbie Raphael, director of the San Francisco Department of the Environment, states that zero waste is still not achievable until all products are designed differently to be able to be recycled or compostable. \n Waste management policy in England is the responsibility of the   (DEFRA). In England, the \"Waste Management Plan for England\" presents a compilation of waste management policies.  In the devolved nations such as Scotland Waste management policy is a responsibility of their own respective departments.\n In  , ASAZA is a community-based organization whose principal purpose is to complement the efforts of the Government and cooperating partners to uplift the standard of living for disadvantaged communities. The project's main objective is to minimize the problem of indiscriminate littering which leads to   and pollution of the environment. ASAZA is also at the same time helping alleviate the problems of unemployment and poverty through income generation and payment of participants, women, and unskilled youths. \n A record 53.6 million metric tonnes (Mt) of electronic waste was generated worldwide in 2019, up 21 percent in just five years, according to the UN's Global E-waste Monitor 2020, released today. The new report also predicts global e-waste – discarded products with a battery or plug – will reach 74 Mt by 2030, almost a doubling of e-waste in just 16 years. This makes e-waste the world's fastest-growing domestic waste stream, fueled mainly by higher consumption rates of electric and electronic equipment, short life cycles, and few options for repair. Only 17.4 percent of 2019's e-waste was collected and recycled. This means that gold, silver, copper, platinum, and other high-value, recoverable materials conservatively valued at US$57 billion – a sum greater than the Gross Domestic Product of most countries – were mostly dumped or burned rather than being collected for treatment and reuse.  E-wasteis predicted to double by 2050. \n The Transboundary E-waste Flows Monitor quantified that 5.1 Mt (just below 10 percent of the total amount of global e-waste, 53.6 Mt) crossed country borders in 2019. To better understand the implication of transboundary movement, this study categorizes the transboundary movement of e-waste into controlled and uncontrolled movements and also considers both the receiving and sending regions. \n Related scientific journals in this area include:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science", "title": "List of pioneers in computer science", "content": "\n\nThis is a list of people who made transformative breakthroughs in the creation, development and imagining of what   could do.\n ~ Items marked with a tilde are circa dates.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/X.25", "title": "X.25", "content": "\n  is an   standard protocol suite for   data communication in   (WAN). It was originally defined by the   (CCITT, now ITU-T) in a series of drafts and finalized in a publication known as   in 1976.  \n The protocol suite is designed as three conceptual layers, which correspond closely to the lower three layers of the seven-layer  , although it was developed several years before the OSI model (1984).  It also supports functionality not found in the OSI  .  An X.25 WAN consists of   (PSE) nodes as the networking hardware, and  ,   connections, or   connections as physical links. \n X.25 was popular with   for their   from the late 1970s to 1990s, which provided worldwide coverage. It was also used in   systems, such as  , and by the credit card payment industry.  However, most users have since moved to the   (TCP/IP). X.25 is still used, for example by the aviation industry. \n The   (later  ), the organization responsible for international standardization of telecom services, began developing a standard for packet-switched data communication in the mid-1970s based upon a number of emerging data network projects.  Participants in the design of X.25 included engineers from Canada, France, Japan, the UK, and the USA representing a mix of national   (France, Japan, UK) and private operators (Canada, USA). In particular, the work of  , contributed significantly to the standard, which was based on a   service. A few minor changes, which complemented the proposed specification, were accommodated to enable   to join the agreement.  Various updates and additions were worked into the standard, eventually recorded in the ITU series of technical books describing the telecommunication systems. These books were published every fourth year with different-colored covers. The X.25 specification is part of the larger set of X-Series. \n \n The CCITT appointed a special Rapporteur on packet switching,  , who held an initial meeting in January 1974. This resulted in a question, to be answered by study group (SG) VII for the next CCITT plenary in 1976, which was “Should the packet-node of operation be provided on public data networks and, if so, how should it be implemented?”. A list of packet switching networks “to be considered” was provided:   (of the   in the USA),   (of the European COST),   (of the British  ),  (of the  ),   (of   in France), the   (of the   in the UK), the SWIFT network (of the international  ), and the   (of the international  ). \n The second Rapporteur meeting, hosted in Oslo by the Norwegian Telecommunications Administration in November 1974, gathered 24 participants, including representatives of other international organizations ( ,  ,  ).  A document submitted by France “with the active support of a number of European administrations” served as “main basis for discussion in this meeting”. It was then “agreed that two types of services should be considered, a ‘datagram’ service and a ‘virtual call’ service”. \n At the third meeting, focus had moved from whether there should be packet-mode networks to whether there could be “a standard for the interface between the network and the computers”. \n Starting in January 1975, several bilateral and multilateral meetings took place between network operators having commitments for a packet switching service, in view to draft a common interface specification. Meetings started between the Canadian   and the French  , continued with the startup   of the USA, and continued with the BPO of the UK. \n In March 1975, Halvor Bothner-By produced a list of recommendations to be created, or simply updated, for a packet switching standard to become possible. It was used as a framework at a drafting meeting in Ottawa between engineers of the four operators wishing to have a standard as soon as possible in the USA, Canada, France, UK and Japan. They prepared contributions to be submitted to SG VII in their name by administrations having voting right in CCITT. One contribution was a X.2x interface specification, the first version of  what will become X.25). \n The fourth Rapporteur meeting, in May 1975 in Geneva, had 45 participants and 27 new documents. The Rapporteur asked whether packet switching recommendations should be issued \"with a view to making international interworking possible”, \"the French administration answered in the affirmative and Canada strongly supported the French proposal\". No firm conclusion was however obtained yet. \n The fifth Rapporteur meeting, in September 1975 in Geneva, had about 60 participants. After discussions on the proposed virtual circuit interface, numerous issues were left unresolved.  Concerning datagrams, ‘It was proposed by Larry Roberts of the US delegation and supported by representatives from France and Canada respectively that the datagram classification be changed from “E” to “A”’, i.e., from essential \"to be available internationally” to additional that \"may be available in certain countries and internationally”.  The Rapporteur's last report expressed doubts “that a standard would be ready for adoption by SG VII”. \n At the last meeting of the full SG VII before the CCITT plenary of September 1976, the available draft X.25 raised numerous clarification questions and/or and technical objections. SG VII's chairman Vern MacDonald appointed an editor and provided a meeting facility for the weekend. After intense work during it, all issues had been dealt with. For an approval by the full study group, a challenge remained: copies of the updated X.25 draft had to be available in two languages. To get them in due time, Anton Rybzynski of DATAPAC and Paul Guinaudeau of TRANSPAC spent a full night to handwrite all negotiated amendments, and to assemble them with paste and scissors into clean documents. COM VII then reviewed distributed copies, and unanimously approved them for submission to the forthcoming CCITT plenary.   At this plenary of September 1976, the X.25 recommendation and the other 10 of SG VII were unanimously approved. \n As requested by the USA, an optional datagram service was added to the revised X.25 of 1980, together with an alignment of its link layer, now called LAPB, with a recent evolution of HDLC in  . In absence of any public network operator implementing this option, datagrams were finally deleted from X.25 in its update of 1984. \n Publicly accessible X.25 networks, commonly called  , were set up in many countries during the late 1970s and 1980s to lower the cost of accessing various  . Examples include  ,  ,  ,  ,  ,  ,  ,  ,   and   as well as the  . Their combined network had large global coverage during the 1980s and into the 1990s. \n Beginning in the early 1990s, in North America, use of X.25 networks (predominated by Telenet and Tymnet)  started to be replaced by   services offered by national telephone companies.  Most systems that required X.25 now use  , however it is possible to transport X.25 over TCP/IP when necessary. \n X.25 networks are still in use throughout the world. A variant called   is used widely by    .   Paknet, now known as Widanet, remains in operation in many regions of the world, running on an X.25 protocol base. In some countries, like the Netherlands or Germany, it is possible to use a stripped version of X.25 via the   of an  -2 (or  ) connection for low-volume applications such as   terminals; but, the future of this service in the Netherlands is uncertain.\n X.25 is still used in the aeronautical business (especially in Asia) even though a transition to modern protocols is increasingly important as X.25 hardware becomes increasingly rare and costly.  As recently as March 2006, the United States National Airspace Data Interchange Network has used X.25 to interconnect remote airfields with  .\n France was one of the last remaining countries where commercial end-user service based on X.25 operated. Known as   it was based on  , itself running on X.25. In 2002,   had about 9 million users, and in 2011 it accounted for about 2 million users in France when France Télécom announced it would shut down the service by 30 June 2012.  As planned, service was terminated 30 June 2012. There were 800,000 terminals in operation at the time.  An X.25 service was still purchasable from BT in the United Kingdom in 2019. \n The general concept of the X.25 was to create a universal and global  . Much of the X.25 system is a description of the rigorous   needed to achieve this, as well as more efficient sharing of capital-intensive physical resources.\n The X.25 specification defines only the interface between a subscriber (DTE) and an X.25 network (DCE).  , a protocol very similar to X.25, defines the interface between two X.25 networks to allow connections to traverse two or more networks. X.25 does not specify how the network operates internally –  many X.25 network implementations used something very similar to X.25 or   internally, but others used quite different protocols internally. The ISO protocol equivalent to X.25, ISO 8208, is compatible with X.25, but additionally includes provision for two X.25 DTEs to be directly connected to each other with no network in between. By separating the  , ISO 8208 permits operation over additional networks such as ISO 8802 LLC2 (ISO LAN) and the OSI data link layer. \n X.25 originally defined three basic protocol levels or architectural layers. In the original specifications these were referred to as   and also had a level number, whereas all ITU-T X.25 recommendations and ISO 8208 standards released after 1984 refer to them as  .  The layer numbers were dropped to avoid confusion with the OSI Model layers. \n The X.25 model was based on the traditional telephony concept of establishing reliable circuits through a shared network, but using software to create \" \" through the network. These calls interconnect   providing endpoints to users, which looked like  . Each endpoint can establish many separate virtual calls to different endpoints.\n For a brief period, the specification also included a connectionless datagram service, but this was dropped in the next revision. The \"fast select with restricted response facility\" is intermediate between full call establishment and connectionless communication. It is widely used in query-response transaction applications involving a single request and response limited to 128 bytes of data carried each way. The data is carried in an extended call request packet and the response is carried in an extended field of the call reject packet, with a connection never being fully established.\n Closely related to the X.25 protocol are the protocols to connect asynchronous devices (such as dumb terminals and printers) to an X.25 network:  ,   and  . This functionality was performed using a   or PAD (also known as a  , referring to the three protocols used).\n Although X.25 predates the   (OSIRM), the   of the OSI model corresponds to the X.25  , the   to the X.25  , and the   to the X.25  .  The X.25  ,  , provides a reliable data path across a data link (or multiple parallel data links, multilink) which may not be reliable itself. The X.25   provides the virtual call mechanisms, running over X.25  . The   includes mechanisms to maintain virtual calls and to signal data errors in the event that the   cannot recover from data transmission errors. All but the earliest versions of X.25 include facilities  which provide for OSI   Addressing (NSAP addressing, see below). \n X.25 was developed in the era of   connecting to host computers, although it also can be used for communications between computers. Instead of dialing directly “into” the host computer –  which would require the host to have its own pool of modems and phone lines, and require non-local callers to make long-distance calls –  the host could have an X.25 connection to a network service provider. Now dumb-terminal users could dial into the network's local “PAD” (  facility), a gateway device connecting modems and serial lines to the X.25 link as defined by the   and   standards.\n Having connected to the PAD, the dumb-terminal user tells the PAD which host to connect to, by giving a phone-number-like address in the   address format (or by giving a host name, if the service provider allows for names that map to   addresses). The PAD then places an X.25 call to the host, establishing a  . Note that X.25 provides for virtual calls, so   to be a   network, even though in fact the data itself is   internally, similar to the way TCP provides connections even though the underlying data is packet switched. Two X.25 hosts could, of course, call one another directly; no PAD is involved in this case. In theory, it doesn't matter whether the X.25 caller and X.25 destination are both connected to the same carrier, but in practice it was not always possible to make calls from one carrier to another.\n For the purpose of flow-control, a   protocol is used with the default window size of 2. The acknowledgements may have either local or end to end significance. A D bit (Data Delivery bit) in each data packet indicates if the sender requires end to end acknowledgement. When D=1, it means that the acknowledgement has end to end significance and must take place only after the remote DTE has acknowledged receipt of the data. When D=0, the network is permitted (but not required) to acknowledge before the remote DTE has acknowledged or even received the data.\n While the PAD function defined by   and   specifically supported asynchronous character terminals, PAD equivalents were developed to support a wide range of proprietary intelligent communications devices, such as those for IBM   (SNA).\n Error recovery procedures at the packet layer assume that the data link layer is responsible for retransmitting data received in error. Packet layer error handling focuses on resynchronizing the information flow in calls, as well as clearing calls that have gone into unrecoverable states:\n X.25 supports two types of  ;   (VC) and   (PVC). Virtual calls are established on an as-needed basis. For example, a VC is established when a call is placed and torn down after the call is complete. VCs are established through a call establishment and clearing procedure. On the other hand,   are preconfigured into the network.  PVCs are seldom torn down and thus provide a dedicated connection between end points.\n VC may be established using X.121 addresses. The X.121 address consists of a three-digit data country code (DCC) plus a network digit, together forming the four-digit data network identification code (DNIC), followed by the national terminal number (NTN) of at most ten digits. Note the use of a single network digit, seemingly allowing for only 10 network carriers per country, but some countries are assigned more than one DCC to avoid this limitation. Networks often used fewer than the full NTN digits for routing, and made the spare digits available to the subscriber (sometimes called the sub-address) where they could be used to identify applications or for further routing on the subscribers networks.\n  facility was added in the X.25(1984) revision of the specification, and this enabled X.25 to better meet the requirements of    .  Public X.25 networks were not required to make use of NSAP addressing, but, to support OSI CONS, were required to carry the NSAP addresses and other ITU-T specified DTE facilities transparently from DTE to DTE.  Later revisions allowed multiple addresses in addition to X.121 addresses to be carried on the same DTE-DCE interface: Telex addressing ( ),   addressing ( ),   addressing ( ),   addresses (IANA ICP), and local    . \n PVCs are permanently established in the network and therefore do not require the use of addresses for call setup. PVCs are identified at the subscriber interface by their logical channel identifier (see below). However, in practice not many of the national X.25 networks supported PVCs.\n One DTE-DCE interface to an X.25 network has a maximum of 4095 logical channels on which it is allowed to establish virtual calls and permanent virtual circuits,  although networks are not expected to support a full 4095 virtual circuits.  For identifying the channel to which a packet is associated, each packet contains a 12 bit logical channel identifier made up of an 8-bit logical channel number and a 4-bit logical channel group number.  Logical channel identifiers remain assigned to a virtual circuit for the duration of the connection.  Logical channel identifiers identify a specific logical channel between the   (subscriber appliance) and the   (network), and only has local significance on the link between the subscriber and the network. The other end of the connection at the remote DTE is likely to have assigned a different logical channel identifier. The range of possible logical channels is split into 4 groups: channels assigned to permanent virtual circuits, assigned to incoming virtual calls, two-way (incoming or outgoing) virtual calls, and outgoing virtual calls.  (Directions refer to the direction of virtual call initiation as viewed by the DTE –  they all carry data in both directions.)  The ranges allowed a subscriber to be configured to handle significantly differing numbers of calls in each direction while reserving some channels for calls in one direction. All international networks are required to implement support for permanent virtual circuits, two-way logical channels and one-way logical channels outgoing; one-way logical channels incoming is an additional optional facility.  DTE-DCE interfaces are not required to support more than one logical channel.  Logical channel identifier zero will not be assigned to a permanent virtual circuit or virtual call.  The logical channel identifier of zero is used for packets which don't relate to a specific virtual circuit (e.g. packet layer restart, registration, and diagnostic packets).\n In public networks, X.25 was typically billed as a flat monthly service fee depending on link speed, and then a price-per-segment on top of this.  Link speeds varied, typically from 2400 bit/s up to 2 Mbit/s, although speeds above 64 kbit/s were uncommon in the public networks. A segment was 64 bytes of data (rounded up, with no carry-over between packets),  charged to the caller  (or callee in the case of reverse charged calls, where supported).  Calls invoking the   facility (allowing 128 bytes of data in call request, call confirmation and call clearing phases)  would generally attract an extra charge, as might use of some of the other X.25 facilities. PVCs would have a monthly rental charge and a lower price-per-segment than VCs, making them cheaper only where large volumes of data are passed.\n The network may allow the selection of the maximal length in range 16 to 4096 octets (2  values only) per virtual circuit by negotiation as part of the call setup procedure. The maximal length may be different at the two ends of the virtual circuit.\n X.25 provides a set of user facilities defined and described in ITU-T Recommendation X.2.  The X.2 user facilities fall into five categories:\n X.25 also provides X.25 and ITU-T specified DTE optional user facilities defined and described in ITU-T Recommendation X.7.  The X.7 optional user facilities fall into four categories of user facilities that require:\n The CCITT/ITU-T versions of the protocol specifications are for   (PDN).  The ISO/IEC versions address additional features for private networks (e.g.   (LAN) use) while maintaining compatibility with the CCITT/ITU-T specifications. \n The user facilities and other features supported by each version of X.25 and ISO/IEC 8208 have varied from edition to edition.  Several major protocol versions of X.25 exist: \n The X.25 Recommendation allows many options for each network to choose when deciding which features to support and how certain operations are performed. This means each network needs to publish its own document giving the specification of its X.25 implementation, and most networks required DTE appliance manufacturers to undertake protocol conformance testing, which included testing for strict adherence and enforcement of their network specific options. (Network operators were particularly concerned about the possibility of a badly behaving or misconfigured DTE appliance taking out parts of the network and affecting other subscribers.) Therefore, subscriber's DTE appliances have to be configured to match the specification of the particular network to which they are connecting. Most of these were sufficiently different to prevent interworking if the subscriber didn't configure their appliance correctly or the appliance manufacturer didn't include specific support for that network. In spite of protocol conformance testing, this often lead to interworking problems when initially attaching an appliance to a network.\n In addition to the CCITT/ITU-T versions of the protocol, four editions of ISO/IEC 8208 exist: \n The X.25 protocol had a lot of overhead to deal with data loss, since circuits back then ran over poor-grade cabling and had a lot of single-bit errors to deal with. As circuits became more and more reliable, the overhead was no longer needed, and less expensive   took over. Frame Relay has its technical base in X.25, but does not attempt to correct errors.\n The world-wide   based on X.25 helped grow IP as a protocol riding on top. \n X.25 was also available in niche applications such as Retronet that allow   to use the  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_shopping_centres_in_Australia", "title": "List of shopping centres in Australia", "content": "\n\n This is a  . It does not include street shopping strips such as   or   which were prevalent in Australian cities until the 1960s.\n The North Coast refers to the   and the   regions.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Program_evaluation_and_review_technique", "title": "Program evaluation and review technique", "content": "\n The     ( ) is a statistical tool used in  , which was designed to analyze and represent the   involved in completing a given  .\n PERT was originally developed by Charles E. Clark for the   in 1958; it is commonly used in conjunction with the   (CPM), which was also introduced in 1958. \n PERT is a method of analyzing the tasks involved in completing a project, especially the time needed to complete each task, and to identify the minimum time needed to complete the total project. It incorporates uncertainty by making it possible to schedule a project while not knowing precisely the details and   of all the activities. It is more event-oriented than start- and completion-oriented, and is used more for projects where time is the major constraint rather than cost. It is applied to very large-scale, one-time, complex, non-routine infrastructure projects, as well as   projects.\n PERT offers a management tool,  which relies \"on arrow and node diagrams of   and  : arrows represent the   or work necessary to reach the   or nodes that indicate each completed phase of the total project.\" \n PERT and CPM are complementary tools, because \"CPM employs one time estimation and one cost estimation for each activity; PERT may utilize three time estimates (optimistic, expected, and pessimistic) and no costs for each activity. Although these are distinct differences, the term PERT is applied increasingly to all critical path scheduling.\" \n PERT was developed primarily to simplify the planning and scheduling of large and complex projects. It was developed for the   to support the U.S. Navy's Polaris nuclear submarine project.  It found applications throughout industry. An early example is the   in   which used PERT from 1965 until the opening of the 1968 Games.  This project model was the first of its kind, a revival for the   of Frederick Taylor and later refined by Henry Ford ( ).  's CPM was invented at roughly the same time as PERT.\n Initially PERT stood for   but by 1959 was renamed.  It had been made public in 1958 in two publications of the U.S. Department of the Navy, entitled   and   both primarily written by Charles F. Clark.  In a 1959 article in  ,  , Head of the Program Evaluation Branch, Special Projects Office, U.S. Navy, gave a detailed description of the main concepts of PERT. He explained:\n Through an electronic computer, the PERT technique processes data representing the major, finite accomplishments (events) essential to achieve end-objectives; the inter-dependence of those events; and   of time and range of time necessary to complete each activity between two successive events. Such time expectations include estimates of \"most likely time\", \"optimistic time\", and \"pessimistic time\" for each activity. The technique is a management control tool that sizes up the outlook for meeting objectives on time; highlights danger signals requiring management decisions; reveals and defines both methodicalness and slack in the flow plan or the network of sequential activities that must be performed to meet objectives; compares current expectations with   completion dates and computes the probability for meeting scheduled dates; and simulates the effects of options for decision— before decision. Ten years after the introduction of PERT, the American   Maribeth Brennan compiled a selected   with about 150 publications on PERT and CPM, all published between 1958 and 1968. \n For the subdivision of work units in PERT  another tool was developed: the  . The Work Breakdown Structure provides \"a framework for complete networking, the Work Breakdown Structure was formally introduced as the first item of analysis in carrying out basic PERT/CPM.\" \n In a PERT diagram, the main building block is the  , with connections to its known predecessor events and successor events.\n Besides events, PERT also tracks activities and sub-activities:\n PERT defines four types of time required to accomplish an activity:\n PERT supplies a number of tools for management with determination of concepts, such as:\n The first step for scheduling the project is to determine the tasks that the project requires and the order in which they must be completed.  The order may be easy to record for some tasks (e.g., when building a house, the land must be graded before the foundation can be laid) while difficult for others (there are two areas that need to be graded, but there are only enough bulldozers to do one).  Additionally, the time estimates usually reflect the normal, non-rushed time.  Many times, the time required to execute the task can be reduced for an additional cost or a reduction in the quality.\n In the following example there are seven tasks, labeled   through  .  Some tasks can be done concurrently (  and  ) while others cannot be done until their predecessor task is complete (  cannot begin until   is complete).  Additionally, each task has three time estimates: the optimistic time estimate ( ), the most likely or normal time estimate ( ), and the pessimistic time estimate ( ).  The expected time ( ) is computed using the formula (  + 4  +  ) ÷ 6. \n Once this step is complete, one can draw a   or a network diagram.\n A network diagram can be created by hand or by using diagram software.  There are two types of network diagrams, activity on arrow ( ) and activity on node ( ).  Activity on node diagrams are generally easier to create and interpret.  To create an AON diagram, it is recommended (but not required) to start with a node named  .  This \"activity\" has a duration of zero (0).  Then you draw each activity that does not have a predecessor activity (  and   in this example) and connect them with an arrow from start to each node.  Next, since both   and   list   as a predecessor activity, their nodes are drawn with arrows coming from  .  Activity   is listed with   and   as predecessor activities, so node   is drawn with arrows coming from both   and  , signifying that   cannot begin until both   and   have been completed.  Activity   has   as a predecessor activity, so an arrow is drawn connecting the activities.  Likewise, an arrow is drawn from   to  .  Since there are no activities that come after   or  , it is recommended (but again not required) to connect them to a node labeled  .\n By itself, the network diagram pictured above does not give much more information than a Gantt chart; however, it can be expanded to display more information.  The most common information shown is:\n In order to determine this information it is assumed that the activities and normal duration times are given.  The first step is to determine the ES and EF.  The ES is defined as the maximum EF of all predecessor activities, unless the activity in question is the first activity, for which the ES is zero (0).  The EF is the ES plus the task duration (EF = ES + duration).\n Barring any  , the project should take 19.51 work days to complete.  The next step is to determine the late start (LS) and late finish (LF) of each activity.  This will eventually show if there are activities that have  .  The LF is defined as the minimum LS of all successor activities, unless the activity is the last activity, for which the LF equals the EF.  The LS is the LF minus the task duration (LS = LF − duration).\n The next step is to determine the   and if any activities have  .  The critical path is the path that takes the   to complete.  To determine the path times, add the task durations for all available paths.  Activities that have slack can be delayed without changing the overall time of the project.  Slack is computed in one of two ways, slack = LF − EF   slack = LS − ES.  Activities that are on the critical path have a slack of zero (0).\n The critical path is   and the critical time is 19.51 work days.  It is important to note that there can be more than one critical path (in a project more complex than this example) or that the critical path can change.  For example, let's say that activities   and   take their pessimistic (b) times to complete instead of their expected (T ) times.  The critical path is now   and the critical time is 22 work days.  On the other hand, if activity   can be reduced to one work day, the path time for   is reduced to 15.34 work days, which is slightly less than the time of the new critical path,   (15.67 work days).\n Assuming these scenarios do not happen, the slack for each activity can now be determined.\n Therefore, activity   can be delayed almost 4 work days without delaying the project.  Likewise, activity     activity   can be delayed 4.68 work days without delaying the project (alternatively,   and   can be delayed 2.34 work days each).\n Depending upon the capabilities of the data input phase of the critical path algorithm, it may be possible to create a loop, such as A -> B -> C -> A. This can cause simple algorithms to loop indefinitely. Although it is possible to \"mark\" nodes that have been visited, then clear the \"marks\" upon completion of the process, a far simpler mechanism involves computing the total of all activity durations. If an EF of more than the total is found, the computation should be terminated. It is worth saving the identities of the most recently visited dozen or so nodes to help identify the problem link.\n During project execution a real-life project will never execute exactly as it was planned due to uncertainty. This can be due to ambiguity resulting from subjective estimates that are prone to human errors or can be the result of variability arising from unexpected events or risks. The main reason that PERT may provide inaccurate information about the project completion time is due to this schedule uncertainty. This inaccuracy may be large enough to render such estimates as not helpful.\n One possible method to maximize solution robustness is to include safety in the baseline schedule in order to absorb disruptions. This is called  , however, allowing for every possible disruption would be very slow and couldn't be accommodated by the baseline schedule. A second approach, termed  , defines a procedure to react to disruptions that cannot be absorbed by the baseline schedule.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/May_the_12th_Be_with_You", "title": null, "content": "\n\n  is an   short film based on the television series  . The short was released on May 10, 2024, on   in celebration of both   and  . \n It is the   and the third   short film related to   after   (2021) and   (2023). \n In its first week of release, the short film topped the most watched films on  . \n  and other moms and children of Disney+ are getting ready for a Mother's Day outing, get in the car, but   hasn't fixed it yet, but the day is saved when   comes to the rescue. On Ahsoka's T-6 shuttle, Marge gets sick and opens a window, ejecting   out of the ship. Right after they arrive at the Disney Playground Planet, the   in her witch form informs them they need to go to the Disney Parking Planet first.\n On the planet, a battle with   ensues against   and   and the other kids join too. Marge gets a little too eager to fight when she gets stopped by a stormtrooper saying it's just a simulation and tells others she ruined the simulation. She gets booed and to apologize, she organizes a party at the Simpsons house. At the party,   kids join, and Homer takes   at  .\n \nJohn Schwarz of   gave   an 8.5 out of 10, stating,  The producers for   do shorts like this all of the time and I think this one’s by far the best one for two reasons: 1) We get far more talking than the previous shorts 2) It was actually funny! And that last part is the most important because whilst the previous shorts seemed to forget that, even in four minutes, you gotta get a laugh, “May the 12th Be With You” is by far the funniest, gag-filled effort of the bunch and you should definitely add it to your watchlist this weekend.", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Outline_of_the_United_States", "title": "Outline of the United States", "content": "\n The following   is provided as an overview of and topical guide to the United States:\n  – federal republic located primarily in  , and the world's third-largest country by both land and total area. It shares land borders with   to its north and with   to its south and has maritime borders with the  ,  ,  , and other nations. With the Soviet Union's collapse and the subsequent end of the Cold War in 1991, the United States emerged as the world's sole superpower.\n The geography of the United States varies across their immense area. Within the continental U.S.,   exist, though each is composed of several smaller physiographic subdivisions.  These major divisions are:\n At the  , the United States consisted of  , former   of the United Kingdom. In the following years, the number of   has grown steadily due to expansion to the west, conquest and purchase of lands by the American government, and division of existing states to the current number of  : \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n All departments are listed by their present-day name and only departments with past or present cabinet-level status are listed. Order of succession applies only to within the cabinet; the vice president has always been first in the line of succession, and the Speaker of the House and the President pro tem of the Senate have at times been included.\n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n  –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   -       –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –   –  \n  –   –   –   –  \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Mindy_Kaling", "title": "Mindy Kaling", "content": "\n  (born June 24, 1979),  known professionally as   ( ), is an American actress, screenwriter, and producer.  Known for her work on television, she has received numerous accolades including two  , a  , and six nominations at the  .\n Kaling first gained recognition starring as   in the      , for which she also worked as a writer.  For her work on the series, she was nominated for a   for  . She gained wider attention for creating, producing and starring as Dr. Mindy Lahiri in the  /Hulu sitcom  . She then created other TV shows such as the  ,  ,   and  . \n Her film career includes voice roles in   (2010),   (2012), and   (2015) as well as live action roles in   (2011)    (2012),   (2018),   (2018), and   (2019), the last of which she also wrote and produced. She wrote two memoirs both reaching  .  She also received a   as a producer for the musical  .  In 2012, Kaling founded the production company  . \n Vera Mindy Chokalingam was born June 24, 1979, in  , to father Avudaiappan Chokalingam and mother Swati Chokalingam (  Roy-Sircar).  She has an elder brother, Vijay Chokal-Ingam.  Her parents are from India;  the family immigrated to the United States in 1979, the same year Kaling was born.  Kaling's mother died of   in 2012. \n Kaling has said she has never been called Vera, her first name,  but has been referred to as Mindy since her mother was pregnant with her while her parents were living in  . They were already planning to move to the United States and wanted, Kaling said, a \"cute American name\" for their daughter, and liked the name Mindy from the show  . \n Kaling graduated from   in 1997. The following year, she entered  , where she was a member of improvisational comedy troupe The Dog Day Players and   group The Rockapellas, and wrote for the   the college's humor magazine.  Kaling graduated from Dartmouth in 2001  with a bachelor's degree in playwriting.  She lists the comedy series  ,  ,   and   as early influences on her comedy. \n While a 19-year-old sophomore at Dartmouth, Kaling was an intern on  .  She has said that she never saw a family like hers on TV, which gave her a dual perspective she uses in her writing.   She thinks the \"everyone against me\" mentality is what she learned as a child of immigrants.  She named her   character   after author  .  After college, she moved to  .  She said one of her worst job experiences was as a production assistant for three months on the   psychic show.  She described it as \"depressing.\"  During this same time, she performed  . \n Kaling devised her stage name after discovering while doing stand-up comedy that emcees would have trouble pronouncing her last name, Chokalingam, and sometimes made jokes about it.  She toured solo and with  , who was later a fellow cast member of   In August 2002, she portrayed   in an   play called  ,  which she co-wrote with her best friend from college,  , who played  .   magazine named it one of their \"Top Ten Theatrical Events of The Year\", and it was \"a surprise hit\" at the 2002  .  \n Initially, Withers and Kaling had, \"for their own entertainment, mockingly pretended to be the best friends Matt Damon and Ben Affleck; that pretending spawned  , the goofy play that reimagined how Damon and Affleck came to write the movie  .\"  Kaling wrote a blog,  ,  which reemerged on her website on September 29, 2011.  She wrote it under the name Mindy Ephron, \"a name Kaling chose because she was amused by the idea of her 20-something Indian-American self as a long-lost   sister.\" \n In 2004, when   producer   was working to adapt   from the   TV series of the same name, he hired Kaling as a writer-performer after reading a   she wrote. He said, \"She's very original ... If anything feels phony or lazy or passé, she'll pounce on it.\"  When Kaling joined  , she was 24 years old and was the only woman on a staff of eight.  She took on the role of  , debuting in the series' second episode, \"Diversity Day\".  Her TV appearances include a 2005 episode of  , playing  's assistant. She is featured on the CD   and guest-wrote parts of an episode of   in April 2006.  After her film debut in   with  , Kaling appeared in the film   as a waitress.\n In an interview with  , she stated that Kelly is \"an exaggerated version of what I think the upper-level writers believe my personality is.\"  Kaling directed   webisode  .  She directed the   episode \" ,\" which marked her television directorial debut. In 2007, she had a small part in   alongside fellow   actors  ,  , and  . She starred in the 2009 film   as a     tour guide.\n On September 15, 2011, when her contract was set to expire at the end of Season 7, she signed a new contract to stay with the show for Season 8 and was promoted to full executive producer.  Her   contract included a development deal for a new show (eventually titled  ), in which she appeared as an actress and contributed as a writer.  Kaling left   after the   episode \" \", but returned to guest-star in its  . In 2011, Kaling published a memoir,  , which appeared on the  .  Her second book,  , covers the events that have happened in her life since 2011, and was published on September 15, 2015.  She published a third memoir,  , with Amazon Original Stories in 2020.\n Kaling and her fellow writers and producers of   were nominated five consecutive times for the Primetime Emmy Award for Outstanding Comedy Series. In 2010, she was nominated with Daniels for Outstanding Writing in a Comedy Series for the episode \"Niagara.\"   In a 2019 interview with   Magazine, Kaling spoke about the sexism she faced with the Television Academy, having had to go to great lengths to prove her contribution as a producer when the academy informed her she would be cut from the producer list because there were too many producers.  She said that to receive her rightful producing credit when   was nominated for an Emmy for Outstanding Comedy Series, \"They made me, not any of the other producers, fill out a whole form and write an essay about all my contributions as a writer and a producer… I had to get letters from all the other male, white producers saying that I had contributed, when my actual record stood for itself.\"  In 2011, she played the role of Shira, a doctor who is a roommate and colleague of the main character Emma (played by  ) in  . Kaling also made an appearance as Vanetha in   in 2012.\n In 2012, Kaling pitched a   to   called  , which Kaling wrote, produced and starred in.  Fox began airing the series in 2012. Also in 2012, Kaling founded the production company,  . \n In 2013,   magazine named one of the  .  Fox canceled her series   in May 2015, with it later being picked up by   for a 26-episode fourth season and a 16-episode fifth season. In March 2017, Kaling announced that the show's sixth season, which would air starting September 2017, would be the last.  The series concluded on November 14, 2017.\n Kaling voiced Taffyta Muttonfudge in Disney's animated comedy film   and Disgust in  's 2015 film  . In 2017,   created   where Kaling is a co-creator, writer, and producer.  She had a recurring guest role on the show, which premiered March 8, 2018, on  .  It was cancelled after one season. In 2018, she played Mrs. Who in  , the live-action Disney adaptation of  , and starred alongside  ,  ,  ,  ,   and   in  , the all-female version of  .  In 2020, Kaling created the   series   with  , a comedy partially based on Kaling's childhood story growing up in the Boston area.  It premiered on Netflix on April 27, 2020, and is about an Indian American high school student, played by  , dealing with the death of her father.  The series received positive reviews.    and   have described the series as a watershed moment for South Asian representation in Hollywood, and praised Kaling for breaking South Asian stereotypes. \n In February 2021,   announced they had ordered the adult-oriented   spin-off series  , with Kaling as executive producer as well as voicing the  .  The series premiered on January 12, 2023, to mixed to negative reviews from critics.   's fan reception was even more polarizing and got overwhelming negative reviews due to the humor and criticized its  , characterization, writing, and departures from the traditional   format.    was later ranked by several publications as one of the worst television series of 2023.  That year, she was appointed as a board member along with historian June Li and   for the Smithsonian's  . \n Kaling is set to co-write the third installment in the   series with  .  The film was scheduled to be released in May 2022,  but has been indefinitely delayed due to scripting.  She is also committed to re-team with Dan Goor to write and star alongside   in a comedy about an Indian-American wedding under  . \n Kaling has three children: a daughter, Katherine, born in December 2017, a son, Spencer, born in September 2020 and a daughter, Anne, born in February 2024.  She has kept the paternity of her children private.  She is an adherent of   and has expressed her desire to give her children a Hindu upbringing. \n Kaling has a close friendship with  , whom she met through writing for  , with Novak calling Kaling \"the most important person in my life\" (on   with  ). They dated on and off while writing and acting on the show.  Novak is the godfather of Kaling's first two children. \n In 2012, Kaling was included in the   100 list of the world's most influential people.  In 2014, she was named one of  s Women of the Year.  On June 10, 2018, she received an   of   from   in  .  In June 2024, the Los Angeles Times featured Kaling in its \"L.A. Influential\" series as a \"creator who is leaving their mark\" in Los Angeles.  On August 21, 2024, she spoke at the Democratic National Convention in support of  . \n In January 2023, a video resurfaced of Kaling being interviewed by   on his show   in 2015.  There, Kaling revealed she delivered an impromptu kiss on the actor   in a recording of  : \"What I did was improvise and kiss him in the scene, something that was not in the script,\" declared the actress, and that she jokingly told the producers \"tell anyone and you're fired.\" Kaling was criticized for making a joke out of something that would be considered an abuse of power, as well as workplace and sexual harassment. \n Over her career she has received two   and the  , and six   nominations. She was recognized by   magazine as   in 2013. A decade later she received the  's  , and was awarded the   from President  . \n In 2013,   identified Kaling as one of the \"50 Coolest and Most Creative Entertainers\" in Hollywood.  In the same year, Kaling was recognized by   magazine as  .  In March 2023, Kaling was awarded the 2021   from the US president   in the  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Mexico_City", "title": "Mexico City", "content": "This is an accepted version of this page \n\n\n  is the   and   of  , and the   in  .  It is one of the most important cultural and financial centers in the world.  Mexico City is located in the   within the high Mexican central  , at an altitude of 2,240 meters (7,350 ft). The city has 16   or  , which are in turn divided into   or  .\n The 2020 population for the   was 9,209,944,  with a land area of 1,495 square kilometers (577 sq mi).  According to the most recent definition agreed upon by the federal and state governments, the population of   is 21,804,515, which makes it the   in the world, the second-largest   in the   (behind  ,  ), and the largest   city (city proper) in the world.    has a   of $411 billion in 2011, which makes it one of the  .  The city was responsible for generating 15.8% of Mexico's GDP, and the metropolitan area accounted for about 22% of the country's GDP.  If it were an independent country in 2013, Mexico City would be the fifth-largest economy in  . \n Mexico City is the   and one of two founded by  .  The city was originally built on a group of islands in   by the   around 1325, under the name  . It was almost completely destroyed in the 1521   and subsequently redesigned and rebuilt in accordance with the  . In 1524, the   of Mexico City was established, known as  ,  and as of 1585, it was officially known as   (Mexico City).  Mexico City played a major role in the   as a political, administrative, and financial center.  Following  , the   was established in 1824.\n After years of demanding greater political  , residents were finally given the right to   both a   and the representatives of the     by election in 1997. Ever since, left-wing parties (first the   and later the  ) have controlled both of them.  The city has several progressive policies,  such as elective  ,  a limited form of  ,   ,   ,  and  .  On 29 January 2016, it ceased to be the   (Spanish:   or  ) and is now officially known as   (or  ), with a greater degree of autonomy.  A clause in the  , however, prevents it from becoming a state within the Mexican federation, as long it remains the capital of the country. \n Mexico City was traditionally known as   (\"the City of the Palaces\"), a   attributed to Baron   when visiting the city in the 19th century, who, sending a letter back to Germany, said Mexico City could rival any major city in Europe. But it was English politician   who really penned the following: \"... look at their works: the moles, aqueducts, churches, roads—and the luxurious   which has risen from the clay-built ruins of Tenochtitlan...\", on page 84 of the Letter V of  . \n During the colonial period, the city's   was \"Muy Noble e Insigne, Muy Leal e Imperial\" (Very Noble and Distinguished, Very Loyal and Imperial).  During  's administration a political slogan was introduced:   ( ). This motto was quickly adopted as a city nickname but has faded since the new motto,   (\"Capital in Movement\"), was adopted by the administration headed by  , though the latter is not treated as often as a nickname in media. \nUp until 2013, it was common to refer to the city by the initialism \n\"DF\" from \"Distrito Federal de México\". Since 2013, the abbreviation \"CDMX\" (Ciudad de México) has been more common, particularly in relation to government campaigns.\n The city is colloquially known as   after the locals' nickname  .  Chilango is used pejoratively by people living outside Mexico City to \"connote a loud, arrogant, ill-mannered, loutish person\".  For their part those living in Mexico City designate insultingly those who live elsewhere as living in   ('the provinces', 'the periphery') and many proudly embrace the term chilango.  Residents of Mexico City are more recently called   (deriving from the postal abbreviation of the Federal District in Spanish: D.F., which is read \"De-Efe\"). They are formally called   (in reference to the city being the capital of the country), but \"[p]erhaps because capitalino is the more polite, specific, and correct word, it is almost never utilized\". \n The oldest signs of human occupation in the area of Mexico City are those of the \" \" and others found in San Bartolo Atepehuacan ( ). They were believed to correspond to the lower Cenolithic period (9500–7000 BC).  However, a 2003 study placed the age of the Peñon woman at 12,700 years old (calendar age),  one of the oldest human remains discovered in the Americas. Studies of her mitochondrial DNA suggest she was either of Asian  or European  or Aboriginal Australian origin. \n The area was the destination of the migrations of the   during the 8th and 13th centuries, people that would give rise to the  , and   (Aztecs) cultures. The latter arrived around the 14th century to settle first on the shores of the lake.\n The city of   was founded by the   people in 1325 or 1327.  The old Mexica city that is now referred to as   was built on an island in the center of the inland lake system of the  , which is shared with a smaller city-state called  .  According to legend, the Mexicas' principal god,  , indicated the site where they were to build their home by presenting a   perched on a   devouring a  . \n Between 1325 and 1521, Tenochtitlan grew in size and strength, eventually dominating the other city-states around   and in the Valley of Mexico. When the Spaniards arrived, the   Empire had reached much of  , touching both the Gulf of Mexico and the Pacific Ocean. \n After landing in  , Spanish explorer   advanced upon Tenochtitlan with the aid of many of the other native peoples, \narriving there on 8 November 1519.  Cortés and his men marched along the causeway leading into the city from   (Ixtapalapa), and the city's ruler,  , greeted the Spaniards; they exchanged gifts, but the camaraderie did not last long.  Cortés put Moctezuma under  , hoping to rule through him. \n Tensions increased until, on the night of 30 June 1520 – during a struggle known as \" \" – the Aztecs rose up against the Spanish intrusion and managed to capture or drive out the Europeans and their   allies.  Cortés regrouped at Tlaxcala. The Aztecs thought the Spaniards were permanently gone, and they elected a new king,  , but he soon died; the next king was  .  Cortés began a   in May 1521. For three months, the city suffered from the lack of food and water as well as the spread of   brought by the Europeans.  Cortés and his allies landed their forces in the south of the island and slowly fought their way through the city.  Cuauhtémoc surrendered in August 1521.  The Spaniards practically razed Tenochtitlan during the final siege of the conquest. \n Cortés first settled in  , but decided to rebuild the Aztec site to erase all traces of the old order.  He did not establish a territory under his own  , but remained loyal to the Spanish crown. The first Spanish   arrived in Mexico City fourteen years later. By that time, the city had again become a  , having power that extended far beyond its borders.  Although the Spanish preserved Tenochtitlan's basic layout, they built   over the old Aztec temples and claimed the imperial palaces for themselves.  Tenochtitlan was renamed \"Mexico\" because the Spanish found the word easier to pronounce. \n The city had been the capital of the   and in the colonial era, Mexico City became the capital of  . The   or vice-king lived in the viceregal palace on the main square or  . The  , the seat of the Archbishopric of New Spain, was constructed on another side of the Zócalo, as was the archbishop's palace, and across from it the building housing the city council or   of the city. A late seventeenth-century painting of the Zócalo by   depicts the main square, which had been the old Aztec ceremonial center. The existing central plaza of the Aztecs was effectively and permanently transformed to the ceremonial center and seat of power during the colonial period, and remains to this day in modern Mexico, the central plaza of the nation. The rebuilding of the city after the siege of Tenochtitlan was accomplished by the abundant indigenous labor in the surrounding area. Franciscan friar  , one of the   who arrived in New Spain in 1524, described the rebuilding of the city as one of the afflictions or plagues of the early period:\n The seventh plague was the construction of the great City of Mexico, which, during the early years used more people than in the construction of Jerusalem. The crowds of laborers were so numerous that one could hardly move in the streets and causeways, although they are very wide. Many died from being crushed by beams, or falling from high places, or in tearing down old buildings for new ones. Preconquest Tenochtitlan was built in the center of the inland lake system, with the city reachable by   and by wide causeways to the mainland. The causeways were rebuilt under Spanish rule with indigenous labor. Colonial Spanish cities were constructed on a grid pattern, if no geographical obstacle prevented it. In Mexico City, the Zócalo (main square) was the central place from which the grid was then built outward. The Spanish lived in the area closest to the main square in what was known as the  , in orderly, well laid-out streets. Indigenous residences were outside that exclusive zone and houses were haphazardly located.  Spaniards sought to keep indigenous people separate but since the Zócalo was a center of commerce for Amerindians, they were a constant presence in the central area, so strict segregation was never enforced.  At intervals Zócalo was where major celebrations took place as well as executions. It was also the site of two major riots in the seventeenth century, one in 1624, the other in 1692. \n The city grew as the population did, coming up against the lake's waters. As the depth of the lake water fluctuated, Mexico City was subject to periodic flooding. A major labor draft, the  , compelled thousands of indigenous over the colonial period to work on infrastructure to prevent flooding. Floods were not only an inconvenience but also a health hazard, since during flood periods human waste polluted the city's streets. By draining the area, the mosquito population dropped as did the frequency of the diseases they spread. However, draining the wetlands also changed the habitat for fish and birds and the areas accessible for indigenous cultivation close to the capital.  The 16th century saw a proliferation of churches, many of which can still be seen today in the  . \nEconomically, Mexico City prospered as a result of trade. Unlike Brazil or  , Mexico had easy contact with both the Atlantic and Pacific worlds. Although the Spanish crown tried to completely regulate all commerce in the city, it had only partial success. \n The concept of   flourished in New Spain in a way not seen in other parts of the Americas. Spaniards encountered a society in which the concept of nobility mirrored that of their own. Spaniards respected the indigenous order of nobility and added to it. In the ensuing centuries, possession of a   did not mean one exercised great political power, for one's power was limited even if the accumulation of wealth was not.  The concept of nobility in Mexico was not political but rather a very conservative Spanish social one, based on proving the worthiness of the family. Most of these families proved their worth by making fortunes in New Spain outside of the city itself, then spending the revenues in the capital, building churches, supporting charities and building extravagant palatial homes. The craze to build the most opulent residence possible reached its height in the last half of the 18th century. Many of these palaces can still be seen today, leading to Mexico City's nickname of \"The city of palaces\" given by  . \n The   (\"Cry of Dolores\"), also known as El Grito de la Independencia (\"Cry of Independence\"), marked the beginning of the  . The Battle of Guanajuato, the first major engagement of the insurgency, occurred four days later. After a decade of war, Mexico's independence from Spain was effectively declared in the Declaration of Independence of the Mexican Empire on 27 September 1821.    is proclaimed Emperor of the   by Congress, crowned in the  . \n The Mexican Federal District was established by the new government and by the signing of their new constitution, where the concept of a   was adapted from the  .  Before this designation, Mexico City had served as the   for both the   and the nation as a whole.   and then   became the capital of the State of Mexico. \n During the 19th century, Mexico City was the center stage of all the political disputes of the country. It was the imperial capital on two occasions (1821–1823 and 1864–1867), and of two   states and two   states that followed innumerable coups d'états in the space of half a century before the triumph of the Liberals after the  . It was also the objective of one of the two French invasions to Mexico ( ), and occupied for a year by American troops in the framework of the   (1847–1848).\n The   was the series of engagements from 8 to 15 September 1847, in the general vicinity of Mexico City during the  . Included are major actions at the battles of   and  , culminating with the fall of Mexico City. The U.S. Army under Winfield Scott scored a major success that ended the war. The American invasion into the Federal District was first resisted during the   on 8 August, where the  , which was composed primarily of Catholic Irish and German immigrants but also Canadians, English, French, Italians, Poles, Scots, Spaniards, Swiss, and Mexicans, fought for the Mexican cause, repelling the American attacks. After defeating the  , the Mexican–American War came to a close after the United States     deep into   resulting in the capture of Mexico City and   by the   1st, 2nd, 3rd and 4th  .  The invasion culminated with the storming of   in the city itself. \n During this battle, on 13 September, the 4th Division, under  , spearheaded the attack against Chapultepec and carried the castle. Future   generals   and   participated in the attack. Serving in the Mexican defense were the cadets later immortalized as   (the \"Boy Heroes\"). The Mexican forces fell back from Chapultepec and retreated within the city. Attacks on the Belén and San Cosme Gates came afterwards. The   was signed in what is now the far north of the city. \n The capital escaped the worst of the violence of the ten-year conflict of the  . The most significant episode of this period for the city was the   (\"Ten Tragic Days\") of February 1913, when forces counter to the elected government of   staged a successful coup. The center of the city was subjected to artillery attacks from the army stronghold of the   or citadel, with significant civilian casualties and the undermining of confidence in the Madero government.  , chief general of the  , saw a chance to take power, forcing Madero and Pino Suarez to sign resignations. The two were murdered later while on their way to  .  Huerta's ouster in July 1914 saw the entry of the armies of   and  , but the city did not experience violence. Huerta had abandoned the capital and the conquering armies marched in.  's   faction ultimately prevailed in the revolutionary civil war and Carranza took up residence in the presidential palace.\n In the 20th century the phenomenal growth of the city and its environmental and political consequences dominate. In 1900, the population of Mexico City was about 500,000.  The city began to grow rapidly westward in the early part of the 20th century  and then began to grow upwards in the 1950s, with the   becoming the city's first skyscraper. \n The rapid development of Mexico City as a center for   was most fully manifested in the mid-1950s construction of the  , the main campus of the  . Designed by the most prestigious architects of the era, including  ,  , and  , the buildings feature murals by artists  ,  , and  . It has since been recognized as a  . \n The   brought about the construction of large sporting facilities.  In 1969, the   was inaugurated.  Explosive growth in the population of the city started in the 1960s, with the population overflowing the boundaries of the Federal District into the neighboring State of Mexico, especially to the north, northwest, and northeast. Between 1960 and 1980 the city's population more than doubled to nearly 9 million. \n In 1980, half of all the industrial jobs in Mexico were located in Mexico City. Under relentless growth, the Mexico City government could barely keep up with services. Villagers from the countryside who continued to pour into the city to escape poverty only compounded the city's problems. With no housing available, they took over lands surrounding the city, creating huge  .\n The inhabitants of Mexico City faced serious   and   problems, as well as  .  Air and water pollution has been contained and improved in several areas due to government programs, the renovation of vehicles and the modernization of public transportation.\n The autocratic government that ruled Mexico City since the Revolution was tolerated, mostly because of the continued economic expansion since World War II. This was the case even though this government could not handle the population and pollution problems adequately. Nevertheless, discontent and protests began in the 1960s leading to the   in  . \n Three years later, a demonstration in the Maestros avenue, organized by former members of the 1968 student movement, was violently repressed by a paramilitary group called \" \", composed of gang members and teenagers from many sports clubs who received training in the US.\n On 19 September 1985, at 7:19am  , the area was struck by the  .  The earthquake proved to be a disaster politically for the   government. The Mexican government was paralyzed by its own bureaucracy and corruption, forcing ordinary citizens to create and direct their own rescue efforts and to reconstruct much of the housing that was lost as well. \n However, the last straw may have been the controversial elections of 1988. That year, the presidency was set between the  's candidate, Carlos Salinas de Gortari, and a coalition of left-wing parties led by  , son of the former president  . The counting system \"fell\" because coincidentally the power went out and suddenly, when it returned, the winning candidate was Salinas, even though Cárdenas had the upper hand.\n As a result of the fraudulent election, Cárdenas became a member of the  . Discontent over the election eventually led   to become the first   of Mexico City in 1997. Cárdenas promised a more  , and his party claimed some victories against crime, pollution, and other major problems. He resigned in 1999 to run for the presidency.\n Mexico City is located in the Valley of Mexico, sometimes called the Basin of Mexico. This valley is located in the   in the high plateaus of south-central Mexico. \n It has a minimum altitude of 2,200 meters (7,200 feet)   and is surrounded by mountains and volcanoes that reach elevations of over 5,000 meters (16,000 feet).  This valley has no natural drainage outlet for the waters that flow from the mountainsides, making the city vulnerable to flooding. Drainage was engineered through the use of canals and tunnels starting in the 17th century. \n Mexico City primarily rests on what was  .  Seismic activity is frequent there.  Lake Texcoco was drained starting from the 17th century. Although none of the lake waters remain, the city rests on the lake bed's heavily saturated clay. This soft base is collapsing due to the over-extraction of groundwater, called  .\n Since the beginning of the 20th century the city has sunk as much as nine meters (30 feet) in some areas. On average Mexico City sinks 20   (1   and 8 inches) or 50   (1/2  ) every year.  This sinking is causing problems with runoff and wastewater management, leading to flooding problems, especially during the summer.  The entire lake bed is now paved over and most of the city's remaining forested areas lie in the southern boroughs of  ,   and  . \n Originally much of the valley lay beneath the waters of  , a system of interconnected salt and freshwater lakes. The   built dikes to separate the   used to raise crops in   and to prevent recurrent floods. These dikes were destroyed during the siege of Tenochtitlan, and during colonial times the Spanish regularly drained the lake to prevent floods. Only a small section of the original lake remains, located outside Mexico City, in the municipality of  ,  .\n Architects   and   along with a group of Mexican urbanists, engineers and biologists have developed the project plan for  . If approved by the government the project will contribute to the supply of water from natural sources to the  , the creation of new natural spaces, a great improvement in air quality, and greater population establishment planning.\n By the 1990s Mexico City had become infamous as one of the world's most polluted cities; however, the city has since become a model for drastically lowering pollution levels. By 2014   pollution had dropped drastically, while   and   were at levels about a third of those in 1992. The levels of signature pollutants in Mexico City are similar to those of  .  Despite the cleanup, the metropolitan area is still the most  -polluted part of the country, with ozone levels 2.5 times beyond  -defined safe limits. \n To clean up pollution, the federal and local governments implemented numerous plans including the constant monitoring and reporting of environmental conditions, such as ozone and  .  When the levels of these two pollutants reached critical levels, contingency actions were implemented which included closing factories, changing school hours, and extending the   program to two days of the week.  The government also instituted industrial technology improvements, a strict biannual vehicle emission inspection and the reformulation of gasoline and  .  The introduction of     and the   bike-sharing were among efforts to encourage alternate, greener forms of transportation. \n , the city's most iconic public park, has history back to the Aztec emperors who used the area as a retreat. It is south of   district, and houses the   the main city's zoo, several ponds and seven museums, including the  . Other iconic city parks include the  , it is recognized as the oldest   in the  .    and   in the hip   district;   and   in  , and   in  .  There are many smaller parks throughout the city. Most are small \"squares\" occupying two or three square blocks amid residential or commercial districts. Several other larger parks such as the   and  , and in the east  , offer many recreational activities. Northwest of the city is a large ecological reserve, the  . In the southeast is the  , a  . West of   district are the pine forests of the  . Amusement parks include  , in Ajusco neighborhood which is the largest in Latin America. There are numerous seasonal fairs present in the city.\n Mexico City has three zoos.  , the   and  . Chapultepec Zoo is located in the first section of Chapultepec Park in the Miguel Hidalgo. It was opened in 1924.  Visitors can see about 243 specimens of different species including kangaroos, giant panda, gorillas, caracal, hyena, hippos, jaguar, giraffe, lemur, lion, among others.  Zoo San Juan de Aragon is near the San Juan de Aragon Park in the Gustavo A. Madero. In this zoo, opened in 1964,  there are species that are in danger of extinction such as the jaguar and the Mexican wolf. Other guests are the golden eagle, pronghorn, bighorn sheep, caracara, zebras, African elephant, macaw, hippo, among others.  Zoo Los Coyotes is a 27.68-acre (11.2 ha) zoo located south of Mexico City in the Coyoacan. It was inaugurated on 2 February 1999.  It has more than 301 specimens of 51 species of wild native or endemic fauna from the area, featuring eagles, ajolotes, coyotes, macaws, bobcats, Mexican wolves, raccoons, mountain lions, teporingos, foxes, white-tailed deer. \n Mexico City has a   (   ), due to its tropical location but high elevation. The lower region of the valley receives less rainfall than the upper regions of the south; the lower boroughs of  ,  ,   and the east portion of   are usually drier and warmer than the upper southern boroughs of   and  , a mountainous region of   and   trees known as the range of  . The average annual temperature varies from 12 to 16 °C (54 to 61 °F), depending on the altitude of the borough. The temperature is rarely below 3 °C (37 °F) or above 30 °C (86 °F).  At the Tacubaya observatory, the lowest temperature ever registered was −4.4 °C (24 °F) on 13 February 1960, and the highest temperature on record was 34.7 °C (94.5 °F) on 25 May 2024.  Overall precipitation is heavily concentrated in the summer months, and includes dense  .\n Snow falls in the city scarcely, although somewhat more often on nearby mountaintops. Throughout its history, the Central Valley of Mexico was accustomed to having several snowfalls per decade (including a period between 1878 and 1895 in which every single year—except 1880—recorded snowfalls ), mostly  . The effects of the draining of   and   have greatly reduced snowfalls after the snow flurries of 12 February 1907.  Since 1908, snow has only fallen three times, snow on 14 February 1920;  snow flurries on 14 March 1940;  and on 12 January 1967, when 8 centimeters (3 in) of snow fell on the city, the most on record.  The 1967 snowstorm coincided with the operation of   that resulted in the total draining of what was left of Lake Texcoco.  After the disappearance of Lake Texcoco, snow has never fallen again over Mexico City.  The region of the   receives   systems. The weak winds of these systems do not allow for the dispersion, outside the basin, of the   which are produced by the 50,000 industries and 4 million vehicles operating in and around the metropolitan area. \n The area receives about 820 millimeters (32 in) of annual rainfall, which is concentrated from May through October with little or no precipitation for the remainder of the year.  The area has two main seasons. The wet humid summer runs from May to October when winds bring in tropical moisture from the sea, the wettest month being July. The cool sunny winter runs from November to April, when the air is relatively drier, the driest month being December. This season is subdivided into a cold winter period and a warm spring period. The cold period spans from November to February, when polar   push down from the north and keep the air fairly dry. The warm period extends from March to May when subtropical winds again dominate but do not yet carry enough moisture for rain to form. \n Historically, and since   times, the   has been one of the most densely populated areas in Mexico. When the Federal District was created in 1824, the urban area of Mexico City extended approximately to the area of today's  . At the beginning of the 20th century, the   began migrating to the south and west and soon the small towns of   and   were incorporated by the growing conurbation. According to the 1921 census, 54.78% of the city's population was considered Mestizo (Indigenous mixed with European), 22.79% considered European, and 18.74% considered Indigenous. \n Up to the 1990s, the Federal District was the most populous   in Mexico, but since then, its population has remained stable at around 8.7 million. The growth of the city has extended beyond the limits of the city proper to 59 municipalities of the   and 1 in the state of  .  With a population of approximately 19.8 million inhabitants (2008),  it is one of the   conurbations in the world. Nonetheless, the annual rate of growth of the   is much lower than that of other large urban agglomerations in Mexico,  a phenomenon most likely attributable to the   of decentralization. The   of Mexico City from 1995 to 2000 was negative. \n The metropolitan area,   ('Zona Metropolitana del Valle de México' or 'ZMVM' in Spanish) consists of Mexico City itself plus 60 municipalities in the   and one in  . With a population of 21,804,515 (2020 census), Greater Mexico City is both the   and the densest metropolitan area in the country. Of the ca. 21.8 million, 9.2 million live in Mexico City proper  and 12.4 million in the State of Mexico (ca. 75% of the state's population), including the municipalities of: \n Greater Mexico City, in turn, forms part of an even larger   officially known as the   ( ), with a population of 33.4 million, more than one quarter of the country's population according to the 2020 census. The megalopolis as defined by the Environmental Commission of the Megalopolis ( ) covers Mexico City and the states of Mexico, Hidalgo, Puebla, Tlaxcala, Morelos, and since 2019, Querétaro,  thus encompassing the metropolitan areas of Mexico City,  ,  ,  ,  ,  , and others. \n Greater Mexico City was the fastest growing metropolitan area in the country until the late 1980s. Since then, government policies have supported decentralization with the aim of reducing pollution in Greater Mexico City. While still growing, the annual rate of growth has decreased and is lower than that of   and  . \n The   of Mexico City proper from 1995 to 2000 was negative,  which implies that residents are moving to the suburbs of the metropolitan area, or to other states of Mexico. In addition, some inner suburbs are losing population to outer suburbs, indicating the continuing expansion of Greater Mexico City.\n The majority (82%) of the residents in Mexico City are  , slightly lower than the 2010 census national percentage of 87%, making it the largest   denomination, though it has been decreasing over the last decades.  Many other religions and philosophies are also practiced in the city: many different types of   groups, different types of  ,  ,   and other   and   groups. There are also growing  numbers of irreligious people, whether   or  .\nThe patron saint of Mexico City is Saint  , a     missionary who became one of the  . \n The   is the largest   in the world.  There are two Catholic cathedrals in the city, the   and the  , and three former Catholic churches who are now the cathedrals of other rites, the   (Anglican church), the   (Melkite Greek Catholic church) and the   (Maronite church).\n Representing around 18.74% of the city's population,   from different areas of Mexico have migrated to the capital in search of better economic opportunities.  ,  ,  ,   and   are the indigenous languages with the greatest number of speakers in Mexico City.  According to the 2020 Census, 2.03% of Mexico City's population identified as Black,  , or of African descent. \n Additionally, Mexico City is home to large communities of   and immigrants from the rest of North America (U.S. and Canada), from South America (mainly from   and  , but also from  ,  ,   and  ), from Central America and the Caribbean (mainly from  ,  ,  ,   and  ); from Europe (mainly from  ,   and  , but also from  ,  ,  ,  ,  ,  ,   and  ),  and from the Arab world (mostly from Lebanon, and other countries like Syria and Egypt). \n Mexico City is home to the largest population of   living outside the United States. Estimates are as high as 700,000 Americans living in Mexico City, while in 1999 the U.S. Bureau of Consular Affairs estimated over 440,000 Americans lived in the Mexico City Metropolitan Area. \n Mexico City is home to some of the best private hospitals in the country, including Hospital Ángeles, Hospital ABC and Médica Sur. The national   institution for   employees,  , has its largest facilities in Mexico City—including the National Medical Center and the   Medical Center—and has an annual budget of over 6 billion pesos. The IMSS and other   institutions, including the ISSSTE (Public Sector Employees' Social Security Institute) and the National Health Ministry (SSA) maintain large specialty facilities in the city. These include the National Institutes of Cardiology, Nutrition, Psychiatry, Oncology, Pediatrics, Rehabilitation, among others.\n Among its many public and private schools (K–13), the city offers  ,   and   attended by Mexican and  . Best known are the   (German school with three main campuses), the   (Japanese), the Centro Cultural Coreano en México (Korean), the   (French), the  , The   (American School), the   and the   (British). Mexico City joined the UNESCO Global Network of Learning Cities in 2015. \n In the   is the   that is recognized for being the first and oldest European school of   in the   and the first major school of interpreters and translators in the  .  Other, the now-defunct   is considered the father of the UNAM, and it was located in the city and was the  .\n The   (UNAM), located in Mexico City, is the largest university on the continent, with more than 300,000 students from all backgrounds. Three  , several Mexican entrepreneurs and most of Mexico's modern-day presidents are among its former students. UNAM conducts 50% of Mexico's   and has presence all across the country with satellite campuses, observatories and research centers. UNAM ranked 74th in the Top 200 World   published by   (then called Times Higher Education Supplement) in 2006,  making it the highest ranked Spanish-speaking university in the world. The sprawling main campus of the university, known as  , was named a World Heritage Site by UNESCO in 2007. \n The second largest higher-education institution is the   (IPN), which includes among many other relevant centers the   (Cinvestav), where varied high-level scientific and technological research is done. Other major higher-education institutions in the city include the   (UAM), the   (ENAH), the   (ITAM), the   (3 campuses), the   (UP), the  , the   (UIC), the   (UVM), the  ,   (USB), the   (UIC), the  , the  ,   (Colmex),   and the  , (CIDE).\nIn addition, the prestigious   maintains a campus known as \"Casa de California\" in the city.  The   is also in Mexico City.\n The Acta Constitutiva de la Federación of 31 January 1824, and the Federal Constitution of 4 October 1824,  fixed the political and administrative organization of the   after the  . In addition, Section XXVIII of Article 50 gave the new Congress the right to choose where the federal government would be located. This location would then be appropriated as federal land, with the federal government acting as the local authority. The two main candidates to become the capital were Mexico City and  . \n Due in large part to the persuasion of representative  , Mexico City was chosen because it was the center of the country's population and history, even though   was closer to the center geographically. The choice was official on 18 November 1824, and Congress delineated a surface area of two leagues square (8,800 acres) centered on the  . This area was then separated from the  , forcing that state's government to move from the   in the city to  . This area did not include the population centers of the towns of  ,  ,   and  , all of which remained as part of the State of Mexico. \n In 1854 president   enlarged the area of Mexico City almost eightfold from the original 220 to 1,700 km  (80 to 660 sq mi), annexing the rural and mountainous areas to secure the strategic mountain passes to the south and southwest to protect the city in event of a foreign invasion. (The   had just been fought.) The last changes to the limits of Mexico City were made between 1898 and 1902, reducing the area to the current 1,479 km  (571 sq mi) by adjusting the southern border with the state of  . By that time, the total number of municipalities within Mexico City was twenty-two. In 1941, the   borough was merged with the Central Department, which was then renamed \"Mexico City\" (thus reviving the name but not the autonomous municipality). From 1941 to 1970, the Federal District comprised twelve   and Mexico City. In 1970, Mexico City was split into four different  :  ,  ,   and  , increasing the number of   to 16. Since then, the whole Federal District, whose   had by then almost formed a single urban area, began to be considered   a synonym of Mexico City. \n The lack of a   stipulation left a legal vacuum that led to a number of sterile discussions about whether one concept had engulfed the other or if the latter had ceased to exist altogether. In 1993, the situation was solved by an amendment to the 44th article of the  ; Mexico City and the Federal District were stated to be the same entity. The amendment was later introduced into the second article of the Statute of Government of the Federal District. \n On 29 January 2016, Mexico City ceased to be the   (Spanish:   or D.F.), and was officially renamed \"Ciudad de México\" (or \"CDMX\").  On that date, Mexico City began a transition to becoming the country's 32nd federal entity, giving it a level of autonomy comparable to that of a state. It will have its own constitution and its legislature, and its   will now be headed by mayors.  Because of a clause in the Mexican Constitution, however, as it is the seat of the powers of the federation, it can never become a state, or the capital of the country has to be relocated elsewhere. \n In response to the demands, Mexico City received a greater degree of autonomy, with the 1987 elaboration the first Statute of Government ( ) and the creation of an assembly of representatives.  The city has a Statute of Government, and as of its ratification on 31 January 2017, a  ,  similar to the states of the Union. As part of the recent changes in autonomy, the budget is administered locally; it is proposed by the   and approved by the  . Nonetheless, it is the   that sets the ceiling to internal and external   issued by the city government. \n The politics pursued by the administrations of heads of government in Mexico City at the end of the 20th century have usually been more liberal than those of the rest of the country,  whether with the support of the federal government, as was the case with the approval of several comprehensive environmental laws in the 1980s, or by laws that were since approved by the Legislative Assembly. The Legislative Assembly expanded provisions on abortions, becoming the first federal entity to expand   beyond cases of rape and economic reasons, to permit it at the choice of the mother before the 12th week of pregnancy.  In December 2009, the then Federal District became the first city in Latin America and one of very few in the world to legalize  . \n After the political reforms in 2016, the city is divided for administrative purposes into 16 boroughs ( , colloquially  ), formerly called  . While they are not fully equivalent to municipalities, the boroughs have gained significant autonomy.  Formerly appointed by the Federal District's head of government, local authorities were first elected directly by   in 2000. From 2016, each borough is headed by a mayor, expanding their local government powers. \n The boroughs of Mexico City with their 2020 populations are: \n 1.   (pop. 759,137) \n2.   (pop. 432,205) \n3.   (pop. 434,153) \n4.   (pop. 614,447) \n5.   (pop. 217,686) \n6.   (pop. 545,884) \n7.   (pop. 1,173,351) \n8.   (pop. 404,695)\n 9.   (pop. 1,835,486) \n10.   (pop. 247,622) \n11.   (pop. 414,470) \n12.   (pop. 152,685) \n13.   (pop. 392,313) \n14.   (pop. 699,928) \n15.   (pop. 443,704) \n16.   (pop. 442,178)\n The   report of 2005  shows that there were three boroughs with a very high Human Development Index, 12 with a high HDI value (9 above .85), and one with a medium HDI value (almost high).   borough had the highest HDI of the country (0.9510) followed by  , which came up fourth nationally with an HDI of (0.9189), and   was fifth nationally, with an HDI of (0.9169).   (15th),   (23rd), and   (25th) also had very high values of 0.8994, 0.8922, and 0.8915, respectively. \n In contrast, the boroughs of   (172nd),   (177th), and   (183rd) presented the lowest HDI values of Mexico City, with values of 0.8481, 0.8473, and 0.8464, respectively, which are still in the global high-HDI range. The only borough that did not have a high HDI was that of rural  , which had a \"medium\" HDI of 0.7984, far below those of all the other boroughs (627th nationally, the rest being in the top 200). Mexico City's HDI for the 2005 report was 0.9012 (very high), and its 2010 value of 0.9225 (very high), or (by newer methodology) 0.8307, was Mexico's highest. \n The Secretariat of Public Security of Mexico City (Secretaría de Seguridad Pública de la Ciudad de México – SSP) manages a combined force of over 90,000 officers in Mexico City. The SSP is charged with maintaining   and safety in the heart of Mexico City. The historic district is also roamed by tourist police, aiming to orient and serve tourists. These horse-mounted agents dress in traditional uniforms. The investigative Judicial Police of Mexico City (Policía Judicial de la Ciudad de México – PJCDMX) is organized under the Office of the   City (the Procuraduría General de Justicia de la Ciudad de México). The PGJCDMX maintains 16 precincts (delegaciones) with an estimated 3,500 judicial police, 1,100 investigating agents for prosecuting attorneys (agentes del ministerio público), and nearly 1,000 criminology experts or specialists (peritos).\n Between 2000 and 2004 an average of 478 crimes were reported each day in Mexico City; however, the actual crime rate is thought to be much higher \"since most people are reluctant to report crime\".  Under policies enacted by Mayor   between 2009 and 2011, Mexico City underwent a major security upgrade with violent and petty crime rates both falling significantly despite the rise in violent crime in other parts of the country. Some of the policies enacted included the installation of 11,000   around the city and a very large expansion of the police force. Mexico City has one of the world's highest police officer-to-resident ratios, with one uniformed officer per 100 citizens.  Since 1997 the prison population has increased by more than 500%.  Political scientist Markus-Michael Müller argues that mostly informal street vendors are hit by these measures. He sees punishment \"related to the growing politicization of security and crime issues and the resulting criminalization of the people living at the margins of urban society, in particular those who work in the city's informal economy\". \n In 2016, the incidence of   was 3.2 per 100 000 inhabitants, the national average being 4.2.  A 2015 city government report found that two of three women over the age of 15 in the capital suffered some form of violence.  In addition to  , one of the places where women in Mexico City are subjected to violence is on and around public transport. Annually the Metro of Mexico City receives 300 complaints of  . \n Mexico City is   with: \n Mexico City is one of the most important economic hubs in  . The city proper produces 15.8% of the country's  .  In 2002, Mexico City had a   score of 0.915,  identical to that of  . In 2007, residents in the top twelve percent of GDP per capita holders in the city had a mean   of  . The high spending power of Mexico City inhabitants makes the city attractive for companies offering prestige and  . According to a 2009 study conducted by  , Mexico City had a GDP of $390 billion, ranking it as the eighth richest city in the world and the richest in Latin America.  In 2009, Mexico City alone would rank as the 30th largest economy in the world. \n Mexico City is the greatest contributor to the country's industrial GDP (15.8%) and also the greatest contributor to the country's GDP in the   (25.3%). Due to the limited non-urbanized space at the south—most of which is protected through environmental laws—the contribution of Mexico City in agriculture is the smallest of all federal entities in the country.  The economic reforms of President   had a tremendous effect on the city, as a number of businesses, including banks and airlines, were privatized. He also signed the   (NAFTA). This led to decentralization  and a shift in Mexico City's economic base, from manufacturing to services, as most factories moved away to either the  , or more commonly to the northern border. By contrast, corporate office buildings set their base in the city.\n Mexico City offers an immense and varied consumer retail market, ranging from basic foods to ultra high-end luxury goods. Consumers may buy in  , in  , from  , from downtown shops in a street dedicated to a certain type of good, in convenience stores and traditional neighborhood stores, in modern supermarkets, in warehouse and membership stores and the shopping centers that they anchor, in department stores, in  , and in modern shopping malls. In addition, \" \" or mobile markets set up shop on streets in many neighborhoods, depending on day of week. Sundays see the largest number of these markets.\n The city's main source of fresh produce is the  . This in itself is a self-contained mini-city in   borough covering an area equivalent to several dozen city blocks. The wholesale market supplies most of the city's \"mercados\", supermarkets and restaurants, as well as people who come to buy the produce for themselves. Tons of fresh produce are trucked in from all over Mexico every day. The principal fish market is known as  , in the same complex as the Central de Abastos.  The world-renowned market of   occupies 25 blocks, and sells a variety of products. A staple for consumers in the city is the omnipresent \"mercado\". Every major neighborhood in the city has its own borough-regulated market, often more than one. These are large well-established facilities offering most basic products, such as fresh produce and meat/poultry, dry goods, tortillerías, and many other services such as locksmiths, herbal medicine, hardware goods, sewing implements; and a multitude of stands offering freshly made, home-style cooking and drinks in the tradition of   and  .\n Street vendors ply their trade from stalls in the   as well as at non-officially controlled concentrations around metro stations and hospitals; at  , where vendors of a certain \"theme\" (e.g. stationery) are housed; originally these were organized to accommodate vendors formerly selling on the street; or simply from improvised stalls on a city sidewalk.  In addition, food and goods are sold from people walking with baskets, pushing carts, from bicycles or the backs of trucks, or simply from a tarp or cloth laid on the ground.  In the center of the city informal street vendors are increasingly targeted by laws and prosecution.  The weekly   is reported to be the largest in Latin America. \n The   is widely known for specialized, often low-cost retailers. Certain blocks or streets are dedicated to shops selling a certain type of merchandise, with areas dedicated to over 40 categories such as home appliances, lamps and electricals, closets and bathrooms, housewares, wedding dresses, jukeboxes, printing, office furniture and safes, books, photography, jewelry, and opticians. \n Mexico City is a destination for many foreign tourists. The   ( ) and the \"floating gardens\" of   in the southern borough have been declared   by  . Landmarks in the Historic Center include the   (Zócalo), the main central square with its epoch-contrasting Spanish-era   and  , ancient Aztec temple ruins   (\"Major Temple\") and modern structures, all within a few steps of one another. (The Templo Mayor was discovered in 1978 while workers were digging to place underground electric cables).\n The most recognizable icon of Mexico City is the golden   on the wide, elegant avenue  , modeled by the order of the Emperor   after the   in Paris. This avenue was designed over the Americas' oldest known major roadway in the 19th century to connect the   (seat of government) with the  , the imperial residence. Today, this avenue is an important financial district in which the   and several   are located. Another important avenue is the  , which extends 28.8 km (17.9 mi) and is one of the longest single avenues in the world.\n  Park houses the  , now a museum on a hill that overlooks the park and its numerous museums, monuments and the national zoo and the   (which houses the  ). \n Another piece of architecture is the  , a white marble theater/museum whose weight is such that it has gradually been sinking into the soft ground below. Its construction began during the presidency of   and ended in 1934, after being interrupted by the   in the 1920s.\n The  , in this square are located the  , that is   European school of higher learning in the  ,  and the archeological site of the  , and the shrine and   are also important sites. There is a  , known as the \"Turibus\", that circles most of these sites, and has timed audio describing the sites in multiple languages as they are passed.\n In addition, according to the Secretariat of Tourism, the city has about 170  —is among the top ten of cities in the world with highest number of museums —over 100  , and some 30  , all of which maintain a constant cultural activity during the whole year. Many areas (e.g. Palacio Nacional and the  ) have murals painted by  . He and his wife   lived in  , where several of their homes, studios, and art collections are open to the public. The house where   was initially granted asylum and finally murdered in 1940 is also in Coyoacán. In addition, there are several   that are now restaurants, such as the San Ángel Inn, the Hacienda de Tlalpan, Hacienda de Cortés and the Hacienda de los Morales.\n  is Mexico City's primary airport ( : MEX), and serves as the hub of   ( ).   ( : NLU) is Mexico City's secondary airport, and was opened in 2022, rebuilt from the former Santa Lucía Air Force Base. It is located in  ,  , 48.8 kilometres (30 mi) north-northeast of the   by car. \n In 2019, the graphic designer   was engaged to create an integrated map of the multimodal public transportation system; he presented a new logo for the  , describing eight distinct modes of transportation. The head of the government,  , said the branding would be used for a new single payment card to streamline public transportation fare collection. \n Mexico City is served by the  , a 225.9 km (140 mi)   system, which is the largest in Latin America. The first portions were opened in 1969 and it has expanded to 12 lines with  , transporting 4.4 million people every day. \n A suburban rail system, the   serves the metropolitan area, beyond the reach of the  , with one line serving to municipalities such as   and  , but with future lines planned to serve e.g.   and  .\n Electric transport other than the metro also exists, in the form of several   routes and the   line, both of which are operated by  . The central area's last   line (tramway, or  ) closed in 1979.\n Mexico City has an extensive bus network, consisting of public buses,  , and  .\n Mexico City has a large road network, and relatively high private car usage, estimated at more than 4.5 million in 2016.  There is an environmental program, called   (\"Today Does Not Run\", or \"One Day without a Car\"), whereby vehicles that have not passed emissions testing are restricted from circulating on certain days according to the ending digit of their  , in an attempt to cut down on pollution and traffic congestion. \n The Mexico City local government oversees the administration of  , North America's second-largest  . Established to promote sustainable urban transportation, Ecobici facilitates convenient access to bicycles for residents and visitors alike. As of September 2013, the system comprised 276 stations strategically positioned across an expansive area extending from the   to  , a prominent district in the city. Within this network, approximately 4,000 bicycles are available for public use, enabling individuals to navigate the metropolitan landscape efficiently and reduce reliance on traditional motorized modes of transportation. Ecobici serves as a model for environmentally conscious urban mobility initiatives, reflecting Mexico City's commitment to fostering sustainable development and enhancing the quality of life for its populace. \n Secular works of art of this period include the   of  , locally known as   (\"The little horse\"). This piece, in bronze, was the work of   and it has been placed at the  , in front of the   (Mining Palace). Directly in front of this building is the   (Munal) (the National Museum of Art).\n During the 19th century, an important producer of art was the   (San Carlos Art Academy), founded during colonial times, and which later became the Escuela Nacional de Artes Plásticas (the  ) including painting, sculpture and graphic design, one of UNAM's  . Many of the works produced by the students and faculty of that time are now displayed in the Museo Nacional de San Carlos ( ). One of the students,  , is considered one of the greatest Mexican landscape painters of the 19th century.  's regime sponsored arts, especially those that followed the French school. Popular arts in the form of cartoons and illustrations flourished, e.g. those of   and  . The permanent collection of the San Carlos Museum also includes paintings by European masters such as Rembrandt, Velázquez, Murillo, and Rubens.\n After the  , an     originated in Mexico City:  . Many of the works of muralists  ,   and   are displayed in numerous buildings in the city, most notably at the   and the  .  , wife of Rivera, with a strong nationalist expression, was also one of the most renowned of Mexican painters. Her house has become a museum that displays many of her works. \n The former home of Rivera muse   houses the namesake museum. The facility is in Xochimilco borough in southern Mexico City and includes several buildings surrounded by sprawling manicured lawns. It houses a large collection of Rivera and Kahlo paintings and drawings, as well as living   ( ). It also regularly hosts small but important temporary exhibits of classical and   (e.g. Venetian Masters and Contemporary New York artists).\n During the 20th century, many artists immigrated to Mexico City from different regions of Mexico, such as  , an engraver from Veracruz, who supported the creation of the socialist Taller de la Gráfica Popular ( ), designed to help   workers find a venue to express their art. Other painters came from abroad, such as   painter   and other Spanish and Jewish exiles. It was in the second half of the 20th century that the artistic movement began to drift apart from the Revolutionary theme.   opted for a modernist style in contrast to the muralist movement associated with social politics.\n Mexico City has numerous museums dedicated to art, including Mexican colonial, modern and  , and international art. The Museo Tamayo was opened in the mid-1980s to house the collection of international contemporary art donated by Mexican painter  . The collection includes pieces by Picasso, Klee, Kandinsky, Warhol and many others, though most of the collection is stored while visiting exhibits are shown. The   is a repository of Mexican artists from the 20th century, including Rivera, Orozco, Siqueiros, Kahlo,  , Carrington, Tamayo, and also regularly hosts temporary exhibits of international modern art. In southern Mexico City, the   showcases avant-garde artists, as does the  , designed by Mexican architect  , inaugurated in late 2008.\n The  , named after the wife of Mexican magnate  , has the largest private collection of original   sculptures outside of France.  It also has a large collection of   sculptures, and recently began showing pieces in its masters collection including  ,  ,   and  . The museum inaugurated a new futuristic-design facility in 2011 just north of Polanco, while maintaining a smaller facility in   in southern Mexico City. The   is a contemporary art museum located on the sprawling grounds of the   juice company in the northern industrial suburb of  . It has the largest private contemporary art collection in   and hosts pieces from its permanent collection as well as traveling exhibits. The Museo de San Ildefonso, housed in the   in Mexico City's historic downtown district is a 17th-century colonnaded palace housing an art museum that regularly hosts world-class exhibits of Mexican and international art. The   is also located in a former palace in the historic center. It houses a large collection of pieces by all major Mexican artists of the last 400 years and also hosts visiting exhibits.\n , the noted American author, spent extended periods of time in the city, and wrote his 1959 masterpiece volume of poetry   here. Another American author,  , also lived in   where he accidentally shot his wife. Most of Mexico City's museums can be visited from Tuesday to Sunday from 10am to 5pm, although some of them have extended schedules, such as the Museum of Anthropology and History, which is open to 7pm. In addition to this, entrance to most museums are free on Sunday. In some cases a modest fee may be charged. \n The  , inaugurated in 2011, showcases historical events of discrimination and genocide. Permanent exhibits include those on the Holocaust and other large-scale atrocities. It also houses temporary exhibits; one on   was inaugurated by the   in September 2011. \n Mexico City is home to a number of orchestras offering season programs. These include the  ,  which performs at the Sala Ollin Yoliztli; the  , whose home base is the   (Palace of the  ), a masterpiece of   and art decó styles; the   of the National Autonomous University of Mexico ( ),  and the  ,  both of which perform at the  , which was the first wrap-around concert hall in the Western Hemisphere when inaugurated in 1976. There are also many smaller ensembles that enrich the city's musical scene, including the  , the  , the   (Orquesta del Nuevo Mundo), the   and the   (Orquesta de Cámara de Bellas Artes).\n The city is also a leading center of   and music. There are a multitude of venues hosting Spanish and foreign-language performers. These include the 10,000-seat   that regularly schedules the Spanish and English-language pop and rock artists, as well as many of the world's leading   ensembles, the auditorium also broadcasts   performances from New York's   on giant, high definition screens. In 2007 National Auditorium was selected world's best venue by multiple genre media. Other sites for pop-artist performances include the 3,000-seat  , the 15,000-seat  , and the larger 50,000-seat   Stadium, where popular international artists perform on a regular basis. The   has held several seasons at the  , in the   district in the western part of the city. There are numerous venues for smaller musical ensembles and solo performers. These include the  , Bataclán, Foro Scotiabank, Lunario, Circo Volador and Voilá Acoustique. Recent additions include the 20,000-seat  , the 3,000-seat Pepsi Center World Trade Center, and the 2,500-seat Auditorio Blackberry.\n The Centro Nacional de las Artes ( ) has several venues for music, theater, dance. UNAM's main campus, also in the southern part of the city, is home to the Centro Cultural Universitario (the  ) (CCU). The CCU also houses the  , the interactive  ,  the Sala Nezahualcóyotl concert hall, several theaters and cinemas, and the new   (MUAC).  A branch of the National University's CCU cultural center was inaugurated in 2007 in the facilities of the former  , known as Tlatelolco, in north-central Mexico City.\n The  , a national library, is located on the grounds of the former Buenavista railroad station in the northern part of the city. The   (Kite Children's Museum), which houses the world's largest dome screen, is located in the wooded park of  , near the  , and  , a former  . The theme park   (the largest amusement park in Latin America) is located in the   neighborhood, in Tlalpan borough, southern Mexico City. During the winter, the main square of the   is transformed into a gigantic  , which is said to be the largest in the world behind that of Moscow's  .\n The   (Mexican Film Library), near the Coyoacán suburb, shows a variety of films, and stages many film festivals, including the annual  , and many smaller ones ranging from Scandinavian and Uruguayan cinema, to Jewish and LGBT-themed films.   and  , the two biggest film  , also have several film festivals throughout the year, with both national and international movies. Mexico City has a number of   theaters, providing residents and visitors access to films ranging from documentaries to blockbusters on these large screens.\n Once considered plebeian fare, by the 19th century   had become a standard of Mexico City's cuisine. Furthermore, as authorities struggled to tax local  , imposing licensing requirements and penalties, they recorded some details of the types of foods being served by these establishments. The most frequent reference was for  . Also mentioned are  ,   and  , along with oyster shops and fried fish stands. There is evidence of some regional specialties being made available for recent migrants; at least two shops were known to serve  , a type of stew similar to   that is a staple of  ,  .  Mexico City is known for having some of the freshest fish and seafood in Mexico's interior.   is the second largest seafood market in the world after the   in Japan.\n Mexico City offers a variety of cuisines: restaurants specializing in the regional cuisines of Mexico's 31 states are available in the city, and the city also has several branches of internationally recognized restaurants. These include Paris' Au Pied de Cochon and  , Philippe (by Philippe Chow); Nobu,  , Morimoto; Pámpano, owned by Mexican-raised opera singer  . There are branches of   restaurant  ,   restaurant Alfredo, as well as New York steakhouses   and  , and Monte Carlo's BeefBar. Three of  's   restaurants, serving  , have locations in Mexico City: La Mar, Segundo Muelle and Astrid y Gastón.\n For the 2023 list of   as named by the British magazine  , Mexico City ranked 13th best with the Mexican avant-garde restaurant   (owned by Mexican chef  ).  Also notable is the Basque-Mexican fusion restaurant   (run and co-owned by Bruno Oteiza and Mikel Alonso), which placed outside the list at 59th, but in previous years has ranked within the top 50.  Other that has been placed on the list in 2019 is the restaurant Sud 777 at 58th place.  In 2024,   received  .  At the other end of the scale are working class   bars known as  , a challenge for tourists to locate and experience.\n Mexico City is Mexico's most important hub for the printed media and   industries. Dozens of daily newspapers are published, including  ,  ,   and  . Other major papers include  ,  ,   and  .  Leading magazines include  ,  ,  , as well as dozens of entertainment publications such as  ,  ,  ,  , and local editions of  ,  , and  .\n It is also a leading center of the  . Most international ad firms have offices in the city, including Grey,  ,  ,  ,  , Ogilvy,  , and  . Many local firms also compete in the sector, including  ,  , Terán, Augusto Elías, and Clemente Cámara, among others. There are 60   operating in the city and many   radio transmission networks.\n The two largest media companies in the Spanish-speaking world,   and  , are headquartered in Mexico City.   often presents itself as the largest producer of Spanish-language content.  Other   channels include:\n  1 (Azteca Uno), \n  2 (Televisa W), \n  3,\n  4,\n  5,\n  6,\n  7,\n  9,\n  11,\n  20,\n  21,\n  22,\n  28,\n  40 and\n  45.\n  is the country's most popular and most  . Its important venues in Mexico City include the  , home to the   and giants   and  , which can seat 91,653 fans, making it the biggest stadium in Latin America. The   in   is home to the football club giants  , with a   of over 52,000. The  , which seats 33,042 fans, is near the   in the Nochebuena  , and is home to the historical  . América, Cruz Azul and Universidad Nacional are based in Mexico City and play in the  ; they are also part, with Guadalajara-based giants  , of Mexico's traditional \"Big Four\". The city's three derbies are the \" \", played between América and Cruz Azul, the capital's two most popular and successful teams; the \" \", between América and Universidad Nacional, and the \"Clásico Metropolitano\", between Cruz Azul and Universidad Nacional.\n The country hosted the   in   and  , and Azteca Stadium is the first stadium in World Cup history to host the final twice. The city will be one of the host cities for the  .  Mexico City is the first Latin American city to host the Olympic Games, having held the   in 1968, winning bids against  ,   and Detroit. The city hosted the 1955 and 1975  , the latter after Santiago and São Paulo withdrew. The   were hosted here in 1974 and 1994.   is a Mexican style of wrestling, and is one of the more popular sports throughout the country. The main venues in the city are   and  .\n The   is the main venue for motorsport, and hosts the Formula 1   since its return to the sport in 2015, the event being held in the past from 1962 to 1970, and again from 1986 to 1992. From 1980 to 1981 and again from 2002 to 2007, the circuit hosted the   World Series  . Beginning in 2005, the     ran the  . 2005 also marked the first running of the Mexico City 250 by the    . Both races were removed from their series' schedules for 2009.\n Baseball is another sport played professionally in the city. Mexico City is home of the   of the  , which is considered a Triple-A league by Major League Baseball. The Devils play their home games at   designed by international Mexican-American architect   Founder   in collaboration with local architect Taller ADG. Mexico City has some 10 Little Leagues for young baseball players. In 2005, Mexico City became the first city to host an   regular season game outside of the United States, at the  . The crowd of 103,467 people attending this game was the largest ever for a regular season game in NFL history until 2009. \n The city has also hosted several   pre-season games and has hosted international basketball's  , along with north-of-the-border Major League Baseball exhibition games at  . In 2017, NBA commissioner   expressed interest in placing an   expansion team in Mexico City as early as 2018. This came to fruition on 12 December 2019 when commissioner Silver announced at a press conference in   that   team,   will be joining the G League in the 2020–21 season on a five-year agreement.\n Other sports facilities in Mexico City are the   indoor arena,  , the  , the  , and venues for equestrianism and horse racing, ice hockey,  , American-style football, baseball, and basketball.   takes place every Sunday during bullfighting season at the 50,000-seat  , the world's largest bullring. Mexico City's   have hosted Women's   action, and two  . Courses throughout the city are available as private as well as public venues.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Index_of_recycling_articles", "title": "Recycling", "content": "This is an accepted version of this page \n\n\n  is the process of converting   materials into new materials and objects. This concept often includes the  . The recyclability of a material depends on its ability to reacquire the properties it had in its original state.  It is an alternative to \"conventional\" waste disposal that can save material and help lower  . It can also prevent the waste of potentially useful materials and reduce the consumption of fresh raw materials, reducing energy use,   (from  ) and   (from  ).\n Recycling is a key component of modern waste reduction and is the third component of the \" ,  , and Recycle\"  .  It promotes environmental   by removing raw material input and redirecting waste output in the economic system.  There are some   related to recycling, such as ISO 15270:2008 for plastics waste and  :2015 for environmental management control of recycling practice.\n  include many kinds of glass, paper, cardboard, metal, plastic,  ,  , batteries, and  . The   and other reuse of  —such as   and  —is also a form of recycling.  Materials for recycling are either delivered to a household recycling center or picked up from curbside bins, then sorted, cleaned, and reprocessed into new materials for manufacturing new products.\n In ideal implementations, recycling a material produces a fresh supply of the same material—for example, used office paper would be converted into new office paper, and used   foam into new polystyrene. Some types of materials, such as  , can be remanufactured repeatedly without losing their purity.  With other materials, this is often difficult or too expensive (compared with producing the same product from raw materials or other sources), so \"recycling\" of many products and materials involves their   in producing different materials (for example,  ). Another form of recycling is the   of constituent materials from complex products, due to either their intrinsic value (such as   from   and   from  ), or their hazardous nature (e.g. removal and reuse of   from   and  ).\n Reusing materials has been a common practice for most of human history with recorded advocates as far back as   in the fourth century BC.  During periods when resources were scarce, archaeological studies of ancient waste dumps show less household waste (such as ash, broken tools, and pottery), implying that more waste was recycled in place of new material.  However,   made from recyclable material, such as glass or metal, may neither be the original object nor resemble it, with the consequence that a successful ancient recycling economy can become invisible when recycling is synonymous with re-melting rather than reuse. \n In   times, there is evidence of   bronze and other metals being collected in Europe and melted down for continuous reuse.    was first recorded in 1031 when Japanese shops sold repulped paper.  In Britain dust and ash from wood and coal fires was collected by \" \" and   as a base material for brick making. These forms of recycling were driven by the economic advantage of obtaining recycled materials instead of virgin material, and the need for waste removal in ever-more-densely populated areas.  In 1813,   developed the process of turning rags into \" \" and \" \" wool in Batley, Yorkshire, which combined recycled fibers with virgin  .  The   shoddy industry in towns such as   and   lasted from the early 19th century to at least 1914.\n Industrialization spurred demand for affordable materials. In addition to rags, ferrous   metals were coveted as they were cheaper to acquire than virgin ore. Railroads purchased and sold scrap metal in the 19th century, and the growing steel and automobile industries purchased scrap in the early 20th century. Many secondary goods were collected, processed and sold by peddlers who scoured dumps and city streets for discarded machinery, pots, pans, and other sources of metal. By  , thousands of such peddlers roamed the streets of American cities, taking advantage of market forces to recycle post-consumer materials into industrial production. \n Manufacturers of beverage bottles, including  ,  began offering refundable recycling deposits in Great Britain and Ireland around 1800. An official recycling system with   for bottles was established in Sweden in 1884, and for aluminum beverage cans in 1982; it led to recycling rates of 84–99%, depending on type (glass bottles can be refilled around 20 times). \n New chemical industries created in the late 19th century both invented new materials (e.g.   in 1907) and promised to transform valueless into valuable materials. Proverbially, you could not  —until the US firm Arthur D. Little published in 1921 \"On the Making of Silk Purses from Sows' Ears\", its research proving that when \"chemistry puts on overalls and gets down to business [...] new values appear. New and better paths are opened to reach the goals desired.\" \n Recycling—or \"salvage\", as it was then usually known—was a major issue for governments during  , where financial constraints and significant material shortages made it necessary to reuse goods and recycle materials.  These resource shortages caused by the  , and other such world-changing events, greatly encouraged recycling.  It became necessary for most homes to recycle their waste, allowing people to make the most of what was available. Recycling household materials also meant more resources were left available for war efforts.  Massive government campaigns, such as the   in Britain and the   campaign in the United States, occurred in every fighting nation, urging citizens to donate metal, paper, rags, and rubber as a patriotic duty.\n A considerable investment in recycling occurred in the 1970s due to rising energy costs.  Recycling aluminium uses only 5% of the energy of virgin production. Glass, paper and other metals have less dramatic but significant energy savings when recycled. \n Although consumer electronics have been popular since the 1920s, recycling them was almost unheard of until early 1991.  The first   scheme was implemented in  , beginning with collection of old refrigerators, then expanding to cover all devices.  When these programs were created, many countries could not deal with the sheer quantity of  , or its hazardous nature, and began to export the problem to developing countries without enforced environmental legislation. (For example, recycling computer monitors in the United States costs 10 times more than in China.) Demand for electronic waste in Asia began to grow when scrapyards found they could extract valuable substances such as  ,  ,  ,  ,  , and   during the recycling process.  The 2000s saw a boom in both the sales of electronic devices and their growth as a waste stream: In 2002, e-waste grew faster than any other type of waste in the EU.  This spurred investment in modern automated facilities to cope with the influx, especially after strict laws were implemented in 2003. \n As of 2014, the   had about 50% of world share of waste and recycling industries, with over 60,000 companies employing 500,000 people and a turnover of €24 billion.  EU countries are mandated to reach recycling rates of at least 50%; leading countries are already at around 65%. The overall EU average was 39% in 2013 \nand is rising steadily, to 45% in 2015. \n In 2015, the United Nations General Assembly set 17  . Goal 12,  , specifies 11 targets \"to ensure sustainable consumption and production patterns\".  The fifth target,  , is defined as substantially reducing waste generation by 2030, indicated by the National Recycling Rate.\n In 2018, changes in the recycling industry have sparked a global \"crisis\". On 31 December 2017, China announced its \" \" policy, setting new standards for imports of recyclable material and banning materials deemed too \"dirty\" or \"hazardous\". The new policy caused drastic disruptions in the global recycling market, and reduced the prices of scrap plastic and low-grade paper. Exports of recyclable materials from   countries to China dropped dramatically, with many shifting to countries in southeast Asia. This generated significant concern about the recycling industry's practices and  . The abrupt shift caused countries to accept more materials than they could process, and raised fundamental questions about shipping waste from developed countries to countries with few environmental regulations—a practice that predated the crisis. \n According to the   (2023), “Every year millions of electrical and electronic devices are discarded ... a threat to the environment and to human health if they are not treated, disposed of, and recycled appropriately. Common items ... include computers ...   are recycled using environmentally unsound techniques and are likely stored in homes and warehouses, dumped, exported or recycled under inferior conditions. When e-waste is treated using inferior activities, it can release as many as 1000 different chemical substances ... including harmful   such as  .”  A paper in the journal   remarks upon the difficulty of managing e-waste, particularly from home automation products, which, due to their becoming obsolete at a high rate, are putting increasing strain on recycling systems, which have not adapted to meet the recycling needs posed by this type of product. \n Copper slag is obtained when copper and nickel ores are recovered from their source ores using a pyrometallurgical process, and these ores usually contain other elements which include iron, cobalt, silica, and alumina.  An estimate of 2.2–3 tons of copper slag is generated per ton of copper produced, resulting in around 24.6 tons of slag per year, which is regarded as waste.   \n Environmental impact of slag include copper  , which leads to death due to gastric hemorrhage, if ingested by humans. It may also cause acute dermatitis upon skin exposure.   Toxicity may also be uptaken by crops through soil, consequently spreading animals and food sources and increasing the risk of cardiovascular diseases, cancer, cognitive impairment, chronic anemia, and damage to kidneys, bones, nervous system, brain and skin. \n Substituting gravel and grit in quarries has been more cost-effective, due to having its sources with better proximity to consumer markets. Trading between countries and establishment of blast furnaces is helping increase slag utilization, hence reducing wastage and pollution. \n Economist  , author of a paper entitled \"Why I Am Not an Environmentalist\",  claimed that   actually reduces tree populations. He argues that because paper companies have incentives to replenish their forests, large demands for paper lead to large forests while reduced demand for paper leads to fewer \"farmed\" forests. \n When foresting companies cut down trees, more are planted in their place; however, such farmed forests are inferior to natural forests in several ways. Farmed forests are not able to fix the soil as quickly as natural forests. This can cause widespread   and often requiring large amounts of   to maintain the soil, while containing little tree and wild-life   compared to virgin forests.  Also, the new trees planted are not as big as the trees that were cut down, and the argument that there would be \"more trees\" is not compelling to forestry advocates when they are counting saplings.\n In particular, wood from tropical rainforests is rarely harvested for paper because of their heterogeneity.  According to the   secretariat, the overwhelming direct cause of deforestation is   (48% of deforestation) and   (32%), which is linked to food, not paper production. \n Other non-conventional methods of material recycling, like Waste-to-Energy (WTE) systems, have garnered increased attention in the recent past due to the polarizing nature of their emissions. While viewed as a sustainable method of capturing energy from material waste feedstocks by many, others have cited numerous explanations for why the technology has not been scaled globally. \n For a recycling program to work, a large, stable   of recyclable material is crucial. Three legislative options have been used to create such supplies: mandatory recycling collection,  , and refuse bans. Mandatory collection laws set recycling targets for cities, usually in the form that a certain percentage of a material must be diverted from the city's waste stream by a target date. The city is responsible for working to meet this target. \n Container deposit legislation mandates refunds for the return of certain containers—typically glass, plastic and metal. When a product in such a container is purchased, a small surcharge is added that the consumer can reclaim when the container is returned to a collection point. These programs have succeeded in creating an average 80% recycling rate.  Despite such good results, the shift in collection costs from local government to industry and consumers has created strong opposition in some areas —for example, where manufacturers bear the responsibility for recycling their products. In the European Union, the   requires producers of consumer electronics to reimburse the recyclers' costs. \n An alternative way to increase the supply of recyclates is to   the disposal of certain materials as waste, often including used  , old batteries,  , and garden waste. This can create a viable economy for the proper disposal of the products. Care must be taken that enough recycling   exist to meet the supply, or such bans can create increased  . \n Four forms of legislation have also been used to increase and maintain the demand for recycled materials: minimum recycled content mandates, utilization rates,   policies, and recycled  . \n Both minimum recycled content mandates and utilization rates increase demand by forcing manufacturers to include recycling in their operations. Content mandates specify that a certain percentage of a new product must consist of recycled material. Utilization rates are a more flexible option: Industries can meet their recycling targets at any point of their operations, or even contract out recycling in exchange for tradable credits. Opponents to these methods cite their large increase in reporting requirements, and claim that they rob the industry of flexibility. \n  have used their own   to increase recycling demand through \"procurement policies\". These policies are either \"set-asides\", which reserve a certain amount of spending for recycled products; or \"price preference\" programs that provide larger   when recycled items are purchased. Additional regulations can target specific cases: in the United States, for example, the   mandates the purchase of oil, paper, tires and   from recycled or re-refined sources whenever possible. \n The final government regulation toward increased demand is recycled product labeling. When producers are required to label their packaging with the amount of recycled material it contains (including the packaging), consumers can make more educated choices. Consumers with sufficient   can choose more environmentally conscious options, prompting producers to increase the recycled material in their products and increase demand. Standardized recycling labeling can also have a positive effect on the supply of recyclates when it specifies how and where the product can be recycled. \n \"Recyclate\" is a raw material sent to and processed in a waste recycling plant or materials-recovery facility  so it can be used in the production of new materials and products. For example,   can be made into plastic pellets and  . \n The quality of recyclates is one of the principal challenges for the success of a long-term vision of a   and achieving  . It generally refers to how much of it is composed of target material, versus non-target material and other non-recyclable material.  Steel and other metals have intrinsically higher recyclate quality; it is estimated that two-thirds of all new steel comes from recycled steel.  Only target material is likely to be recycled, so higher amounts of non-target and non-recyclable materials can reduce the quantity of recycled products.  A high proportion of non-target and non-recyclable material can make it more difficult to achieve \"high-quality\" recycling; and if recyclate is of poor quality, it is more likely to end up being   or, in more extreme cases, sent to other recovery options or  .  For example, to facilitate the remanufacturing of clear glass products, there are tight restrictions for colored glass entering the re-melt process. Another example is the   of plastic, where products such as plastic food packaging are often downcycled into lower quality products,  and do not get recycled into the same plastic food packaging.\n The quality of recyclate not only supports high-quality recycling, but it can also deliver significant environmental benefits by reducing, reusing, and keeping products out of  .  High-quality recycling can support economic growth by maximizing the value of waste material.  Higher income levels from the sale of quality recyclates can return value significant to local governments, households and businesses.  Pursuing high-quality recycling can also promote consumer and business confidence in the waste and resource management sector, and may encourage investment in it.\n There are many actions along the recycling supply chain, each of which can affect recyclate quality.  Waste producers who place non-target and non-recyclable wastes in recycling collections can affect the quality of final recyclate streams, and require extra efforts to discard those materials at later stages in the recycling process.  Different collection systems can induce different levels of contamination. When multiple materials are collected together, extra effort is required to sort them into separate streams and can significantly reduce the quality of the final products.  Transportation and the compaction of materials can also make this more difficult. Despite improvements in technology and quality of recyclate, sorting facilities are still not 100% effective in separating materials.  When materials are stored outside, where they can become wet, can also cause problems for re-processors. Further sorting steps may be required to satisfactorily reduce the amount of non-target and non-recyclable material. \n A number of systems have been implemented to collect recyclates from the general waste stream, occupying different places on the spectrum of trade-off between public convenience and government ease and expense. The three main categories of collection are drop-off centers, buy-back centers and curbside collection.  About two-thirds of the cost of recycling is incurred in the collection phase. \n Curbside collection encompasses many subtly different systems, which differ mostly on where in the process the recyclates are sorted and cleaned. The main categories are mixed waste collection, commingled recyclables, and source separation.  A   generally picks up the waste.\n In mixed waste collection, recyclates are collected mixed with the rest of the waste, and the desired materials are sorted out and cleaned at a central sorting facility. This results in a large amount of recyclable waste (especially paper) being too soiled to reprocess, but has advantages as well: The city need not pay for the separate collection of recyclates, no public education is needed, and any changes to the recyclability of certain materials are implemented where sorting occurs. \n In a commingled or  ,   are mixed but kept separate from non-recyclable waste. This greatly reduces the need for post-collection cleaning, but requires   on what materials are recyclable. \n Source separation is the other extreme, where each material is cleaned and sorted prior to collection. It requires the least post-collection sorting and produces the purest recyclates. However, it incurs additional   for collecting each material, and requires extensive public education to avoid recyclate  .  In  , USA,   surveyed multi-family property managers; about half of them reported problems, including contamination of recyclables due to trespassers such as   gaining access to collection areas. \n Source separation used to be the preferred method due to the high cost of sorting commingled (mixed waste) collection. However, advances in sorting technology have substantially lowered this overhead, and many areas that had developed source separation programs have switched to what is called  . \n At buy-back centers, separated, cleaned recyclates are purchased, providing a clear incentive for use and creating a stable supply. The post-processed material can then be sold. If profitable, this conserves the emission of greenhouse gases; if unprofitable, it increases their emission. Buy-back centres generally need government subsidies to be viable. According to a 1993 report by the U.S.  , it costs an average $50 to process a ton of material that can be resold for $30. \n Drop-off centers require the waste producer to carry recyclates to a central location—either an installed or mobile collection station or the reprocessing plant itself. They are the easiest type of collection to establish but suffer from low and unpredictable throughput.\n For some waste materials such as plastic, recent technical devices called   enable a form of distributed recycling called DRAM ( ). Preliminary   (LCA) indicates that such distributed recycling of   to make filament for   in rural regions consumes less energy than using virgin resin, or using conventional recycling processes with their associated transportation. \n Another form of distributed recycling mixes waste plastic with sand to make bricks in  .  Several studies have looked at the properties of recycled waste plastic and sand bricks.  The composite pavers can be sold at 100% profit while employing workers at 1.5× the minimum wage in the West African region, where distributed recycling has the potential to produce 19 million pavement tiles from 28,000 tons of plastic water sachets annually in  ,  , and  .  This has also been done with COVID19 masks. \n Once commingled recyclates are collected and delivered to a  , the materials must be sorted. This is done in a series of stages, many of which involve automated processes, enabling a truckload of material to be fully sorted in less than an hour.  Some plants can now sort materials automatically; this is known as  . Automatic sorting may be aided by robotics and machine learning.  In plants, a variety of materials is sorted including paper, different types of plastics, glass, metals, food scraps, and most types of  .  A 30% increase in recycling rates has been seen in areas with these plants.  In the US, there are over 300 materials recovery facilities. \n Initially, commingled recyclates are removed from the collection vehicle and placed on a conveyor belt spread out in a single layer. Large pieces of   and   are removed by hand at this stage, as they can cause later machinery to jam. \n Next, automated machinery such as disk screens and air classifiers separate the recyclates by weight, splitting lighter paper and plastic from heavier glass and metal. Cardboard is removed from mixed paper, and the most common types of plastic—  (#1) and   (#2)—are collected, so these materials can be diverted into the proper collection channels. This is usually done by hand; but in some sorting centers,   scanners are used to differentiate between types of paper and plastic based on their absorbed wavelengths.  Plastics tend to be incompatible with each other due to differences in  ; their   molecules repel each other, similar to oil and water. \n Strong magnets are used to separate out   such as iron, steel and  .   are ejected by magnetic  : A rotating magnetic field   an electric current around aluminum cans, creating an eddy current inside the cans that is repulsed by a large  , ejecting the cans from the stream. \n Finally, glass is sorted according to its color: brown, amber, green, or clear. It may be sorted either by hand,  or by a machine that uses colored filters to detect colors. Glass fragments smaller than 10 millimetres (0.39 in) cannot be sorted automatically, and are mixed together as \"glass fines\". \n In 2003,  's Department of the Environment set a citywide goal of zero waste by 2020.  San Francisco's refuse hauler,  , operates an effective recyclables sorting facility that has helped the city reach a record-breaking landfill diversion rate of 80% as of 2021.  Other American cities, including Los Angeles, have  .\n Although many government programs concentrate on recycling at home, 64% of waste in the United Kingdom is generated by industry.  The focus of many recycling programs in industry is their cost-effectiveness. The ubiquitous nature of   packaging makes cardboard a common waste product recycled by companies that deal heavily in packaged goods, such as  ,  , and goods distributors. Other industries deal in niche and specialized products, depending on the waste materials they handle.\n Glass, lumber,   and paper manufacturers all deal directly in commonly recycled materials; however, independent tire dealers may collect and recycle   for a profit.\n The waste produced from burning   in a   is often called   or   in the  . It is a very useful material and used in   construction. It exhibits  . \n Levels of metals recycling are generally low. In 2010, the  , hosted by the   (UNEP), published reports on metal stocks  and their recycling rates.  It reported that the increase in the use of metals during the 20th and into the 21st century has led to a substantial shift in metal stocks from below-ground to use in above-ground applications within society. For example, in the US, in-use copper grew from 73 to 238 kg per capita between 1932–1999.\n The report's authors observed that, as metals are inherently recyclable, metal stocks in society can serve as huge above-ground mines (the term \"urban mining\" has thus been coined ). However, they found that the recycling rates of many metals are low. They warned that the recycling rates of some   used in applications such as mobile phones, battery packs for hybrid cars and fuel cells, are so low that unless future end-of-life recycling rates are dramatically increased, these critical metals will become unavailable for use in modern technology.\n The military recycles some metals. The  's Ship Disposal Program uses   to reclaim the steel of old vessels. Ships may also be sunk to create  .   is a dense metal that has qualities superior to lead and   for many military and industrial uses. Uranium left over from processing it into   and fuel for   is called  , and is used by all branches of the U.S. military for the development of such things as armor-piercing shells and shielding.\n The construction industry may recycle concrete and old  , selling these materials for profit.\n Some rapidly growing industries, particularly the   and   industries, are proactively creating recycling policies even before their waste streams have considerable volume, anticipating future demand. \n \nRecycling of plastics is more difficult, as most programs are not able to reach the necessary level of quality. Recycling of   often results in   of the material, which means only products of lower quality standard can be made with the recycled material.  is a growing problem, accounting for 20–50 million metric tons of global waste per year according to the  . It is also the fastest growing waste stream in the EU.  Many recyclers do not recycle e-waste responsibly. After the cargo barge   dumped 14,000 metric tons of toxic ash in  , the   was formed to stem the flow of hazardous substances into poorer countries. They created the   to ensure that recyclers are held to the highest standards for environmental responsibility and to help consumers identify responsible recyclers. It operates alongside other prominent legislation, such as the   of the EU and the   National Computer Recycling Act, to prevent poisonous chemicals from entering waterways and the atmosphere.\n In the recycling process, television sets, monitors, cell phones, and computers are typically tested for reuse and repaired. If broken, they may be disassembled for parts still having high value if labor is cheap enough. Other e-waste is shredded to pieces roughly 10 centimetres (3.9 in) in size and manually checked to separate toxic batteries and  , which contain poisonous metals. The remaining pieces are further shredded to 10 millimetres (0.39 in) particles and passed under a magnet to remove ferrous metals. An   ejects non-ferrous metals, which are sorted by density either by a centrifuge or vibrating plates. Precious metals can be dissolved in acid, sorted, and smelted into ingots. The remaining glass and plastic fractions are separated by density and sold to re-processors. Television sets and monitors must be manually disassembled to remove lead from   and the mercury backlight from  . \n , solar panels and wind turbines can also be recycled. They often contain   (REE) and/or  . For  , large amounts of REE's are typically required. \n Whereas many critical raw elements and REE's can be recovered, environmental engineer     6 September 2021 at the   reports that recycling of  ,  ,  ,  , and   is still very difficult and their recycling rates are very low. \n Plastic recycling is the process of recovering scrap or waste plastic and reprocessing the material into useful products, sometimes completely different in form from their original state. For instance, this could mean melting down soft drink bottles and then casting them as plastic chairs and tables.  For some types of plastic, the same piece of plastic can only be recycled about 2–3 times before its quality decreases to the point where it can no longer be used. \n Some plastics are remelted to form new plastic objects; for example, PET water bottles can be converted into polyester destined for clothing. A disadvantage of this type of recycling is that the molecular weight of the polymer can change further and the levels of unwanted substances in the plastic can increase with each remelt. \n A commercial-built recycling facility was sent to the   in late 2019. The facility takes in   and unneeded plastic parts and physically converts them into spools of feedstock for the space station   facility used for in-space  . \n For some polymers, it is possible to convert them back into monomers, for example, PET can be treated with an alcohol and a catalyst to form a dialkyl terephthalate. The terephthalate diester can be used with ethylene glycol to form a new polyester polymer, thus making it possible to use the pure polymer again. In 2019,   announced initiatives of   and   designed to handle a greater variety of used material. \n Another process involves the conversion of assorted polymers into petroleum by a much less precise thermal   process. Such a process would be able to accept almost any polymer or mix of polymers, including   materials such as vulcanized rubber tires and the   in feathers and other agricultural waste. Like natural petroleum, the chemicals produced can be used as fuels or as feedstock. A RESEM Technology  plant of this type in  , US, uses turkey waste as input material. Gasification is a similar process but is not technically recycling since polymers are not likely to become the result.\nPlastic Pyrolysis can convert petroleum based waste streams such as plastics into quality fuels, carbons. Given below is the list of suitable plastic raw materials for  :\n In order to meet recyclers' needs while providing manufacturers a consistent, uniform system, a   was developed. The recycling code for plastics was introduced in 1988 by the plastics industry through the  .  Because municipal recycling programs traditionally have targeted packaging—primarily bottles and containers—the   offered a means of identifying the resin content of bottles and containers commonly found in the residential waste stream. \n In the United States, plastic products are printed with numbers 1–7 depending on the type of resin. Type 1 ( ) is commonly found in   and  . Type 2 ( ) is found in most hard plastics such as  , laundry detergent bottles, and some dishware. Type 3 ( ) includes items such as shampoo bottles, shower curtains,  ,  , wire jacketing, medical equipment, siding, and piping. Type 4 ( ) is found in shopping bags, squeezable bottles, tote bags, clothing, furniture, and carpet. Type 5 is   and makes up syrup bottles, straws,  , and some automotive parts. Type 6 is   and makes up meat trays, egg cartons, clamshell containers, and compact disc cases. Type 7 includes all other plastics such as bulletproof materials, 3- and 5-gallon water bottles, cell phone and tablet frames, safety goggles and sunglasses.  Having a recycling code or the chasing arrows logo on a material is not an automatic indicator that a material is recyclable but rather an explanation of what the material is. Types 1 and 2 are the most commonly recycled.\n In addition to environmental impact, there is debate over whether recycling is  . According to a   study, waste collection and landfill disposal creates less than one job per 1,000 tons of waste material managed; in contrast, the collection, processing, and manufacturing of recycled materials creates 6–13 or more jobs per 1,000 tons.   According to the U.S. Recycling Economic Informational Study, there are over 50,000 recycling establishments that have created over a million jobs in the US.  The   (NWRA) reported in May 2015 that recycling and waste made a $6.7 billion economic impact in Ohio, U.S., and employed 14,000 people.  Economists  would classify this extra labor used as a cost rather than a benefit since these workers could have been employed elsewhere; the cost effectiveness of creating these additional jobs remains unclear. \n Sometimes cities have found recycling saves resources compared to other methods of disposal of waste. Two years after New York City declared that implementing recycling programs would be \"a drain on the city\", New York City leaders realized that an efficient recycling system could save the city over $20 million.  Municipalities often see   benefits from implementing recycling programs, largely due to the reduced   costs.  A study conducted by the   according to the Economist found that in 83 percent of cases, recycling is the most efficient method to dispose of household waste.  However, a 2004 assessment by the Danish Environmental Assessment Institute concluded that incineration was the most effective method for disposing of drink containers, even aluminium ones. \n Fiscal efficiency is separate from economic efficiency. Economic analysis of recycling does not include what economists call  : unpriced costs and benefits that accrue to individuals outside of private transactions . Examples include less air pollution and greenhouse gases from incineration and less waste leaching from landfills.  Without mechanisms such as taxes or subsidies, businesses and consumers following their private benefit would ignore externalities despite the costs imposed on society. If landfills and incinerator pollution is inadequately regulated, these methods of waste disposal appear cheaper than they really are, because part of their cost is the pollution imposed on people nearby. Thus, advocates have pushed for legislation to increase demand for recycled materials.   The   (EPA) has concluded in favor of recycling, saying that recycling efforts reduced the country's   by a net 49 million   in 2005.  In the United Kingdom, the   stated that Great Britain's recycling efforts reduce   by 10–15 million tonnes a year.  The question for economic efficiency is whether this reduction is worth the extra cost of recycling and thus makes the artificial demand creates by legislation worthwhile.\n Certain requirements must be met for recycling to be economically feasible and environmentally effective. These include an adequate source of recyclates, a system to extract those recyclates from the  , a nearby factory capable of reprocessing the recyclates, and a potential demand for the recycled products. These last two requirements are often overlooked—without both an industrial market for production using the collected materials and a consumer market for the manufactured goods, recycling is incomplete and in fact only \"collection\". \n Free-market economist   remarked \"There are three ways society can organize waste disposal: (a) commanding, (b) guiding by tax and subsidy, and (c) leaving it to the individual and the market\". These principles appear to divide economic thinkers today. \n  favours a high level of government intervention to provide recycling services. He believes that recycling's benefit cannot be effectively quantified by traditional   economics.   supports intervention, saying that it is a public service equal to education and policing. He argues that manufacturers should shoulder more of the burden of waste disposal. \n Paul Calcott and Margaret Walls advocate the second option. A deposit refund scheme and a small refuse charge would encourage recycling but not at the expense of  . Thomas C. Kinnaman concludes that a landfill tax would force consumers, companies and councils to recycle more. \n Most free-market thinkers detest subsidy and intervention, arguing that they waste resources. The general argument is that if cities charge the full cost of garbage collection, private companies can profitably recycle any materials for which the benefit of recycling exceeds the cost (e.g. aluminum ) and do not recycle other materials for which the benefit is less than the cost (e.g. glass ). Cities, on the other hand, often recycle even when they  not only do not receive enough for the paper or plastic to pay for its collection, but must actually pay private recycling companies to take it off of their hands.      and Donald Leal think that all recycling programmes should be privately operated, and therefore would only operate if the money saved by recycling exceeds its costs.   argues that it wastes people's resources and lowers the wealth of a population.  He notes that recycling can cost a city more than twice as much as landfills, that in the United States landfills are so heavily regulated that their pollution effects are negligible, and that the recycling process also generates pollution and uses energy, which may or may not be less than from virgin production. \n Certain countries trade in unprocessed  . Some have complained that the ultimate fate of recyclates sold to another country is unknown and they may end up in landfills instead of being reprocessed. According to one report, in America, 50–80 percent of computers destined for recycling are actually not recycled.  There are reports of illegal-waste imports to China being dismantled and recycled solely for monetary gain, without consideration for workers' health or environmental damage. Although the Chinese government has banned these practices, it has not been able to eradicate them.  In 2008, the prices of recyclable waste plummeted before rebounding in 2009. Cardboard averaged about £53/tonne from 2004 to 2008, dropped to £19/tonne, and then went up to £59/tonne in May 2009. PET plastic averaged about £156/tonne, dropped to £75/tonne and then moved up to £195/tonne in May 2009. \n Certain regions have difficulty using or exporting as much of a material as they recycle. This problem is most prevalent with glass: both Britain and the U.S. import large quantities of wine bottled in green glass. Though much of this glass is sent to be recycled, outside the   there is not enough wine production to use all of the reprocessed material. The extra must be downcycled into building materials or re-inserted into the regular waste stream. \n Similarly, the northwestern United States has difficulty finding markets for recycled newspaper, given the large number of   in the region as well as the proximity to Asian markets. In other areas of the U.S., however, demand for used newsprint has seen wide fluctuation. \n In some U.S. states, a program called   pays people to recycle, receiving money from local municipalities for the reduction in landfill space that must be purchased. It uses a single stream process in which all material is automatically sorted. \n \n Critics dispute the net economic and environmental benefits of recycling over its costs, and suggest that proponents of recycling often make matters worse and suffer from  . Specifically, critics argue that the costs and energy used in collection and transportation detract from (and outweigh) the costs and energy saved in the production process; also that the jobs produced by the recycling industry can be a poor trade for the jobs lost in logging, mining, and other industries associated with production; and that materials such as paper pulp can only be recycled a few times before material degradation prevents further recycling. \n Journalist   notes that it is generally more expensive for municipalities to recycle waste from households than to send it to a landfill and that \"recycling may be the most wasteful activity in modern America.\" \n Much of the difficulty inherent in recycling comes from the fact that most products are not designed with recycling in mind. The concept of   aims to solve this problem, and was laid out in the 2002 book   by architect   and chemist  .  They suggest that every product (and all packaging it requires) should have a complete \"closed-loop\" cycle mapped out for each component—a way in which every component either returns to the natural ecosystem through   or is recycled indefinitely. \n Complete recycling is impossible from a practical standpoint. In summary, substitution and recycling strategies only delay the depletion of non-renewable stocks and therefore may buy time in the transition to true or strong  , which ultimately is only guaranteed in an economy based on renewable resources. While recycling diverts waste from entering directly into landfill sites, current recycling misses the dispersive components. Critics believe that complete recycling is impracticable as highly dispersed wastes become so diluted that the energy needed for their recovery becomes increasingly excessive.\n As with  , care must be taken to ensure a complete view of the costs and benefits involved. For example,   packaging for food products is more easily recycled than most plastic, but is heavier to ship and may result in more waste from spoilage. \n \n The amount of energy saved through recycling depends upon the material being recycled and the type of energy accounting that is used. Correct accounting for this saved energy can be accomplished with   using real energy values, and in addition,  , which is a measure of how much useful energy can be used. In general, it takes far less energy to produce a unit mass of recycled materials than it does to make the same mass of virgin materials. \n Some scholars use   (spelled with an m) analysis, for example, budgets for the amount of energy of one kind (exergy) that is required to make or transform things into another kind of product or service. Emergy calculations take into account economics that can alter pure physics-based results. Using emergy life-cycle analysis researchers have concluded that materials with large refining costs have the greatest potential for high recycle benefits. Moreover, the highest emergy efficiency accrues from systems geared toward material recycling, where materials are engineered to recycle back into their original form and purpose, followed by   systems where the materials are recycled into a different kind of product, and then by-product reuse systems where parts of the products are used to make an entirely different product. \n The   (EIA) states on its website that \"a paper mill uses 40 percent less energy to make paper from recycled paper than it does to make paper from fresh lumber.\"  Some critics argue that it takes more energy to produce recycled products than it does to dispose of them in traditional landfill methods, since the curbside collection of recyclables often requires a second waste truck. However, recycling proponents point out that a second timber or logging truck is eliminated when paper is collected for recycling, so the net energy consumption is the same. An emergy life-cycle analysis on recycling revealed that fly ash, aluminum, recycled concrete aggregate, recycled plastic, and steel yield higher efficiency ratios, whereas the recycling of lumber generates the lowest recycle benefit ratio. Hence, the specific nature of the recycling process, the methods used to analyse the process, and the products involved affect the energy savings budgets. \n It is difficult to determine the amount of energy consumed or produced in waste disposal processes in broader ecological terms, where causal relations dissipate into complex networks of material and energy flow. \n [C]ities do not follow all the strategies of ecosystem development. Biogeochemical paths become fairly straight relative to wild ecosystems, with reduced recycling, resulting in large flows of waste and low total energy efficiencies. By contrast, in wild ecosystems, one population's wastes are another population's resources, and succession results in efficient exploitation of available resources. However, even modernized cities may still be in the earliest stages of a succession that may take centuries or millennia to complete.   How much energy is used in recycling also depends on the type of material being recycled and the process used to do so. Aluminium is generally agreed to use far less energy when recycled rather than being produced from scratch. The EPA states that \"recycling aluminum cans, for example, saves 95 percent of the energy required to make the same amount of aluminum from its virgin source,  .\"  In 2009, more than half of all aluminium cans produced came from recycled aluminium.  Similarly, it has been estimated that new steel produced with recycled cans reduces greenhouse gas emissions by 75%. \n Every year, millions of tons of materials are being exploited from the earth's crust, and processed into consumer and capital goods. After decades to centuries, most of these materials are \"lost\". With the exception of some pieces of art or religious relics, they are no longer engaged in the consumption process. Where are they? Recycling is only an intermediate solution for such materials, although it does prolong the residence time in the anthroposphere. For thermodynamic reasons, however, recycling cannot prevent the final need for an ultimate sink. Economist   has suggested that the sole benefit of reducing landfill space is trumped by the energy needed and resulting pollution from the recycling process.  Others, however, have calculated through life-cycle assessment that producing recycled paper uses less energy and water than harvesting, pulping, processing, and transporting virgin trees.  When less recycled paper is used, additional energy is needed to create and maintain farmed forests until these forests are as self-sustainable as virgin forests.\n Other studies have shown that recycling in itself is inefficient to perform the \"decoupling\" of economic development from the depletion of non-renewable raw materials that is necessary for sustainable development.  The international transportation or recycle material flows through \"... different trade networks of the three countries result in different flows, decay rates, and potential recycling returns\".  As global consumption of a natural resources grows, their depletion is inevitable. The best recycling can do is to delay; complete closure of material loops to achieve 100 percent recycling of nonrenewables is impossible as micro-trace materials dissipate into the environment causing severe damage to the planet's ecosystems.  Historically, this was identified as the metabolic rift by  , who identified the unequal exchange rate between energy and nutrients flowing from rural areas to feed urban cities that create effluent wastes degrading the planet's ecological capital, such as loss in soil nutrient production.  Energy conservation also leads to what is known as  , where improvements in energy efficiency lowers the cost of production and leads to a rebound effect where rates of consumption and economic growth increases. \n \n The amount of money actually saved through recycling depends on the efficiency of the recycling program used to do it. The   argues that the cost of recycling depends on various factors, such as   and the amount of disposal that the community recycles. It states that communities begin to save money when they treat recycling as a replacement for their traditional waste system rather than an add-on to it and by \"redesigning their collection schedules and/or trucks\". \n In some cases, the cost of recyclable materials also exceeds the cost of raw materials. Virgin plastic resin costs 40 percent less than recycled resin.  Additionally, a   (EPA) study that tracked the price of clear glass from 15 July to 2 August 1991, found that the average cost per ton ranged from $40 to $60  while a   report shows that the cost per ton of raw silica sand from years 1993 to 1997 fell between $17.33 and $18.10. \n Comparing the market cost of recyclable material with the cost of new raw materials ignores economic  —the costs that are currently not counted by the market. Creating a new piece of plastic, for instance, may cause more pollution and be less sustainable than recycling a similar piece of plastic, but these factors are not counted in market cost. A   can be used to determine the levels of externalities and decide whether the recycling may be worthwhile despite unfavorable market costs. Alternatively, legal means (such as a  ) can be used to bring externalities into the market, so that the market cost of the material becomes close to the true cost.\n The recycling of waste electrical and electronic equipment can create a significant amount of pollution. This problem is specifically occurrent in India and China. Informal recycling in an underground economy of these countries has generated an environmental and health disaster. High levels of lead (Pb), polybrominated diphenylethers (PBDEs),   and  , as well as polybrominated dioxins and furans (PCDD/Fs and PBDD/Fs), concentrated in the air,  , dust, soil, water, and sediments in areas surrounding recycling sites.  These materials can make work sites harmful to the workers themselves and the surrounding environment.\n \n In some countries, recycling is performed by the entrepreneurial poor such as the  ,  , the  ,  , and  . With the creation of large recycling organizations that may be profitable, either by law or  ,  the poor are more likely to be driven out of the recycling and the   job market. To compensate for this loss of income, a society may need to create additional forms of societal programs to help support the poor.  Like the  , there is a net loss to the poor and possibly the whole of a society to make recycling artificially profitable, e.g. through the law. However, in Brazil and Argentina, waste pickers/informal recyclers work alongside the authorities, in fully or semi-funded cooperatives, allowing informal recycling to be legitimized as a paid public sector job. \n Because the social support of a country is likely to be less than the loss of income to the poor undertaking recycling, there is a greater chance for the poor to come in conflict with the large recycling organizations.  This means fewer people can decide if certain waste is more economically reusable in its current form rather than being reprocessed. Contrasted to the recycling poor, the efficiency of their recycling may actually be higher for some materials because individuals have greater control over what is considered \"waste\". \n One labor-intensive underused waste is electronic and computer waste. Because this waste may still be functional and wanted mostly by those on lower incomes, who may sell or use it at a greater efficiency than large recyclers.\n Some recycling advocates believe that   individual-based recycling does not cover all of society's recycling needs. Thus, it does not negate the need for an organized recycling program.  Local government can consider the activities of the recycling poor as contributing to the ruining of property.\n Changes that have been demonstrated to increase recycling rates include:\n In a study done by social psychologist Shawn Burn,  it was found that personal contact with individuals within a neighborhood is the most effective way to increase recycling within a community. In her study, she had 10 block leaders talk to their neighbors and persuade them to recycle. A comparison group was sent fliers promoting recycling. It was found that the neighbors that were personally contacted by their block leaders recycled much more than the group without personal contact. As a result of this study, Shawn Burn believes that personal contact within a small group of people is an important factor in encouraging recycling. Another study done by Stuart Oskamp  examines the effect of neighbors and friends on recycling. It was found in his studies that people who had friends and neighbors that recycled were much more likely to also recycle than those who did not have friends and neighbors that recycled.\n Many schools have created recycling awareness clubs in order to give young students an insight on recycling. These schools believe that the clubs actually encourage students to not only recycle at school but at home as well.\n Recycling of metals varies extremely by type. Titanium and lead have an extremely high recycling rates of over 90%. Copper and cobalt have high rates of recycling around 75%. Only about half of aluminum is recycled. Most of the remaining metals have recycling rates of below 35%, while 34 types of metals have recycling rates of under 1%. \n \"Between 1960 and 2000, the world production of plastic resins increased 25 times its original amount, while recovery of the material remained below 5 percent.\"  Many studies have addressed recycling behaviour and strategies to encourage community involvement in recycling programs. It has been argued  that recycling behavior is not natural because it requires a focus and appreciation for long-term planning, whereas humans have evolved to be sensitive to short-term survival goals; and that to overcome this innate predisposition, the best solution would be to use social pressure to compel participation in recycling programs. However, recent studies have concluded that social pressure does not work in this context.  One reason for this is that social pressure functions well in small group sizes of 50 to 150 individuals (common to nomadic hunter–gatherer peoples) but not in communities numbering in the millions, as we see today. Another reason is that individual recycling does not take place in the public view.\n Following the increasing popularity of recycling collection being sent to the same landfills as trash, some people kept on putting recyclables on the recyclables bin. \n Art objects are more and more often made from recycled material.\n By extending the lifespan of goods, parts, and materials, a circular economy seeks to minimize waste and maximize resource utilization.  Advanced sorting techniques like optical and robotic sorting may separate and recover valuable materials from waste streams, lowering the requirement for virgin resources and accelerating the shift to a circular economy.\n Community engagement, such as education and awareness campaigns, may support the acceptance of recycling and reuse programs and encourage the usage of sustainable practices. One can lessen our influence on the environment, save natural resources, and generate economic possibilities by adopting a circular economy using cutting-edge sorting technology and community engagement. According to Melati et al.,  to successfully transition to a circular economy, legislative and regulatory frameworks must encourage sustainable practices while addressing possible obstacles and difficulties in putting these ideas into action.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_vacuum-tube_computers", "title": "List of vacuum-tube computers", "content": "\n \n , now called  ,  are programmable digital computers using   logic circuitry. They were preceded by systems using electromechanical   and followed by systems built from discrete  . Some later computers on the list had both vacuum tubes and transistors.\n This   is sorted by date put into service:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Brooklyn_College", "title": "Brooklyn College", "content": " is a   in   in  , United States. It is part of the   system and as of 2019 enrolls over 17,000 undergraduate and over 2,800 graduate students on a 35-acre (14 ha) campus in the   and   sections of Brooklyn.\n New York City's first public coeducational  , the college was formed in 1930 by the merger of the Brooklyn branches of   (centered in  ), then a  , and of the   (also Manhattan), then a  , both established in 1926. Once tuition-free, the city's 1975 fiscal crisis ended the free tuition policy. The college also consolidated to its main campus.\n Prominent alumni of Brooklyn College include US senators, federal judges, US financial chairmen, Olympians, CEOs, and recipients of  ,  ,  , and  .\n Brooklyn College was founded in 1930.  That year, as directed by the   on April 22, the college authorized the combination of the   branches of  , at that time a  , and the  , then a  , both established in 1926.   Meanwhile, Brooklyn College became the first public coeducational   in New York City.  The school opened in September 1930,  holding separate classes for men and women until their junior years.  Admission would require passing a stringent entrance exam. \n In 1932,   Randolph Evans drafted a plan for the campus on a substantial plot that his employer owned in Brooklyn's   section.  Evans sketched a   campus facing a central  , and anchored by a library building with a tower.   Evans presented the sketches to the college's then president, Dr.  ,  who approved the layout.\n The land was bought for $1.6 million (equivalent to $35.7 million in 2023),  and construction allotment was $5 million (equivalent to $112 million in 2023).  Construction began in 1935.  At the groundbreaking ceremony was     and Brooklyn   Raymond Ingersoll.  In 1936, United States President   visited and laid the gymnasium's  .  The new campus opened for the fall 1937 semester.  In the 1940s, Boylan, Ingersoll, Roosevelt and La Guardia each became namesake of a campus building. \n During the tenure of its second president,  , from 1939 to 1966, Brooklyn College ranked high nationally in number of alumni with doctorate degrees.  As academics fled  , nearly a third of refugee historians who were female would at some point work at Brooklyn College.  In 1944, sociologist   became the first permanent black faculty member appointed at any of the New York municipal colleges.  And in 1956, with   joining, Brooklyn College became the first \"white\" college to hire on a permanent basis a historian who was black. \n In 1959, still tuition-free, about 8,000 undergraduates were enrolled.  In 1962, the college joined six other colleges to form the  , creating the world's second-largest university.  In 1983, Brooklyn College named its library the Harry D. Gideonse Library. \n Nevertheless, Gideonse remains a controversial figure in the college's history; as one account noted, he is \"either lauded as a hero and great educator in hagiographic accounts . . . or decried by faculty and alumni as an autocrat who stifled academic freedom and students' rights.\" \n In addition to his curricular and student life reforms, Gideonse was known for his decades-long campaign to ferret out Communists among the college community and his testimony before congressional and state investigating committees during the Second  . \n On the other hand, perhaps retaining the memory of the time when, as a   professor, he was unjustly accused of being a Communist and advocating \" ,\"  Gideonse also attacked those who, without evidence, charged faculty, staff and students with being subversives and defended faculty free speech rights against outside critics. \n The college's third president,  , served from 1966 to 1967.  The fourth president,  , resigned due to ill health in February 1969, when George A. Peck was named acting president.   , Brooklyn College's fifth president, served from 1969 until 1979.  These presidents served during what were perhaps the most tumultuous years for Brooklyn College.\n During the Vietnam War, as they did on other U.S. campuses, student protests rocked Brooklyn College. President Gideonse, in a 1965 television interview, blamed demonstrations on Communists who were \"duping the innocents\" into demanding more freedom on campus,  leading the New York Civil Liberties Union to criticize Gideonse for \"his efforts to smear student groups at the college with the Communist label.\" \n Also in 1965, student protests forced the Gideonse administration to rescind new, stricter dress rules that forbade male students from wearing dungarees or sweatshirts on campus at any time and mandated that female students wear skirts and blouses even in extremely cold weather.  After Gideonse's retirement in June 1966,  a newly-appointed dean of administration, Dante Negro, said he was not bothered by the students' more casual dress \"that makes it hard to distinguish between the sexes,\" calling it \"a passing fad.\" \n On October 21, 1967, a front-page story in   reported that the college was virtually closed down by a strike of thousands of students angered by police action against antiwar demonstrators protesting U.S. Navy recruiters earlier in the week.  Five days later, another front-page   story reported that students had agreed to return to classes after an agreement was reached with college administrators after negotiations.  A few days after that, President Kilcoyne walked out when New York Mayor   appeared at the college, citing Lindsay's insult in calling the school \"Berkeley East.\" \n Around the same time, the college's students were involved in campus protests involving racial issues. In May 1968, Brooklyn College news again made the front page of   when police broke up a 16-hour sit-in at the registrar's office to demand that more Black and Puerto Rican students be admitted to the school.  At trial, a Black Brooklyn judge reacted angrily when one student said they had been reacting to racism and sentenced him and 32 other white students to five days in jail for the sit-in.  In May 1969, 19 or 20 Brooklyn College students faced criminal charges in connection with campus disorders during the spring semester, including raids  in which students allegedly ransacked files and smoke-bombed the library. \n In late April 1970, students demanding more open admissions and racial diversity staged a sit-in at President Kneller's office, holding him and five deans there for several hours.  The next week, in early May 1970, students seized the president's office and other buildings during a   upon the   and the  .  President Kneller terminated classes, but kept campus buildings open for students and faculty, obtaining a court order against students occupying buildings. \n In October 1974, 200 Hispanic students took over the registrar's office to protest President Kneller's appointment of a chair of the Puerto Rican Studies Department different from that of the person selected by a faculty search committee.  Defying a judge's temporary court order to leave the building, the protesters were supported at a rallies outside Boylan Hall by many student groups and the alumni association, but Kneller refused to rescind his controversial appointment.  Protests flared up again in the spring 1975 semester with another takeover of the registrar's office.  By January 1976, the college's faculty union voted \"no confidence\" in Kneller, charging that he \"consistently ignored faculty rights\" and failed to provide leadership. \n Brooklyn College, along with the rest of CUNY, shut down for two weeks in May and June 1976 as the university was unable to pay its bills.  Amid New York City's financial crisis, near bankruptcy, Brooklyn College's campus in   closed, leaving the Midwood campus as the Brooklyn College's only campus.  In the fall of 1976, with some 30,000 undergraduates enrolled, the college charged tuition for the first time. \n In January 1978, the college's Faculty Council approved a vote of \"no confidence\" in President Kneller on Wednesday and recommended to the Board of Higher Education that he be replaced. \n Brooklyn College's sixth president was  , who served from 1979 to 1992.  Hess initiated major changes in the college curriculum, mandating a standard core for all students.  Implementation of the new curriculum was aided by a large grant from the National Endowment for the Humanities.  By 1984, in a national report's otherwise gloomy assessment of humanities education, Brooklyn College was singled out as \"a bright spot\" among American universities for stressing the study of the humanities. \n In a 1988 survey of thousands of American college deans, Brooklyn College ranked 5th in providing students with a strong general education, and was the only public institution among the top five.  As of 1989, Brooklyn College ranked 11th in the US, and ahead of six of the eight   universities, by number of graduates who had acquired doctoral degrees.  At Brooklyn College being called “the poor man’s Harvard,” President Hess quipped, “I like to think of Harvard as the rich man’s Brooklyn College.” \n Even as Brooklyn College rebounded academically, it suffered a severe budget crunch in the 1988-1989 school year due to reductions in state financing; this resulted in fewer courses, larger classes, no new faculty and staff hirings, supply shortages, and deferral of maintenance of buildings and grounds. \n  was the seventh president of Brooklyn College, from 1992 to 2000.  \nDuring Lattin's tenure, Brooklyn College began a complete overhaul of campus buildings  and vastly improved computer and Internet access for students and faculty.  The college returned to intercollegiate sports competition  and the college chess team won U.S. and international championships.  Lattin was also president at the time of the first individual million-dollar donation to the Brooklyn College Foundation. \n Brooklyn College's campus leafy East Quad looks much like it did when it was originally constructed.  The campus also serves as home to BCBC/ Brooklyn College Presents complex and its four theaters, including the  .\n Gershwin Hall was demolished and replaced by The Leonard & Claire Tow Center for the Performing Arts, for which ground was broken in 2011.  The performing arts center was named for alumni   and Claire Tow, who gifted $10 million to the college.  Other changes to the original design include the demolition of Plaza Building, due to its inefficient use of space, poor ventilation, and significant maintenance costs.  To replace the Plaza Building, the college constructed West Quad Center, designed by the notable   architect  . The new building contains classroom space, offices, gymnasiums and a swimming pool. It houses the offices of Registration, Admissions, Financial Aid, and the Department of   and Exercise Science.  The grounds contain a   with grassy areas and trees. New   are being constructed on Roosevelt and James halls where they once connected with Plaza Building. The 2009–10   championship men's basketball team now plays its home games in the West Quad Center.\n This followed a major $70 million library renovation completed in 2003 that saw the library moved to a temporary home while construction took place.  The Brooklyn College library is now located in its original location in a completely renovated and expanded LaGuardia Hall.\n From 2000 to 2009 when he retired,   was the eighth president of Brooklyn College.  In the 2003 edition of  , the   named Brooklyn College as the most beautiful campus in the country and ranked it fifth in the nation for \"Best Academic Bang for the Buck\". \n  was named the ninth president of Brooklyn College in 2009.  Among her accomplishments were creating a new graduate film school and four new academic schools, new athletic fields, and increasing enrollment in the sciences.  Her tenure was marked by repeated free speech controversies involving Israel that drew both criticism and praise.  After 42 years in higher education, Gould announced her retirement in 2015. \n  became the 10th president of Brooklyn College in 2016.  In 2016, Brooklyn College announced a new home for the Koppelman School of Business, with the planned construction of a new building, Koppelman Hall, on property adjacent to the 26-acre campus bought in 2011. This increased the campus size to 35 acres. \n For four straight years, starting in 2018,   named Brooklyn College the most ethnically diverse college in the North Region. \n Brooklyn College has five schools:\n Beginning in 1981, the college instituted a group of classes that all undergraduates were required to take, called \"Core Studies\".  The classes were: Classical Origins of Western Culture, Introduction to Art, Introduction to Music, People, Power, and Politics, The Shaping of the Modern World, Introduction to Mathematical Reasoning and Computer Programming, Landmarks of Literature, Chemistry, Physics, Biology, Geology, Studies in African, Asian, and Latin American Cultures, and Knowledge, Existence and Values. \n In 2006, the Core Curriculum was revamped, and the 13 required courses were replaced with 15 courses in 3 disciplines, from which students were required to take 11.  In the fall of 2013, Brooklyn College embarked on CUNY's new general education alternative, the Pathways curriculum, consisting of three components: Required Core (four courses), Flexible Core (six courses) and College Option (four courses)—totaling 42 credits.   Brooklyn College offers over a hundred majors varying from the visual arts to Women's Studies. \n The Division of Graduate Studies at Brooklyn College was established in 1935 and offers more than seventy programs in the arts, education, humanities, sciences, and computer and social sciences. Among those programs is the Graduate theatre program, which is the top ranked in the CUNY system and 14th in the United States; faculty include   nominee Justin Townsend. \n The Brooklyn College  –  program is an eight-year program affiliated with  . The program follows a rigorous selection process, with a maximum of 15 students selected every year. Each student selected to the program receives a Brooklyn College Presidential Scholarship. B.A.–M.D. students must engage in   for three years, beginning in their lower sophomore semester. During one summer of their undergraduate studies, students are required to volunteer in a clinical setting where they are involved in direct  . B.A.–M.D. students are encouraged to major in the   or  . \n The Scholars Program is home to a small number of students with strong writing ability and academic record. Being the oldest honors program in the   system, The Scholars Program has served as a model for many other honors programs nationwide. It was established in 1960 and is an interdisciplinary liberal arts program. The program offers honors-level Core courses and seminars as well as small, personalized classes. Upon graduation from Brooklyn College, many Scholars continue their education in competitive programs at top-ranked universities like Princeton, Yale, and New York University. The program accepts incoming freshmen in addition to matriculated sophomores and transfer students (up to 48 credits). Once admitted, they receive a Brooklyn College Foundation Presidential Scholarship of up to $4,000 for every year of their undergraduate study at Brooklyn College and a laptop computer. \n The Coordinated Honors Engineering Program offers a course of study equivalent to the first two years at any engineering school. Students who maintain the required academic level are guaranteed transfer to one of the three coordinating schools— , City College of New York School of Engineering, and the College of Staten Island Engineering Science Program—to complete their bachelor's degree in engineering. Coordinating Engineering students have also transferred to the  ,  ,  ,  ,  , and the  . Students admitted as incoming First-Year receive a Brooklyn College Foundation Presidential Scholarship that provides full tuition for their two years of full-time undergraduate study in the Coordinated Engineering Program. As members of the Honors Academy, Engineering Honors students take advantage of individual advising, faculty consultation, and early registration. In the Commons they find study facilities, computer access, academic, scholarship, internship, and career opportunities, and, above all, intellectual stimulation among other talented students like themselves. Students applying to the Engineering Honors Program will also be considered for the Scholars Program. \n Barry R. Feirstein Graduate School of Cinema is the first public graduate film school in New York City. It is the only film school in America to have its own classroom on a film lot with the collaboration of  , the largest soundstage on the East Coast. The program offers a two-year M.A. in Cinema Studies, a two-year M.F.A. in Cinema Arts in the discipline of  , and a three-year M.F.A in Cinema Arts with five disciplines of  ,\n ,  ,  , and Digital Arts and Visual Effects. The school opened in the fall of 2015. The first graduating class was in Spring 2018.\n  ranked the school tied for 62nd overall as a Regional college (North region), 6th in \"Top Performers on Social Mobility\", 15th in \"Top Public Schools\", and tied for 33rd in \"Best Colleges for Veterans\" for 2021. \n Brooklyn College athletic teams are nicknamed the Bulldogs. The college is a member at the   level of the   (NCAA); primarily competing in the   (CUNYAC) since the 1996–97 academic year (which they also competed in a previous stint from 1978–79 to 1979–80). The Bulldogs previously competed in the   at the   level during the 1991–92 academic year.\n Men's sports include basketball, cheerleading, cross country, soccer, swimming & diving, tennis and volleyball; while women's sports include basketball, cheerleading, cross country, soccer, softball, swimming & diving, tennis and volleyball. Their basketball program would find infamy for being the first reported incident of a potential bribe to fix a game against the Municipal University of Akron (now just the  ) on January 29, 1945, leading to five arrests against Brooklyn College's players in question.  Another former basketball player of theirs, a previous captain named David Budin, would later be involved as a part of the   as a late addition for  ' rigging group in question.  The football field was used for the outdoor scenes in the 1978 adult film  . \n In 2010, Brooklyn College adopted the Bulldog as its new mascot.  The athletic program was originally known as the Kingsmen. In 1994, the mascot was changed to the Bridges. However, after the school built new facilities and underwent other changes the athletic director pushed for a new name to reflect the new program. \n Notable alumni of Brooklyn College in government include Senate majority leader and 1996 Republican presidential nominee:   (1943-1944),  Senator   (1959–1960),  Senator   (née Barbara Levy; B.A. 1962), Congresswoman   (B.A. 1946),   chairmen   (B.S. 1933) and   (B.A. 1965), and federal judges   (B.A. 1959),   (B.A. 1943),   (B.A. 1963),   (B.A. 1963),   (B.A. 1967), and   (B.A. 1995; M.A. 1997).\n Notable alumni in business include   CEO   (B.S. 1974),   CEO   (B.S. 1978),   and   CEO  ,   President   (B.A. 1960),   owner   (1937),  ,   CEO   (B.A. 1961),   CEO   (B.A. 1953),   co-founder   (B.A. 1950), and   Chairman   (B.S. 1969).\n Notable alumni in the sciences and academia include  –winning biochemist   (B.A. 1943),  –winning mathematician   (1953), social psychologists   (B.A. 1954) and   (B.A. 1954),   professor and author   (A.B. 1959),   Dean   (B.A. 1953),   Chancellor   (B.A. 1963),   President   (B.S. 1976), and NASA scientist and   professor   (B.S. 1964).\n Notable alumni in the arts include  ,  , and  –winning director, writer, and actor   (born Melvin Kaminsky; 1946),  –winning actor   (M.F.A. 2009),  –winning actor   (B.A. 1980), Academy Award–winning screenwriter   (B.A.), Academy Award-nominated filmmakers   (B.A. 1952) and   (B.A. 1992),   stars   (B.A. 1980) and   (B.A. 1961), director   (1962; M.A. 1968),   winner   (born Bernard Nierow; B.A. 1956),  –winning author   (born Irwin Shamforoff; B.A. 1934); and a number of   winners: author   (M.A. 1967), playwrights   (B.A. 1950) and   (M.F.A. 2009), journalists   (B.A. 1951),   (1947), and   (B.A. 1937), photographer  , and historian   (B.A. 1934).\n Other notable alumni include Olympic fencers   and   (B.S. 1972), chess   and five-time U.S. champion   (B.A. 1999),   founder   (B.A. 1954), and civil rights activist   (1975).\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_shopping_malls_in_the_Northern_Mariana_Islands", "title": "List of shopping malls in the United States", "content": "\nThis is a list of current and former notable  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Harold_Kerzner", "title": "Harold Kerzner", "content": " (born ca 1940) is an American  ,  , Emeritus Professor of Systems Management at  , and Sr. Executive Director for Project Management at the International Institute for Learning,  known for his work in the field of  . \n Kerzner received an MS and PhD at the   and an MBA at  . \n Kerzner started as an engineer at the  , where he worked in program management and project engineering. Later he started his academic career at the   teaching engineering, and afterwards at   teaching business administration. \n In the early 1980s, he became Professor of Systems Management at Baldwin-Wallace College, now Baldwin Wallace University. \n In 1998, Kerzner received the Distinguished Service Award for his contributions to project management from the  , and the   granted him the Distinguished Recent Alumni Award. The  , the Northeast Ohio Chapter, annually grants the Kerzner Award for excellent achievements in project management to a company or individual. \n Kerzner is the Executive Director for International Institute for Learning (IIL).  With the company, he has authored numerous books about Project Management. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Extinct_(film)", "title": null, "content": " is a 2021 animated     directed by  , and co-directed by  , from a screenplay by  ,  , and  .  The film features the voices of  ,  ,  ,  ,  ,  ,  , and  . Its story follows Op and Ed, two adorable  -like creatures with giant holes in the center, called the \"flummels\", that find themselves transported from their island home in the year 1835 to modern day  .\n Extinct was released in Russia on February 11, 2021, then theatrically by   in the United Kingdom on August 20, 2021, and then was released worldwide on   on November 19, 2021.\n Siblings Op and Ed (a species of fluffy  -like creatures with holes in her center, known as the \"flummels\") are native to the  . The flummels are ostracized by their community, due to Op's proneness to disaster, and are labelled weird by mallei. Just before   discovers their island during one of his voyages, Op and Ed find and fall into a large flower that teleports them to modern-day  , where they meet and befriend a white poodle named Clarance. The flummels learn their species is now extinct after Darwin found the island destroyed by a volcanic eruption.\n Clarance brings them to the Time Terminal, a pavilion where Clarance's owner, Dr. Lee Chung, kept and studied the flowers and their seeds, which have time-traveling properties. Op accidentally knocks some seeds out, causing the Terminal to malfunction and sending Clarance to 1915 Antarctica, along with the seed that leads the flummels home. In Antarctica, Clarance is captured by  's expedition team. With the help of the Extinctables — a team of extinct animals composed of Dottie, a  ; Burnie, a  ; Alma, a female  ; and Hoss, a male  , who were bought by Dr. Chung to the Terminal — Op and Ed travel through each seed in order to find the one that can bring them home and rescue Clarance.\n Following a falling out with Ed, Op returns to the flummels' time, where she attempts to warn the rest of the flummels about the volcano. Clarance imprisons her, telling her that flummels ruined his life and that he is actually behind their extinction. Clarance had been adopted by Dr. Chung, but after Dr. Chung was charmed by the adorable flummels, Clarance went Maverick, pushing Dr. Chung into one of the flowers and destroying the seed that would send him back. He then caused the flummels' extinction by planting a drone bomb. Following Ed's arrival after seeing the video Op made, they make several attempts to escape and stop the bomb, eventually deploying a seed to move the entire island into the present day. Clarance survives, but Dr. Chung arrives and punishes him by sending him back to 1915 Antarctica, thanking the flummels and the Extinctables.\n A year later, Op and Ed are finally accepted by their community, while Dottie surprises Ed by laying a blueish egg shaped like a flummel. The egg hatches, but the creature inside the egg is unknown.\n In a mid-credits scene, Op surprises Ed by pulling Wally into the Time Terminal. Wally exclaims that they have so much to talk about, while Op leaves to \"get him a glass of water\".\n The film was first announced on September 3, 2019, as a new animated feature in production at   directed by   with   as co-director. The announcement revealed  ,  ,   and   as cast members. \n The film was released in the United Kingdom in August 20, 2021 by  .  The film was also released in Russia theatrically on February 11, 2021. The film was released worldwide on   on November 19, 2021.   was in the Top 10 most watched English films on Netflix during the first week of its release. \n Review aggregator   reported a score of 43% based on seven reviews, with an average rating of 4.90/10.  Steve Rose for   gave the film 2 out of 5 stars, writing that: \"In the Darwinian world of kids' entertainment,   looks like an evolutionary dead end.\" \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/United_States_Geological_Survey", "title": "United States Geological Survey", "content": "\n\n The   ( ), founded as the  , is an   of the   whose work spans the disciplines of  ,  ,  , and  . The agency was founded on March 3, 1879, to study the   of the United States, its  , and the   that threaten it. The agency also makes maps of extraterrestrial planets and moons based on data from  .\n The sole scientific agency of the U.S. Department of the Interior, USGS is a fact-finding research organization with no regulatory responsibility.  It is headquartered in  , with major offices near  ; at the  ; and in   in California.  In 2009, it employed about 8,670 people. \n The current motto of the USGS, in use since August 1997, is \"science for a changing world\".  The agency's previous slogan, adopted on its hundredth anniversary, was \"Earth Science in the Public Service\". \n Since 2012, the USGS science focus has been directed at topical \"Mission Areas\"  that have continued to evolve. Further organizational structure includes headquarters functions, geographic regions, science and support programs, science centers, labs, and other facilities.\n The USGS regional organization  aligns with the U.S. Department of the Interior Unified Interior Regions: \n USGS operates and organizes within a number of specific science programs, facilities, and other organizational units:\n The   monitors   activity worldwide. The   (NEIC) in  , on the campus of the   detects the location and magnitude of global earthquakes. The USGS also runs or supports several regional monitoring networks in the United States under the umbrella of the   (ANSS).  The USGS informs authorities, emergency responders, the media, and the public, both domestic and worldwide, about significant earthquakes. It maintains long-term archives of earthquake data for scientific and engineering research. It also conducts and supports research on long-term  . USGS has released the  \n As of 2005,  the agency is working to create a   by improving the instrumentation monitoring   and by establishing methods for measuring the relative threats posed at each site.\n The USGS also operates five volcano observatories throughout the nation: the   in  , the   in  , the   (covering volcanoes in  ,  , and  ) in  , the   in  , and the   (covering volcanoes in  ,  ,  ,  ,  , and  ) in  , Wyoming. \n The USGS Coastal and Marine Science Center (formerly the USGS Center for Coastal Geology) has three sites, one for the   (located in  ), one for the   (located in  ) and one for the   (located on the   campus). The goal of this department is to conduct research in geology, mapping, hydrology, biology, and related sciences; evaluate hazards associated with floods, droughts, hurricanes, subsidence, human activity, and climate change; map the onshore and offshore geologic framework; assess mineral resources and develop techniques for their discovery; assess water resources and develop an understanding of the impact of human activities and natural phenomena on hydrologic systems; assess links between biodiversity, habitat condition, ecosystem processes and health; and develop new technologies for collection and interpretation of earth science data. \n The USGS   monitors the   at magnetic observatories and distributes   data in real time.\n The USGS collaborates with   and   government scientists, along with the  , to produce the  , which is used to depict and track environmental issues for a continental perspective.\n The USGS operates the   network for the United States, with over 7400  . Real-time streamflow data  are available online.\n As part of the Water Resources Research Act of 1984, the State Water Resources Research Act Program created a Water Resources Research Institute (WRRI) in each state, along with Washington DC, Puerto Rico, the US Virgin Islands, and Guam.  Together, these institutes make up the National Institutes for Water Resources (NIWR). The institutes focus on water-related issues through research, training and collaboration. \n The National and regional Climate Adaptation Science Centers (CASCs)  is a partnership-driven program that teams scientific researchers with natural and cultural resource managers to help fish, wildlife, waters, and lands across the country  . The National CASC (NCASC), based at USGS headquarters in Reston, Virginia, serves as the national office for the CASC network, while   made up of federal-university consortiums located across the U.S., U.S. Pacific Islands, and U.S. Caribbean deliver science that addresses resource management priorities of the states within their footprints.\n Since 1962, the   has been involved in global,  , and   exploration and  .\n In collaboration with  , the USGS also operates the USGS-Stanford Ion Microprobe Laboratory,  a world-class  analytical facility for U-(Th)-Pb   and trace element analyses of minerals and other earth materials.\n USGS operates a number of water-related programs, notably the National Streamflow Information Program  and National Water-Quality Assessment Program.  USGS Water data is publicly available from their National Water Information System  database.\n The USGS also operates the  , whose mission is \"to serve the nation and its natural resources by providing sound science and technical support, and to disseminate information to promote science-based decisions affecting wildlife and ecosystem health. The NWHC provides information, technical assistance, research, education, and leadership on national and international wildlife health issues.\"  It is the agency primarily responsible for surveillance of     outbreaks in the United States. The USGS also runs 17 biological research centers in the United States, including the  .\n The USGS is investigating collaboration with the social networking site   to allow for more rapid construction of ShakeMaps.  ShakeMaps are an interactive tool allowing users to visually observe the distribution and severity of Shaking resulting from Earthquakes. \n The USGS produces several national series of   which vary in   and extent, with some wide gaps in coverage, notably the complete absence of 1:50,000 scale topographic maps or their equivalent. The largest (both in terms of scale and quantity) and best-known topographic series is the 7.5-minute, 1:24,000 scale,  , a non-metric scale virtually unique to the United States. Each of these maps covers an area bounded by two lines of   and two lines of   spaced 7.5   apart. Nearly 57,000 individual maps in this series cover the  ,  ,  , and areas of   near  ,  , and  . The area covered by each map varies with the latitude of its represented location due to convergence of the meridians. At lower latitudes, near 30° north, a 7.5-minute quadrangle contains an area of about 64 square miles (166 km ). At 49° north latitude, 49 square miles (127 km ) are contained within a quadrangle of that size. As a unique non-metric map scale, the 1:24,000 scale naturally requires a separate and specialized   scale for plotting map positions.  In recent years, budget constraints have forced the USGS to rely on donations of time by civilian volunteers in an attempt to update its 7.5-minute topographic map series, and USGS stated outright in 2000 that the program was to be phased out in favor of   (not to be confused with the   produced by the  , one of whose bureaus is USGS).\n An older series of maps, the 15-minute series, was once used to map the contiguous 48 states at a scale of 1:62,500 for maps covering the continental United States, but was discontinued during the last quarter of the twentieth century. Each map was bounded by two   and two   spaced 15 minutes apart—the same area covered by four maps in the 7.5-minute series. The 15-minute series, at a scale of 1:63,360 (one inch representing one mile), remains the primary topographic quadrangle for the state of Alaska (and only for that particular state). Nearly 3,000 maps cover 97% of the state.  The United States remains virtually the only developed country in the world without a standardized civilian topographic map series in the standard 1:25,000 or 1:50,000 metric scales, making coordination difficult in border regions (the U.S. military does issue 1:50,000 scale topo maps of the continental United States, though only for use by members of its defense forces).\n The next-smallest topographic series, in terms of scale, is the 1:100,000 series. These maps are bounded by two lines of longitude and two lines of latitude. However, in this series, the lines of latitude are spaced 30 minutes apart and the lines of longitude are spaced 60 minutes, which is the source of another name for these maps; the 30 x 60-minute quadrangle series. Each of these quadrangles covers the area contained within 32 maps in the 7.5-minute series. The 1:100,000 scale series is unusual in that it primarily employs the  . One centimeter on the map represents one kilometer of distance on the ground.  , spot elevations, and horizontal distances are also specified in meters.\n The final regular quadrangle series produced by the USGS is the 1:250,000 scale topographic series. Each of these quadrangles in the conterminous United States measures 1 degree of latitude by 2 degrees of longitude. This series was produced by the U.S.   in the 1950s, prior to the maps in the larger-scale series, and consists of 489 sheets, each covering an area ranging from 8,218 square miles (21,285 km ) at 30° north to 6,222 square miles (16,115 km ) at 49° north.  Hawaii is mapped at this scale in quadrangles measuring 1° by 1°.\n USGS topographic quadrangle maps are marked with grid lines and tics around the map collar which make it possible to identify locations on the map by several methods, including the   measurements of longitude and latitude, the   and   method within the  , and   in both the   and the  .\n Other specialty maps have been produced by the USGS at a variety of scales. These include   maps, maps of special interest areas, such as the  , and areas of scientific interest.\n A number of Internet sites have made these maps available on the web for affordable commercial and professional use. Because works of the U.S. government are in the  , it is also possible to find many of these maps for free at various locations on the Internet.   map images are available from the USGS as   (DRGs) in addition to digital data sets based on USGS maps, notably   (DLGs) and   (DEMs).\n In 2015, the USGS unveiled the topoView website, a new way to view their entire digitized collection of over 178,000 maps from 1884 to 2006. The site is an interactive map of the United States that allows users to search or move around the map to find the USGS collection of maps for a specific area. Users may then view the maps in great detail and download them if desired. \n In 2008 the USGS abandoned traditional methods of surveying, revising, and updating topographic maps based on aerial photography and field checks.  Today's U.S. Topo quadrangle (1:24,000) maps are mass-produced, using automated and semiautomated processes, with cartographic content supplied from the National GIS Database.  In the two years from June 2009 to May 2011, the USGS produced nearly 40,000 maps, more than 80 maps per work day.  Only about two hours of interactive work are spent on each map, mostly on text placement and final inspection; there are essentially no field checks or field inspections to confirm map details. \n While much less expensive to compile and produce, the revised digital U.S. topo maps have been criticized for a lack of accuracy and detail in comparison to older generation maps based on aerial photo surveys and field checks.  As the digital databases were not designed for producing general-purpose maps, data integration can be a problem when retrieved from sources with different resolutions and collection dates.  Human-made features once recorded by direct field observation are not in any public domain national database and are frequently omitted from the newest generation digital topo maps, including windmills, mines and mineshafts, water tanks, fence lines, survey marks, parks, recreational trails, buildings, boundaries, pipelines, telephone lines, power transmission lines, and even railroads.  Additionally, the digital map's use of existing software may not properly integrate different feature classes or prioritize and organize text in areas of crowded features, obscuring important geographic details.  As a result, some have noted that the U.S. Topo maps currently fall short of traditional topographic map presentation standards achieved in maps drawn from 1945 to 1992. \n The Hydrologic Instrumentation Facility (HIF) has four sections within its organizational structure;  the Field Services Section which includes the warehouse, repair shop, and Engineering Unit; the Testing Section which includes the Hydraulic Laboratory, testing chambers, and Water Quality Laboratory; the Information Technology Section which includes computer support and the Drafting Unit; and the Administrative Section.\n The HIF was given national responsibility for the design, testing, evaluation, repair, calibration, warehousing, and distribution of hydrologic instrumentation. Distribution is accomplished by direct sales and through a rental program. The HIF supports data collection activities through centralized warehouse and laboratory facilities. The HIF warehouse provides hydrologic instruments, equipment, and supplies for USGS as well as Other Federal Agencies (OFA) and USGS Cooperators. The HIF also tests, evaluates, repairs, calibrates, and develops hydrologic equipment and instruments. The HIF Hydraulic Laboratory facilities include a towing tank, jet tank, pipe flow facility, and tilting flume. In addition, the HIF provides training and technical support for the equipment it stocks.\n The Engineering Group seeks out new technology and designs for instrumentation that can work more efficiently, be more accurate, and or be produced at a lower cost than existing instrumentation. HIF works directly with   to help them produce products that will meet the mission needs of the USGS. For instrument needs not currently met by a vendor, the Engineering Group designs, tests, and issues contracts to have HIF-designed equipment made. Sometimes HIF will patent a new design in the hope that instrument vendors will buy the rights and mass-produce the instrument at a lower cost to everyone.\n USGS researchers publish the results of their science in a variety of ways, including peer-reviewed scientific journals as well as in one of a variety of USGS Report Series  that include preliminary results, maps, data, and final results. A complete catalog of all USGS publications is available from the USGS Publications Warehouse. \n In the mid-1800s, various states set up geological survey institutions; e.g., the  , established in 1854. \n In 1879, a report from the   prompted Congress to set up a federal survey agency, in part to inventory the vast lands added to the United States by the   in 1803 and the   in 1848. The USGS was authorized on March 3 in a last-minute amendment to an unrelated bill that charged the new agency with the \"classification of the public lands, and examination of the geological structure, mineral resources, and products of the national domain\". The legislation also provided that the  ,  , and   surveys be discontinued as of June 30, 1879. \n , the first director of USGS, assembled the new organization from disparate regional survey agencies. After two years, King was succeeded by  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Jennifer_Coolidge", "title": "Jennifer Coolidge", "content": "\n\n  (born August 28, 1961) is an American actress. Known for her work in the  , Coolidge is the recipient of several accolades, including a   and two  . In 2023, she was included in the annual   list of the most influential people in the world. \n Coolidge had supporting roles in the   (1999–2012) and the   (2001–2003). She has collaborated with   on four of his   films,   (2000),   (2003),   (2006), and   (2016). She has also appeared in the films   (2004),   (2006),   (2006),   (2007),   (2020),   (2021), and   (2022).\n On television, Coolidge has appeared in the sitcoms   (2004–2006),   (2008–2012),   (2011–2017), and the drama series   (2022). She garnered critical acclaim for her role as Tanya McQuoid, an insecure wealthy woman, in the   anthology series   (2021–2022), winning two   and a  .\n Coolidge was born in  , on August 28, 1961, and raised in  ,  . As a child, she played the   and attended orchestra camp for three summers.  Coolidge is an eighth cousin twice removed of U.S. President  . \n She attended   in Norwell and   in  , and then   in Boston and the   in New York City.  During college, Coolidge aspired to be a dramatic actress similar to  , but instead pursued comedic character acting.  As a student at the American Academy of Dramatic Arts, Coolidge worked as a waitress in a restaurant alongside  , who also aspired to be an actress. \n Coolidge made her first television appearance in the November 1993   episode \" \".   In 1994, she was a regular on  , a short-lived   that also featured  ,  ,  , and  . She had small roles appearing in such films as  ,  ,  , and  .  She also voiced  's beauty school teacher, Miss Kremzer, in a recurring role on  . She worked with  , an improv and sketch comedy troupe based in  . \n In 1999, Coolidge got her big break playing  , or \" 's mom\" in  . The film was a box-office hit and grossed $235 million worldwide.  In 2001, she reprised her role in  . Later in that same year, she had a supporting role in   as Paulette Bonafonté Parcelle the manicurist.   was a box-office hit, grossing US$96 million domestically.  The film's box-office success led to her reprising the role in its 2003 sequel,  , but the movie was not as financially successful as the first and generated mostly negative reviews.  In 2003, she again played Stifler in  .\n In 2003, she played the protagonist's agent Luise in   filmed in Argentina starring   as Dean Seagrave and  , as Pablo. In 2004, she had a supporting role in the romantic comedy   playing  's character's vain, self-absorbed stepmother. The film went on to become a moderate box office hit despite negative critical reviews. \n She has appeared in 2001 on   as Frederica,  's new physical therapist, in 2003-2004 in 3 episodes of  , playing Roxanne, Jim's sister, and in 2003 in an episode of  . Coolidge nearly received the role of   on  , but it eventually went to  .  \n In 2003, she starred in an episode of   in its final season as Amanda, an obnoxious acquaintance whom   and   try to shake off. From 2004 to 2006, Coolidge had a role in the NBC comedy series   as  's oversexed agent Roberta \"Bobbie\" Morganstern. During its second season, she went from a recurring character to a more prominent role, appearing in 37 out of 46 episodes in the series. NBC officially canceled the series in May 2006, citing low ratings.  \n Coolidge also appeared in 1998 in the children's comedy  , and as the voice of Aunt Fanny in the animated feature   in 2005. The film was accompanied by an original short animated film based on  , titled  , in which she reprised her role. \n In late 2005, Coolidge was invited to join the  .  In 2006, she guest starred on an episode of  , and played as  's wife's friend, Janine, in the comedy film  . From 2000 to 2006 she played comic parts in the   \n   ,  , and  , all directed by  . \n She appeared in the 2006 film   as a spoof of  's   character. The film received unfavorable critic reviews and   ranked the film 77th in the 100 worst reviewed films of the 2000s, with a rating of 6%.  However,   did praise Coolidge for providing a few bright moments with a spot-on spoof of Streisand, albeit otherwise unimpressed describing the film as \"padded and repetitious\". \n , released in 2007 and made by the same people behind  , was the first movie in which she received a starring role. In the film she played the \"White Bitch\" (the  ) of Gnarnia ( ), a lampoon of the   and   film  .   of   called the film \"irreverent and also appreciative, dragging its satiric prey down to the lowest pop-cultural denominator\" and added, \"The humor is coarse and occasionally funny. The archly bombastic score ... is the only thing you might call witty. But happily, Jennifer Coolidge and Fred Willard show up ... to add some easy, demented class.\" \n During 2007, Coolidge appeared on   and  , on  . In 2008, she guest-starred on   as a  .  In the second season, she was a frequently recurring character, now playing the fiancé of Ben's dad and future stepmother of Ben.  She also starred in the 2008   film  . Coolidge appeared in the 2008 film   as Rosalee. \n In 2009, Coolidge took a dramatic role in   as Genevieve McDonagh. The   on September 9, 2009, at the  , and it opened in general release in the United States on November 20, 2009.  Also In 2009, she starred alongside   and   in  , a   about a set of women who form their own \"silent revolution\", wreaking havoc on the abusive men in their lives.\n In 2010, Coolidge appeared in another film starring   titled  , an   television film produced by   that originally aired on April 18, 2010.  It was based on the novel   by Daniella Brodsky.  The film was released on DVD and Blu-ray in the US on February 8, 2011. \n In June 2011, Coolidge curated a   art show in  .  \nIn the same month Coolidge began to do standup comedy. She hosted the \"Women in Film\" at the  . It went well, and she decided to take an act on the road. Coolidge ended up doing shows all over the country and the world for two years, Scotland included.  Coolidge told Australian radio show   that she would be touring Australia as part of her   stand-up tour. \n In October 2011, Coolidge began a recurring role in the   sitcom   as Zofia \"Sophie\" Kaczyński, a Polish neighbor of the two lead characters.  She was later promoted to main cast from   up until the show's cancellation in 2017.  Coolidge reprised her role as Jeanine Stifler in an   sequel   which opened in North America on April 6, 2012. \n During 2013, additional voice cast members were announced for  , including Coolidge as Carol Sue, a transitions-relations officer.  Film distributor   set November 6, 2015, for the film's release date (which was moved a few months later up to September 25),  In 2014,   reported that the film had been delayed again, with no replacement release date set.  It was reported the film's concept has gone back to development.  Also in 2013, Coolidge and actress   joined the cast of  ; Coolidge playing Ms. Suggs, the driving instructor.  The film was released in North America on October 10, 2014.\n The next year, she had a voice role in  , and had a cameo in  .  In 2016, she appeared in  , directed by \n .  In 2017, Coolidge lent her voice to portray Mary Meh in  .  In 2018, Coolidge made an appearance in  's music video for her song \" \".\n In 2020, she starred in  , the first studio comedy film of the 2020s, for  , co-starring with  ,  , and  .  Coolidge had a supporting role in  's directorial debut   as the mother of  's character, Cassie. The movie received universal acclaim upon release. \n In October 2020, Coolidge was cast as Tanya McQuoid, a troubled wealthy woman on vacation, in  's comedy-drama series   and began filming shortly after in Hawaii. The show premiered in July 2021 and was widely praised, with Coolidge receiving critical acclaim and winning a   for her performance.  Coolidge reprised her role for the  , and received a second Emmy Award for   for the role at the  . \n In 2021, she starred in the   Christmas romantic comedy   alongside  ,  , and  .  In 2022, Coolidge starred in  's mini-series   along with   and  . \n Coolidge dated comedian  .  \n In 2005, after having visited   up to ten times a year over ten years,  Coolidge purchased a house there,  which was featured in some of the interior scenes in   (2017).  \n Her charitable work and activism includes supporting AIDS assistance and  .  Coolidge is   and is passionate about animal rights causes. She was crowned PETA's \"Vegan Queen\" in 2023.  She has also adopted a dog named Chuy that was rescued from a meat factory in Korea. \n Coolidge is widely considered a  , often impersonated by  ,  with Coolidge noting in 2021 that she surrounded herself socially with gay men and women from a young age. Coolidge has also long been vocal about her support for the  . \n She was one of the people listed on  's \" \", and was featured on the magazine cover for the issue.  She also hosted the 2023 Time 100 gala.  In February 2023, Coolidge was named Woman of the Year by  ’s  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Tehran", "title": "Tehran", "content": "\n  ( ;  :        ) is the   and largest city of  . In addition to serving as the capital of  , the city is the administrative center for   and its  .  With a population of around 9.4 million in the city as of  , and 16.8 million in the metropolitan area, Tehran is the   in Iran and  ,  the   in the   after  , and the 24th most populous metropolitan area in the world.   includes several municipalities, including,  ,  ,  ,  ,  , and  .\n In the  , part of the territory of  present-day Tehran was occupied by Rhages (now  ), a prominent   city  almost entirely destroyed in the medieval  ,  , and   invasions. Modern Ray was absorbed into the metropolitan area of Greater Tehran.\n Tehran was first chosen as the capital of Iran by   of the   in 1786, because of its proximity to Iran's territories in the  , then separated from Iran in the  , to avoid the vying factions of the previously ruling Iranian dynasties. The capital has been moved several times throughout history, however, and Tehran became the 32nd  . Large-scale construction works began in the 1920s, and Tehran became a destination for mass migrations from all over Iran since the 20th century. \n Tehran is home to many historical sites, including the royal complexes of  ,  , and  , where the last two dynasties of the former   were seated. Tehran's landmarks include the  , a memorial built under the reign of   of the   in 1971 to mark the  , the  , the world's  , completed in 2007, another famous landmark in Tehran is the  , completed in 2014. \n Most of the population are  ,  with roughly 99% of them speaking the  , alongside   in the city which became Persianized and assimilated. \n Tehran is served by  , alongside the domestic  ,  ,  , a   system,  , and  .\n Plans to relocate the capital from Tehran to another area due to   and earthquakes have not been approved so far. A 2016 survey of 230 cities across the globe by   ranked Tehran 203rd for  .  According to the   in 2016, Tehran is among the top ten fastest  .  In 2016, the Tehran City Council declared 6 October to be Tehran Day, celebrating the date in 1907 when the city officially became the capital of Iran. \n Various theories on the origin of the name Tehran have been put forward.\n Iranian linguist  , in an article \"Shemiran-Tehran\", suggested that Tehran and Kehran mean \"the warm place\", and \"Shemiran\" means \"the cool place\". He listed cities with the same base and suffix and studied the components of the word in ancient  , and came to the conclusion that Tehran and Kehran meant the same thing in different Iranian language families, as the constant \"t\" and \"k\" are close to each other in such languages. He also provided evidence that cities named \"Shemiran\" were colder than those named \"Tehran\" or \"Kehran\". He considered other theories not considering the ancient history of Iranian languages such as \"Tirgan\" theory and \"Tahran\" theory  . \n Another theory is that \"Tehran\" derives from Tiran/Tirgan, \"the abode of  \", the   equivalent of  ). The ancient   town of Tiran had a neighbour,   (\"abode of Mehr/Mithra\", the Zoroastrian sun/justice angel). Both of these were mere villages in the suburbs of the great city of Ray/Rhages. Mehran still exists as a residential district in Greater Tehran, as well as Ray, which forms the southern suburbs of Tehran.  \n The official City of Tehran website says that \"Tehran\" comes from the Persian words \"Tah\" meaning \"end\", or \"bottom\", and \"Ran\" meaning \"[mountain] slope\"—literally, the bottom of the mountain (ته کوه), referring to Tehran's position at the foot of the   mountains. \n In English, it is also spelt \" \",  with both variants being used in books since at least 1800, and \"Teheran\" being the dominant form from after WWII until shortly before the Islamic Revolution. \n Archaeological remains from the ancient city of Ray suggest that settlement in Tehran dates back over 6,000 years. \n Tehran is in the historical   region of ( :    ) in northwestern Iran. By the time of the  , part of present-day Tehran was a suburb of the prominent Median city of Rhages ( :    ). In the  's   (i, 15), Rhages is mentioned as the 12th sacred place created by  .  In   inscriptions, Rhages appears as a province (  2, 10–18). From Rhages,   sent reinforcements to his father  , who was putting down a rebellion in   (Bistun 3, 1–10).  Some   texts give Rhages as the birthplace of  ,  although modern historians generally place the birth of Zoroaster in  .\n , the highest peak of Iran, which is located near Tehran, is an important location in  's  ,  an Iranian   based on the  . It appears in the epics as the homeland of the    , the birthplace of King  , the place where King   bound the dragon fiend   (Bivarasp), and the place where   shot his arrow. \n In 641, during the reign of the  ,   issued his last appeal to the nation from Rhages, before fleeing to Khorasan.  Rhages was dominated by the    , and  —the son of  , the son of  —who resisted the seventh-century  .  Because of this resistance, when the Arabs captured Rhages, they ordered the town destroyed and rebuilt anew by traitor aristocrat  . \n In the ninth century, Tehran was a well-known village, but less so than the city of Rhages, flourishing nearby. Rhages was described in detail by tenth-century Muslim geographers.  Despite the interest that Arabian   displayed in Rhages, the number of Arabs in the city remained insignificant and the population mainly consisted of Iranians of all classes. \n The   invaded Rhages in 1035, and again in 1042, but the city was recovered under the   and the  .  Medieval writer   declared the population of Rhages about 500,000 before the  . In the 13th century, the   invaded Rhages, laid the city to ruins, and massacred many of its inhabitants.  Others escaped to Tehran.\n In July 1404,   ambassador   visited Tehran on a journey to  , the capital of Turco-Mongol conqueror  , the ruler of Iran at the time. He described it in his diary as an unwalled region.\n Italian traveler   passed through Tehran overnight in 1618, and in his memoirs called the city  . English traveler   entered Tehran in 1627, and mentioned it as  . Herbert stated that the city had about 3,000 houses. \n In the early 18th century,   of the   ordered a palace and a government office built in Tehran, possibly to declare the city his capital; but he later moved his government to  . Eventually, Qajar king   chose Tehran as the capital of Iran in 1786. \n Agha Mohammad Khan's choice of his capital was based on a similar concern for the control of both northern and southern Iran.  He was aware of the loyalties of the inhabitants of former capitals   and Shiraz to the   and Zand dynasties respectively, and was wary of the power of the local notables in these cities.  Thus, he probably viewed Tehran's lack of a substantial urban structure as a blessing, because it minimized the chances of resistance to his rule by the notables and by the general public.  Moreover, he had to remain within close reach of   and Iran's integral   and    —at that time not yet irrevocably lost per the treaties of   and   to the neighboring  —which would follow in the course of the 19th century. \n After 50 years of Qajar rule, the city still barely had more than 80,000 inhabitants.  Up until the 1870s, Tehran consisted of a walled citadel, a roofed  , and the three main neighborhoods of  , Chale-Meydan, and Sangelaj, where the majority resided.\n During the long reign of   (1848-1896), Tehran witnessed Iran's first  ,  ,   and museum.   The city expanded rapidly through multiple development plans  The first development plan of Tehran in 1855 emphasized traditional spatial structure. The second, under the supervision of   in 1878, included new city walls, in the form of a perfect octagon with an area of 19 square kilometers, mimicking the   cities of Europe.  Tehran was 19.79 square kilometers, and had expanded more than fourfold. \n Growing awareness of civil rights resulted in the   and the   in 1906. On June 2, 1907, the parliament passed a law on local governance known as the   ( ), providing a detailed outline of issues such as the role of councils within the city, the members' qualifications, the election process, and the requirements to be entitled to vote. The then-Qajar monarch   abolished the constitution and   the parliament with the help of the Russian-controlled   on June 23, 1908. That was followed by the capture of the city by the revolutionary forces of   (Sardar Asad II) and   (Sepahsalar e Tonekaboni) on July 13, 1909. As a result, the monarch was exiled and replaced by his son  , and the parliament was re-established.\n During the  , Russian forces that were occupying the northwest of Iran marched around   and approached Tehran, caused a crisis and the dissolution of  .   and his entourage decided to leave Tehran and move the capital to another place, sparking fears of rebellion in other cities. \n During the  , Iranian forces led by Heydar Latifiyan prevented the Russians from taking Tehran, despite the latter winning the battle.  This also allowed government functions to be moved to Qom and then to Isfahan, while the monarchy remained in Tehran. \n After  , the   elected   of the   as the new monarch, who immediately suspended the Baladie law of 1907, replacing the decentralized and autonomous city councils with centralist approaches to   and planning. \n From the 1920s to the 1930s, under the rule of Reza Shah, the city was essentially rebuilt from scratch. Several old buildings, including parts of the  ,  , and  , were replaced with modern buildings influenced by classical Iranian architecture, particularly the buildings of the  , the police headquarters, the telegraph office, and the military academy.\n Changes to the urban fabric began with the street-widening act of 1933, which served as a framework for changes in all other cities. The   was divided in half and many historic buildings were demolished and replaced by wide straight avenues,  and the traditional texture of the city was replaced with intersecting cruciform streets that created large roundabouts in major public spaces such as the bazaar.\n As an attempt to create a network for easy transportation within the city, the old citadel and city walls were demolished in 1937, replaced by wide streets cutting through the urban fabric. The new city map of Tehran in 1937 was heavily influenced by modernist planning patterns of zoning and gridiron networks. \n During  , Soviet and British troops entered the city. In 1943, Tehran was the site of the  , attended by U.S. President  , Soviet Premier  , and British Prime Minister  .\n The establishment of the planning organization of Iran in 1948 resulted in the first socioeconomic development plan to cover from 1949 to 1955. These plans not only failed to slow the unbalanced growth of Tehran but with the 1962 land reforms that Reza Shah's son and successor   named the  , Tehran's chaotic growth was further accentuated.\n Throughout the 1960s and 1970s, Tehran developed rapidly under Mohammad Reza Shah. Modern buildings altered the face of Tehran and ambitious projects were planned for the following decades. To resolve the problem of  , the first comprehensive plan was approved in 1968. The consortium of Iranian architect   and the American firm of   identified the main problems blighting the city as high-density suburbs, air and water pollution, inefficient infrastructure, unemployment, and rural-urban migration. Eventually, the whole plan was marginalized by the   and the subsequent  . \n Tehran's most famous landmark, the Azadi Tower, was built by the order of the Shah in 1971. It was designed by  , an architect whose design won a competition, combining elements of classical   with post-classical Iranian architecture. Formerly known as the  , it was built to commemorate the  .\n During the   in 1980 to 1988, Tehran was repeatedly targeted by airstrikes and   missile attacks.\n The 435-meter-high Milad Tower, one of the proposed development projects of pre-revolutionary Iran,  was completed in 2007, and has become a famous landmark of Tehran. Tabiat Bridge, a 270-meter   that was designed by award-winning architect  , was completed in 2014.\n The city of Tehran had a population of 7,711,230 in 2,286,787 households at the time of the 2006 National Census.  The following census in 2011 counted 8,154,051 people in 2,624,511 households.  The 2016 census measured the population of the city as 8,693,706 people in 2,911,065 households. \n With its cosmopolitan atmosphere, Tehran is home to diverse ethnic and linguistic groups from all over the country. The present-day dominant language of Tehran is the   of the  , and the majority of people in Tehran identify themselves as  .  However, before, the native language of the Tehran–Ray region was not Persian, which is linguistically Southwest Iranian and originates in  , but a now extinct  . \n  form the second-largest ethnic group of the city, comprising about 10-15%   of the total population, while ethnic   are the third-largest, comprising about 5% of the total population.  Tehran's other ethnic communities include  ,  ,  ,  ,  ,  ,  ,  ,  , and  .\n According to a 2010 census conducted by the Sociology Department of the  , in many districts of Tehran across various socio-economic classes in proportion to population sizes of each district and socio-economic class, 63% of the people were born in Tehran, 98% knew Persian, 75% identified themselves as ethnic Persian, and 13% had some degree of proficiency in a European language. \n Tehran saw a drastic change in its ethnic-social composition in the early 1980s. After the political, social, and economic consequences of the   and the years that followed, a number of Iranian citizens, mostly Tehranis, left Iran. The majority of   have left for the  ,  ,  , and  .\n With the start of the   (1980–1988), the second wave of inhabitants fled the city, especially during the Iraqi air offensives on the capital. With most major powers backing Iraq at the time, economic isolation gave yet more reason for many inhabitants to leave the city (and the country). Having left all they had and having struggled to adapt to a new country and build a life, most of them never came back when the war was over. During the war, Tehran also received a great number of migrants from the west and the southwest of the country bordering  .\n The unstable situation and the war in neighbouring   and Iraq prompted a rush of refugees into the country who arrived in millions, with Tehran being a magnet for many seeking work, who subsequently helped the city to recover from war wounds, working for a far lower pay than local construction workers. Many of these refugees are being repatriated with the assistance of the  , but there are still sizable groups of Afghan and Iraqi refugees in Tehran who are reluctant to leave, being pessimistic about the situation in their own countries. Afghan refugees are mostly  -speaking   and  , speaking a variety of Persian, and Iraqi refugees are mainly  -speakers who are often of Iranian and Persian ethnic heritage.\n The majority of Tehranis are officially    , which has also been the state religion since the 16th-century  . Other religious communities in the city include followers of the   and   branches of Islam, various   denominations,  ,  , and the  .\n In the 2016 \"Tehran Survey\", when residents of Tehran were asked about the importance of religion in their life, 53.5% considered it to be \"very important / important\", 31.1% to be \"rather important\", 10.5% to be \"not very important\" and 4.8% to be \"not at all important.\" \n There are many religious centres scattered around the city, from old to newly built centres, including  ,  ,  , and  . The city also has a very small third-generation Indian   community with a local   that was visited by the  ,   in 2012. \n The metropolis of Tehran is divided into 22 municipal districts, each with its own administrative center. Of the 22 municipal districts, 20 are located in  's  , while districts   and   are respectively located in the counties of   and  .\n : \n \n • Farmaniyeh \n • Evin \n • Darakeh \n • Zaferaniyeh \n • Mahmoodiyeh \n • Velenjak \n • Darband \n • Golabdarreh \n • Jamaran \n • Dezashib \n • Niavaran \n • Darabad \n • Tajrish \n • Gheytariyeh \n • Chizar \n • Ozgol \n • Aghdasiyeh \n • Elahieh \n • Jamshidiyeh \n • Saadabad \n • Kamraniyeh \n \n • Farahzad \n • Shahrara \n • Gisha \n • Punak-e    Bahtari \n • Saadat Abad \n • Sadeghieh \n • Shahrak-e Gharb \n • Tarasht \n • Tohid \n \n • Darus \n • Davoodiyeh \n • Ekhtiariyeh \n • Golhak \n • Vanak \n • Jordan \n \n • Bolvar-e    Ferdowsi \n • Jannat Abad \n • Ekbatan \n • Punak \n \n • Amir Abad \n • Arjantin \n • Yousef Abad \n • Park-e Laleh \n : \n \n • Khak Sefid \n • Hakimiyeh \n • Lavizan \n • Ozgol \n • Pasdaran \n • Resalat \n • Shams Abad \n • Shemiran-e-No \n • Tehranpars \n • Zargande \n • Narmak \n \n • Abbas Abad \n • Behjat    Abad \n • Emam    Hossein \n • Sabalan \n \n • Mo'allem \n • Narmak \n • Samangan \n • Nezam Abad \n \n • Dowshan Tappe \n • Niru Havaii \n • Tehran-e-No \n • Piroozi \n \n • Chaharsad    Dastgah \n • Dulab \n • Esfahanak \n • Khorasan \n • Sad Dastgah \n : \n \n • Beryanak \n • Haft Chenar \n • Salsabil \n \n • Dokhaniyat \n • Lashkar \n • Moniriyeh \n • Sheikh Hadi \n \n • Baharestan \n • Bazar-e Tehran \n • Ferdowsi \n • Gorgan \n • Park-e Shahrr \n • Pich-e Shemiran \n \n • Emamzade    Hasan \n • Bagh Khazaneh \n • Qal'e Morghi \n : \n \n • Afsariyeh \n • Bisim \n • Khavaran \n • Kiyanshahr \n • Masoudiyeh \n • Moshiriyeh \n \n • Ali Abad \n • Bagh-e Azari \n • Khazane \n • Yakhchi Abad \n • Javadiyeh \n • Nazi Abad \n \n • Abdol Abad \n • Khani Abad No \n • Nemat Abad \n \n • Dolat Abad \n • Javanmard-e    Ghassab \n • Ebn    Babviyeh \n • Hazrat-e    Abdol-Azim \n • Sizdah-e    Aban \n • Rey \n : \n \n • Jey \n • Sar-Asyab \n • Mehr Abad \n \n • Khalije Fars \n • Yaft Abad \n • Shad Abad \n • Shahrak-e    Vali-Asr \n • Tolid Daru \n • Ferdows \n \n • Shahrak-e-Darya \n • Bashgah-e    Naft \n • Tehransar \n • Shahrak-e-Pasdaran \n • Shahrak-e-Azadi \n • Vardavard \n \n • Bagh-e    Haj-Seif \n • Kan \n • Kuy-e    Sazman-e    Barname \n • Park Chitgar \n • Peykanshahr \n • Stadium-e    Azadi \n • Shahrak-e    Cheshmeh \n • Shahrak-e    Rah-Ahan \n • Shahrak-e    Omid\n • Shahid Baqeri \n • Dehkade-ye-Olympic \n • Daryache Chitgar \n • Golestan \n Northern Tehran is the wealthiest part of the city,  consisting of various districts such as  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , Ozgol and  .  While the center of the city houses government ministries and headquarters, commercial centers are located further north.\n Most of Tehran has a  , according to the   (  (hot semi-arid) in the region of the  , and   (cold semi-arid) in higher areas), with a borderline   ( ) in the northern area of the city, with hot, dry summers and cool, rainy winters. Tehran's climate is largely defined by its geographic location, with the towering   mountains to its north and the country's central desert to the south.\n As the city has a large area, with significant differences in elevation among various districts, the weather is often cooler in the hilly north than in the flat southern part of Tehran. For instance, the 17.3 km (10.7 mi)   runs from Tehran's railway station at 1,117 m (3,665 ft) elevation above sea level in the south of the city to   at 1712.6 m (5612.3 ft) elevation above sea level in the north.  However, the elevation can even rise up to 2,000 m (6,600 ft) at the end of   in northern Tehran. The sparse texture, the existence of old gardens, orchards, green spaces along the highways and the lack of industrial activities in the north of the city have helped the air in the northern areas to be 2 to 3 degrees Celsius cooler than the southern areas of the city. \n The main direction of the prevailing wind in Tehran is northwest to southeast.  Other air currents that blow in the area of Tehran are:\n Air currents have a great effect on Tehran's weather. The prevailing wind blowing from the west causes the west of the city to always be exposed to fresh air; Although this wind brings smoke and pollution from the western industrial areas, its strong wind can take the polluted air out of the city of Tehran. \n In most years, winter provides half of Tehran's total annual rainfall. March is the rainiest month of the year and about one-fifth of the annual rainfall occurs in it. Summer is also the least rainy season and September is the driest month of the year in Tehran. The average annual rainfall of the city is sometimes very different in the north and south regions.  There are between 205 and 213 days of clear to partly cloudy weather in Tehran. \n One of the most intense rains in Tehran happened on April 21, 1962 and this rain lasted for 10 hours. Meteorology also announced that the amount of rainfall on that one day in Tehran was equivalent to six years. \n Summer is hot and dry with little rain, but   is generally low, making the heat tolerable. Average high temperatures are between 31 °C (88 °F) and 38 °C (100 °F) during  , and it can sometimes rise up to 40 °C (104 °F) during  . Average low temperatures in summer are between 18 °C (64 °F) and 25 °C (77 °F), and it can occasionally drop to below 14 °C (57 °F)  in the mountainous north of the city at night.\n Winter is cold and occasionally snowy, with an average of 12.3 snow days annually in central Tehran and more than 23.7 snow days annually in northern Tehran. During the  , average high temperatures are between 3 °C (37 °F) and 11 °C (52 °F) and average low temperatures are between −5 °C (23 °F) and 1 °C (34 °F), and it can occasionally drop to below −10 °C (14 °F)  during  .\n Most of the annual   occurs from late autumn to mid-spring. March is the wettest month with an average precipitation of 39.6 millimetres (1.56 in). The hottest month is July, with a mean minimum temperature of 24 °C (75 °F) and a mean maximum temperature of 36.7 °C (98.1 °F), and the coldest is January, with a mean minimum temperature of −0.4 °C (31.3 °F) and a mean maximum temperature of 7.9 °C (46.2 °F). \n The highest recorded temperature was 43 °C (109 °F) on 3 July 1958 and the lowest recorded temperature was −15 °C (5 °F) on 8 January 1969. \n In February 2005, heavy snow covered all parts of the city. Snow depth was recorded as 15 cm (6 in) in the southern part of the city and 100 cm (39 in) in the northern part of city. One newspaper reported that it had been the worst weather in 34 years. Ten thousand bulldozers and 13,000 municipal workers were deployed to keep the main roads open. \n On January 5 and 6, 2008, a   covered the city in a thick layer of snow and ice, forcing the Council of Ministers to officially declare a   and close down the capital from January 6 through January 7. \n On February 3, 2014, Tehran received heavy snowfall, specifically in the northern parts of the city, with a depth of 2 metres (6.6 ft). In one week of successive snowfalls, roads were made impassable in some areas, with the temperature ranging from −8 °C (18 °F)  to  −16 °C (3 °F). \n On June 3, 2014, a severe thunderstorm with powerful   created a  , engulfing the city in sand and dust and causing five deaths, with more than 57 injured. This event also knocked down numerous trees and power lines. It struck between 5:00 and 6:00 p.m., dropping temperatures from 33 °C (91 °F)  to 19 °C (66 °F)  within an hour. The dramatic temperature drop was accompanied by wind gusts reaching nearly 118 kilometres per hour (73 mph) . \n A plan to move the capital has been discussed many times in prior years, due mainly to the environmental issues of the region. Tehran is one of the world's most polluted cities and is also located near two major  .\n The city suffers from severe air pollution, 80% of it due to cars.  The remaining 20% is due to  . Other estimates suggest that motorcycles alone account for 30% of air and 50% of   in Tehran.  Tehran is also considered one of the strongest sources of greenhouse gas emissions in the Middle East. Enhanced concentration of carbon dioxide over the city (that are likely originated from the anthropogenic urban sources in the city) is easily detectable from satellite observations throughout the year. \n In 2010, the government announced that \"for security and administrative reasons, the plan to move the capital from Tehran has been finalized.\"  There are plans to relocate 163 state firms and several   from Tehran to avoid damages from a potential  . \n The officials are engaged in a battle to reduce air pollution. It has, for instance, encouraged taxis and buses to convert from petrol engines to engines that run on  . Furthermore, the government has set up a \"Traffic Zone\" covering the city centre during peak traffic hours. Entering and driving inside this zone is only allowed with a special permit.\n There have also been plans to raise people's awareness of the hazards of pollution. One method that is being employed is the installation of Pollution Indicator Boards all around the city to monitor the level of   (PM2.5/PM10),   (NO ), ozone (O ),   (SO ), and   (CO).\n Tehran is the economic centre of Iran.  About 30% of Iran's public-sector workforce and 45% of its large industrial firms are located in the city, and almost half of these workers are employed by the government.  Most of the remainder of workers are factory workers, shopkeepers, laborers, and transport workers.\n Few foreign companies operate in Tehran, due to the government's complex international relations. But prior to the  , many foreign companies were active in Iran.  Tehran's present-day modern industries include the manufacturing of automobiles, electronics and electrical equipment, weaponry, textiles, sugar, cement, and chemical products. It is also a leading centre for the sale of carpets and furniture. The oil refining companies of  ,  , and   are based in Tehran.\n Tehran relies heavily on private cars, buses, motorcycles, and taxis, and is one of the most car-dependent cities in the world. The  , which is a full member of the   (WFE) and a founding member of the  , has been one of the world's best-performing stock exchanges in recent years. \n Design, manufacturing, distribution, marketing, retail, advertising and other sectors of the   have been able to grow significantly according to the needs of the country. In particular, a large number of male and female models are working in Tehran's fashion advertising and promotion sections. Despite the lack of adequate laws to support models, payments to female models have been considered high. Also, modeling of children is usually prohibited in Tehran. Clothing manufacturers are closely related to other fashion sectors in Tehran. For example, the manufacturers of women's boots and bodysuits have strengthened their exports and branding in other countries by using this connection. \n Tehran has a wide range of shopping centers, and is home to over 60 modern shopping malls.  The city has a number of  , including those located at  ,  , and  . The largest old   of Tehran are the   and the  .   is the largest mall in the world in area. \n Most of the international branded stores and upper-class shops are in the northern and western parts of the city. Tehran's retail business is growing with several newly built malls and shopping centres. \n Tehran is a center for the production of women's clothing in Iran. Shoe (Mostly women's boots) manufacturing companies in Tehran can be reached in the malls. \n Tehran, as one of the main tourist destinations in Iran, has a wealth of cultural attractions. It is home to royal complexes of  ,   and  , which were built under the reign of the country's last two monarchies.\n There are several historic, artistic, and scientific museums in Tehran, including the\n Also the  , which hosts works of famous artists such as  ,  , and  . The  , one of the largest jewel collections in the world, are also on display at Tehran's National Jewelry Museum.\n A number of cultural and trade exhibitions take place in Tehran, which are mainly operated by the country's  . Tehran's annual   is known to the international publishing world as one of the most important publishing events in Asia. \n Following the   in 1979, the political system changed from   to  . Then the construction of political power in the country needed to change so that new spectrums of political power decision-making centers emerged in Iran. Motives, desires and actions of these new political power decision-making centers in Iran, made them rename streets and public places throughout the country, especially Tehran. For example Shahyad square changed to   and Pahlavi street changed to  . \n The metropolis of Tehran is equipped with a large network of highways and interchanges.\n According to the head of Tehran Municipality's Environment and Sustainable Development Office, Tehran was designed to have a capacity of about 300,000 cars, but more than five million cars are on the roads.  The automotive industry has recently developed, but international sanctions influence the production processes periodically. \n According to local media, Tehran has more than 200,000 taxis plying the roads daily,  with several types of taxi available in the city. Airport taxis have a higher cost per kilometer as opposed to regular green and yellow taxis in the city.\n Buses have served the city since the 1920s. Tehran's transport system includes conventional buses,  , and   (BRT). The city's four major bus stations include the South Terminal, the East Terminal, the West Terminal, and the northcentral Beyhaghi Terminal.\n The trolleybus system was opened in 1992, using a fleet of 65   trolleybuses built by  's  .  This was the first trolleybus system in Iran.  In 2005, trolleybuses were operating on five routes, all starting at  .  Two routes running northeastwards operated almost entirely in a segregated   located in the middle of the wide   along  , stopping only at purpose-built stops located about every 500 metres along the routes, effectively making these routes trolleybus-BRT (but they were not called such). The other three trolleybus routes ran south and operated in mixed traffic. Both route sections were served by   services and local (making all stops) services.  A 3.2-kilometer extension from Shoosh Square to Rah Ahan Square was opened in March 2010.  Visitors in 2014 found that the trolleybus system had closed, apparently sometime in 2013.  However, it reopened in March 2016, operating on a single 1.8-km route between Meydan-e-Khorasan (Khorasan Square) and Bozorgrah-e-Be'sat.   Around 30 vehicles had been refurbished and returned to service.  Extensions were planned. \n  (BRT) was officially inaugurated in 2008. It has 10 lines with some 215 stations in different areas of the city. As of 2011 , the BRT system had a network of 100 kilometres (62 miles), transporting 1.8 million passengers on a daily basis.\n Tehran has a   that connects services round the clock to various cities in the country, along with a Tehran–Europe train line also running.\n The feasibility study and conceptual planning of the construction of Tehran's subway system were started in the 1970s. The first two of the eight projected metro lines were opened in 2001.\n Tehran is served by the international airports of   and  . Mehrabad Airport, an old airport in western Tehran that doubles as a military base, is mainly used for domestic and charter flights. Imam Khomeini Airport, located 50 kilometres (31 miles) south of the city, handles the main international flights.\n There are over 2,100 parks within the metropolis of Tehran,  with one of the oldest being  , which was first established as a private garden for Qajar prince Jamshid Davallu, and was then dedicated to the last empress of Iran,  . The total green space within Tehran stretches over 12,600 hectares, covering over 20 percent of the city's area. The Parks and Green Spaces Organization of Tehran was established in 1960, and is responsible for the protection of the urban nature present in the city. \n Tehran's Birds Garden is the largest bird park in Iran. There is also   located on the Tehran–Karaj Expressway, housing over 290 species within an area of about five hectares. \n In 2009, the   (\"Water and Fire park\") was founded. Its main features are an open   area for cooling in the hot climate,  , and an  . \n Fresh water resources of Tehran Province in 2017\n  with its population of more than 13 million is supplied by surface water from the   on the   in the Northeast of the city, the   on the   in the North, the   in the Northwest, as well as by groundwater in the vicinity of the city.\n Solar panels have been installed in Tehran's   for green electricity production, said  , head of the Department of Environment.\n According to the national energy roadmap, the government plans to promote green technology to increase the nominal capacity of power plants from 74 gigawatts to over 120 gigawatts by the end of 2025. \n Tehran is the largest and most important educational center in Iran. There are a total of nearly 50 major colleges and universities in Greater Tehran.\n Since the establishment of   by the order of   in the mid-19th century, Tehran has amassed a large number of institutions of higher education. Some of these institutions have played crucial roles in the unfolding of Iranian political events.  , whom Jordan Avenue in Tehran was named after, was one of the founding pioneers of the  , which was one of the first modern high schools in the Middle East.\n Among major educational institutions located in Tehran,   (Tehran Polytechnic),  ,  , and   are the most prestigious. Other major universities located in Tehran include  ,  ,  ,   (Melli University),  ,  ,  ,  ,  , Iran's Polymer and Petrochemical Institute,  , and  .  ,  ,   and   also located in Tehran are nationally well known for taking in the top undergraduate Engineering and Science students; and internationally recognized for training competent under graduate students. It has probably the highest percentage of graduates who seek higher education abroad.\n Tehran is also home to Iran's largest military academy, and several religious schools and seminaries.\n The   concerns the arts, music, museums, festivals, many   and sports activities in Tehran, the capital city of Iran.   are held in Tehran along with regional and western festivals.  ,  ,  ,  ,   and   have been popular festivals in recent decades. \n The oldest surviving architectural monuments of Tehran are from the   and   eras. In Greater Tehran, monuments dating back to the   era remain as well; notably the   in Ray.  , dating back to the ancient  , of which some artifacts are housed at the  ;  and the  , which remains since the  .\n Tehran only had a small population until the late 18th century but began to take a more considerable role in Iranian society after it was chosen as the capital city. Despite the regular occurrence of earthquakes during the Qajar period and after, some historic buildings remain from that era. \n Tehran is Iran's  , and is considered to have the most modernized infrastructure in the country. However, the   of old neighbourhoods and the demolition of buildings of cultural significance have caused concerns. \n Previously a low-rise city due to seismic activity in the region, modern high-rise developments in Tehran have been built in recent decades in order to service its growing population. There have been no major quakes in Tehran since 1830. \n  is the tallest skyscraper in Iran. It is 54-stories tall and located in the northern district of  .\n The  , a memorial built under the reign of the  , has long been the most famous symbol of Tehran. Originally constructed in commemoration of the  , it combines elements of the architecture of the   and   eras with post-classical  . The  , which is the   and the   in the world,  is the city's other famous landmark tower.  's  , the largest pedestrian overpass in Tehran, was completed in 2014 and is also considered a landmark. \n The city has produced many notable Iranian design houses and clothing companies. Fashion events are also held in some areas of the city.  Many famous Iranian models were born in Tehran, including  ,  ,  , Elnaaz Norouzi,   and  .\n Women of Tehran widely used over-the-knee and leather boots after 2000s. \n Under the reign of the  , Tehran was home to the royal theatre of  , located to the southeast of the  , in which traditional and religious performances were observed. It was eventually demolished and replaced with a bank building in 1947, following the reforms during the reign of  .\n Before the 1979 Revolution, the Iranian national stage had become the most famous performing scene for known international artists and troupes in the Middle East,  with the Vahdat Hall, formerly known as Rudaki Hall, constructed to function as the national stage for opera and ballet. The hall was inaugurated in October 1967 and named after prominent Persian poet  . It is home to the  , the Tehran Opera Orchestra, and the  .\n The  , one of Iran's biggest theatre complexes, which contains several performance halls, was opened in 1972. It was built at the initiative and presidency of empress  , and was designed by architect Ali Sardar Afkhami, constructed within five years.\n One of the gathering centers of   in old Tehran was  . Famous Persian cabarets were active in the city until 1979. They also introduced many domestic artists. In common language, cabaret was sometimes called \"home of dance\" or \"dancing place\". \n The annual events of   and   take place in Tehran.\n The first movie theater in Tehran was established by   in 1904.  Until the early 1930s, there were 15 theaters in Tehran Province and 11 in other provinces. \n In present-day Tehran, most of the movie theatres are located downtown. The complexes of  ,  ,  , and   are among the most popular cinema complexes in Tehran.\n Several film festivals are held in Tehran, including  ,  , House of Cinema Festival, Mobile Film and Photo Festival, Nahal Festival,  , Tehran Animation Festival, Tehran Short Film Festival, and Urban Film Festival.\n There are a variety of concert halls in Tehran. An organization like the Roudaki Culture and Art Foundation has five different venues where more than 500 concerts take place this year.  ,  , Ferdowsi Hall, Hafez Hall and Azadi Theater are the top five venues in Tehran, where classical, pop, traditional, rock or solo concerts take place. \n  were active and trained in Tehran until the 1979 revolution. But after this date, due to the policies of the new government, these activities were completely banned. \n Football and volleyball are the city's most popular sports, while wrestling, basketball, and futsal are also major parts of the city's sporting culture. Ice hockey and rugby are also popular in Tehran.\n  operate in Iran, the most famous being  ,  , and  , all within one to three hours from the city of Tehran.\n 's resort is the world's fifth-highest ski resort at over 3,730 meters (12,240 feet) above sea level at its highest point. It is also the world's nearest ski resort to a capital city. The resort was opened in 1976, shortly before the 1979 Revolution. It is equipped with an 8-kilometre-long (5 mi) gondola lift that covers a huge vertical distance.  There are two parallel chair ski lifts in Tochal that reach 3,900 meters (12,800 feet) high near Tochal's peak (at 4,000 m/13,000 ft), rising higher than the gondola's seventh station, which is higher than any of the European ski resorts. From the Tochal peak, there are views of the   range, including the 5,610-metre-high (18,406 ft)  , a dormant volcano.\n \nTehran is the site of the  , the   in West Asia, where many of the top matches of Iran's Premier League are held. The stadium is a part of the  , which was originally built to host the   in September 1974. This was the first time the Asian Games were hosted in West Asia. Tehran played host to 3,010 athletes from 25 countries/NOCs, which was at the time the highest number of participants since the inception of the Games.  That followed hosting the   in June 1976, and then the first   in November 1997. The success of the games led to the creation of the   (WAGF), and the intention of hosting the games every two years.  The city had also hosted the final of the  . Several   courses have also been hosted in Tehran. There are many restaurants and cafes in Tehran, both modern and classic, serving both Iranian and cosmopolitan cuisine. Pizzerias,  , and   make up the majority of food shops in Tehran. \n Many styles of graffiti are seen in Tehran. Some are political and revolutionary slogans painted by governmental organizations,  and some are works of art by ordinary citizens, representing their views on both social and political issues. However, unsanctioned street art is forbidden in Iran,  and such works are usually short-lived.\n During the  , many graffiti works were created by people supporting the  . They were removed from the walls by the paramilitary   forces. \n In recent years, Tehran Municipality has been using graffiti in order to beautify the city. Several graffiti festivals have also taken place in Tehran, including the one organized by the   in October 2014. \n Tehran is   with: \n Tehran cooperates with:\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_environmental_degrees", "title": "List of environmental degrees", "content": "\n This is a  , including for such Various disciplinary fields as  ,  ,  ,  ,  ,  ,   and  , etc., at both undergraduate and graduate levels.\n  \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/University_of_Oklahoma", "title": "University of Oklahoma", "content": "\n The   ( ) is a     in  , United States. Founded in 1890, it had existed in   near   for 17 years before the two territories became the state of Oklahoma. In Fall 2023, the university had 32,676 students enrolled,  most at its main campus in Norman. Employing nearly 4,000 faculty members,  the university offers 174   programs, 199   programs, 101   programs, and 88 certificate programs. \n The university is   among \"R1: Doctoral Universities – Very high research activity\",  with over $416 million in research expenditures across its three campuses in 2022.  Its Norman campus has two prominent museums, the  , specializing in French   and   artwork, and the  , specializing in the natural history of Oklahoma.\n The University of Oklahoma has won 44 team national championships, ranking the Sooners 13th all-time in NCAA team titles. OU also ranks 7th all-time in the number of NCAA Academic All-Americans with 215 athletes. The   has won the national championship eight times: in 2000, 2013, and consecutively in 2016 and 2017 and in 2021, 2022, 2023, and 2024. The   teams have won a combined 18 national championships, with the   winning eight in the last 15 years, including three consecutive titles from 2015 to 2017.\n Beginning with the   in  , Sooners have made 90 appearances at the Olympics and collected 23 medals in total. \n With the support of    , on December 18, 1890, the   legislature established three universities: the state university in Norman, the agricultural and mechanical college in   (later renamed  ) and a   in   (later renamed  ).  Oklahoma's admission into the union in 1907 led to the renaming of the   as the University of Oklahoma. Norman residents donated 407 acres (1.6 km ) of land for the university 0.5 miles (0.8 km) south of the Norman railroad depot. The university's first president ordered the planting of trees before the construction of the first campus building because he \"could not visualize a treeless university seat.\"  Landscaping remains important to the university. \n The university's first president,  , arrived in Norman in August 1892, and the first students enrolled that year. The university established a School of Pharmacy in 1893 because of the territory's high demand for pharmacists. Three years later, the university awarded its first degree to a pharmaceutical chemist.  The \"Rock Building\" in downtown Norman held the initial classes until the university's first building opened on September 6, 1893. \n On January 6, 1903, the university's only building burned down and destroyed many records of the early university. Construction began immediately on a new building, as several other towns hoped to convince the university to move. President Boyd and the faculty were not dismayed by the loss. Mathematics professor Frederick Elder said, \"What do you need to keep classes going? Two yards of blackboard and a box of chalk.\"  As a response to the fire, English professor   created a plan for the development of the campus. Although much of the plan was never implemented, Parrington's suggestion for the campus core formed the basis for the North Oval. The North and South Ovals are now distinctive features of the campus.\n The campus has a distinctive architecture, with buildings designed in a unique \" \" style. The style has many features of the Gothic era but has also mixed the designs of local Native American tribes from Oklahoma. This term was coined by the renowned American architect Frank Lloyd Wright when he visited the campus.  The university has built over a dozen buildings in the Cherokee Gothic style.\n In 1907, Oklahoma entered statehood, fostering changes in the state's political atmosphere. Up until this point, Oklahoma's   tendencies changed with the election of Oklahoma's first  , the    . Since the university's inception, religion had divided those on campus. Early in the university's existence, many professors were  , as was Boyd. Under pressure, Boyd hired several   and Southern  .  The Presbyterians and Baptists coexisted but the Southern Methodists conflicted with the administration. Two notable Methodists, Nathaniel Lee Linebaugh and Ernest Taylor Bynum, were critics of Boyd and activists in Haskell's election campaign. When Haskell took office, he fired many of the university's Republicans, including President Boyd. \n The campus expanded over the next several decades. By 1932, the university encompassed 167 acres (0.7 km ). Development of South Oval allowed for the southern expansion of the campus. The university built a new library on the oval's north end in 1936. By convincing the Oklahoma legislature to increase their original pledge of $200,000 for the library to $500,000, President Bizzell ensured an even greater collection of research materials for students and faculty. \n Enrollment in 1945 dropped to 3,769, from its pre–World War II high of 6,935 in 1939. \n Many infrastructure changes have occurred at the university. The southern portion of south campus near Constitution Avenue, still known to long-time Norman residents as 'South Base', was originally built as an annex to Naval Air Station Norman. It contained mostly single-story frame buildings used for classrooms and military housing.  By the late 1980s, most were severely deteriorated and were demolished in the 1990s to make room for redevelopment. The Jimmie Austin University of Oklahoma Golf Course was built as a U.S. Navy recreational facility. \n During World War II, OU was one of 131 colleges and universities nationally that took part in the   which offered students a path to a Navy commission. \n The north campus and airfield were built in the early 1940s as Naval Air Station Norman. The station served mainly an advanced flight training mission and could handle all but the largest bombers.  A large earthen mound east of   and north of Robinson Street, colloquially known as 'Mount Williams',  was a gunnery (the mound has been removed to make way for a commercial development).  In the post–World War II  , the university received the installation. Naval aviator's wings displayed at the entrance to the terminal commemorates this airfield's Naval past.\n After the World War, the university enjoyed rapid growth and a surge in enrollment. By 1965, enrollment had risen over 450% to 17,268, causing housing shortages.  In the mid-1960s, three new 12-story dormitories were erected immediately south of the South Oval. In addition to these three towers, they built an apartment complex for married students, including men returning to college under the  . \n In 1943   took over as president of the university. He served until 1968, 25 years later.\n The   began a new era as the university began policies against racial discrimination and segregation after legal challenges and court cases outlawed discrimination. The   has been designated a U.S.   in commemoration of the cases of G. W. McLaurin, a black man denied admission to graduate school in 1948. A court case effectively forced the Board of Regents to vote to admit McLaurin, but he was directed to study in a separated area within the law library and to be allowed to lunch only in a segregated area. The National Association for Advancement of Colored People brought the case to the U.S. Supreme court in  . In 1950, the court overturned the university's policy for segregation at the graduate school level. The case was an important precedent for the more famous and sweeping 1954 case of   which disallowed \"separate but equal\" policy at all school levels. \n Since   became president in 1994, the University of Oklahoma system has experienced tremendous growth and purchased 60 acres (0.2 km ) for OU-Tulsa, the new Gaylord Hall, Price Hall, the ExxonMobil Lawrence G. Rawl Engineering Practice Facility, Devon Energy Hall, the Wagner Student Academic Services Center, the Research and Medical Clinic, the expansions of the Fred Jones Jr. Museum of Art,  and the  . \n In March 2015, the University of Oklahoma shut down the Oklahoma Kappa chapter of the   fraternity when a video surfaced that showed members   as they rode a bus.  University of Oklahoma president   gave members two days to leave the fraternity house. He also expelled two students who he said \"played a leadership role\" in the incident, creating \"a hostile learning environment for others\".  The expulsion, allegedly without due process, earned the university a spot on the  's 2016 \"10 Worst Colleges for Free Speech\". \n , a former   and  , served as the university's president from 1994 to 2018.   succeeded Boren on July 1, 2018, only to retire ten months later.    Dean   was appointed effective immediately May 16, 2019 to a 15-month term as interim president.  On May 9, 2020, Harroz was announced as the 15th president of the university by the Board of Regents. \n As of Fall of 2022, the Norman campus had 22,249   and 9,406  .  Following the Sooners' 2000 football national-championship season  the university experienced an increase in college applicants and admissions. The falls of 1999 and 2000 both saw a 1.3% increase in the number of students over the respective previous years, while fall 2001 saw an increase of 4.8% over 2000. \n The largest school,  , enrolls 35.2% of the OU-Norman students. The College of Arts & Sciences offers several programs, which include internships and most notably a joint archaeological program (with   of  ) in  , Italy.  The next largest school,   enrolls 13%. Other large colleges on the Norman campus include the   with 10.6% and the  ,  , and  , each with approximately 6% of the student body. \n Smaller schools include the Colleges of   and  ,  , the  , and the  .\n New students do not have to declare a   (a concentrated course of study) immediately and are not required to declare a major until their Junior year. If they are undecided in their major, they are considered a part of the  , composing approximately 8% of the student body. Many Pre-Health majors choose this option until they are able to apply for the medical program of their choice. \n The Norman campus has three sections: north campus, main campus, and south campus. All three are connected by a bus service funded by student fees which allows students to park at   and provides 5- to 10-minute service to the main and south campuses.  Other regular Norman bus routes provide service to north campus as well as the main campus. The main and south campus are contiguous while the north campus is about two miles north of the main campus.\n The Norman campus is the focus of a number of ghost stories, some negative, some positive. \n \nThe main campus is bordered by Boyd Street on the north, Timberdell Road on the south, Chautauqua Avenue on the west, and Jenkins Avenue on the east.  The Norman campus is centered on two large \"ovals.\" The Parrington Oval (or North Oval as it is commonly called) is anchored on the south by Evans Hall, the main administrative building. This building highlights the \"   \" style of architecture locally derived from the   style, the style that dominates and defines the older buildings on the OU campus. The North Oval is bordered on the east by the  .  \nOn the east side of the northernmost part of campus sits Sarkeys Energy Center while to the west is the Fred Jones, Jr. School of Art and  , home to the Weitzenhoffer Collection of   art  and the Catlett Music Center. Just south of Catlett is Goddard Health Center,  an on-campus clinic that provides medical care and counseling and testing services to students, faculty, staff, and their dependents. Goddard comprises the OU Health Services laboratory, Counseling Services, Health Promotion, and a pharmacy. The Van Vleet Oval (or South Oval) is anchored on the north by the   and flanked by academic buildings. When class is in session, the South Oval is often inundated with students going to and from class. Elm Avenue bounds the western edge of the academic portion of OU, with a few exceptions. Lying between Elm Avenue and Chautauqua Avenue are mostly   houses.  On the east side of the central part of campus lies  , just north of Lindsey Street on Jenkins Avenue. Immediately adjacent to the stadium is the  , a museum highlighting the historical success of Oklahoma athletics, as well as a comprehensive training facility for Oklahoma athletes. North of the stadium is the  , the former home of Oklahoma Basketball and the current home of Oklahoma's wrestling, volleyball and gymnastics programs. Across Jenkins Avenue are the athletic dorms and statues honoring Oklahoma's past seven   winners. Other statues on campus include several honoring the   who defined much of Oklahoma's history and a new memorial statue on the north side of Oklahoma Memorial Stadium honoring OU students, faculty, and staff that have died while serving in the  . \n The portion of OU's main campus south of Lindsey Street includes three colleges, university housing, student activity and fitness facilities, and the Oklahoma Center for Continuing Education. The Joe C. and Carole Kerr McClendon Honors College is in David L. Boren Hall, which serves as an Academic Arts Community where residential rooms, faculty offices, classrooms, a computer center and library are all available in the same building.  Other residence halls include the twelve-story Adams, Couch and Walker Centers, as well as Cate Center, made up of three- and four-story buildings, which are transitioning to faculty offices. \n Adjacent to the residence facilities are the Sarkeys Fitness Center (formerly the Houston Huffman Fitness Center), Henderson-Tolson Cultural Center and the Jim Thorpe Multicultural Center. The Murray Case Sells Swim Complex is also nearby, providing indoor and outdoor swimming opportunities for the OU community. The Oklahoma Center for Continuing Education (OCCE) is one of eleven W. K. Kellogg Foundation-funded centers in the United States and Britain. It is home to OU Outreach, which consists of the College of Continuing Education and the  , and includes a conference center able to host events of up to 1500 participants. \n The Oklahoma administration prides itself on the aesthetic appeal of the campus.  All three campuses (Norman, Oklahoma City, and Tulsa) have beautifully landscaped gardens. Trees were planted on the OU campus before the first building was ever built.  There are also many statues and sculptures around campus, most of which portray the strong influence of the   culture.\n There are also four buildings on the main campus that are listed on the  . They are the  , the   fraternity house, Casa Blanca (the old   sorority house), and   – the residence of the university president. \n In September 2008, it was announced that the University of Oklahoma's main campus will be entirely   by 2013.  According to OU president David Boren, \"It is our patriotic duty as Americans to help our country achieve energy independence and to be sound stewards of the environment.\"  The school plans to purchase its energy from the OU Spirit Wind Farm, which is scheduled for construction near Woodward in late 2009. The new source of energy is projected to cost the university an additional $5 million per year. \n The Anne and Henry Zarrow School of Social Work was completed on the Norman campus in 2011 and houses facilities for the training of undergraduate and graduate social workers. The 12 million dollar building is named for the Zarrow family, a philanthropic couple from Tulsa, Oklahoma. The Zarrows donated $5 million as the keystone donors for the new building with the remaining funds coming from a bequest of Ruth I. Knee, a graduate of the program, and a portion of the states federal stimulus funds.\n On the far north side of Norman is the OU Research Campus-North, which includes   ( : KOUN), the  , the old   facility, the OU OKDHS Training and Research Center, and Merrick Computer and Technology Center. Additional research facilities as part of OU's Gallogly College of Engineering also operate out of North campus including the High-Speed Aerothermodynamics Laboratory, Measurement and Automation Laboratory, Laboratory for Electrical Energy and Power Systems, and Laboratory for Smart Buildings.\n OU's College of Aviation runs a programs in the education of future pilots, air traffic controllers and aviation industry professionals. The Aviation Accreditation Board has accredited the College of Aviation at North Base as one of only 29 accredited colleges in the world. \n South of student housing is Timberdell Road, the approximate southern boundary of the university. South of this road are University-owned apartments and athletic complexes. Also on the south side of Timberdell Road is the   building which was expanded in 2002 by the addition of a larger law library and courtroom.  There are additional athletic complexes in this area, including  , the OU Softball Field, and   (the basketball arena).\n OU owns the wooded area just south of Highway 9 between Chautauqua and Jenkins. This area is called Oliver's Woods. Ecology classes take field trips to Oliver's Woods frequently. They can use the area to study Ecological patterns including tree growth and pH in the ground. Visible patterns of plant dispersion can be studied in Oliver's Woods as well, including uniform, random, and clumped patterns. The area has a trail for people to follow and a creek running through the lower elevated area.\n While this area has traditionally lacked academic buildings, the pressure of expansion in the northern part of campus led recently  to the construction of new academic buildings – such as the   and Stephenson Research and Technology Center – on the south end of campus. This area, now termed The University of Oklahoma's Research Campus,  \"brings academic, public and private sector organizations together in a mutually beneficial collaborative environment.\" \n In 2004, global weather information provider WeatherNews opened its U.S. Operations Center in One Partners Place, in the research campus one block from the new NWC building.  The southern boundary of the research campus is  . OU's   is also on the Research campus in its new Radar Innovations Laboratory building.\n As of 2013  the Life Sciences Research Center has opened, housing numerous chemical and biochemical research labs. Other buildings on the research campus include One Partners Place, Two Partners Place, Three Partners Place, Four Partners Place, and Five Partners Place. Housed within these buildings are the Center for Spatial Analysis and the Center for Applied Social Research among several others.\n The  's main campus is at the Oklahoma Health Center in Oklahoma City, while a secondary Health Sciences campus is in  . About 3,500 students enroll in one of the seven colleges at the Health Center. The distribution of students in each of these colleges is more uniform than that of the main campus.\n The University of Oklahoma Health Sciences Center ( ), established in the early 20th century, is OU's presence in Oklahoma City. OUHSC is one of only four academic health centers in the nation with seven professional colleges.  The nineteen buildings that make up the OUHSC campus occupies a fifteen block area in Oklahoma City near the  . Surrounding these buildings are an additional twenty health-related buildings some of which are owned by the University of Oklahoma. With approximately 600 students and 600 residents and fellows training in specialties and subspecialties of medicine, the   is the largest part of the Health Sciences Center. The major clinical facilities on campus are the OU Medical Center hospital complex, which and include The Children's Hospital, the OU Physicians clinics, and the Oklahoma City   Medical Center. The Oklahoma Health Center at large has large, university-operated biomedical research facilities joined on campus by a growing biomedical and pharmaceutical research corporations developed by the Presbyterian Health Foundation, dedicated to biotechnology, research, and new scientific ventures.\n The University of Oklahoma-Tulsa Schusterman Center (OU-Tulsa) is home to all OU programs in Tulsa, OU Physicians-Tulsa, and the School of Community Medicine. OU-Tulsa offers six bachelor's degree completion programs; 14 master's degree programs; doctoral programs in medicine, physical therapy, education, early childhood education, engineering and nursing, as well as nine residency programs in medicine. Graduate certificate programs are also offered at OU-Tulsa.\n More than 200 full-time faculty teach OU-Tulsa students and enrollment at OU-Tulsa exceeds 1,600 students. More than 1,000 employees work at the OU-Tulsa Schusterman Center and OU Physicians medical clinics throughout Tulsa. OU-Tulsa has service, education and research affiliations with more than 100 community agencies.\n Programs offered at OU-Tulsa that are affiliated with departments on the Norman (main) campus of OU are referred to as Norman-based programs even when offered at OU-Tulsa. Norman-based programs on the Tulsa campus are primarily graduate level programs although an undergraduate degree completion program in Social Work is now being offered. Masters and doctoral level graduate programs as well as graduate certificate programs affiliated with a number of colleges on the Norman campus are offered on the Tulsa campus. The College of Arts and Sciences is the largest college on the Tulsa campus and includes programs in Human Relations, Library and Information Studies, Organizational Dynamics, Public Administration, and Social Work. Some graduate programs offered at OU-Tulsa are unique to the Tulsa campus such as Urban Design and Organizational Dynamics. Norman-based programs offered in Tulsa are predominately professional programs that include non-traditional scheduling formats such as evening and compressed format weekend courses to support the needs of working adults.\n Established in 1972 as a branch of the main Health Sciences Center campus in Oklahoma City, the  , formerly the College of Medicine–Tulsa, has enabled the university to establish medical residencies and provide for expanded   capabilities in the state. Between 1972 and 1999, OU's presence in Tulsa had grown but scattered. In 1999, a 60-acre (24 ha) site formerly owned by   was sold to the university for $24 million (even though the property was appraised at $48 million). The site already featured a 370,000 square feet (34,370 m ) building with offices, labs, and classrooms.  The university purchased this property with the help of a $10 million gift from the Charles and Lynn Schusterman Family Foundation. The existing building was renamed the  .  This historic, 60-acre property in the heart of Tulsa features original mid-century architecture surrounded by nearly 1,000 trees. New construction of the Schusterman Library and Schusterman Learning Center at OU-Tulsa has been designed in keeping with the original building style.\n In 2003, Tulsa voters approved the   plan for capital improvements to the Tulsa metro area. Included in this plan was $30 million for a new Research and Medical Clinic near the existing Schusterman Center.  Construction on the new building, the OU Schusterman Clinic, was completed in June 2007.\n OU-Tulsa is also home to the OU School of Community Medicine. Created with the support of a $50 million donation from the George Kaiser Family Foundation, the school's mission is to improve the health status of all Oklahomans, particularly the urban and rural underserved.\n The OU School of Community Medicine faculty comprises around 200 physicians representing a wide field of specialties. These doctors also form the OU Physicians medical practice group, which provides care to patients at some 25 clinic sites in the Tulsa area. The faculty's time is split among teaching medical students, supervising medical residents and providing patient care.\n In 2012, The University of Oklahoma purchased a monastery in  .  In early 2016, renovations to the monastery neared completion and OU began the use of its newest permanent \"campus\" (denominated as a \"Study Center\") location outside of the state of Oklahoma. The university expects that one in five OU students who study abroad will go through the Arezzo campus.  The Arezzo campus has been described by university president, David Boren, as a first step for students and their parents to become acquainted with the world and gain an educational experience in a foreign land. The campus is scheduled to be dedicated in the summer of 2016. Boren chose the smaller town of Arezzo in part because of the small size of the town relative to nearby  , which boasts programs from about 50 American universities. With such a large number of American college students in Florence, Boren was concerned that OU students would have socialized with other Americans rather than the local Italians. \n OU has study centers in  , and  . A center is planned for  .\n The University of Oklahoma is a large residential,  .  The university consists of fifteen  , including 174  .  Native American studies includes language classes in  ,   ,  , and   as part of the university's Native American language program; currently Creek, Choctaw, and Cherokee I, II, and III are offered in both fall and spring semesters.  The university has a high four-year full-time undergraduate enrollment including a high transfer-in population.  While the two main campuses are in Norman and  , affiliated programs in   expand access for students in eastern Oklahoma. Some of the programs in Tulsa include: architecture, arts and sciences, education, engineering, medicine, nursing, public health, allied health and liberal arts studies. \n In addition to 174 majors to choose from, the University of Oklahoma also has a nationally recognized   featuring its own dedicated faculty, dormitories, and writing center.  Every student from any major can apply to the college; if accepted the student is eligible to take honors classes and graduate  . In order to graduate with honors, the student must complete 18 credit hours of honors classes and submit an honors thesis. Transfer students are able to transfer up to nine credit hours of honor classes from a different university. \n In addition to being a member of the Southeastern Universities Research Association and Universities Research Association, undergraduate admission to the University of Oklahoma is categorized by the   as \"more selective\". For the 2010–2011 school year, 9,996 applied and 8,498 were admitted (85%).  The university's freshman retention rate in 2009 was 82% and the six-year graduation rate was 62.0%. \n In May 2019,   said that the University of Oklahoma gave \"inflated\" data on its alumni giving rates for two decades and in response, would show the university as unranked in its 2019 edition of \"Best Colleges\" rankings. \n The School of Drama was founded in 1931. By 1948, dramatic performances were given in the North Campus auditorium, a Studio Theater and a Little Theater on the North Campus. Main productions were produced in Holmberg Hall on the Main Campus. 150 students were enrolled in theater and radio education. Rupel J. Jones was chairman of the School of Drama.  A theater on campus was originally named after Jones, but in 2015  was named after Elsie C. Brackett. \n The university has two prominent museums, the   and the  .\n The University of Oklahoma Library system has its headquarters in  . It is the largest research library in Oklahoma and contains over 4.7 million volumes.  It contains more than 1.6 million  , subscriptions to over 31,000  , over 1.5 million  , government documents dating back to 1893, and over 50  .  It has five locations on campus. The primary library is Bizzell Memorial Library, in the middle of the main campus. Other notable campus libraries include the Architecture Library, the Fine Arts Library, and the Geology Library. The OU library system contains many unique collections such as the History of Science Collections (which houses over 94,000 volumes related to the history of science,  including hand-noted works by  ),  the Bizzell Bible Collection, and the Western History Collection.\n The School of Library and Information Studies (SLIS), the only  -accredited program in Oklahoma,  offers a graduate degree (Master of Library and Information Studies) and an undergraduate degree (Bachelor of Arts in Information Studies). The impact of OU and SLIS on the history of libraries in Oklahoma is shown in the recent list of 100 Oklahoma Library Legends as produced by the Oklahoma Library Association.  Two current faculty, one faculty emeriti, and numerous others associated with either the OU libraries or SLIS account for nearly 10% of the list's members.\n Oklahoma requires, with few exceptions, that all freshmen live in one of the six residence halls:  the Towers, which are two (formerly three) 12-story buildings on the south side of campus.\n David L. Boren Hall is the fourth major residence hall on campus.  Headington Hall, completed in the Summer of 2013, is the fifth major residence hall on campus. \n Dunham and Headington Residential Colleges are the sixth and newest major residence hall, having opened in 2017.  Dunham and Headington are connected by a dining hall that is open to all students.\n The university owns several apartment complexes around the campus. \n Due to a low   in Oklahoma, many students find it financially viable to live off campus in apartments or houses. In recent years, many new apartment or condominium complexes (not including the OU-owned properties) have been built.  Some students commute from nearby   and  .\n The  , the university's  , celebrated its 100th anniversary in 2004 and consists of 311 student musicians and dancers from 19 states. Students wishing to enter the band go through a rigorous audition process. The band plays at every home football game. A smaller pep band, which usually consists of 100 members, travels to every away football game. The full band makes trips to the AT&T   game against  ,  ,   and other games of importance. Members of the band are also present for many student events. It was awarded the   in 1987. In 2007, The Pride of Oklahoma marched in the Macy's Thanksgiving Day Parade, making it one of only a few bands to have ever marched in both the Tournament of Roses and Macy's Parades. \n The   provides officer training and education for nearly 100 OU students. Officially founded in 1919, it is one of the oldest such programs in the nation. OU Army ROTC   are active in numerous campus and   activities. They provide military   for   and various on-campus ceremonies and events. After completing the Army ROTC program, OU students receive a   in either the  ,  , or  .\n The campus student radio station, Studio U, broadcasts over the Internet. The campus TV station, OUTV, features student-produced programming five nights a week and is available on     (  Ch. 124, ATT uVerse 99) also via Facebook and YouTube sites.  , the live student newscast, airs weekdays at 7:00am, 12:00pm, 4:30pm live and 9:30pm.  , a live sports program, airs live Monday nights at 7:30 on Fox Sports SW and throughout the week as repeats on OUTV. Oklahoma's Gaylord College of Journalism and Mass Communication programs Studio U and OUTV. Oklahoma's Department of Continuing Education operates   and  , a   station broadcasting on 106.3 FM. KGOU is affiliated with  .\n The campus newspaper,  , is produced daily during the fall and spring semesters and weekly during the summer semester.  s sister publication,   yearbook, creates a 400-page coffee table book for current students and alumni.  , ranked as one of the top two yearbooks nationwide, focuses on capturing the year with storytelling packages of text, photos and design. \n The school's sports teams are called the  , a nickname given to early settlers during the   who sneaked into the offered territory and staked claims illegally before they were officially allowed to. They participate in the  's Division I-Bowl Subdivision and in the   (SEC). The school sponsors nine sports for both men and women. The university has claimed 43 team national championships, which includes 17   (football championships are not awarded by the NCAA).  By far, OU's most famous and storied athletic program is the football program, which has produced seven   winners:   in 1952,   in 1969,   in 1978,   in 2003,   in 2008,   in 2017, and   in 2018.  Many Pro Football Hall of Famers, including   and  , also attended the University of Oklahoma. In 1988, OU became the first school to participate in both the football and basketball national championships in the same year, an achievement unequaled until the 2006 season, when   and the   were both in each, with Florida winning both games. Oklahoma also currently holds the record for the longest winning streak in NCAA Division I history when they won 47 consecutive games between 1953 and 1957.  In reference to the team's success and popularity as a symbol of state pride,  , OU's president from 1943 to 1968, once told the Oklahoma State Senate, \"I want a university the football team can be proud of.\" \n The   program is the fourth most decorated in college wrestling, having won seven national championships.  The men's gymnastics team has won twelve national championships, the most out of all sports at the University of Oklahoma.  In addition, Oklahoma has produced five   winners, more than any other school and the only school with back-to-back honorees.  The women's gymnastics team was crowned co-national champions with the University of Florida in 2014 and won back-to-back national championships in 2016 and 2017.  The   team has won eight national championships, the first in 2000  another in 2013, back to back titles in 2016 and 2017, and four consecutive titles in 2021, 2022, 2023, and 2024. The baseball team won a national championship in 1951 and 1994.  On May 10, 2007, the university announced the addition of women's rowing to the intercollegiate athletics program.  A rowing facility will be built on the   near downtown  . This is the first sport added since women's soccer was added in 1996. \n The University of Oklahoma has had a long and bitter rivalry with the   known as the  , Red River Rivalry, or OU–Texas, with Texas having the better overall record at 59–43–5. This rivalry is often thought of as a contest of state pride along with school pride. OU also has a long-standing rivalry with  . Known as the  , it encompasses all the athletic contests between the two universities with the winner receiving the Bedlam Bell. Another major historic rival is the  , which was part of the   with Oklahoma and later joined with Oklahoma and other schools in the formation of the  . The Sooners made football history December 6, 2008, when they scored sixty or more points in five consecutive games. This achievement occurred during their victory over the University of Missouri for the Big 12 Championship.\n On June 30, 2021, the University of Oklahoma Board of Regents unanimously accepted an invitation to join the   (SEC) along with the University of Texas beginning on July 1, 2024. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/National_Junior_College_Athletic_Association", "title": "National Junior College Athletic Association", "content": "The   ( ), founded in 1938, is the governing association of  ,   and   athletics throughout the United States. Currently the NJCAA holds 24 separate regions across 24 states and is divided into 3 divisions.\n The idea for the NJCAA was conceived in 1937, in  . A handful of junior college representatives met to organize an association that would promote and supervise a national program of junior college sports and activities consistent with the educational objectives of junior colleges.\n A constitution was presented and adopted at the charter meeting in Fresno on May 14, 1938.\n In 1949, the NJCAA was reorganized by dividing the nation into sixteen regions. The officers of the association were the president, vice president, secretary, treasurer, public relations director, and the sixteen regional vice presidents.  Although the NJCAA was founded in California, it no longer operates there, having been supplanted by the unaffiliated  .\n The NJCAA only allowed male competitors until 1975, when it established a women's division following the enactment of  .\n Based out of   since 1968, the national office relocated to   in 1985. Headquarters moved to   in 2018.\n Each institution belonging to the NJCAA chooses to compete on the Division I, II or III level.  Division I colleges may offer full athletic scholarships, totaling a maximum of tuition, fees, room and board, course-related books, up to $250 in course-required supplies, and transportation costs one time per academic year to and from the college by direct route. Division II colleges are limited to awarding tuition, fees, course related books, and up to $250 in course required supplies. Division III institutions may provide no athletically related financial assistance. However, NJCAA colleges that do not offer athletic aid may choose to participate at the Division I or II level if they so desire. \n The NJCAA is divided into 24 different regions: \n  \n Due to the relatively small number of schools fielding teams, some football-only conferences exist. They may be home to teams from multiple regions.\n There are also independent schools in regions 2 (Arkansas Baptist), 3 (upstate New York), 8  (ASA-Miami), 10 (Louisburg, N.C.), 12 (Hocking College), and 17 (Georgia Military).  's football program does not compete in the NJCAA but instead competes at the   level.\n Regions 7, 9, 16, 20, 21, 22 and 24 do not have any football programs. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/List_of_time_offsets_by_U.S._state_and_territory", "title": "List of time offsets by U.S. state and territory", "content": "\n This is a  . For more about the time zones of the U.S. see  .\n Most states are entirely contained within one time zone.  However, some states are in two time zones, due to geographical, socio-political or economic reasons.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Alan_M._Stretton", "title": "Alan M. Stretton", "content": "\n\n  (born 1930s) is an Australian  ,   manager, retired Adjunct Professor of Project Management at the   and author. He is known for his work on the state of  , and its history. \n Stretton obtained his BSc in   from the  , and his MS in   from the   in the 1950s.  He was the Rhodes Scholar for Tasmania in 1948. \n From the 1950s to 1988 Stretton made his career in the   as designer and project manager from Australia and New Zealand to the United States. In his days he witnessed the emerge of \"project management of construction... information and control systems, internal management education programs and organizational change projects.\" \n In 1988 Stretton joined the Faculty of Design, Architecture and Building at the University of Technology, Sydney (UTS), where he later became appointed Adjunct Professor of Project Management. As a start he established a Master of Project Management program at the University. After his retirement in 2006 he joined the   faculty. \n From 1998 to 1992 Stetton chaired the Standards Committee of the   (PMI),  which developed the   first published by the PMI in 1996. Stretto co-authored parts of it.  Later in the 1990s he continued these standardization efforts at the Australian Institute of Project Management (AIPM). \n In 1996 Stretton was elected Life Fellow of the Australian Institute of Project Management (AIPM), and in 2015 he was awarded the honorary doctorate in strategy, programme and project management from the French business school  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Ray_Gunn", "title": "Brad Bird", "content": "\n  (born September 1957) is an American filmmaker, animator, and voice actor. He has had a career spanning over four decades in both   and  .\n Bird was born in   and grew up in  . He developed an interest in the art of animation early on, and completed his first short subject by age 14. Bird sent the film to  , leading to an apprenticeship from the studio's  . He attended the   in the late 1970s, and worked for Disney shortly thereafter.\n In the 1980s, he worked in film development with various studios; he wrote the screenplay for   (1987), and developed two episodes of   for  , including its spin-off (based on a segment written by Bird for the show), the widely panned animated sitcom  . Afterwards, Bird joined   as creative consultant for eight seasons. He directed the traditional animated feature   (1999), adapted from a book by poet  ; though critically lauded, it was a  . He moved to   where he wrote and directed two computer-animated films,   (2004) and   (2007) that were worldwide critical and financial smash hits; they earned Bird two   and   nominations. He transitioned to live-action filmmaking with similarly successful   (2011), he then directed Disney's   (2015). He returned to Pixar to develop   (2018), which became the  , and earned him another nomination for the Academy Award.\n Bird has a reputation for supervising his projects to a high degree of detail. Some commentators have drawn parallels between Bird's films and novelist  's   philosophy, an analysis Bird has dismissed. He advocates for creative freedom and the possibilities of animation, and has criticized its   as children's entertainment, or classification as a  , rather than art.\n Philip Bradley Bird  was born in September 1957 in  , Montana, the youngest of four children to Marjorie A. (née Cross) and Philip Cullen Bird. His father worked in the   business, and his grandfather, Francis Wesley \"Frank\" Bird, who was born in  , was a president and chief executive of the  .  Bird's fascination with filmmaking began at an early age. He started   at age three, with his first   clear attempts at  . He was particularly enamored with animation after a screening of   (1967), and a family friend who had taken animation classes explained how the medium worked. Bird's father found a   that could shoot one frame at a time, and helped him setup the device for making films.  He began animating his first short subject at age 11; that same year, his family connection introduced him to composer  , who set him up a tour of   in  .  Bird met the  —the animators responsible for the studio's earliest and most celebrated features—and proclaimed he would join them one day. \n Bird has characterized his parents as generous and supportive of his interests. His mother once made a rainy drive two hours each way to the only theater playing a reissue of   for Bird's education.  After two years, Bird had completed his first short, a fifteen-minute adaption of  .  On his parents' advice, to \"start at the top and work your way down\", he sent the film to his idols at Disney. The studio responded with an open invitation for Bird to stop by whenever in town, which led him to make several visits to the studio's California headquarters in the ensuing years.  This opportunity—an \"unofficial apprenticeship\" of sorts—was \"never offered\" to anyone previously. He worked closely with  , whom he considered a hero. He began another film, titled  , which was more ambitious and in color, but the workload was intense. Instead, Bird focused on other interests in his   years, including dating, athletics, and  . \"Animation is the illusion of life, and you can't create that illusion convincingly if you haven't lived it,\" he later remarked.  The family relocated to   in his youth, and he graduated from   in 1975.\n That year, he was awarded a scholarship by Disney to attend the newly formed   (CalArts) in  ; Bird has joked he was a \"retired\" animator by the time he received this offer. Instead, he considered attending the acting program at  .  After a three-year break, Bird chose CalArts and moved down south.  Bird's classmates included prominent future animators such as  ,  , and  .  Like many students, they were dazzled by the   in   (1977); both Lasseter and Bird agreed these feats were possible in animation.  First-year students met in the room labeled  —a small, sterile classroom with no windows.  Bird later used A113 as an   in his films; it has since become a fixture of media made by the school's alumni. The first use of A113 was in the pilot episode for the short-lived television series   (1993). The pilot episode was a part of the series   (1985–1987), which aired February 16, 1987, and was titled \"Family Dog\". He used it for the license plate number on a van. The first Disney movie he used it in was   (1987), for which he was an animator. \n Within two years, Bird accepted a job as an animator at Walt Disney Productions. Bird arrived at the studio in the midst of a transition: much of the studio's original creative staff were retiring, leaving the studio to a new generation of artists. What was left of the original staff got along with the newcomers, but Bird clashed with the middlemen in charge. While animating at Disney, he became a part of a small group of animators who worked in a suite of offices inside the original studio called the \"Rat's Nest\".  There, Bird openly criticized the state of the studio, and characterized senior leadership as unwilling to take risk. He felt as though he was standing behind the studio's original principles. This volatile attitude prompted his firing by animation administrator Edward Hansen.  He left Disney after only two years; he received credits on   (1978) and   (1981), and went uncredited on   (1983) and   (1985).\n Bird was dispirited with the  , and he considered his departure from Disney as the end of his long-held love of the form.  Still, he pulled together funds to make  , a   of potential animated projects, ones he felt the medium was capable of. Bird was hopeful of receiving financial backing from other studios, but ended up frustrated by  's development system: \"for every good project I've made, I've got equally good projects that are sitting [un-produced by] various studios,\" he said in 2018.  He relocated to the  , eager to become a part of its burgeoning film scene, which birthed films like   and  .  He tried for several years to adapt  's comic book   to feature animation,  but studios declined, unwilling to take a risk given Disney's dominance. He briefly attempted a computer-animated film at   with  , presaging his later work with Pixar. \"He had all these ideas for making animated movies, but he didn't have a technical bone in his body and he didn't have any tolerance that you would need to have at the time to put up with some of the awfulness of the early technology,\" said  .  Bird's next credit was as an animator on the dark animated     (1982); he was also fired by the film's director,  , during its production. \n One piece from his test reel,  , attracted the attention of director  .   centered on a pet's perspective of his dysfunctional suburban family, and its original   featured designs by Bird's classmate Tim Burton. Bird had hoped to develop the concept into theatrical shorts, like those from the  , but the market simply no longer existed.  Instead, Bird moved back to Los Angeles and joined Spielberg's  ,  and became involved with his television program  , an   series which debuted in 1985. He co-wrote the   for \"The Main Attraction\", the show's second episode, with  . Spielberg enjoyed the script, and invited Bird to pitch other ideas. Bird storyboarded another   segment, which was decided to be adapted into an episode of  . The episode, which aired in 1987, was a ratings success. The experience was exciting for Bird; \"Not only was Steven one of my favorite filmmakers, but he was powerful enough to clear space that allowed us creative freedom,\" he later remarked.    was later   into its own half-hour  , against Bird's urging and without his involvement, as he felt the idea would not work. He was also perturbed to see Burton's role in designing the characters overshadow his deeper contributions to the concept. \n He was later brought on to co-write the screenplay for   (1987), a   film that stemmed from an   outline. The film opened in fourth place domestically,  and was overall a   hit, generating $65.1 million on its $25 million budget. Bird also helped with  , a 3-D short film starring   viewed at  .  These successes brought Bird more opportunity, but he continued to spend many years in   with studios. He grew irritated with notes from middle management: executives he felt \"would analyze your work and dictate everything you'd need to do to make it 'more pleasing to an audience'—and in the process would only make stories smaller and more like everything else,\" he complained.  In his personal life, he wed Elizabeth Canney, an editor on  . In 1989, Bird's sister Susan, with whom he was very close, was killed by her estranged husband in a murder-suicide.  The event was traumatic for Bird; he felt emotionally \"kind of gone in that period. I don't really have a lot of memories from it.\"  He had enough funds to support himself for a time, so he simply rested: \"I just kind of didn't do anything,\" he confessed. \n Bird's cinematic sense of visual storytelling with   was uncommon in television animation to that point, mainly due to budgetary restrictions. Most television productions retained rudimentary cinematography, with frequent abuse of standard  , medium angles, and   to move the story along. In contrast, Bird favored using more filmic techniques, utilizing extreme  , long   shots,  , pushed  , and so on. Bird's work on   caught the eye of producers   and  , who with   were developing  , the first   animated sitcom in decades for  . In 1989, he was invited to join   (and later  ), where he served as \"executive consultant\" for the show. The role required Bird oversee the script-to-animation pipeline 2–3 days per week;  the first episode produced on which Bird received credit (save for the reworked cut of the pilot episode \" \") was \" \".\n Bird worked on the show for its first eight seasons (with his final credited episode being \" \" (1997), the second episode of season nine to be produced), and directed the episodes \" \" (1990) and \" \" (1992). He also designed the character  , who made his speaking debut in the former episode. In his role, Bird pushed the show's artists to visualize episodes as miniature films, taking inspiration from the work of   and  . In the 1990s, he also contributed to other episodic animated sitcoms like   and the first season of  , both of which took cues from this established template. Bird called his work at   a \"golden opportunity,\" recognizing that the material was more to his sensibility than the work he had done for Disney. On a personal level, the job was deeply fulfilling; he attended weekly   which he found delightful,  and he considered the gig the only bright spot in the years following his sister's passing. The show's crew hoped to get Bird to direct its later 2007  , but he was too busy on   which came out the same year. \n Animation had a commercial and creative renaissance in the U.S. during the 1990s, with Hollywood studios eager to capitalize on the success of Disney's   (1994). Bird continued to shop around film ideas to studios throughout the decade,  but grew frustrated with his lack of progress in his dream of directing a feature. He was momentarily signed to direct a live-action comedy,  , at  , but it did not pan out.  In addition, his growing family gave rise to other concerns. \"I had anxiety about devoting my energy to work that was meaningful and spending time with my family, which was also meaningful to me. If I did one, would I fail at the other?\" he worried.  He poured these themes into a screenplay for  , which he pitched to studios beginning in 1992.  He also developed an original sci-fi feature titled  , with a script co-written by  . Its futuristic story centered on a private detective in an   world of humans and  . Bird signed a production deal with   in January 1995,  but the studio felt   would be too intense for its target demographic of young children.  The following year, Turner merged with  , which contained the last three months of Bird's contract. \n Warner executives set up a meeting, and made it clear they had no interest in  . Instead, they offered Bird several in-development projects, including a   version of poet  ' book  , first envisioned by rocker  . Bird read the novel and felt \"enchanted\" by it; he felt drawn to Hughes' rationale for writing the story, which was to comfort his children after the death of his wife,  . Bird connected with its themes, relating it to his sister's passing from  .  He significantly revised the entire story to center on a central question: \"What if a gun had a soul?\" Warner leadership was sold and Bird signed the contract to direct   in December 1996.  Bird penned the screenplay with  , which centers on a young boy named Hogarth Hughes, who discovers and befriends a giant alien   during the   in 1957.\n He was quickly faced with assembling a team with little time to spare; most big-budget animated films of the era were workshopped for years, whereas Bird only had two. Adding to the pressure was Bird's frequent disagreements with the film's co-producer,  .  In a trade-off, the crew received significant creative freedom to make the film they wanted to make, though Bird occasionally fielded suggestions from executives to make the film more merchandisable or kid-friendly. The film scored highly on  , but Warner neglected to secure prominent promotion for the movie as they were promoting   instead.   opened in August 1999 to rave reviews from critics, but very low ticket sales; theater owners discarded the picture after only a few weeks. Altogether, the movie grossed $31.3 million worldwide against its $50 million budget, which was considered a significant loss for Warner. Upon its arrival on  , the film took on a  .  Bird was disappointed by the failure of  ; he visited multiple cineplexes only to view the film in empty auditoriums.  Afterwards, he was briefly attached to direct a   adaptation for Universal,  but he instead set his sights toward another animation studio:  .\n In the late 1990s, Bird reconnected with old friend John Lasseter, who went on to work for Pixar, the computer hardware maker that had recently moved into animation. The company released the first fully computer-animated feature film,  , in 1995. Bird was stunned by the film, and in 1997, the two began to negotiate Bird joining Pixar.  In March 2000, Bird went to Pixar's  , campus and pitched his ideas, including  , to Lasseter.  The studio announced a multi-film contract with Bird in May of that year,  making Bird the first outside voice for the studio, which previously required talent to rise through the ranks. He was excited to return to the Bay Area, where he had lived intermittently two decades prior.  He purchased a home in  , across the bay from Pixar's Emeryville headquarters.  He grew comforted by the \"creative and supportive\" atmosphere at Pixar, unlike many of the L.A. studios he had worked for; he convinced a core team to join him up north, including artists Tony Fucile,  , and  , all of whom had contributed development artwork for   for much of the past decade. \n Bird's first film,  , follows   ( ) and   ( ), a couple of  , known as Mr. Incredible and Elastigirl, who hide their powers in accordance with a government mandate, and attempt to live a quiet suburban life with their three children. Bob's desire to help people draws the entire family into a confrontation with a vengeful fan-turned-foe, Syndrome. Bird also provides the voice of costume designer  . As an inside joke, the character Syndrome was based on Bird's likeness (as was Mr. Incredible) and according to him, he did not realize the joke until the movie was too far into production to have it changed.  The animation team was tasked with creating computer animation's first all-human cast, which required creating new technology to animate detailed human anatomy, clothing, and realistic skin and hair.   composed the  , marking the first in a series of collaboration between the two men.   was Bird's first global critical and box-office smash, grossing $631.4 million, making it the  . Bird won his first  , and his screenplay was nominated for  .  It was the first animated film to win the prestigious  .\n Bird's next project was   (2007), which follows a   named Remy, who dreams of becoming a   and tries to achieve his goal by forming an alliance with a Parisian restaurant's garbage boy. The film was developed by  , who worked on the concept for many years. By the time the project was slated to enter the animation process, Pixar leadership became concerned it was not ready. Bird was hired on in July 2005 to assess the mistakes and turn the project around in a short time.  He disliked having to take over Pinkva's passion project: \"It was a rough position to be in because I always come down on the side of the creator,\" he later said.  However, he was also in position with Pixar as a member of their \"brain trust\"—a group of individuals who critique and help each other—so he felt the role came naturally. When Bird took over, much of the design work had been completed, but Bird wrote an entirely new script that eschewed much of its original dialogue.  Giacchino returned to compose the Paris-inspired music for the film. Upon release,   was another huge hit for Pixar; the film grossed $623.7 million and earned critical acclaim. It won the   award at the 2008  ; it was also nominated for five Academy Awards, including Best Original Screenplay and Best Animated Feature, which it won. \n Midway through the aughts, Bird was attached to direct an adaption of  's novel,  ,  which chronicles the   that struck   a century prior. Due to the size and scale of such a project, three studios were to finance its making—Pixar, Disney, and Warner Bros.—but the project stalled. He paused when Pixar management asked he take over  , and returned afterward. He attempted to re-write   to work within the confines of a feature's length, but struggled. Instead, Bird helmed the next installment of the      , starring  . \n Bird's foray into live-action filmmaking after a major career in animation had little precedent, according to critics.  Cruise had been impressed by the style and storytelling of  , and urged Bird to contact him should he venture into the live-action sphere. The idea of combining the commercial aspects of a franchise—this was the third   sequel—and more artistic tones challenged Bird, who signed on to direct in May 2010.  In the picture, Cruise reprises his role of   agent  , who with his team race against time to find a   who gains access to Russian nuclear launch codes.   was shot on location partially in  , and includes a memorable scene when Cruise scales the newly erected  . Upon release in December 2011, it became the highest-grossing film in the series up to that point, with $694 million worldwide.  It was the   as well as the second-highest-grossing film starring Cruise. \n Though he was asked to direct  , Bird turned down the opportunity to focus on his new project: the sci-fi film  ,  named for the   found at  .  Bird co-wrote the screenplay with  . In the film, a disillusioned genius inventor ( ) and a teenage science enthusiast ( ) embark to an intriguing   known as \"Tomorrowland,\" where their actions directly affect their own world. The film ended up being a box-office bomb, losing Disney $120–150 million, and attracting a mixed critical response. \n Over the years, Bird mentioned the possibility of an   sequel in interviews. An official sequel was announced in 2014. Bird began writing its screenplay in earnest the next year; he attempted to distinguish the script from the breadth of superhero-related content released since the first film, focusing on the family dynamic rather than the superhero genre. The story follows the Incredibles as they try to restore the public's trust in superheroes while balancing their family life, only to combat a new foe who seeks to turn the populace against all superheroes. Though scheduled for release on June 21, 2019, the film was completed on an accelerated production schedule, as it was farther ahead in production than  , which required more development and was later released on that day; the two simply swapped years, with   debuting in theaters on June 15, 2018.  Giacchino returned to compose the score.\n  made $182.7 million in its opening weekend, setting the record for  , and grossed over $1.2 billion worldwide, making it the   at the time, the highest-grossing Pixar film, and the  .   was named by the   as the   of 2018. The film was nominated for Best Animated Feature at the   and  , but lost both awards to  .\n Bird has expressed interest in developing an animated   or  .  However, Bird returned to revive his long-dormant project   at   before he was approached by John Lasseter to produce it for  . In 2022, it was announced that Bird had signed a deal with Skydance the previous year and reassembled frequent collaborators Michael Giacchino, Teddy Newton, Tony Fucile,  , and   for the film.  According to  , the presumptive production costs were estimated to be $150 million. This resulted in Skydance leaving its distributor deal with  , in which they later partnered with  . \n In August 2024, at the  , Pixar chief creative officer   announced   was in development, with Bird returning. \n I love all the arts, but I love movies most because they combine so many of them. \n Bird says he was influenced by dozens of filmmakers, singling out early moviemakers  ,  , and  , to mid-twentieth century auteurs like  ,  ,  , and  . More contemporary directors like  ,  ,  ,  ,  and the   have inspired Bird as well.  His passion for the medium was evident even in his college years; friend John Lasseter remembered, \"Brad would hang out all night talking about   and Coppola and how he could do what they did in animation.\"  Bird himself has observed that his career was \"very long, very delayed and full of disappointment,\" mainly because he aspired to \"lofty\" self-set expectations. \n He has been characterized as controlling with an exquisite attention to detail.  His \"demanding, often punishing\"  direction has prompted some to consider him difficult to work with.  Bird is outspoken about the potential of the art of animation, and has asked the public not refer to his films as cartoons.  In the   for the home release of  , Bird joked he would fight the next person to refer to animated movies as a \"genre\", as opposed to art form.\nHe has also taken exception to the classification of modern animated fare as solely for children or families;  suggesting it discriminatory and belittling.  He has expressed a love for hand-drawn animation and lamented its current absence from the industry. \n Many critics have analyzed his films and suggested they reflect   novelist  's   philosophy, which Bird vehemently denies, suggesting it a monumental misreading of his work.  Though he claims he was drawn to Rand's work in his younger years, he offers, \"Me being the Ayn Rand guy is a lazy piece of criticism.\"  He stated that a large portion of the audience understood the message as he intended whereas \"two percent thought I was doing   or  .\"    plot line—a group of geniuses form a utopia to sequester themselves from the world—has been considered reminiscent of   and its   enclave.  In  , father Bob Parr complains of what he feels is society's increasing  , and later in the film, its villain Syndrome asserts that \"when everyone's super, no one will be.\" Analysts suggested these lines a reflection of views shared by German philosopher  .  One writer distilled   down to \"if you don't have talent, you should get out of the way of people who do.\"  David Sims at   has suggested Bird's films are instead \"stories about the frustrations of unbridled creativity [...] In each film, there's an indelible recurring image: the frustrated genius, locked away in a dusty closet, obsessing over the talents he has to hide.\"  Likewise,  's Eric Kohn called Bird a \"pivotal figure in exploring the American dream through the vernacular of popular culture.\" \n Bird and his wife Elizabeth (m. 1988) have three sons: Nicholas, who voiced Squirt in the Pixar film   and Rusty the bike boy in  ; Michael, who voiced Tony Rydinger in   and its  ;  and Jack. Bird maintains properties in Tiburon, California, and  . \n \n \n \n Critical response to films Bird has directed:\n Brad Bird has cast certain actors and crew members in more than one of the films he has directed.\n In addition to his  ,   and   wins, Bird holds the record of the most animation   wins with eight, winning both   and   for each of  ,   and  , as well as   for  . His eighth Annie was the 2011   for lifetime contribution to animation. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/White_House_Office_of_Energy_and_Climate_Change_Policy", "title": "White House Office of Energy and Climate Change Policy", "content": "The   was a government entity in the United States created in 2008 by     by Executive Order. It existed for over two years and was combined with another presidential office in April 2011. The office was created to coordinate administration   on energy and  . Under the  , it has been succeeded by both the   and the  .\n The office was created in December 2008. Its first (and only) director was  ,  who was   for the eight years of the  .\n President Obama launched the   to facilitate candid dialogue among key developed and developing countries regarding efforts to advance clean energy and reduce greenhouse gas emissions. For the new forum, President Obama invited the leaders of 16 major economies and the   of the   to designate representatives to participate in a preparatory session at the   that occurred on April 27–28 in   This and other preparatory sessions culminated in a 17-nation   meeting, as part of the   which Italian Prime Minister   agreed to host in  , Italy, in July 2009.  The G8 summit was subsequently moved to  , Italy, as part of an attempt to redistribute disaster funds after the  .  The forum took place on July 9, 2009.\n In April 2011, it was reported that Congress would no longer fund the office in the 2011 budget.  On March 2, 2011, the White House announced that the   work done by the office would be transferred to the  , thereby eliminating it as an office within the  .  It was succeeded in 2021 by the White House Office of Domestic Climate Policy, headed by the  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/HoYeon_Jung", "title": "HoYeon Jung", "content": "\n\n  ( :  ; born June 23, 1994) is a South Korean model and actress. She began her career as a freelance model in 2010, walking in   shows for two years. In 2013, she competed on the   of   and placed as a runner-up. She became known for her \"fiery\" red hair after making her international runway debut during  . She was a   exclusive in 2016, and became a global ambassador for the brand in 2021.\n Jung made her acting debut in 2021, starring in the first season of the   series   as  , which brought her worldwide attention and critical acclaim as the series' breakout star. For her role on the series, she won the   and earned a nomination for the  .\n Jung Ho-yeon was born on June 23, 1994,  in  ,  , South Korea,  and has two sisters.  Her parents are restaurateurs.  She graduated from   College of Performing Arts, where she majored in modeling. \n Jung started taking modeling classes at age 15, and began working as a freelance model in 2010 at age 16,  walking in shows for   without an agency for two years.  While freelancing, she auditioned for the   of the   reality competition series   Season 2 in 2011, but quit after making it into the top 30.  She signed with ESteem Models in 2012  and went on to compete on the   of   in 2013, where she placed as a runner-up.  She appeared in the music video for  's song \"Move\" in 2014.  She was also featured in spreads for the Korean editions of magazines such as  ,  , and   before signing with   and leaving South Korea in 2016 to pursue a career overseas.  She also signed to   and Nomad Management.  Before moving to New York, Jung inadvertently dyed her hair a \"fiery\" red color, which became her signature look. \n After her booking to walk as an exclusive for   was canceled, she made her international runway debut in September 2016 at  's S/S 2017 show at  .  Shortly after, she walked in shows for  ,  ,  ,  , and  ; appeared in  ,  , and  ; and was featured in campaigns for   and  .  Also in 2016, she made her   runway debut as an exclusive model for   at their S/S 2017 show, selected by   and casting director  .  In September 2018, Models.com named Jung on their list of the top 50 models.  At the 2019 Asian Model Awards, she won the Asian Star Award. \n Jung has walked in runways for  ,  ,  ,  ,  ,  ,  ,  ,   ,  ,  ,   ,  ,  ,   ,  ,   ,  ,   ,   ,   , and  .  She has also appeared in advertisements for  ,  ,  , and  ,  and on the covers of  ,  ,  , and  . \n Jung appeared in a promotional video for   and  's collaborative capsule collection in March 2019.  In October 2021, she was named  's Global House Ambassador for fashion, watches, and jewelry.  That same month, she partnered with   for their Adicolor campaign.  She was featured on the cover of the February 2022 issue of  , making her the magazine's first solo Korean cover star.  In 2022, she became one of the faces of N°1 de Chanel.  In 2022, Models.com listed Jung on the \"New Supers\" list, calling her a \"supermodel for the modern era.\" \n In 2023, Jung and French singer   became global brand ambassadors for French luxury beauty brand  . \n Jung decided to start her career in acting because of the short life span of model careers, which she felt as her work in modeling began to decrease.  While modeling overseas, Jung periodically returned to South Korea during holidays to take acting lessons, and took three months' worth of acting lessons altogether. She also improved her English in order to help her learn acting. \n In January 2020, Jung was signed to Korean talent agency  . She made her acting debut in the first season of the 2021       in which she played  , a   and pickpocket who needs money to support her younger brother and track down her mother in North Korea.  One month after signing with Saram, she was given three scenes from the show's script, and auditioned for the role via video while in New York for Fashion Week.  She was then asked by director   to audition again in person in South Korea, where she was given the part immediately.  She studied for the role of Sae-byeok by practicing her character's   with real North Korean defectors, watching documentaries about North Korean defectors, and learning martial arts. She also drew upon her own feelings of loneliness while modeling overseas to build the character, and wrote a daily diary from her character's perspective. \n Sae-byeok became a fan favorite, and Jung was called  s   by critics.  For her performance on the show, Jung won the   at the  .  This nomination made her the second actress of   as well as   descent to receive an individual SAG Award nomination.  Her win, along with costar   winning the  , made history for the show becoming the first non-English language television series to win at the SAG Awards.  She was also nominated along with her costars for the  . \n In November 2021, she signed a contract with  , an American talent agency.  Jung was featured in  's music video \" \" in 2022   as well as two of  ' music videos that were released the following year. \n In 2024, she made a cameo in the comedy mystery   as Hong Cha, a renowned food blogger. The same year, she will appear in  's thriller series   opposite  .  Jung is set to make her feature film debut with the   film  , directed by  .  She has joined  's upcoming film  . \n While working as a model, Jung became known by designers as the \"red-haired Asian\".   s Monica Kim called her \"one of Seoul's top modeling talents\" in 2015.  In 2021, K-Ci Williams of   called Jung \"the world's current  .\"  Jung became the most-followed South Korean actress on   in 2021, surpassing actresses   and   and, as of November 2023, has over 20 million followers on the platform. \n Jung has been in a relationship with actor   since 2015. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Trojena", "title": "Trojena", "content": "\n\n  (styled  ;  :  ) is a mountain tourism destination under construction in  ,  ,  . Trojena is one of the various announced regions of   and will be located 50 km (31 mi) from the  , covering a total area of 60 km  (23 sq mi) with an elevation ranging from 1,500–2,600 m (4,900–8,500 ft) above  .  The tourism destination is part of   and when announced in 2022 was set to be completed by 2026. \n The region aims to attract 700,000 visitors and 7,000 permanent residents by the year 2030. Trojena is expected to contribute to the Kingdom's   by $800 million and create 10,000 jobs. \n Trojena will consist of a ski village, a variety of restaurants and retail stores, ultra-luxury family and health resorts, in addition to sports activities such as mountain biking, ski slope, water sports, and an interactive nature reserve. According to the  , the all-year-round average temperature will be 10 °C (18 °F) below neighbouring regions, and will drop below zero during winter times. \n Trojena was announced in 3 March 2022 by crown prince   as part of Saudi Arabia's megacity,  . The project was announced inline with Saudi Arabia's   goals to diversify the county's economy away from   by growing its tourism sector. \n On 3 August 2022, the   (SOPC) submitted a letter of interest to the   (OCA) to host the 10th   in Trojena.  On 5 October 2022, Saudi Arabia was officially chosen to host the   at Trojena. \n Since its announcement, several hotel projects have been planned for Trojena, including the 60-key Collective Trojena (2026),  the 270-key   Trojena (2026),  the 105-key   Trojena (2027),  the 236-key   Trojena, the 500-key   Trojena,  and a currently unnamed 60-key  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Themed_walk", "title": "Themed walk", "content": "A   is a type of   and often is defined by a   along which there are information boards or other identifying codes (e.g.  ) covering a specific topic or theme such as history,  geology or forestry.  An   or school subject can define a  . A walk can consist of one or more themes. Whilst themed walks are often designed to encourage  , educational paths and   tend to be aimed more at educating or training.\n For nature-based themes, paths may be several kilometres long and may be used both for educational purposes and  . They may connect places, buildings or natural features that have a  particular theme in common by a signed route, but may also have specifically positioned  .\n For science themes, informal learning provides ways to engage in diverse settings.  For themes related to the nature,  features of nature (e.g.   or  ) or of   may be laid out as special  .\n For themes related to   or  , these walks provide objective interpretation of   encountered en route.\n Municipal authorities or local societies may be responsible for their establishment and maintenance. Other walks are managed by individuals who are highly knowledgeable in a theme, and host theme-based tours. \n In Austria there are more than 300 themed walks. These paths are intended to give summer   in the   a new impulse, but are also helping to improve the network of footpaths.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Ohio_University", "title": "Ohio University", "content": "\n  (  or  ) is a     with its main campus in  , United States.  The university was first   by the   and subsequently approved by the territorial legislature in 1802 and the   in 1804,  opening for students in 1809.  It was the first university chartered by an   and the first university to be established in the former  .  \n Ohio University comprises nine campuses, nine   colleges, a graduate college, a college of medicine, and a public affairs school. It offers more than 250 areas of undergraduate study  as well as certificates, master's, and doctoral degrees.  It is a member of the  . The university is   by the   and   among  .  As of fall 2020, the university's total enrollment at Athens was slightly more than 18,000, while the all-campus enrollment was just over 30,000. \n Ohio's intercollegiate athletic teams are known as the   and compete in the   (NCAA) at the   level as charter members of the  .    has participated in 16   through the 2023 season. The   has made 14 appearances in the  , with their most recent appearance in  . \n A university in the   was first envisioned by  , credited as the school's founder along with Revolutionary War Brigadier General  .  In addition to being instrumental in its founding, Putnam was also an original trustee of the university. Putnam Hall there is named for him.  Cutler had served as a   in  's  . The institution's first name was American Western University.  In 1797, settlers from   traveled downstream on the Ohio River and up the   to establish a location for the school in what the Congress designated as the  , founding Athens due to its location directly between the original capital of   and Marietta. In 1802, approval was granted by the territorial government for the establishment of the American Western University, but the school was not operated under that name. Ohio University was recognized by the new state on February 18, 1804, with its charter being certified by the  . This last approval happened eleven months after Ohio was admitted to the Union. The first three students enrolled in 1809. The first two bachelor's degrees were granted in 1815. \n Ohio University was closed between 1843 and 1848.  Women were first admitted to the university in 1868. In 1874, the   created the new   in   as a   upon passage of the   of 1862. At that time some representatives proposed that both Ohio University and   be demoted to preparatory schools.  In 1880, it was instead suggested that Ohio and Miami be merged directly with Ohio State, but the 1896 Sleeper Bill, introduced by Athenian  , the speaker of the Ohio House of Representatives, provided annual support for the university; this set the precedent for continuing state support of Ohio University.  A second challenge was defeated in 1906. The 20th century saw dramatic growth in student enrollment, academic offerings, and research facilities. Between 1955 and 1970, undergraduate enrollment tripled from 7,000 to 20,000. During this era, the campus grew, with the construction of 25 new dormitories located on two new residential college greens, with radio and television stations, research and classroom facilities, and the construction of the 13,000-seat   arena. Ohio University ranks among the top 25 largest residential college campuses in the United States, and the 5th largest in total campus size after acquiring acreage from adjacent hilltop properties in the 1990s.\n Ohio restructured its two colleges into five in 1935, establishing the colleges of Commerce, Fine Arts, and Applied Science in addition to the existing colleges of Arts & Sciences and Education. The graduate college was created in 1936, and the first   program was initiated in 1956 in chemistry.  Starting mid–century, the university also began to establish regional campuses throughout southeast Ohio. The first,  , was opened in 1946 to help eliminate post-  overcrowding on the university's main campus. The school began with 281 students, 70 percent of which were armed services veterans. Later campuses would come in 1946 at  , 1956 in   and  , 1957 in  , and formerly   in 2006.\n In 1964, U.S. President   publicly referenced his   initiative for the first time on the  ,  giving the university exposure across America and internationally. On May 4, 1970, the   was ordered to   demonstrating against the   at  , killing 4 and wounding 9. At the same time, there were sit-ins and anti-war riots at Ohio University, even more intense than those of Kent State. This was partly due to the administration's refusal to close the university; instead of going home, many students from other Ohio universities that did close came to Athens to protest further. When the Ohio National Guard was called in to Athens, there was a 3-hour battle at the Baker Center, resulting in 23 injured and 54 arrested students. On May 15, the campus was closed.  Alden Library was completed in 1969. In 1975, Ohio established its medical school, known as the  . Heritage is the only   in the state to award the   degree. In 1979, on the university's 175th anniversary,   of Japan donated 175 cherry trees.  The Ohio University Innovation Center, a technology business incubator, started in 1983. The Ohio University Edison Biotechnology Institute was founded in 1984. In the Glidden administration, from 1994 to 2004, new construction included the Life Sciences Research Facility, Emeriti Park, Walter Hall, plus major renovations to Gordy Hall, Grover Center, and Memorial Auditorium; the expansion of Bentley Hall and Copeland Hall; and groundwork for the new Baker Center that opened in 2007.  In the Fall of 2012, Ohio University converted its academic calendar from quarters to semesters, after first having changed to quarters in 1967. \n The main residential university campus is in Athens, Ohio, overlooking the  .  Constructed under the  ,   and   themes are prevalent in the university's earliest architecture.  Development of the campus began in 1812 with the erection of the university's central building,  , a registered national landmark, and built only 20 years after the White House. Cutler Hall's University Chimes, replacing an existing old cast iron bell, chime on the half hour every day until 9:00pm. The original bell, the 3rd oldest university bell in America, which is still hung in the Cutler Hall Cupola, rang to signal the start and end of the school day, as well as to signal the end of different class periods. Cast in the early 1800s, it served the university for well over a century.\n The historic College Green is the centralized quadrangle lawn and location of significant campus buildings:  , the Office of the President; Wilson Hall, the  ; McGuffey Hall, named for  ; and the College Gateway.  These three original primary structures are featured elements of the official current university logo and maintain true to their original design of over 200 years ago. The College Green has changed little in the past two centuries, which contributes to the university's colonial appearance. The green, inspired by the university founders, is based upon the classic layout of traditional English and New England towns and similar to university quadrangles.  College Green features Galbreath Chapel, the spire of which, topped with a brass weather vane, is modeled after that of the portico of Nash's   in  . Other buildings on the College Green include Chubb Hall, home to Undergraduate Admissions as well as the Offices of the Bursar and Registrar; Ellis Hall, home to the departments of English,  , Religious Studies, and Philosophy; Templeton-Blackburn Memorial Auditorium; as well as Bryan Hall, an upperclassman residence hall. The University Sundial, located behind Galbreath Chapel, was constructed in 1907 and marks the original location of the university's first building. College Green is framed by two main university gateways. Alumni Gateway, built in 1915, features the text \"That thou Mayest Grow In Knowledge, Wisdom and Love,\" borrowed from the Latin phrase inscribed over a gateway to the   and was dedicated upon the 100th anniversary of the university's first graduating class.  The newer College Gate, built in the 1960s, features words taken from the Northwest Ordinance of 1787 regarding public education. Traditions surrounding College Green include the latter half of first year convocation, where students, led by the  , march up Richland Avenue, onto Presidents Street, turning north onto Court Street, and entering the Green through the College Gate at the corner of Court and Union Streets. From there, a large involvement fair is held where students find clubs they wish to join.\n The John Calhoun Baker University Center, which opened in January 2007, is named after the 14th president of the university. The facility replaced the original Baker Center located on East Union Street across from College Green and serves as the hub of campus activity. Electronic maps and virtual university e-tours, available at center information desks and online, direct visitors across campus.  The building features     and large windows that admit natural light and afford expansive views of the southern and western sides of the campus. In contrast to the exterior's red brick and white columns, the interior has a more contemporary style with high domed ceilings.   mosaics of aspects of the earth's globe are embedded in the atrium of the main entrance to the building. Baker Center contains a large food court called West 82; a pub bistro called Latitude 39; a Grand Ballroom; The Honors Collegium, The Wall of Presidents, the Bobcat Student Lounge, a shop called Bobcat Depot that sells apparel, computers, and accessories; a theater seating 400; study areas; computer labs; administrative offices; and numerous conference rooms. The Front Room, a large coffee house named after a former popular university  , features a stage, artwork and a community fireplace. It serves Starbucks products and university bakery items and is housed on the fourth floor, which opens onto its own outside terrace as well as onto the intersection of Park Place and Court Streets, making it a popular spot for students between classes. Other amenities include a United States Post Office  and the Trisolini Art Gallery, named after a prominent fine arts faculty member. \n There are twelve residence halls on East Green.  This area of the university is the oldest residential green and includes three of the steepest walkways at the hilly Athens campus: Morton Hill, the Bryan Hall terrace and staircase, and Jefferson Hill. Each walkway affords East Green residents access to classrooms if they are willing to walk or bicycle. East Green is also home to Shively Court, a newly renovated dining hall with dine-in, take-out, and grab-and-go options.  East Green includes Jefferson Marketplace with several food vendors. \n South Green includes areas near Emeriti Park, and extends along the Hocking River valley. There are eighteen residence halls on South Green, following the addition of four new residence halls in the summer of 2015. \nSouth Green is home to several facilities, including:\n West Green includes buildings around the western part of the Athens campus.  The Ohio Athletic Mall spans the western portion of the campus, near the end of the Athens bike path at the Union street crossing. The mall features lacrosse, baseball, track, field and related athletic venues. Along the surrounding Hocking River is a series of   trees planted to commemorate the university's historic partnership with  . Japanese students sponsor an annual \"Sakura Festival\" each year, a cultural event celebrating the visually dramatic blossoming of the cherry trees and their evening lightings. Nearby Bicentennial Park features  , a landscape artwork by artist  .\n Anchoring the West Green quadrangle is the Stocker Center, which houses the Russ College of Engineering and Technology.\n There are eight residence halls on the West Green.  The West Green also includes:\n The Charles J. Ping Center is one of the largest recreational facilities in the nation.  Covering 168,000 square feet (15,600 m ) on three floors, Ping houses a 36-foot (11 m), double-sided climbing wall, five basketball/volleyball courts, two multipurpose gymnasiums, an elevated four-lane indoor running track, eight racquetball courts and an enclosed glass fitness area. Ping Center also provides free weight and cardio rooms, aerobics and fitness classes, combative sports, dance, meeting rooms and personal training.  The recreation center also houses club sports and intramural sports. Construction began in 1994 and it opened in January 1996. Ping was named in honor of the 18th president of Ohio University, Charles J. Ping. Ping is also one of the largest student employers on campus. \n The first regional campus,  , was opened in 1946 to help eliminate post-World War II overcrowding on the university's main campus. The school began with 281 students, 70 percent of which were armed services veterans. Today, more than 9,800 students attend Ohio University's five regional campuses:\n Ohio University maintained the Proctorville Center, which was opened in April 2007. It was acquired by the Collins Career Technical Center in October 2023.\n The   operates two campuses in addition to Athens:\n The Athens campus is organized by its 12 degree-granting academic colleges and schools, the Ohio University Libraries system, and various support services. The   is the largest academic division at the university, host to a broad range of   courses in the  , the  , and the   as the foundation for all undergraduate degrees.\n The   is home to the university's highly ranked programs in the traditional fields of engineering at the undergraduate and graduate level.  It enrolls approximately 1,400 undergraduates and almost 300 graduate students. It is named in honor of Fritz J. Russ, an alumnus in electrical engineering and the founder of Systems Research Laboratories, a major bioengineering concern. \n The Scripps College of Communication comprises five schools and one research lab: The  ,  the J. W. McClure School of Information and Telecommunication Systems, the School of Communication Studies, the School of Media Arts and Studies (formerly the School of Telecommunications), the School of Visual Communication (VisCom), and the Game Research and Immersive Design (GRID) Lab.\n The College of Business offers nine different majors and a general business minor for students with non-business majors, as well as the \"OHIO MBA\" in a variety of learning formats. Copeland Hall, seat of the college, maintains six computer labs and two study lounges with computers, as well as many conference rooms and small group rooms for an intimate, collaborative team atmosphere. All business classes are taught by professors instead of graduate students.\n The College of Fine Arts offers academic programs in art, dance, film, interdisciplinary arts, music, and theater. The Ohio University School of Music celebrated its 100th anniversary in 2017. The university's film program is located within the School of Dance, Film, and Theater in the College of Fine Arts. The Kennedy Museum of Art is housed at   in Lin Hall.\n The history of the Patton College of Education dates back to May 11, 1886. The Normal Department – the predecessor to today's College of Education – was the first state-supported teacher preparation program in Ohio. The state's first kindergarten opened on the Ohio University campus in 1907. Today, the College of Education is organized into three departments: Counseling and Higher Education, Educational Studies, and Teacher Education. The college currently serves more than 2,100 undergraduate and 800 graduate students.  On July 1, 2010, The Patton College became the home of several programs previously housed in the College of Health and Human Services, creating two new departments: Human and Consumer Science Education, and Recreation and Sport Pedagogy. \n The   offers programs in 34 disciplines, ranging from journalism to astrophysics. The Office of Nationally Competitive Awards is housed in the college.  It is based on the British   typically found at undergraduate colleges, where students are placed either one on one or in small group instruction.\n  was established in 1975.  It is the only osteopathic medical college in the state, and offers the degree   (D.O.). The college is accredited by the  .  In 1993, Barbara Ross-Lee was appointed to the position of dean of the Heritage College of Osteopathic Medicine; she was the first African-American woman to serve as the dean of a U.S. medical school. In 2014, alongside pre-eminent training partner OhioHealth,  the college opened a second medical school campus in Dublin, Ohio.  In 2015, the college opened a third campus in affiliation with Cleveland Clinic  at Cleveland Clinic South Pointe Hospital in Warrensville Heights, Ohio.  Approximately 120 medical students train at the Athens campus, 70 in Dublin and 60 in Cleveland.\n The College of Health Sciences and Professions was established in 1979, and is the home for departments of exercise physiology, dietetics and nutrition sciences, physical therapy, athletic training, health studies, nursing, rehabilitation and communications science, social and public health, and social work.\n University College was established in 2004.  The college comprises students who design a major program with faculty approval and awards the Bachelor of Specialized Studies (BSS) degree. The University College faculty are from various disciplines.\n Several research programs and institutes allow students to learn from scientists and scholars who are actively engaged in advancing their disciplines. Ohio University's Board of Trustees-approved research centers and institutes cover a broad range of disciplines.\n The College of Arts & Sciences sponsors the African American Research and Service Institute, the Astrophysical Institute,  the Contemporary History Institute, the Charles J. Ping Institute for the Teaching of the Humanities, Center for Intelligent Chemical Instrumentation, the Nanoscale and Quantum Phenomena Institute,  the Institute for Applied and Professional Ethics, Institute for the Empirical Study of Language, the Institute of Nuclear and Particle Physics,  the Ohio University Cartographic Center, the Institute for Quantitative Biology, and the Center for Ring Theory and Its Applications. The Center for International Studies was established in 1964.  The George Washington Forum on Ideas sponsors exchanges on a wide range of topics  and the university launched the Global Leadership Center to engage students from any major in a wide variety of global impact projects during their studies. \n The Heritage College of Osteopathic Medicine sponsors the Institute for Neuromusculoskeletal Research, Tropical Disease Institute,  Edison Biotechnology Institute, and Appalachian Rural Health Institute.\n In Engineering and Technology, Ohio sponsors the Institute for Sustainable Energy and the Environment, the Center for Advanced Materials Processing, the Center for Advanced Software Systems Integration, the Automatic Identification Education and Research Center, the Avionics Engineering Research Center,  the Institute for Corrosion & Multiphase Technology,  the Center for Intelligent, Distributed and Dependable Systems, the Ohio Research Institute for Transportation and the Environment, and the T. Richard and Eleanora K. Robe Leadership Institute.  The Condensed Matter and Surface Science  program supports research in condensed matter and materials physics. The Nanoscale and Quantum Phenomena Institute  (NQPI) supports research in diverse aspects of nanoscience and quantum mechanical phenomena in nature.\n The College of Business sponsors the center for eBusiness,  the Center for International Business Education and Development, the Ohio University Insurance Institute,  the Center for Sports Administration,  and the Schey Sales Center.  The university also has a business incubator and innovation center.\n In Scripps College of Communications disciplines, Ohio sponsors the Institute for International Journalism, the Scripps Survey Research Center,  the Telecommunications Center, and the Institute for Telecommunication Studies.  The College of Communication also sponsors the Game Research and Immersive Design (GRID) Lab, an initiative of its Scripps College of Communication, providing Ohioans the training, education, and opportunity to develop technical and creative skills with digital game technology. The GRID Lab serves as an innovative and creative center for undergraduate and graduate students, faculty, and staff research and project development. It was founded by various faculty and staff from the School of Media Arts and Studies. \n In Education, Ohio sponsors the Center for Cooperative Curriculum Development and Partnerships, the Institute for Democracy in Education,  the George Hill Center for Counseling & Research,  the Center for Higher Education, the Child Development Center,  and the Edward Stevens Center for the Study and Development of Literacy and Language. \n Vernon R. Alden Library serves the Athens campus as the central  , staffed with research librarians. Several smaller libraries serve various departments, as well as collection libraries within the Alden Library building. Also housed within Alden Library is the Ohio University Press, Ohio University's publishing company. Each regional campus has its own library and printed text collections. The collection of Ohio University's library contains over 2.3 million units of microfilm material, 13,500 periodical subscriptions and more than 4 million printed volumes,  making it one of the 100 largest libraries in the United States. Alden Library was the first in the world to generate an electronic library record in 1971.  The university maintains a complex system of archives in its libraries.  The Robert E. and Jean R. Mahn Center for Archives and Special Collections maintains and displays rare books and collections, including a 14th-century  .  Laptops and other accessories are available through technology services at the reference desk. Outside Alden Library and directly behind Cutler Hall is Wolfe Garden, a small enclave in the shape of the State of Ohio, which features native Ohio trees and plants.\n Ohio University maintains its own police department.  Operating out of 118 Ridges Circle (the Ridges, Building 13, first floor), the Ohio University Police Department (OUPD) is a fully-fledged, independent law enforcement agency with 31 sworn officers, 5 dispatchers, and 2 administrative support personnel.  It has patrol and investigative divisions, two explosive detective canine teams,  a SWAT team,  and are members of the Athens-Hocking-Fairfield Major Crimes Unit.  OUPD was certified with the   on January 27, 2017. \n Academe at Ohio University comprises its thirteen degree granting colleges and centers.  \nThe university   includes the traditional pillars of  ,  ,  ,  , and  .  Freshmen formally enter the university with their annual convocation and march beneath Alumni Gateway along with university officials. The university is nationally known for its   programs, as well as its journalism, business, and medicine programs. Additionally, it maintains five branch campuses, two regional medical campuses in   and  , and an engineering research and development center in  . The total university student enrollment is in excess of 36,000, encompassing its main campus in Athens and regional campuses; its body mostly hails from the   and   and graduated from public high schools. Undergraduate admissions are more selective with further admission requirements for its journalism and other select schools.  The   maintains separate select admissions criteria and is the most selective college at the university. Ohio University is accredited by the   and   among  .    has recognized the university as one of the top producers of   by type of institution, with the highest number of recipients in the state as well as the Mid-American Conference in 2011–12.  Ohio University was recognized by the U.S. Department of State's   as a top producer of 2014–2015 Fulbright U.S. Students.  Since 2008, 16 students have won the  ,  32 students have won the   and 94 students have become   U.S. grantees.  One alumnus has shared the Nobel Prize. Ohio faculty has achievements ranging from the first university to successfully accomplish a   DNA injection, to Francis Bundy's work on early synthesis of diamond  to   celebrated  . Some sense of research achievements at Ohio University can be seen in the biographies of the Edwin and Ruth Kennedy  Distinguished Professors  appointed annually since 1959.\n Undergraduate admission to Ohio University is classified as \"selective\" by both the   and     gives Ohio an \"Admissions Selectivity Rating\" of 85.  The university extends offers of admission to, on average, around 85% of all applicants yearly after holistic review that includes examination of academic rigor, recommendations, essays, and high school performance, and admissions test scores, when submitted.  The university no longer requires test scores and does not publish average tests scores for public release. Ohio University admitted 85% of all applicants, including first year and transfer students, for the incoming 2022 class.\n The Class of 2026 enrolled as Ohio University's largest class, coming from all 50 states. \n  \n The Ohio University Marching 110 is the official marching band of Ohio University, founded in 1923 and based out of the College of Fine Arts. The nickname Marching 110 is a reference to the band's original number of members; modern bands consist of approximately 225 members. The 110 represents the university at various athletic functions and other events. The Marching 110 became the first collegiate marching band to perform in   in 1976. In January 1993, the 110 performed in  's first inaugural parade through  , after Clinton asked campaign chairman and Ohio University alumnus   for the band to perform.  Other notable performances include the   in 2000, 2005, and 2017, as well as the 2010  .\n Athens' annual     is the most well-known and far-reaching tradition, with Ohio University providing support services for the thousands of partiers who attend. Among more traditions which students enjoy being involved in each year are  , with its grand   through the streets of Athens and activities that allow students to mingle with alumni. International Week in the Spring features another colorful parade and festivities along Court Street. The Student Activities Commission (SAC) sponsors a yearly springtime concert with prominent musicians, usually held at the Convocation Center. The university community is well known for its unofficial springtime fests and concerts, as well. Other traditions include the Kissing Circle on College Green, a tradition where couples will kiss on College Green to solidify their relationship so it becomes a \"Bobcat Bond;\" the week of Hellenic \"rushing\" in the Fall, for freshmen to become sorority and fraternity members; and the entire month of April featuring ecological advocacy and   awareness programs across all campuses. \n Students maintain a variety of organized and independent service events.  The Community Service Leadership Council involves students to oversee a Project of the Week every Saturday. The projects have included work with Good Earth Farms, Last Chance Corral,  ,  ,  ,  ,  ,  ,  , the Survivor Advocacy Program, and the Thursday Supper Volunteer Corps, among others. Charities at Ohio University have involved flag football tournaments and the 5K Flour Run, and have benefited O'Bleness Health System's Women's Health Fund and the Athens Backpack Program, respectively. Student Senate's Beautification Day regularly receives a large turnout and is particularly unique in the Spring.  In early 1962, President   signed the first of several contracts with the federal government to facilitate   volunteer training programs. Today, Ohio University hosts a recruiting office for the Peace Corps in a tradition affiliated with that organization since  's visit. \n The university operates the  , publishing on a range of subjects.  Students operate a newspaper, television, radio stations, numerous online sites, among more media, at Ohio University. The main newspaper,  , publishes in print once a week and online all days of the week while the university is in session, and is officially independent of the university and its administration. Ohio University Public Television is a   affiliate broadcasting on  . In addition to national PBS programs, WOUB features  , a nightly news broadcast with student reporters. Other student-produced programs include   (following the Southeastern Ohio and parts of West Virginia high school football season, the recipient of many Emmys) and   (following the   during the year). WOUB also airs  ,  a radio show and podcast featuring stories wherever \"campus meets community.\"   91.3 Athens, WOUC-FM 89.1  , WOUH-FM 91.9  , WOUL-FM 89.1  , and WOUZ-FM 90.1   broadcast the same programs throughout southeastern Ohio. Separate public radio programming is also heard in Athens on   AM 1340. ACRN (\"The  \"), founded in 1971, is an  -only station and the university's only  .  Ohio University has an   (also known as ham radio) club, the Ohio University Amateur Radio Club, call sign W8PZS, that operates out of Stocker Center.    is a web publication with the latest news on campus and state politics.    is the   quarterly and   is the campus periodical about  ; both are written by undergraduates.    is the official university magazine for alumni and friends,  and   is its female-reader digest.  The university also publishes the OHIO News page,  the institution's official online news and information resource.   is the official online publication of the  .  OIT (Ohio  ) is the university tech depot and  , responsible for a wide range of duties from CatMail (campus email) to hosting official websites. \n Ohio University sports began in 1894 with an 8–0 loss to   in  . The university competes in the major   (NCAA) at the   level and is a charter member of the   (MAC), established in 1946, and remains the sole charter member competing in the conference. University intercollegiate athletics include six men's squads and eight women's squads. At the national level, Ohio University defeated 4th-seeded   in the  . They followed up that with a 62–56 win over 12th-seeded  , reaching the   for the first time since 1964. All university sporting events are open to students at no additional charge.  Ohio's men's and women's athletics teams compete under the official colors of hunter green and white. The school mascot is Rufus the Bobcat, and a life-sized sculpture of a bobcat stands poised at the entrance to Peden Stadium.\n The 13,080-seat   serves as home to the university's   and   teams, as well as women's volleyball teams.\n The first Ohio basketball game occurred in 1907 when the Bobcats defeated the   46–9. Since that day, Ohio has posted a .571 winning percentage over their 100-year history and a .566 winning percentage in their 65 years in the Mid-American Conference. The Bobcats have won 7 Mid-American Conference tournament titles in  ,  ,  ,  ,  ,  , and  ; as well as 10 MAC regular-season titles in 1960, 1961, 1964, 1965, 1970, 1972, 1974, 1985, 1994, and  . In addition, Ohio has played in the   14 times, appearing in  ,  ,  ,  ,  ,  ,  , 1983, 1985,  ,  ,  ,  , and  . The Bobcats have been selected for the   5 times in   (runner-up),  ,  ,  , and  , while also appearing in the   in   and  , they made 2 appearances in the   in   and  . Prior to joining the MAC, the 'Cats won an Ohio Athletic Conference title in 1921 and three Buckeye Athletic Association championships in 1931, 1933, and 1937. As a result of the storied tradition of Ohio Bobcats basketball, the program was recently ranked 86th in  , published in 2005. \n The team has won three MAC Tournaments (1986, 1995,  ) since beginning play in 1973 and starting MAC play in 1982. They have reached the NCAA Tournament in those three championship years. They have four MAC conferences (1986, 1995, 2015, 2016) and four-division championships (2015, 2016, 2019, 2020).The women's team was the first team to win 30 games during the   going 30-6 losing in the quarterfinals of the  .\n Ohio Bobcats football began in 1894 with an 8–0 loss to  . They most recently triumphed over the   with a score of 41–21 in the   in 2023; another impressive win to come in 2023 was over   of the  . Since 1894, the Bobcats have posted a 584–580–65 (.502) record and a 252–248–12 record in the  .  , built in 1929, is the oldest football venue in the MAC and among the oldest in the nation. Located on the south of Ohio University's campus in Athens, the venue has a   of 27,000, with the addition of the Sook Student Center at south end of the stadium. At the suggestion of alumnus Michael Massa, Peden Stadium was designated an Official Ohio Historical site in 2010. Many recent renovation and expansion efforts have allowed the stadium to keep pace with the ever-changing landscape of college football stadiums.  As such, Peden Stadium is nicknamed \"The   of College Football\".  The stadium brought its largest crowd on September 8, 2012, when 25,893 fans were in attendance to watch the Bobcats decisively beat the   by a score of 51–24.  This mark overtook the previous record set on September 5, 2009, when 24,617 fans were in attendance to watch the Bobcats drop a 23–16 decision to the  .  The Bobcats have won five MAC Football championships in 1953, 1960, 1963, 1967, and 1968, and MAC East Division championships in 2006, 2009, and 2011. Prior to joining the MAC, the Bobcats won six Buckeye Athletic Association championships in 1929, 1930, 1931, 1935, 1936, and 1938. In 1960, the Bobcats were crowned National Small College Champions after compiling a 10–0 record under Coach Bill Hess. The Bobcats have appeared in several bowl games, losing 15–14 to   in the 1962  , losing 49–42 to   in the 1968  , falling 28–7 to   in the 2007  , losing 21–17 to   in the 2009  , and losing to Troy in the 2010  , 48–21, before finally winning a bowl game in the 2011   against Utah State, 24–23. The bobcats took down the   in the   30–27 in overtime.\n There are 36 active club sports programs at Ohio, run out of the Department of Campus Recreation. Club sports include sports for all genders, including co-ed sports. \n Ohio University has over 300,000 living  . Presidents of countries, Nobel Prize winners, senators, Pulitzer Prize winners, generals and astronauts are counted among its ranks. Among these distinguished alumni are Worldwalker  ;  , who discovered the  ;  , recipient of the 2009 Nobel Prize in Chemistry and president of the  ;  , former Ohio governor and U.S. senator for Ohio; and  , first graduate of Ohio University, the first Secretary of the Interior, a U.S. senator for Ohio and Secretary of the Treasury under U.S. President  .  Eighty-four Scripps College of Communication alumni have won or contributed to  .\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Youth_sports", "title": "Youth sports", "content": " is any   event where competitors are younger than   age, whether   or  .  Youth sports includes school sports at   and   level, as well as sports played outside the education system, whether informally or organized.\n In   and   contexts, an age limit of 18 (the  ) is usual in discussing \"youth sport\". Not all   define \"youth\" as \"under-18\": while the   and the   are for under-18s, the   is for under-17s. Many youth sport programmes have multiple age levels, for example under-8, under-10, under-12, etc. It is not, however, only   that may be considered as \"youth\" sport; for example, the existence of the   recognises that adults aged 18–22 have not yet reached peak condition. Moreover, many definitions consider postsecondary/collegiate students ranging from the ages of 17 to 25 participating in sports to be \"youth\" as well.\n Sport is one of the most popular activities among youth all over the world.  The most popular sports are  ,  , running and swimming.   In 2008, a  -sponsored report on \"Sport for Development and Peace\" stated: \n According to WinterGreen Research, the size of the U.S. youth sports market has grown 55 percent since 2010 and is a $15.3 billion market in 2017. \n Participation in organized sports during childhood  and adolescence has important benefits for physical, psychological, and  . Sport-based youth development programs outside of school promote a wide range of learning and life skill development. Involvement in youth athletics encourages youth to live a healthy and happy lifestyle, foregoing the common issues many youth face such as obesity and depression.  However, sport involvement goes beyond health, other benefits allow them to form and strengthen affective relationships, teach youth to value self-improvement over winning, how to be competitive in a competitive society, and to work culturally with different peers and authorities.  In the classroom, high school student-athletes are far less likely to drop out of school and 15% more likely to attend college. \n The practice of sport fosters young people's physical and   and builds valuable social connections.   It also offers opportunities for play and self-expression especially for those young people with few other opportunities. Sport also acts as a healthy alternative to harmful actions such as  , and involvement in crime. Beyond the individual, sport involvement cuts barriers that divide societies, making it a powerful tool to support conflict prevention both symbolically on the global level and practically within communities. \n Communication plays a critical role in the development and success of youth sport programs. Effective communication among youth athletes, coaches, and parents improves team cohesion, facilitates skill development, and creates an environment that promotes physical, social, and emotional growth. \n Verbal communication includes direct instructions, feedback, motivational speeches, and discussions. It should be clear, concise, and appropriate for the age and comprehension level of the athletes. Nonverbal communication, encompasses, body language, facial expressions, gestures, and eye contact, which are important for reinforcing verbal messages, showing empathy and building rapport with athletes.\n Written communication involves the use of training plans, feedback forms, emails, and other written materials to convey information. This type of communication ensures that important information is recorded and can be referred back to enhancing understanding and consistency\n Coaches and athletes should practice active listening to ensure mutual understanding and respect. This involves giving full attention, acknowledging messages, and providing appropriate responses. Emphasizing positive behaviors and achievements helps in building confidence and motivation among youth athletes.  Maintaining consistency and transparency in communication helps in building trust and credibility within the team. Incorporating visual aids such as diagrams, videos, and demonstrations can enhance understanding and retention of information.\n The number of dropouts reaches a peak in the adolescent years.  The most important reason for not playing sport are \"not having enough time,\" \"no interest anymore,\" and \"other leisure activities\". \n Negative experiences can be created through a sport that is overly focused on competition and winning at all costs or that fails to place the healthy development of youth at the center of the experience. Such negative experiences may result in a young person's low self-esteem, involve them in negative relationships, encourage poor sportsmanship, permit aggression and violence, allow racism, perpetuate gender discrimination, or expose them to psychological, sexual and commercial exploitation and abuse.  Many of these negative experiences can be avoided when parents and coaches are chosen carefully, ensuring that programs offer a positive development experience for youth.\nIn response to the evidence of negative experiences in sport for many youth, especially low-income youth, youth of color, overweight youth, and LGBTQ youth,   (SBYD) emerged. Sports-based youth development is a theory and practice model for programs to place the mental and physical health of a youth over their athletic success.  Programs that use SBYD to define program activities and train staff members generally provide free or reduced-cost programming to reduce the barriers low-income youth face when playing sports. These programs are typically found in low-income and under-served neighborhoods, but any sports coach or sports program can apply SBYD principles.\n Injuries have always been of concern in terms of sport but youth are much more susceptible to injury considering both their immature musculoskeletal system and increasingly high intensity training. According to the U.S. Centers for Disease Control, participation in organized sports is on the rise. Nearly 30 million children and adolescents participate in youth sports just in the United States.  This high rise in sport participation has led to some startling statistics, high school athletes account for an estimated 2 million injuries, 500,000 doctor visits, and 30,000 hospitalizations each year. The most common types of sports-related injuries among youth are sprains, muscle strains, bone or growth plate injuries, and   .\n  has long been typical among children and teenagers in gymnastics, swimming, diving and figure skating, especially if they have aspirations of being competitive at elite levels.  Undeniably, the main purpose for athletes to specialize in sport is to become a better player in order to increase their chances of making it to the big leagues or to become an elite athlete. Unfortunately, the data does not prove that specializing as a youth will be enough to make a child into a successful athlete later on (Latorre-Roman, Pinillos, & Robles, 2018). Youth athletes that are considered less specialized have been found to exhibit more all around athleticism and other advantages that specialized athletes do not benefit. (Rugg, Kador, Feley, & Pandya, 2018). Studies have supported that decreasing specialization at a young age will lower the rates of injuries for the players while increasing playing times and length of careers compared to athletes who specialized as a youth (Rugg, Kador, Feley, & Pandya, 2018). Still, sport specializers tend to dramatically outweigh those who stayed multi sport athletes because of the standards people place on sports and how valuable a sports career can be. As youth athletes exhibit skills at higher levels than there peers at a young age, parents, coaches, and the athletes themselves tend to focus on that sport in order to take advantage of their natural skills. parents, coaches, and athletes should know that showing promise in sport from a young age does not guarantee future success as competition levels rise and the athlete develops as a person (Latorre-Roman, Pinillos, & Robles, 2018).\n Noting that specializing in a sport at a young age by no means guarantees success, it is most important understand that sport specialization in youth can lead to higher injury rates throughout ones sports career (Mcguine et al., 2017). Research has found that high school athletes that specialize in one sport are more likely to be injured than athletes that play multiple sports (Mcguine et al., 2017). Further, students who were classified to play moderate amount of sports were found to have less injuries than those who specialized in only one (McGuine et al., 2017) This helps to emphasize the importance of sport diversity in youth athletes and its impact on preventing injuries. Looking at sport specialization more in depth, researchers have suggested that athletes, coaches, and parents monitor the weekly, monthly, and yearly participation rates for youth athletes in a single sport (Post et al., 2017) It is generally recognized that athletes should not participate in more than 8 months worth of intense sport practice and no more than an athlete's age in hours of practice a week (post et al., 2017). Also, experts recommend that all athletes engage in a wide variety of athletic activities, including unstructured athletic activities such as playing outside, until at least the age of 15.' \n Teenage athletes have been pushed by parents and sport programmes to train excessively and to dedicate an enormous amounts of time and money to sport.   Some youth report playing up to eight football games per week, sometimes in the hope of earning one of a few university scholarships.   Sleep, schoolwork, family time, and other normal activities are sacrificed to sport. \n A few countries are beginning to regulate sport programmes to reduce this problem.   , which has a strong track record in the Olympic Games, is seen as a model.   In 2018, after the death of an apparently healthy but exhausted teenage athlete, the government of   required that all youth sport programmes be regulated.   Under the initial rules in Puerto Rico, children under the age of 9 cannot play in tournaments or officially keep score, and youth under the age of 16 cannot play more than three games per week.   As of 2020, there is widespread sentiment that the overall system must change, but programmes in each of the regulated sports, and the coaches and other staff whose pay depends upon operating these lucrative tournaments and expensive travel teams, are lobbying for exemptions that will permit their own businesses to continue as before. \n  nations tend to have less access to organized sports because the politics of their countries do not have the resources to have leisure and entertainment influence their lives.   Children in Global South nations have less opportunity to attend school where majority of organized sport takes place.  Sport programs within the community provide children marginalized by poverty, gender, disability, family dissolution, ethno-cultural background and conflict with family, crime and other lack of opportunity. \n In Global North nations, the evolving and complex youth sport system requires significant resources such as time, access, and money to develop as an athlete and play competitively.  The financial costs involved in facilitating organized sport at an elite level ranges from an average of a few thousand dollars per year, to more than 20,000 dollars per year in some sports. For these financial reasons, participation is not feasible for a majority of kids growing up in lower income families.\n In recent years, youth sports have become more expensive in the United States.  The financial burden of organized sports has grown, and children from low-income families are less likely to participate.  The single greatest predictor of whether a child will start playing organized sports young, is whether their household income exceeds $100,000 per year. \n Gender conditioning often starts at an early age where boys and girls are taught behave differently and participate in certain activities. While there is no doubt that girls' sport participation has skyrocketed in recent decades, a   in youth sports still exists.  The \"separate but equal\" ideal of   is very much prevalent in society and its contradictions inherent a strategy that pushes for both individual equal opportunity and categorical separation of the sexes.  Team sport participation peaks at age 11 and participation in sport by girls are high and continuing to increase. However, frequent participation by both boys and girls in team sports is declining. \n Girls are more likely to enter sport later than boys and are more likely to take part in cheerleading, dance, competitive jump roping and volleyball while boys tend to stick with more traditional sports such as baseball, basketball and football. No matter the sport, the benefits of participating remain. With this said, the gender gap in the   is much larger than that of the   based on significant power relations and religious beliefs, specifically within Muslim communities in countries like  ,  ,  ,  ,  ,   and  . For many,   is a way of life in which sporting and educational institutions are culturally constructed by cultural and religious dynamics, as well as political, social, and economic factors. \n The gap between participation in sport in the   and the   can be due to a shortage of physical education, a lack of financing, few sport facilities and little equipment and no capacity to host major sporting event in the global south.  Other limitations for people living in certain countries may include a lack of accessible transportation, education and lack of understanding of the sport. There are also several social and cultural barriers faced by youth living in the   that impact sport participation. A few of these are religion, culture and language.\n There are typically two types of youth sport programs.  One is sponsored by schools and the other is sponsored by city recreational departments and agencies. Generally school sponsored programs have qualified coaches and dedicated facilities for their sports but that is not always the case.  Requirements for coaches for school sponsored programs vary from state to state, but the standard for the head coach of a major sport is usually a teaching certificate, with some coaching experience and training.  Non-school youth sports programs operate in a different way and use volunteers as coaches.  They have to find places to practice such as open gyms.  Youths in these programs are assigned or drafted to different teams depending on the program. \n The Sport for Development and Peace organization was found in research by Simon Darnell to have positive outcomes on the twelve-year-old boys participating in the program by promoting time management and personal responsibility.  This helped the boys fit into the goals of self-regulation required in   societies.  The nature of sport in itself also showcased leaders and those willing to make sacrifices for the sake of their team and also their families.\n The Culture, Education, Sport and Ethics program (CESEP) is an international outreach initiative to engage teachers and student from different countries and cultures in the dialogue of healthy sport. This program seeks to create collaboration among teachers, students under 18, and counselors to exchange ideas about sports and culture in an educational program. \n The International Olympic Committee's Sports for Hope program, located in  , enhances national sports development through organized sports competitions, camps and clinics.  They organize seminars for coaches and sports administrators as well as community development services.  The program has an educational component about important societal issues, including girls’ empowerment, civic participation, HIV/AIDS, malaria and other health issues for athletes and the general public. The center offers indoor and outdoor sports fields, lockers, a gym, a boxing hall, classrooms and a variety of sports.\n Youth athletics were popular in 20th-century America. In an attempt to \"energize America's youth and transform its fledgling bodies into healthy future citizens\"  recreation facilities for youth were created.    was based on the philosophy of sports and exercise strengthening the body which was the shelter of the soul.  This philosophy shaped the creation of   programs across America.  This led to the invention of basketball and volleyball in the late 19th century.  Also, the YMCA had a female counterpart, the YWCA. The   movement, \"found sports to be a useful tool to draw inner-city youth to their churches, which often housed gymnasiums.\"  The social gospel movement lead to the creation of settlement houses, where middle-class men and women would study the social problems of the neighbourhood and attempt to fix them.  The best known settlement house was Hull house in Chicago which had a community institution which attempted to Americanize immigrants.  At Hull house, \"they also provided a gym and sponsored athletic teams for both boys and girls, both as part of the acculturation process and the broader goal of improving the social, mental and physical well-being of inner-city residents. \n Social agencies such as the  YMCA and YWCA, as well as Boys and Girls Clubs, and Boy Scouts and Girl Scouts, provided most of the organized sports to youth in America prior to 1954.  While athletics was encouraged by the social gospel movement, youth sports were often organized by youth themselves through the social agencies.  This shifted to adults organizing youth sports programs, which was exemplified with the advent of Little League Baseball by Carl Stotz.  Little League Baseball was formed in 1939, with a three team league, while in 1954, there were 70,000 participants.  Evidently, organized youth athletics grew rapidly throughout the 20th century in America. There were multiple reasons to support youth athletics programs, but one that was mostly agreed upon was \"the notion of providing wholesome, character-building activities to occupy the leisure time of children and youth, to enable them to make the transition from childhood to adulthood.\" \n Within the 20th century, youth athletics were supported for their many believed positive aspects on youth culture. This included the fact that many believed participation in youth athletics would decrease delinquency. In 1965 Coleman wrote, \"if it were not for inter-scholastic athletics or something like it, the rebellion against school, the rate of drop-out, and the delinquency of boys might be far worse than they presently are.\"  Also, youth athletics were a way for Jewish immigrants to disprove the stereotypes that they were bookish and weak in the early 20th century.  Some Jews pursued professional careers in sports, which provided young Jewish Americans with role models who showed, \"the possibility and benefits of assimilation,\"  which encouraged more participation in youth athletics. Catholic youths were interested in youth sports to, \"demonstrate patriotism and morality.\"  Overall, both Catholics and Jews were attracted to youth athletics, to \"demonstrate American-ness and experience a sense of belonging in the United States.\"  As well as physical fitness, sports were also seen as a way to increase social and moral development in youth.  However, there remained some believed negative aspects of youth athletics. This included the fact that, \"premature sports insolvent may result in undesirable emotional consequences for children.\"  The stress placed on youths during sports could lead to frustration, discouragement and low self-esteem. \n Race has played a role within youth sports as it has enforced  , but it has also given opportunities to racial minorities.  In some ways, youth sports perpetrated segregation, as schools were segregated in the early 20th century.  Within African American neighbourhoods in America, there was not the same level of public and private sports facilities as in other neighbourhoods.  However, the streets and vacant lots became centres for youth sports.  Segregation and prejudice kept African Americans out of sports facilities, but sports also played a positive role. While schools and subsequently sports teams were created out of segregation, athletics could bring success and accomplishment to schools.  Sports were ways that members of the African- American community could gain self- esteem and a sense of community. \n Youth sports were an important way of life for Native Americans within boarding schools.  Sports for Native Americans living in boarding schools were so important that they were  on a similar level of importance as work and teaching.  School sports such as track and field, basketball, and wrestling were activities that some Native Americans felt pride in when they participated.  This pride was created by the appeal of competition and success, especially against white teams.  Former resident of a boarding school for Native Americans, Jeff McCloud's experiences in sports, \"helped him to critically read the pain and degradation of contemporary life on and off Indian reservations as something other than a flaw in Native American character or the inevitable outcome of historical progress.\"  Through these experiences, sport could be a positive aspect of the lives of Native Americans.\n Female youth athletics was advocated for in the early 20th century because it was, \"believed that sports improved young women's health and beauty, promoted self-confidence, and offered a source of enjoyment.\"  However, girls' sports was not supported by all Americans as some believed it would lead to injuries and girls acting too aggressive and manly.  During the early parts of the 20th century, some people felt that sport might reduce a girl's femininity and produce too much competitiveness.  Some sports, such as basketball, were modified for girls' play.  These modifications included eliminating physical contact and playing half-court games to limit exhaustion.  American girls participated in more organized sports after the passage of   in 1972 as they gained more opportunities to do so.  It has been stated that, \"among the many forms of sexism in sports, perhaps the most pervasive and devastating is the lack of equal opportunities for girls to compete in programs similar to those offered for boys.\"  Girls' participation remained much lower than that of boys, but it increased \"from 32 percent of the male's participation in 1973-74 to 63 percent in 1994-95.\"  While there are barriers to girls' participation in sports, it grew sizeably  in the 20th century.\n Youth athletics also affected the lives of boys as it could be used to define masculinity.  Sports were a way to promote bravery, and were tied to masculinity through Muscular Christianity.  Sports were even thought to reduce degeneracy as boys were thought to be becoming less brave than their forefathers by some.  Betty DeBerg believes that gender divisions increased as some feared that industrialization and city life were changing gender roles.  Sports were thought to be a way to increase masculinity in boys and to perpetrate social divisions. Furthermore, the masculine aspect of sports perpetrated through the 20th century, has continued an idea of homophobia.  Eric Anderson states, \"in a time of greatly decreasing cultural and institutional homophobia, institutions of sport have remained steadfast in their production of a homophobic and conservative gender ideology.\"  In 1997, a high school football player wrote that he faced, \"victimization and personal distress over the profusion of homophobia within his sport...\"  This homophobic environment lead to depression for the victim.  The heightened idea of masculinity has allowed homophobia to also permeate sports. Youth sports within the 20th century enforced masculinity on boys, as well as created an environment filled with homophobia.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Permanent_time_observation_in_the_United_States", "title": "Permanent time observation in the United States", "content": "\n Establishing either permanent   or   (DST) eliminates the practice of semi-annual clock changes, specifically the advancement of clocks by one hour from standard time to DST on the second Sunday in March (commonly called \"  forward\") and the retraction of clocks by one hour from DST to standard time on the first Sunday in November (\"  back\"). \n The   formalized the specification of   and the   in the United States. Prior to this law, time zones and DST observation in America were independent and erratic across states and cities.  The law requires states to change clocks semiannually between standard time and DST on federally mandated dates, and it permits states to opt out of DST observation altogether and remain on permanent standard time, but does not permit observation of permanent DST.    (with the exception of the  ),  , and all   observe permanent standard time.\n Studies have shown the semi-annual clock changes result in sleep disturbances, ultimately resulting in more health problems and traffic accidents.  Legislators in 25 states have attempted to switch to either permanent standard time or permanent DST. Currently more states are pursuing permanent DST. \n Prior to the nationwide implementation of DST in 1967, some American states observed permanent Standard Time. \nCurrently in the US, Arizona (with the exception of the  ), Hawaii, and all permanently inhabited territories ( ,  , the  ,  , and the  ) observe permanent standard time.  A number of states have proposed bills to restore observation of permanent standard time, but few have gained ground as of yet.  \n Permanent standard time is considered by   researchers and   experts worldwide to be the best option for health, safety, schools, and economy, including the  ,  ,  ,  ,  , Canadian Sleep Society,  ,  , and several state sleep societies.  Permanent standard time is supported by advocates for school children, including the  ,  ,  ,  , and  . They cite both the health benefits of circadian alignment, and the safety advantages regarding morning commutes.  \n Permanent standard time is also supported by   data, owing to evidence that DST observation increases morning heating, evening driving, and evening residential air conditioning, which all in turn increase energy consumption and pollution. \n A change in federal law would be necessary to allow states to observe DST permanently all year. A number of states have pursued state bills, resolutions, and referendums to indicate intention to observe permanent DST if federal law would permit it.\n In 2018, 2019, 2020, and 2021, Florida   Senator   introduced to Congress the \" \", a bill to permit states to observe permanent DST. The bill had achieved referral to committee, but had not received a hearing.  Also in 2021, Florida Republican Representative   introduced a daylight saving time for the whole country, by changing everyone's time zone forward by an hour (Eastern Time would become permanently UTC-0400 instead of UTC-0500). That bill also allowed states to opt out under certain conditions.  On March 15, 2022, Rubio's bill passed the Senate. \n As a work-around to the Uniform Time Act's prohibition on permanent DST, a bloc of states in New England has proposed a statutory move from the   to the   (Atlantic Time being one hour ahead of Eastern Time), and then abolishing biannual clock changes. If approved by the  , such a move would effectively put these states on permanent DST without needing to await amendment to the Uniform Time Act by Congress. Similarly, on the West Coast, Washington passed both a bill for permanent DST and an alternative bill to move the state's official observation from the   to the  . \n A meta-analysis by   researchers found that permanent DST would eliminate 171 pedestrian fatalities (a 13% reduction) per year.  DST has been supported by the Chamber of Commerce since 1915 attributing added sales and outdoor activity to sunlight in the evenings. Additionally, DST has been expanded to nearly 8 months of the year, effectively making it the new standard. \n Some have warned, however, that the decreased exposure to morning sunlight will have significant detrimental effects. Sleep researchers have likened the resulting increased fatigue to \"permanent [jet lag]\".  Experts such as   argue that permanent observation of DST significantly  increases rates of disease and accidents, and lowers productivity and wages.  In 2018, the  , the  , and the   released a joint statement to the EU Commission on DST in opposition to permanent DST and in support of permanent standard time.  The SRBR followed with its own more comprehensive statement and set of materials supporting the same position in 2019.  In August 2020, the   provided a statement on why they oppose permanent daylight saving time and favor permanent standard time. \nPoor sleep among workers costs the United States $411 billion annually, according to Rand Europe. This figure, which equates to about 1.23 million workdays lost due to insufficient sleep each year, ranks the United States first in terms of economic losses due to insufficient sleep. \n The idea of staying on Daylight Saving Time during winter months is opposed by certain religious communities, such as  , whose daily prayers and other customs are synchronized with times of sunrise and sunset. \n Permanent DST in the US was briefly enacted by president   in January 1974, in response to the  .  The new permanent DST law was retracted within the year.  Year-round daylight saving time was initially supported by 79% of the public, but that support had dropped to 42% after its first winter. \n The main argument for introducing year-round DST is that the lifestyles and work patterns of modern-day citizens are no longer compatible with the concept of shifting the clock every spring and fall. Supporters also argue that switching to ''Forward Time'' would also result in saving energy by reducing the need for artificial light.  The   of 2019 was introduced in the Senate by Senator Marco Rubio (R) of Florida to make the times used for DST permanent and to abolish biannual clock change. It had bipartisan support from senators from Washington and Tennessee, but it had not received a hearing in the Senate Commerce, Science, and Transportation Committee. \n In 2015, the   passed   Joint Resolution 4,  which urged Congress to enact legislation allowing individual states to establish daylight saving time as the standard time in their respective states throughout the calendar year. This would mean that   is on the same time as Arizona all year, but would be an hour ahead of California in the winter.  The   has not yet enacted any enabling legislation in this regard.\n In 2018, the   approved the Sunshine Protection Act which would put Florida on permanent daylight saving time year round, and Governor   signed it March 23. Congress would need to amend the existing 1966 federal law to allow the change. \n In 2018, voters in California approved a ballot measure to permit the state legislature to pursue legislation for permanent daylight saving time or standard time. However, California law still requires a vote of two-thirds of the state's legislature (and approval of Congress for permanent DST). Bills for permanent DST followed in 2019 and 2022, which both failed. \n In 2019, the   passed Substitute House Bill 1196,  which would establish year-round observation of daylight saving time contingent on the   amending federal law to authorize states to observe daylight saving time year-round.  Tennessee and Oregon also passed bills in 2019 for year-round DST. \n In 2021, the   passed Senate Bill 100 providing for year-round daylight saving time if the United States Congress amends 15 U.S.C. Section 260a to authorize states to observe daylight saving time year round. \n In 2022, the United States Senate passed the   to make daylight saving time permanent;  the bill failed in the House and expired at the end of the year.  The   has opposed the Sunshine Protection Act and called instead for permanent standard time, a position supported by the   and the  , among others. \n In March 2023, the Sunshine Protection Act was reintroduced, but as of April 2024 , there has been no appreciable progress of the bill. \n State-level permanent DST is prohibited by the Uniform Time Act and would require Congress to change federal law. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Roland_Gareis", "title": "Roland Gareis", "content": " (born March 15, 1948) is an Austrian  , former Professor of Project Management at the  , and consultant. He is known for his work on the theory and practice of  ,  and is considered co-founder of the \"Management by projects\" approach. \n Gareis was born in 1948  , son of Gunter Gareis and Erika Gareis. In his early years he wa an active youth player at the  Austrian football club  . he participated in the  . In 1969 he graduated from the   with a thesis on a new structure for the  , where in 1972 he also obtained his PhD. \n Gareis started his academic career at the Institut für Baubetrieb und Bauwirtschaft at the Vienna University of Economics and Business, where in 1979 he obtained his   with a thesis on \"Investment planning for the construction company.\"\n From 1979 to 1981 Gareis was professor at the   in Atlanta, Georgia. In 1982 he started his own consultancy firm, which he continued to president during his further career. From 1994 until 2013 he was also university professor for project management at the Vienna University of Economics and Business.\n Over the years he was Visiting Professor at the   (Swiss Federal Institute of Technology) in 1982, at Georgia State University in Atlanta in 1987; and at the   in Montreal in 1991.  From 1986 to 2002 he was chairman of the Project Management Association Project Management Austria, and in 1990 Research Director of the IPMA and organizer of the IPMA World Congress on \"Management by Projects.\"\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Satoshi_Kon", "title": "Satoshi Kon", "content": "\n\n  was a Japanese film director,  ,   and   from  ,  , and a member of the   (JAniCA).  He was a graduate of the   department of the  . He is best known for his acclaimed   films   (1997),   (2001),   (2003), and   (2006), and the TV series   (2004).\nHe died of pancreatic cancer at the age of 46 on August 24, 2010. \n Satoshi Kon was born on October 12, 1963.  Due to his father's job transfer, Kon's education from the fourth elementary grade up to the second middle-school grade was based in  . Kon was a classmate and close friend of manga artist Seihō Takizawa. While attending  , Kon aspired to become an animator.  Kon entered the Graphic Design course of the   in 1982. \n While in college, Kon made his debut as a   artist with the short manga   (1984) and earned a runner-up spot in the 10th Annual Tetsuya Chiba Awards held by   ( ).  Afterward, he found work as  's assistant.  After graduating from college in 1987,  Kon authored the single-volume manga   (1990) and wrote the script for Otomo's live-action film  . \n In 1991, Kon worked in   for the first time as an animator and on background design for the film  , which was written by Otomo. \n He began working around 1992 as a scriptwriter, layout artist and background designer for   (directed by Koji Morimoto), one of three short films in Katsuhiro Otomo's omnibus   (released in 1995).  This was the first time he adopted \"the fusion of fantasy and reality\" as the theme of his work. \n Kon worked as one of five layout artists on  's   in 1993, along with other animated films.  He worked as a key animator on episode 2 of the 1993–1994    , and he worked as the writer and storyboard artist for episode 5. \n Kon then worked with Mamoru Oshii on the manga  , which was written by Oshii and drawn by Kon. The manga was serialized in the monthly anime magazine   starting in 1994. However, as the series progressed, the opinions of Kon and Oshii became divided, and the series went on hiatus and ended unfinished.  After this work, Kon ended his career as a manga artist and devoted himself to making anime.\n In 1997, Kon began work on his directorial debut   (based on  's novel of the same name).  It was the first film by Kon to be produced by  , and producer   invited him because he was impressed in Kon's work on  .  A suspense story centered on a pop idol, Kon was initially unsatisfied with the first script based on the original and requested to make changes to it.  With the permission of the original author, Yoshikazu Takeuchi, Kon was allowed to make any changes he wanted, except for keeping the three elements of the novel (\"idol,\" \"horror\" and \"stalker\").  The screenplay was written by Sadayuki Murai,  who worked in the idea of a blurred border between the real world and imagination. \n Following  , Kon considered adapting the 1993 Yasutaka Tsutsui novel   into his next film. However, these plans were stalled when the distribution company for   (Rex Entertainment) went bankrupt.  Coincidentally, Kon's next work would also feature a film studio going bankrupt. \n In 2002, Kon's second film,  , was released to the public. The distribution company for the North American release was DreamWorks-affiliated Go Fish Pictures. The film centers on a retired actress who mysteriously withdraws from the public eye at the peak of her career. Having the same estimated budget as   (approximately 120 million yen),    garnered higher critical and financial success than its predecessor and earned numerous awards. The screenplay was written by Sadayuki Murai,  who utilized a seamless connection between illusion and reality to create a \"  kind of film\".    was the first Satoshi Kon film to feature  , of whom Kon was a long-time fan, as composer. \n In 2003, Kon's third work,  , was announced. The distribution company for the North American release was Sony Pictures-affiliated Destination Films. The film centers on a trio of homeless persons in Tokyo who discover a baby on Christmas Eve and set out to search for her parents.   cost more to make than Kon's previous two films (with a budget of approximately 300 million yen),  and centered on the themes of homelessness and abandonment, with a comedic touch worked in.  The screenplay was written by  .  This work also marked the transition from celluloid animation to digital animation.\n In 2004, Kon released the 13-episode television series  , in which Kon revisits the theme of the blending of imagination and reality, as well as working in additional social themes.  The series was created from an abundance of unused ideas for stories and arrangements that Kon felt were good but did not fit into any of his projects. \n In 2006,   was announced, after having been planned out and materializing for several years. The story centers on a new form of psychotherapy that utilizes dream analysis to treat mental patients. The film was highly successful and earned a number of film awards. Kon summed up the film with \"Kihonteki na   igai wa subete kaeta\" —roughly, \"Everything but the fundamental story was changed.\" Much like Kon's previous works, the film focuses on the synergy of dreams and reality. \n He participated in the TV program   broadcast by   in 2007. His one-minute short film   was aired along with works by Mamoru Oshii,   and others.  That same year, Kon helped establish and served as a member of the   (JAniCA). \n Following  , Kon began work on his next film,  . In May 2010, Kon was diagnosed with terminal  . Given half a year to live, Kon chose to spend the remainder of his life in his home. Shortly before his death Kon composed a final message, which was uploaded to his blog by his family upon his death. As Kon explained in the message, he chose not to make news of his rapidly advancing illness public, in part out of embarrassment at how drastically emaciated and ravaged his body had become. The result was that the announcement of his death was met with widespread shock and surprise, particularly given that Kon had shown no signs of illness at relatively recent public events, as the cancer progressed to a terminal state in a matter of months after being diagnosed.  Kon died on August 24, 2010, at the age of 46.  After his death, Kon was mentioned among the   in  s people of the year 2010.   wrote a   to him, which was printed in  , a Japanese retrospective book of his animation career. \n In November 2010,  , the animation studio that had previously produced Kon's works, officially announced that they would continue to produce the unfinished \"Yumemiru Kikai\", and that the animation director Yoshimi Itazu would be acting as the director. According to  , animator and frequent collaborator with Satoshi Kon, Kon disappeared in the middle of production on the movie. He had not informed most of the staff on the movie about his pancreatic cancer including producer  . Maruyama recorded the script to the movie on Kon's deathbed and promised to see the project to completion.  However, the project was halted in 2011 due to financial reasons. As of 2013, the completion of   remains uncertain due to funding difficulties, with only 600 of the 1,500 shots being animated.\n At Otakon 2012, Madhouse founder Masao Maruyama, who was involved in all of Kon's films from   to   and was also his friend and collaborator, stated: \"Unfortunately, we still don't have enough money. My personal goal is to get it within five years after his passing. I'm still working hard towards that goal.\" \n In July 2015, Maruyama reported that   remains in production but they are looking for a director to match Kon's abilities and similar vision. \n In August 2016, Mappa Producer Masao Maruyama said in an interview: \"For 4~5 years, I kept searching for a suitable director to complete Kon's work. Before his death, the storyboard and script, even part of the keyframe film was already completed. Then I thought, even if someone can mimic Kon's work, it would still be clear that it's only an imitation. For example, if   took the director's position, the completed   would still be a good piece of work. However, that would make it Hosoda's movie, not Kon's.  should be Kon's movie, him and only him, not someone else's. That means we cannot and should not \"compromise\" only to finish it. I spent years to finally reach this hard conclusion. Instead, we should take only Kon's \"original concept\", and let somebody turn it into a feature film. By doing so, the completed piece could 100% be that person's work, and I'm OK with that. I also considered about doing a documentary of Kon.\" \n However, Maruyama has not completely given up on the production. He says, \"If a talented director from overseas is willing to take on the project, it is not entirely without possibility,\" suggesting that the project is not entirely without a chance of restarting. \n The theme of \"mixture of fiction and reality\" is a keyword that symbolizes Kon Satoshi's works, and he repeatedly depicts the relationship between \"fiction and reality\" with various approaches in each of his works.  In  ,  ,  , and  , the boundary between fiction and reality gradually became blurred, and the characters were portrayed as going back and forth between fiction and reality.  At first glance,   does not seem to deal with the motif of \"fiction and reality,\" but it does have a device in which the \"fiction\" of \"miracles and coincidences\" is successively introduced into the realistic life of homeless people in Tokyo.  Because of the character designs and the way they are expressed, Kon's works seem to be aiming for realism.  However, Kon's goal is not to \"depict landscapes and people that look as if they are real\" but to \"depict the moment when landscapes and people that look as if they are real suddenly reveal themselves to be 'fiction' or 'pictures'.  His ability to depict a realistic world, which he has demonstrated in order in the films he has participated in as a staff member, such as Otomo's and Oshii's works, is utilized in his own works to most effectively show the drop of \"transition from reality to fiction\".  The world that appears to be real in Kon's works does not remain real, but is suddenly transformed into an unfamiliar world in order to disorient the audience.  This is the reason why he insisted on animated films instead of live action. \n When asked about his interest in female characters, Kon stated that female characters were easier to write because he is not able to know the character in the same way as a male character, and \"can project my obsession onto the characters and expand the aspects I want to describe.\"  With a frame of reference up to  ,   notes that while the theme of performance is the one obvious commonality in his works, she finds that the concept of the   is the more important topic for discussion. Napier shows the evolution of Kon's use of the gaze from its restrictive and negative aspects in   and  , to a collaborative gaze in   before arriving at a new type of gaze in   which revels in uncertainty and illusion. \n  said, \"Satoshi Kon used the hand-drawn medium to explore social stigmas and the human psyche, casting a light on our complexities in ways that might have failed in live action. Much of it was gritty, intense and, at times, even nightmarish. Kon didn't shy away from mature subject matter or live-action sensibilities in his work, and his films will always occupy a fascinating middle ground between 'cartoons' and the world as we know it.\" \n Kon stated in 2007 that the music of   had been the greatest influence on his expressive style. \nKon said that he has learned a lot from Hirasawa's attitude towards music and production, and that he owes a lot of the stories and concepts he creates to his influence.  Kon's idea of   control of film comes from Susumu Hirasawa, who has applied fractal-generating programs to music production.  Hirasawa's lyrics sparked Kon's interest in   and the writings of  , Japan's foremost expert on Jungian psychology, who has psychologically deciphered ancient myths and folktales, which greatly influenced his storytelling and direction.  All of Kon's works, from   to the suspended  , have been inspired by Hirasawa's lyrics and songs.  Susumu Hirasawa's \"Rotation (LOTUS-2)\", which is the theme song of  , was played at Kon's funeral. \n Kon says that he is influenced by everything he has been exposed to in his life, including writing, painting, music, film, manga, anime, television and theater.  He has learned a lot from   and   in manga,   in animation,   and many other great Japanese and international directors in film. \n He was familiarized with Tezuka's manga and animation works such as  ,   and   in his childhood. \n He was an avid watcher of anime titles, such as   (1974),   (1974),   (1978),   (1978) and   (1979) during his junior and senior high school years, which Japanese anime fans of the time were crazy about. \n Otomo had a strong influence on him, and his favorite works were   and  , especially  , which he liked so much that he said if he could make a movie out of only one manga he had ever read, it would be that one. \nHe was also influenced by the   movement in manga started by Otomo and others, and decided to not only read but also draw manga himself in his high school days.  He was enlightened by the New Wave's way of overwhelmingly depicting a story in which nothing in particular happens, focusing on a character who could never be the protagonist of the story.  Kon has also said that his drawing style has been influenced by Otomo, as he used to work as Otomo's assistant when he was a manga artist.  After entering the animation industry, he was greatly influenced by animators  ,  ,  ,   and art setter Takashi Watabe. \n He had been watching only live-action films since he started college.  He watched most of the movies on video and made it a routine to draw manga based on the setting, format and direction of the scenes.  Ninety percent of the films he watched were made in the U.S., and he said that he learned a lot about his own style of visual expression from  .  However, he was not influenced by any particular film or director, but by everything he had ever seen.  For example,   has scenes that borrow images from Kurosawa's  ,  's films, the hero of the   film  , or the great Japanese star  .  The film that directly influenced   is  's   (1972).  When he was in college, it was not one film that influenced him the most, but the entire body of work of  , including   (1981),   (1985) and   (1989).  However, the filmmaker whose works and books he had read the most is Akira Kurosawa. \n As for novels, the works of  , the Japanese historical novelist, had a great impact on Kon in terms of his own relationship with Japan.  He was also very much inspired by  , whose works have been translated into many foreign languages.  He had seen the film   (1982) before reading the novel and had not read all of his works, but   was one of the authors he wanted to read and he became very interested in images of nightmares under his influence.  He has been a long-time fan of   since before he directed  , and was especially influenced by reading Tsutsui's works intensively when he was around 20 years old.  It was such a fundamental influence that even he did not know how or where Tsutsui's work influenced him.  According to Kon, the appeal of Yasutaka Tsutsui's work is \"deviation from common sense.\" What he learned from Tsutsui was \"doubt the framework of common sense.\" \n Kon has had a great influence on directors around the world even after his death,  and artists and works have been influenced by his realistic visual expression and vivid editing.  Kon's influence on foreign filmmakers was more pronounced than in Japan, with directors such as   and   expressing their support. \n American filmmaker Aronofsky is one of the directors greatly influenced by Kon, especially  .  In an interview with Kon in 2001, he said that any scene in   that seems to be influenced by   is a homage to it, and that he still wants to make a live-action version of  .  His 2010 film   was also pointed out by several critics for its similarity to  , but Aronofsky denied any direct influence. \n 's 2010 film   was also noted by several critics and scholars to have many similarities with Kon's   (2006), including plot similarities, and similar scenes and characters. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Office_of_American_Innovation", "title": "Office of American Innovation", "content": "\n\n The   ( ) was an office within the   that existed from 2017 until 2021 during the  . Under  , The office's purpose was to be the liaison between the White House and the American tech industry as part of an effort to reform the federal bureaucracy by applying pragmatic business principles.\n The Office of American Innovation (OAI) was established by President   on March 27, 2017, with the purpose to \"make recommendations to the President on policies and plans that improve Government operations and services, improve the quality of life for Americans now and in the future, and spur job creation.\"  The office was to draw on the lessons of the private sector to bring \"new thinking and real change\" to the country's problems, including the federal government's   spend, economic activity, and the  . According to  , the office was intended to be the White House's primary point of contact with the  . \n OAI was directed by President Trump’s son-in-law and Senior Advisor to the President  ,  By July 2017, OAI's operational team consisted of Kushner, Liddell,  , and Matt Lira.  Communications were run by Josh Raffel, a former     executive,  until February 2018, when Raffel announced his resignation from the position.  Between April 2019 to November 2020,   served as the office's Deputy Director. \n After its founding in May 2017, OAI convened a summit of more than a dozen tech CEOs, including Amazon's  ,   of Apple,   of  , and   of  . The office was also involved in the  ' purchase of a multi-billion dollar computer system and the administration's   on apprenticeships. \n In its first year, the office established the Trump Administration's IT Modernization Plan.   It also established a Centers of Excellence program within the   in December 2017 that encouraged federal agencies to move to the   and improve  . The program was included in the   to implement the recommendation of the IT Modernization Plan. \n The office was closed during the   in 2021, and there were no plans to revive it. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Yeom_Hye-ran", "title": "Yeom Hye-ran", "content": " (born October 30, 1976) is a South Korean actress, with a portfolio of film, television, and theatre performances.  Yeom began her career in theater in 1999 and made her screen debut in 2003. She has since played supporting roles in film and television, notably   (2016),   (2017),   (2018),  ,   (2019),   (2019–2020),   (2020–2023),   (2022–2023), and   (2024).\n Yeom was born on October 30, 1976, in  ,  , South Korea. She comes from a family of farmers and her mother was also a market rice seller. \n Yeom's original career aspiration was to be a Korean language teacher.  Hence she attended Department of Korean Literature of  ,  where she discovered her love of acting as member of college theater club. \n By chance, Yeom saw flyers of member recruitment from  .  In 1999, she auditioned and was accepted as a member. The following year, Yeom debuted as an actress with the play \"Teacher Choi\"  . \n Yeom made her screen debut in  's film  , which was released in 2003. It was during Yeom's portrayal of So-hyeon's mother in Yeonwoo's play   (이 爾) that Director Bong witnessed her talent and invitated her to audition in his film. \n In 2003, Yeom took part in a play produced by the theater company Iwa-sam, written and directed by Jang Woo-jae.  The play, titled  , depicts the story of an accordionist who wanders around the country looking for his runaway wife, his honest friend Cha Charyeoksa, a third-rate theater actor Yang Yang-sook, and a naive virgin girl called Sunny. Yeom's performance as Sunny was praised as chilling. \n It is a play called  . I played the character 'Sunny' in the play, and it is an innocent and pure character. To the point of being stupid to other people. It resembles my favorite movie, 'Gelsomina from The Road'. I thought deeply about my sincerity while doing the piece. The play was selected as 2003 Culture and Arts Promotion Agency New Artist Support and had an encore performance in 2004 thanks to the audience's response. Yeom reprised her role Sunny in the encore performance.  In December 2004, Yeom won Popular Actress Award from 1st Beautiful Play Award voted by theater netizen for her performance as Sunny. \n In 2004, former Yeonwoo member, Son Ki-ho established   (극단 이루) based in Seondol Theater. Yeom and fellow actress   followed him to be founding members. Iru first founding performance was the play \"Ask the Blind Father for Directions\"  . Written and directed by Son Ki-ho, it premiered on June 4 at Dongsung Stage Small Theater in Daehangno, Seoul, and ran until July 4, 2004. The story centered in a family of three consisting of a son, So Seon-ho who was diagnosed by cancer with a parent with disability. Yeom acted as Seon-ho's mother, opposite   who acted as the father.  Yeom was praised for her performances and even called as the second  .  Her costar also praised her performance and said,\n Hye-ran is an actress who can act as if memories of the past flood in at once, like a shaman receiving a reception. The play \"Ask the Blind Father for Directions\"   won an award at    and received support from the Seoul Foundation for Arts and Culture. From March to July 2005, Yeom reprised her role in the play \"Ask the Blind Father for Directions\" at National Theater, Seoul Arts Theater and other theaters.  In February 2006, Yeom won the Rookie Award at the 42nd Dong-A Theater Award for her role in the play. \n In 2008, Yeom acted as Park Mi-cheon in Son Ki-ho's play \"The person who lived in Gampo, Deokyi, and Yeolsu\" (감포사는 분이, 덕이, 열수). She reprised the role in 2009.  In 2009, at the 14th Hee-seo Theater Award,  Yeom won the Expected Theater Actress Award. \n In May 2010, Iru's play \"The person who lived in Gampo, Deokyi, and Yeolsu\" performed at the 2010 Seoul Theater Festival. Yeom won Acting Award and the play won Popularity Award. \n Yeom debuted in television with  's drama   in 2016. Directed by  , it had star-studded casts, starring  ,  ,  ,  ,  ,  ,  ,   and  .  Yeom acted as Soon-yeong, adopted eldest daughter of Moon Jung-ah (played by  ), who struggled with domestic violence.  Yeom was praised for her daughter-mother lasting impression performance with  . \n \nShe was cast in the drama by chance. Writer   came to watch  's play Goodnight Mom, where Yeom played her daughter, Jessi. After watching her performance in the play, writer Noh offered her role in her upcoming drama, trough Na. \"Teacher Na Moon-hee and the writer are very close, so they came to see the performance. Dear My Friends was in the planning stage, and she said that it would be nice to appear. Thanks to practicing and performing together, it was a great help to the drama. If I had met her for the first time during the drama filming, I would have frozen in front of her since he was a senior I respect so much.\" In the same year, Yeom acted as a villain in her next drama  . She took on the role of Ji Yeon-sook, Ji Eun-tak's maternal aunt who bullied her niece Eun-tak (played by  ) for her sister's death insurance.  Ji was a villain, but somehow Yeom lively acting, which makes people laugh, was a feat to watch. \n In 2017, Yeom reunited for the second time with   and director   with four episode dramas  . It was a remake of the drama of the same name by Noh that aired in 1996 on  . Yeom played Shin Yang-soon, Kim Geun-deok's wife, acted opposite  , who played Kim Geun-deok, In-hee's brother.  In 2018, Yeom worked for the third time with  's drama   as Yeom Sang-soo's mother (role played by  ).  Yeom also reunited for the third time with director   in drama   as Kang Kyung-ah, manager of Sangkook University Hospital. It was written by  . \n In the same year, Yeom also had reunion project with   in feature film   She played market shop owner Jin Ju-daek, who has close relationship with main character, Na Ok-bun (Na Moon-hee). Yeom was cast in   after the casting director watched the audition video for   from a decade ago. \n In 2019, Yeom starred as supporting role in drama   Yeom acted as Hong Ja-young, a sophisticated divorce lawyer and wife to Gyu-tae (played by  ).  Hong Ja-young is a confident and charismatic woman, who also had trust issues with her husband. Her acting in the drama garnered favorable reviews from viewers who see her character as  , affectionately called the nation older sister.  Her chemistry with Oh, made them won Best Couple at  , in which she won Best Supporting Actress Award. Yeom also received nomination for Best Supporting Actress in   and  . \n In 2021, Yeom starred in   drama   with  ,  , and  . Yeom acted as Choo Mae-ok, a former photographer, who had powerful healing abilities. She joins the Counters after being possessed by her Son Su-ho's spirit.  Yeom received Best Supporting Actress Award at   for this role. \n After over two decades of debut, Yeom had her first title role in Bae Jong-dae's mystery film Blacklight, which was released in February 2021.  Produced by One Take Film, New Life, it depicts two women who their fate entangled through their husbands' car accidents. Yeom acted as Yeong-nam, a single mom, who had to care for daughter and her comatose husband.  Yeom garnered critical acclaim for her role and nominated in 8th   and  . She won the Best Actress Award at the 21st Jeonju International Film Festival. \n In 2022, she starred in the   revenge thriller web series,  , starring   playing the role of Kang Hyeon-nam, a   who became a revenge accomplice to Hye-kyo's character. She was nominated for Best Supporting Actress Award at   for this role. \n In 2005 Yeom married her non-celebrity husband.  They have a daughter together. She gave birth in 2012 and took a break from acting for a while. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Rabih_Alenezi", "title": "Rabih Alenezi", "content": " is a former intelligence officer  and Saudi dissident colonel in the  . Known for his vocal criticism of the  , particularly Crown Prince   (MBS), Alenezi has been living in exile in the  .  He has made significant contributions to the discourse on  , particularly with respect to the   project, a planned megacity in the desert.\nHis allegations of human rights violations and his personal experiences have brought international attention to the issue. Despite facing numerous threats, Col. Alenezi continues to speak out against oppression and advocate for human rights.\nAccording to Human Rights Watch, hundreds of migrants are said to have been shot dead on the border with Yemen on the orders of MBS. In a   interview (Second German Television), Col. Rabih spoke of an order that has been carried out for three years: In 2020, a killing order came from Mohammed bin Salman himself. The order said to kill anyone who comes near the Saudi border, any person near the border was considered a terrorist to be neutralized immediately. \nOn the British channel itv, Col. Rabih Alenezi appeared in the movie (Kingdom Uncovered: Inside Saudi Arabia) and confirmed that he had received an order to use lethal force against any resistance from the Al-Huwaitat tribe. However, he pretended to be very ill and apologized for carrying out the mission for fear of being involved in human rights violations. Despite this, the mission proceeded and ended with the killing of Abdul Rahim al-Huwaiti, who refused to evacuate his house for the NEOM LINE project. \n Alenezi studied both his bachelor’s and master’s degrees in the UK.  In addition to that, he worked with American police officers and studied security in Phoenix the capital city of Arizona in United States.  He also served as a senior official in Saudi Arabia's security service for two decades. During his tenure, he claims he was ordered to commit human rights abuses. \n Col. Alenezi defected from Saudi Arabia's  .  He requested asylum in the UK after he claimed he had been ordered to commit human rights abuses.  He announced his defection and began speaking out online. \n Since his defection, Alenezi has received numerous death threats. He was receiving an average of 50 death threats a week.  The Saudi royal court reportedly had a $250,000 (£200,000) bounty on his head, therefore, the British police advised him to adopt the lifestyle of Edward Snowden, the former US intelligence operative who is currently hiding in Russia.  Col. Rabih Alenezi fears for his life and lives in hiding now. \n Col. Alenezi, who carries a diplomatic passport, arrived in London in February 2023, but doesn’t feel safe. He feared he could be killed in the same way as Jamal Khashoggi, a vocal critic of the Saudi regime and Washington Post journalist, who was murdered inside the Saudi embassy in Istanbul in 2018. \n According to BBC, Col Alenezi is now based in the UK but still fears for his security. He says an intelligence officer told him that he would be offered $5M (£4M) if he attended a meeting at London's Saudi embassy with the Saudi interior minister but he refused. \n Dr. Manisha Ganguly, the investigative reporter for The Guardian, stated on her official account on the X platform that Saudi government agents continue to offer rewards for Colonel Rabih's capture, despite the fact that he lives in exile in the United Kingdom, and she attached an advertising poster from a verified account named @whatsayeezy stating that \"First person to geolocate this individual (Col. Rabih Alenezi) and where he rests his head at night gets $15,000,000 in clean crypto serious offer only\" and he attached a photograph of Col. Rabih Alenezi \n A former senior security and intelligence official, Rabih Alenezi, now seeking asylum in the UK after having a bounty put on his head for speaking out against Mr bin Salman, said the culture of fear rules under the de facto ruler. Col. Alenezi, who reached the top echelons of the country’s security establishment, said that the death penalty, often carried out by beheading with a sword or shooting, is a way to “intimidate people and terrorise society because Mohammed bin Salman knows that people hate him”, including ministers.“He does not believe that people will carry out his orders and accept his projects without fear,” he added. \n Col. Alenezi has used his platform to speak out against Prince  . He has gained a huge following online and lives on donations from his followers. \n Col. Alenezi has made numerous allegations of human rights abuses he was asked to carry out, including the  's order to crack down on the   tribe in   in 2020, Prince Mohammed's Location of pet project  , a planned megacity. in the desert.  He claimed that Saudi authorities authorized the use of lethal force to clear land for the Neom project. Speaking to Dezeen, Col Alenezi urged companies involved in the project to withdraw from it. \"I think Neom firms should pull out of this contentious project immediately lest they be implicated in Saudi Arabian human rights abuses,\" he said. \n\"I assume that all businesses consider the values of human rights. In Saudi Arabia, there are blatant violations of human rights and systematic oppression of civilians,\" he continued. \"I would like to remind architects that housing is an inalienable human right and that it is not rational to demolish entire towns and force their inhabitants to flee in the name of a wild, impractical plan.\" \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Trail", "title": "Trail", "content": "\n A  , also known as a   or  , is an unpaved lane or a small paved road not intended for usage by  , usually passing through a  . In the   and  , a path or   is the preferred term for a pedestrian or hiking trail.  The term is also applied in North America to accompanying routes along rivers, and sometimes to highways. In the US, the term was historically used for a route into or through wild territory used by explorers and migrants (e.g. the  ). In the United States, \"trace\" is a synonym for trail, as in  .\n Some trails are dedicated only for walking, cycling,  ,   or  , but not more than one use; others, as in the case of a   in the UK, are   and can be used by pedestrians, cyclists and equestrians alike. Although most trails are for low-traffic, non-motorized usage, there are also unpaved trails used by  ,   and other  , usually for   and  . In some places, like the  , trails are used by alpine agrarian communities for  .\n In Australia, the term track can be used interchangeably with trail or walk, and can refer to anything from a   to an unpaved  . \n In New Zealand, the terms track or   are used almost exclusively except when referring to  : \"walkways vary enormously in nature, from short urban strolls, to moderate coastal locations, to challenging tramps [hikes] in the high country [mountains]\".  Walkway is used similarly in  , Canada, where the \" \", is an integrated walkway system. \n In the United Kingdom, the term trail is in common usage. Longer distance walking routes, and government-promoted long-distance paths, collectively known as  , are also frequently called ways as in the   and  . Generally, the term footpath is preferred for pedestrian routes, including long-distance trails, and is used for urban paths and sometimes in place of  . Track is used for wider paths (wide enough for vehicles), often used for hiking. The terms  ,  ,   are all recognised legal terms and to a greater or lesser extent in general usage.\n The increased popularity of   has led to a proliferation of mountain bike trails in many countries.  Often these will be grouped to form larger complexes, known as trail centers.\n In the early years of the 20th century, the term   was used for a marked highway route,  and trail is now used to designate routes, including highway routes, designated for tourist interest like the  , Nova Scotia, Canada and the   in the US. The term trail has been used by developers and urban planners for a variety of modern paved  , highways, and  , in these countries, and some highways continue to be officially called a trail, such as the Susquehanna Trail in Pennsylvania, a designation that varies from a two-lane road to a four-lane freeway. An unusual use of the term is in the Canadian province of  , which has multi-lane   called trails. \n Animals created the first trails, which were \"later adapted by humans\".  Subsequently, farmers moved cattle to market along   and between   creating trails.  More recently, former industrial routes, such as   and canal  , have been turned into recreational trails.\n Many historic routes, like the  , the   and the   of the  , existed before the   and covered great distances.\n The  , a prehistoric   in the valley of the   in the  , England, is one of the oldest known constructed trackways and dates from around 3838 BC. \n The idea of following a path or track for exercise or pleasure developed during the 18th century in Europe and arose because of changing attitudes to the landscape and nature associated with the  .  In earlier times, walking generally indicated poverty and was associated with vagrancy.  In previous centuries long walks were undertaken as part of religious   and this tradition continues throughout the world.\n The first footpath built specifically for recreational hiking in America, and likely the world, is the   in the White Mountains of New Hampshire. The path was blazed in 1819 by Abel Crawford and his son, Ethan Allen. Originally 8.25 miles in length (now 8.5 miles), the trail leads to the summit of Mt. Washington. \n Trails can be located in different settings for various uses. These can include:\n Trail segregation, the practice of designating certain trails as having a specific preferred or exclusive use, is increasingly common and diverse.  For example,   are used not only on roads open to motor vehicles but also in trail systems open to other trail users. Some trails are segregated for use by both equestrians and mountain bikes or by equestrians or mountain bikes alone. Designated \"wilderness area\" trails may be segregated for non-wheeled use permitting backpacking and horses but not permitting mountain bikes and motorized vehicles. \n Often, trail segregation for a particular use is accompanied by prohibitions against that use on other trails within the trail system. Trail segregation may be supported by signage, markings, trail design and construction (especially the selection of tread materials), and by separation between parallel treads. Separation may be achieved by \"natural\" barriers including distance, ditching, banking, grading, and vegetation, and by \"artificial\" barriers including fencing, curbing, and walls. \n Bicycle trails encompass a wide variety of trail types, including shared-use paths used for commuting, off-road   trails and   trails. \n The number of off-road cycle trails has increased significantly, along with the popularity of  .  Off-road bicycle trails are generally function-specific and most commonly waymarked along their route. They may take the form of single routes or form part of larger complexes, known as trail centers. Off-road trails often incorporate a mix of challenging terrain,  , smooth  , and even paved paths. Trails with an easy or moderate technical complexity are generally deemed cross-country trails, while trails difficult even to experienced riders are more often dubbed  ,  , or downhill. Downhilling is popular at ski resorts like   in California,  or   in British Columbia, where   are used to get bikes and riders to the top of the mountain.\n  bicycle routes are a network of (currently 17)   criss-crossing Europe in various stages of completion; more than 90,000 km (55,923 mi) was in place by 2020.  EuroVelo is a project of the   (ECF).\n EuroVelo routes can be used for   across the continent, and by local people making short journeys. The routes comprise both existing  , such as the Dutch  , the German  , and the British  , and existing general-purpose roads, together with new stretches of cycle routes to connect them. \n Off-road cycling can cause   and   if not carried out on established trails. This is true when trails are wet, though overall, cycling may not have more of an impact as other trail users. \n In cross-country skiing, a trail is also called a track or piste.  Recreational cross-country skiing is also called touring, especially in Europe. Some skiers stay out for extended periods using   and equipment similar to bushwalkers and hikers, whereas others take shorter trips from ski resorts on maintained trails. In some countries, organizations maintain a network of huts for use by cross-country skiers in wintertime. For example, the   maintains over 400 huts stretching across hundreds of kilometres of trails hikers use in the summer and skiers use in the winter. \n Horse riding and other   uses of trails continue to be a popular activity for many trail users.  Horses can usually negotiate much the same grades as hikers, but not always, although they can more easily clear obstacles in the path such as logs. \n The   (BNT) in Australia is one of the longest marked multi-use trail in the world, stretching 5,330 km (3,312 mi) from  , through   to  .  This trail runs the length of the rugged   through  , private property and alongside of  . One of the objectives was to develop a trail that linked up the   tracks,    and   along the Great Dividing Range, thus providing an opportunity to legally ride the routes of   and   who once travelled these areas with  . This Trail provides access to some of the wildest, most remote country in the world.  The Bicentennial National Trail is suitable for self-reliant horse riders, fit walkers and mountain bike riders. \n Within the United States National Trail Classification System,  equestrian trails include simple day-use bridle paths and others built to accommodate long strings of pack animals on journeys lasting many days.  Trail design parameters for these uses include trail base width and material, trail clear width, trail clear height, access to water suitable for stock (not human) use, and trail routing.\n A footpath is a type of   that is intended for use only by   either within an urban area or through the countryside. An urban footpath is usually called an alley or lane and often paved (see also:   and  ). Other public  , such as  ,  , towpaths, and   are also used by pedestrians.\n In England and Wales, there are rights of way on which pedestrians have a legally protected right to travel.  ,  ,   and other protected   areas may have trails that are restricted to pedestrians. \n Footpaths can be connected to form a   or way, which can be used by both day hikers and  . Some trails are over 1,000 miles (1,600 km) long. \n In the US and Canada, where   has reached rural communities, developers and local leaders are currently striving to make their communities more conducive to non-motorized transportation through the use of less traditional trails. The   in the US has established the   program to improve the   of communities in part through developing trails,  The   in   has done similar work on traditional trails, while the   in  , and related paths, are examples of urban initiatives. In St. John's, Newfoundland, Canada the \"Grand Concourse\", is an integrated walkway system that has over 160 km (99 mi) of walkways, which link every major park, river, pond and green space in six municipalities. \n A motorized trail is a trail intended for off-road vehicles for example 4×4 cars, dirt bikes, All-terrain vehicles (ATV).   Motorized trail use remains very popular with some people, particularly in the US.  The   defined as part of the   of 1991 mandates that states must use a minimum of 30 percent of these funds for motorized trail uses. \n Some members of the US government  and environmental organizations, including the   and  .  have criticized off-road vehicle use on  . They have noted several consequences of illegal ORV use such as pollution, trail damage,  ,  , possible  ,  and habitat destruction  which can leave hiking trails impassable. ORV proponents argue legal use taking place under planned access along with the multiple environmental and trail conservation efforts by ORV groups will mitigate these issues. Groups such as the BlueRibbon Coalition advocate Treadlightly, which is the responsible use of public lands used for off-road activities.\n  is also a concern,  and several studies conducted by  ,  , the   and others have cited possible negative behavioral changes in wildlife as the result of some ORV use.  Several US states such as Washington have laws to reduce noise generated by off-road and non-highway vehicles. \n , also referred to as blueways or paddling trails, are marked routes on   such as  ,  ,   and coastlines for people using small non-motorized   such as  ,  ,  , or  . Some trails may be suitable for   or developed in concert with motorized use. They include: signs and route markers; maps; facilities for parking, boat ramps or docks, and places to camp and picnic. There are also state programs and other promotion for water trails in the United States.  The   has compiled a database of water trails in the United States.  The   Rivers, Trails, and Conservation Assistance Program has compiled a list of water trail resources, success stories, and statewide contacts for water trails. \n Shared use may be achieved by sharing a trail easement, but maintaining segregated and sometimes also separated trail treads within it.  This is common with  . Shared use may also refer to alternate day arrangements, whereby two uses are segregated by being permitted every other day. This is increasingly common on   shared by equestrians and mountain bike users; these two user communities have similar trail requirements but may experience difficult encounters with each other on the trail.\n The   can be used by cyclists, hikers, horseback riders, and walkers, as well as  ,   and   in winter. \n In the United States, the  —3,000 mi (4,828 km) from Key West to the Canadian border — and the 11 September National Memorial Trail, a 1,300 mi (2,092 km) triangular loop connecting the three 9/11 memorial sites, are two long-distance multi-use paths for cyclists, runners, walkers, even equestrians. \n In Belgium  , French for   ( ), is a   initiative aimed at creating a network of route itineraries reserved for pedestrians, cyclists, horse riders and people with reduced mobility. The 1,350 km (840 mi) network makes use of towpaths on river banks and disused railway or   lines ( narrow-gauge tramways).  Old railway lines have been leased by the Walloon Government for 99 years using   contracts.  Where necessary, new paths are created to link parts of the network.\n In   a bridleway is a trail intended for use by equestrians,  but walkers also have a  , and Section 30 of the  , permits the riding of bicycles (but not motor-cycles) on public bridleways, though the act says it \"shall not create any obligation to facilitate the use of the bridleway by cyclists\". Thus the right to cycle exists even though it may be difficult to exercise on occasion, especially in winter. Cyclists using a bridleway must give way to other users on foot or horseback. \n The   in  ,  , Canada is popular for walking, running, cycling, and  . There are two paths, one for skaters and cyclists and the other for pedestrians. The lane for cyclists and skaters goes one-way in a counterclockwise loop. \n  (also  ) is a term used in   for a type of   that provides a public   along the edge of the sea open to both walkers and cyclists. \n A   is a type of rudimentary access road, built mainly for the  . In some cases they are used for   recreation access.\n There is open access to most   roads and land in Great Britain for walkers, cyclists and horse riders and, since the Countryside Bill of 1968, it has become the largest provider of outdoor recreation in Britain.  The commission works with associations involved in  , cycling, mountain biking and   to promote the use of its land for recreation. The trails open to the public are not just forest roads. A notable example of the commission's promotion of outdoor activity is the   project in Scotland, where seven purpose built areas of mountain bike trails have been laid, including facilities for disabled cyclists. \n A Holloway (also hollow way) is a  , i.e., a road or track that is significantly lower than the land on either side, not formed by the (recent) engineering of a road cutting but possibly of much greater age. Various mechanisms have been proposed for how holloways may have been formed, including erosion by water or traffic; the digging of embankments to assist with the herding of livestock; and the digging of double banks to mark the boundaries of estates. These mechanisms are all possible and could apply in different cases. \n  or paths are shared-use paths that take advantage of abandoned railway corridors. They can be used for walking, cycling and horseback riding. They exist throughout the world. RailTrails Australia describes them as: Following the route of the railways, they cut through hills, under roads, over embankments and across gullies and creeks. Apart from being great places to walk, cycle or horse ride, rail trails are linear conservation corridors protecting native plants and animals. They often link remnant vegetation in farming areas and contain valuable flora and fauna habitat. Wineries and other attractions are near many trails as well as B&B's and other great places to stay. Most trails have a gravel or dirt surface suitable for walking, mountain bikes and horses. In the USA the 42 mi (68 km)  , in  , can be used by hikers, horseback riders, snowmobilers, cross-country skiers, cyclists, and even  . \nIn Canada, following the abandonment of the   in 1989, the government of   purchased the right-of-way to the entire railway system. The   was developed as a tip-to-tip walking/cycling gravel rail trail which doubles as a monitored and groomed snowmobile trail during the winter months, operated by the PEI Snowmobile Association. A considerable part of the   is repurposed defunct rail lines donated to provincial governments by the   and   railways rebuilt as walking trails. Much of the Trans Canada Trail development emulated the successful   initiative in the United States. The Trail is multi-use and depending on the section may allow hikers, bicyclists, horseback riders, cross-country skiers and snowmobilers. \n A   is a road or path on the bank of a river, canal, or other inland waterway. The original purpose of a towpath was to allow a horse, or a team of human pullers, to tow a boat, often a  . They can be   or unpaved and are popular with cyclists and walkers; some are suitable for equestrians. Equestrians have legal access to all towpaths in Scotland, and there is a campaign for similar rights in England and Wales.  In snowy winters in the USA they are popular with cross-country skiers and snowmobile users. \n Most canals were owned by private companies in Britain, and the towpaths were deemed to be private, for the benefit of legitimate users of the canal. The nationalisation of the canal system in 1948 did not result in the towpaths becoming public rights of way, and subsequent legislation, such as the Transport Act of 1968, which defined the government's obligations to the maintenance of the inland waterways for which it was now responsible, did not include any commitment to maintain towpaths for use by anyone.  Ten years later   started to relax the rule that a permit was required to give access to a towpath, and began to encourage leisure usage by walkers, anglers and in some areas, cyclists.  The   still did not enshrine any right of public access, although it did encourage recreational access of all kinds to the network,  although the steady development of the leisure use of the canals and the decline of commercial traffic had resulted in a general acceptance that towpaths are open to everyone, and not just boat users.  The concept of free access to towpaths is enshrined in the legislation which transferred responsibility for the English and Welsh canals from British Waterways to the   in 2012. \n Not all towpaths are suitable for use by cyclists, but where they are, and the canal is owned by British Waterways, a permit is required. There is no charge for a permit, but it acts as an opportunity to inform cyclists about safe and unsafe areas to cycle. Some areas including London are exempt from this policy, but are covered instead by the London Towpath Code of Conduct and cyclists must have a bell, which they ring twice when approaching pedestrians. Parts of some towpaths have been incorporated into the National Cycle Network, and in most cases this has resulted in the surface being improved. \n In France it is possible to cycle,  , and hike along the banks of the  . A paved stretch of 50 km (31 mi) from   to   and another 12 km (7.5 mi) between   and   are particularly suited to cycling and rollerblading. It is possible to cycle or walk the entire   from   to  .  Other French canals provide walkers \"with many excellent routes, as they are always accompanied by a towpath, which makes a pleasant off-road track, and have the added virtues of flatness, shade and an abundance of villages along the way\", though walking a canal can be monotonous, so that \"a long trip beside a canal is better done by bicycle\". \n An urban trail is a citywide network of non-motorized, multi-use pathways that are used by bicyclists, walkers and runners for both transportation and recreation.  Urban trails average ten foot in width and are surfaced with asphalt or concrete. Some are striped likes roads to designate two-way traffic. Urban trails are designed with connections to neighborhoods, businesses, places of employment and public transport stops. \n Urban pedestrian footpaths are sometimes called   or lanes and in older cities and towns in Europe and are often what is left of a medieval street network or rights-of-way or ancient footpaths. Similar paths also exist in some older North American towns and cities, like  ,  , and  , Pennsylvania. Such urban trails or footpaths are narrow, usually paved and often between the walls of buildings. This type is usually short and straight, and on steep ground can consist partially or entirely of steps. Some are named. Because of geography   are a common form of footpath in hilly cities and towns. This includes Pittsburgh (see  ),   (see  ),  ,  and San Francisco  in the United States, as well as Hong Kong,   , Quebec, Canada,  and  .    trails are found in a number of hilly American cities. This includes the Stairway Trails in  , East San Francisco. \n A linear trail goes from one point to another without connecting trails.  These trails are also known as \"out-and-back\" or \"destination\" trails. Rail trails and long-distance trails are examples of linear trails. Linear trails usually follow long distances. A shorter linear trail is a spur trail, which takes a user to a particular point-of-interest, such as a waterfall or mountain summit. \n A looped trail allows a user to end up where they started with either minimal or no repeating parts of the trail.  Looped-trail systems come in many permutations. A single-looped trail system is often used around lakes, wetlands, and other geological features.  A series of looped trails is a stacked-loop trail system. A stacked loop trail system has several interconnected looped trails. This creates an efficient, compact design with many route options. In a multiple-loop system, each loop extends from a single trailhead.\n Trail systems often combine linear trails with looped trails. In a spoked-wheel system, linear trails connect a central trailhead with an outer loop. In a primary-and-secondary loop system, linear trails connect a primary loop with secondary loops. Last, a maze system incorporates both loops and linear trails. Maze systems provide users many choices; some users may find navigation difficult. \n A group of public and private organisations from the eight Alpine countries in Europe created the   in 2000, receiving EU funding from 2001 until 2008. It was initiated by the Association   in  , which hosted the Via Alpina international secretariat until January 2014, when it was transferred to the   CIPRA, in Liechtenstein. There are national secretariats (hosted by public administrations or hiking associations) in each country. Its aim is to support sustainable development in remote mountain areas and promote the Alpine cultures and cultural exchanges. \n The   (French),   or   (Dutch),   (Portuguese) or   (Spanish) is a network of   in Europe, mostly in France, Belgium, the Netherlands and Spain. Many GR routes make up part of the longer   which cross several countries. In France alone, the trails cover approximately 60,000 km (37,000 mi). In France, the network is maintained by the   (French Hiking Federation),  and in Spain by the Spanish Mountain Sports Federation. \n In England and Wales, many trails and footpaths are of ancient origin and are protected under law as  . In  , the   organization is campaigning for similar rights.  Local highway authorities, in England and Wales, (usually   or  ) are required to maintain the definitive map of all public rights of way in their areas, and these can be inspected at council offices. If a path is shown on the  , and no subsequent order (e.g. a stopping up) exists, then the right of way is conclusive in law. But just because a path is not on that map, does not mean that it is not a public path, as the rights may not have been recorded. The   estimated that over 10% of public paths are not yet listed on the definitive map. The   provides that paths that are not recorded on the definitive map by 2026 and that were in use prior to 1949 will automatically be deemed stopped-up on 1 January 2026. \n In Scotland,   is a route over which the public has passed unhindered for at least 20 years.  The route must link two \"public places\", such as villages, churches or roads. Unlike in England and Wales, there is no obligation on Scottish   to signpost or mark a right of way. The charity  , formed in 1845 to protect rights of way, records and signs the routes. There is no legal distinction between   and bridleways in Scotland, as there is in England and Wales, though it is generally accepted that cyclists and horseback riders may follow rights of way with suitable surfaces. \n The   established a general presumption of access to all land in Scotland, making the existence of rights of way less important in terms of access to land in Scotland. Certain categories of land are excluded from this presumption of open access such as railway land, airfields and private gardens. \n  has very few public rights of way and access to land there is more restricted than other parts of the UK. In many areas, walkers can enjoy the countryside only because of the goodwill and tolerance of landowners.  Northern Ireland shares the same legal system as England, including concepts about the ownership of land and public rights of way, but it has its own court structure, system of precedents and specific access legislation. \n In England and Wales a National Trails system of   also exists administered by   and the  , statutory agencies of the   and the  , respectively. These include  , the  , the   (bridleway), the   (South West Way) (the longest), and the  , and many more. Together these are over 4,000 km (2,500 mi) long. \n In Scotland, the equivalent trails are called   and are administered by  . The first, and probably the most popular, is the  , which is 152 km (94 mi) long and was opened in 1980. \n  is a British charity that promotes  , and it works on projects to encourage people to walk,  , and use public transport, to give people the choice of \"travelling in ways that benefit their health and the environment\".  Sustrans' flagship project is the National Cycle Network, which has created over 14,000 mi (23,000 km) of signed   throughout the UK. \n In 1968, the United States'  , which includes  ,   and  , was created under the National Trails System Act.  The most famous American long trails are the  , generally known as the Appalachian Trail and the  . The Appalachian Trail is a marked hiking route in the eastern United States extending between  ,  , and  ,  .  The trail is approximately 2,200 miles (3,500 km) long.  The Pacific Crest Trail is a long-distance hiking and equestrian trail closely aligned with the highest portion of the   and   mountain ranges, which lie 100 to 150 miles (160 to 240 km) east of the US Pacific coast. The trail's southern terminus is on the US border with Mexico and its northern terminus on the US-Canada border on the edge of   in British Columbia, Canada; its corridor through the US is in the states of California,  , and  . It is 2,663 miles (4,286 km) long. \n The land management agency in charge of a trail writes and enforces the rules and regulations for it. A trail may be completely contained within one administration (e.g. a State Park) or it may pass through multiple administrations, leading to a confusing array of regulations, allowing dogs or mountain bikes in one segment but not in another, or requiring   for a portion of the trail, but not everywhere. \n In the United States agencies administering trails include the National Park Service, the  , the  , State Park systems, County Parks, cities, private organizations such as land trusts, businesses and individual property owners. \n New trail construction by an agency must often be assessed for its environmental impact and conformance with State or Federal laws. For example, in California new trails must undergo reviews specified by the   (CEQA). \n All trails and shared use paths—indeed, any areas open to pedestrians—that are owned or operated by a public or private entity covered by the   are subject to federal regulations on Other Power-Driven Mobility Devices (\"OPDMDs\"). These rules potentially greatly expand the types of vehicular devices that must be permitted on trails, shared use paths, other routes, and other areas open to the public. This publication discusses ways to manage access by these vehicles. \n There are many types of non-motorized, land-based recreational trails and shared use paths: hiker and pedestrian trails, mountain biking trails, equestrian trails, and multi-use trails designed for several user types. The companion guide to this publication, the   (the \"Pennsylvania Trail Design Manual\"), provides guidance and detailed information about the characteristics of the various types of trails and paths. The publication is a resource to help evaluate, plan, design, construct, and manage  a route on a site. The publication   focuses on the accessibility aspects of the most commonly constructed types. \n While most trails have arisen through common usage, the design and construction of good quality new paths is a complex process that requires certain skills.\n When a trail passes across a flat area that is not wet, brush, tree limbs and undergrowth are removed to create a clear, walkable trail. A bridge is built when a stream or river is sufficiently deep to make it necessary. Other options are  ,  , and shallow fords. For equestrian use, shallow   may be preferred. In wet areas an elevated trailway with fill or a   is often used, though boardwalks require frequent maintenance and replacement, because boards in poor condition can become slippery and hazardous. \n Trail gradients are determined based on a site specific assessment of soils and geology, drainage patterns of the slope, surrounding vegetation types, position on the slope of a given trail segment (bottom, mid-slope, ridgeline), average precipitation, storm intensities, types of use, volume and intensity of use, and a host of other factors affecting the ability of the trail substrate to resist erosion and provide a navigable surface. Trails that ascend steep slopes may use  , but switchback design and construction is a specialized topic.\n Trails that are accessible by users with disabilities are mandated by the U.S. Federal Government to have slope of less than 12%, with no more than 30% of the trail having slope greater than 8.33%. \n Trails outside of wilderness areas have outward side-to-side gradients less than 8%,.  A flat or inward-sloping trail collects water and causes extra trail maintenance.  The ideal path is built almost, but not quite, level in cross-section.\n To achieve a proper slope in hilly terrain, a   trail is excavated. This type of trailway is created by establishing a line of a suitable slope across a hillside, which is then dug out by means of a   or similar tool. This may be a   trail, where the treadway is only on the firm ground surface after the overlying soil is removed and sidecast (thrown to the side as waste), or a   trail, where soil is removed and packed to the side so that the treadway is half on firm old ground and half on new packed fill. In areas near drainages, creeks and other waterways, excavation spoils are taken away in bulk and deposited in an environmentally benign area. Trails are established entirely on fill in problem areas. In such cases, the soil is packed down firmly and the site is periodically checked to maintain the stability of the trail.\n Cycle trails built for commuting may be built to a different set of standards than pedestrian-only trails and, in some cases, may require a harder surface, fewer changes in grade and slope, increased sight visibility, and fewer sharp changes in direction. On the other hand, the cross-slope of a bicycle trail may be significantly greater than a foot trail, and the path may be narrower in some cases. The   recommends different widths for different types of bicycle facilities.  For example, a shared use path has a recommended one directional width of 8 feet (2.44 m), while a bidirectional path should be significantly wider (10 to 12 feet or 3.05 to 3.66 metres) to accommodate bidirectional traffic and users.  The US Department of Transportation provides additional guidance on recreational bicycle and pedestrian trail planning and design standards. \n A well designed recreational   path for the exclusive use of bicycles has an average grade of less than 10% and generally follows a  , rather than straight downhill.\n Trail construction requires proper drainage. If drainage is inadequate, three issues may occur: water may accumulate on flat terrain to the point that the trail becomes unusable; moving water can erode trails on slopes; or inadequate drainage may create local mud spots. Mountain bike trails slope out or across the trail 3–5% downhill to encourage water to run off the side, rather than down the trail bed. \n To remedy the first problem, water accumulation on flat terrain, raised walkways are often built. They include turnpikes, causeways, embankments, stepping stones, and bridges (or deckwalks).  The earthen approaches are often done by cutting poles from the woods, staking parallel poles in place on the ground, then filling between them with whatever material is available to create the raised walkway. The more elaborate option of the deckwalk is by necessity reserved for shorter stretches in very high-traffic areas. Water accumulation is particularly common in the   of England.\n The second problem, water erosion, is caused because trails, by their nature, tend to become   channels and eventually gullies when the drainage is poorly controlled. Where a trail is near the top of a hill or ridge, this is usually a minor issue, but when it is farther down, it can become a very major one.\n In areas of heavy water flow along a trail, a ditch is often dug on the uphill side of the trail with drainage points across the trail. The cross-drainage is also accomplished by means of culverts cleared on a semi-annual basis, or by means of cross-channels, often created by placing logs or timbers across the trail in a downhill direction, called \"thank-you-marms\", \"deadmen\", or  . Timbers or rocks are also used for this purpose to create erosion barriers. Rock paving in the bottom of these channels and in the trailside ditches is sometimes used to maintain stability. The creation of water bars, with or without ditching, at major points of water flow on or along the trail, and in conjunction with existing drainage channels below the trail, is a technique that can be applied. Another technique that has been adopted is the construction of  , or drain dips, points on the trail where it falls briefly (for a meter or so) and then rises again. These provide positive drainage points that are almost never clogged by debris.\n The third type of problem can occur both on bottomlands and on ridgetops and a variety of other spots. A local spot or short stretch of the trail may be chronically wet. If the trail is not directly on rock, then a mud pit forms.  Trail users go to the side of the trail to avoid the mud pit, and the trail becomes widened. A \"corduroy\" is a technique used when an area cannot be drained. This ranges from random sticks to split logs being laid across the path. Some early turnpikes in the United States were  , and these can still be found in third-world forested areas. With recreational trails, it is common for the sticks to be one to three inches thick and laid in place, close together. Sometimes, a short bridge is used. \n Natural surface, single-track trails will require some ongoing maintenance. If the trail is properly designed and constructed, maintenance should be limited to clearing downed trees, trimming back brush and clearing drainages. Depending on location, if the trail is properly designed, there should be no need for major rework such as grading or erosion control efforts. Mountain trails which see both significant rainfall and human traffic may require \"trail hardening\" efforts to prevent further erosion. Most of the seemingly natural rock steps on the mountain trails of the northeast United States are the work of professional and volunteer trail crews. \n For long-distance trails, or trails where there is any possibility of someone taking a wrong turn,   or signage is provided (the term   is used in Britain). This is accomplished by using either paint on natural surfaces or by placing pre-made medallions or sometimes  . Horseshoe-shaped blazes are used frequently for bridle trails. The   is blazed with white rectangles, and blue is often used for side trails.   are blazed with yellow points encircled with red. Other walking paths in European countries are blazed in a variety of manners.\n Where bike trails intersect with pedestrian or equestrian trails, signage at the intersections and high visibility onto the intersecting trails are needed to prevent collisions between fast-moving cyclists and slower moving hikers and horses. Bicycles and horses can share the same trails where the trail is wide enough with good visibility.  The US Department of Transportation provides standards and guidelines for traffic control, including signage and striping, for bicycle facilities. \n A simple colored symbol to classify a trail's difficulty in the USA was first used for ski trails and is now being used for hiking, bicycle, other trails. \n Other systems may be used in different locations. \n In Switzerland, paths are classified by three levels of difficulties: Hiking paths (yellow markers), mountain paths (white-red-white markers) and alpine paths (white-blue-white markers).\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Urbana_University", "title": "Urbana University", "content": " was a   specializing in   education and located in  . In its final few years, it was purchased by   and was a branch campus of that university.\n Urbana University was founded in 1850 as   by followers of the 18th century   philosopher and scientist,  . The university was the second institution of higher learning in Ohio to admit women; the first was  . \n The groundwork for the founding of the university was in part laid by John Chapman, better known as  , who became the inspiration for the   founded for his extraordinary history. While more famous for spreading   seeds throughout the East, Chapman was also a     and helped spread this faith among the early settlers around Urbana.  Chapman encouraged his friend and fellow Swedenborgian,  , to donate the land on which Urbana University was built.  To this day, the university maintains an informal relationship with the  .  The university is also home to the   to honor John Chapman. \n Classes for elementary and secondary students under the name Urbana Seminary began in the fall of 1850 in a rented room in a building in downtown  .  College level classes were first held in the fall of 1854, following the construction of Bailey Hall, the first building on the campus.  Less than 10 years after the college opened it suspended operations from 1861 to 1866 during the  .  The college experienced a number of changes in the early 20th century when the college's curriculum was shortened to a two-year   format in 1907.  The school later shut down the primary school in 1911; and the   was closed in 1928. \n Urbana operated as a two-year college until 1968, when it returned curriculum to a four-year format.  In 1975, Urbana was granted full membership in the  .  In 1985, the institution changed its name from   to  .  Until 2014, in addition to having been a traditional  , Urbana University's School of Adult and Graduate Education offered associate degree and Bachelor of Science degree completion programs in Business Management, Education, Criminal Justice Leadership, Human Services Leadership, and many more. In addition to these programs, Master's programs were available in Business Administration, Education, Nursing, and Criminal Justice. Classes met on the Urbana University main campus, and at several off-campus locations throughout Western  . These locations were in  ,  ,  ,  ,  , and  . \n In 2014, the university was purchased by   after undergoing significant budget shortfalls.  Under the agreement, Urbana would retain its name, and act as a physical campus for both Urbana and Franklin students.  On August 1, 2017, Franklin University received approval for its change of status application by the Higher Learning Commission (HLC) to bring Urbana University under Franklin's accreditation as a \"branch campus.\" The campus closed in 2020, transferring records to Franklin University in Columbus, Ohio. Urbana cited the   and declining enrollment. \n The 128-acre (51.8 ha) main campus was located on the southwest side of Urbana in west central Ohio. Its buildings ranged from historic 19th-century buildings styled in traditional architecture to modern structures. Bailey Hall, Oak Hall, and Barclay Hall are the three oldest buildings on the campus. All three are listed on the  .  The university had undergone various changes in the early 21st century with the construction of Sycamore Hall in 2004, the Urbana University Stadium,  the Student Center in 2006, McConnell Hall in 2007, and Ross Hall in 2019. \n Urbana University offered 28 undergraduate majors and Graduate programs in Nursing (MSN), Education (MEd), Business Administration (MBA), Criminal Justice Administration (MA), and a Post-Baccalaureate in Teacher Licensure \n The Urbana athletic teams were called the Blue Knights. Their athletic colors were blue and white. The university was a member of the   ranks, primarily competing in the   (MEC) from 2013–14 to 2019–20. The Blue Knights previously competed in the   (G-MAC) as a provisional member only during the 2012–13 school year; as an   from 2008–09 to 2011–12; and in the defunct   (AMC) of the   (NAIA) from 1971–72 to 2007–08.\n Urbana competed in 19 intercollegiate varsity teams: Men's sports included baseball, basketball, cross country, football, golf, soccer, swimming, volleyball and wrestling; while women's sports included acrobatics & tumbling, basketball, cross country, golf, lacrosse, soccer, softball, swimming, volleyball and water polo.\n Urbana University also offered club sport programs in  ,  , and  .\n In 2010, Urbana completed the transition from the NAIA to the NCAA in the Division II ranks.  Also in that year, the   (GLVC) had accepted Urbana as an associate member of the GLVC in football only starting with the 2012 fall season.  In 2011, the university and five other schools, many also transitioning to the NCAA from the NAIA, had announced their intentions to form the G-MAC in 2013.  The G-MAC ultimately launched a year earlier than planned, in 2012, with Urbana as a member. The school spent only one season in the G-MAC; on August 20, 2012, Urbana was unveiled as a charter member of the MEC, a new Division II conference set to launch for the 2013–14 school year.  The MEC is mostly made up of schools leaving the then-soon-to-be dissolved   (WVIAC), but also includes another Ohio school in  . \n Urbana University had several recognized student organizations including leadership groups such as Student Government Association, Campus Activities Board, and Student Athlete Advisory Committee. There were organizations with special interest topics around politics, disc golf, and cancer awareness; and there were academic groups for history students and students interested in social sciences.\n There were six residence halls on campus (South, East, Francis E. Hazard, McConnell, Sycamore, and Ross halls). Urbana's residence halls emphasized civic responsibility, mutual respect, mature interpersonal relationships, multicultural understanding, and community engagement. Students living on campus forged friendships to last a lifetime while learning about different cultures, backgrounds and ideas, gaining an understanding of being part of a community, and developing their leadership skills. Residential living provides students with life skills that were transferable to careers and other aspects of independent living after graduation. Advice and guidance are available from trained upperclass student resident assistants and professional resident hall directors, as well as an Area Coordinator.  Resident assistants lived on each floor of each residence hall and served as a resource for students dealing with any type of issue. The university's Student Conduct programs were recognized as Ohio's most innovative Student Affairs program in 2014 by the Ohio College Personnel Association. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/The_Foundation_for_Global_Sports_Development", "title": "The Foundation for Global Sports Development", "content": "The   is a   which creates and supports programs promoting sportsmanship, education, fair play and ethics for children around the world.  Attorney   is president of the foundation and author and psychologist   is vice president of the board of the foundation. \n In 2015, the foundation pledged $75,000 to the   (IPC) in order to spread education and awareness about the IPC's efforts in the United States. \n The foundation helped fund the film   about the   released in 2016, as well as a memorial to the 11 Israelis that were killed by terrorists at the  .  The film has been nominated for an Emmy in the Outstanding Category of the 38th Annual News & Documentary Awards. \n In April 2017, the foundation co-hosted a symposium on anti-doping issues in sport at   in Malibu.  , president of the International Paralympic Committee delivered the keynote speech. \n The Foundation for Global Sports Development founded the Playmakers Program which works with youth programs to bring kids to the Olympics.  The program sent 50 at-risk kids that attended the Boys & Girls Clubs of San Francisco to the Vancouver Olympics in 2010.  In 2012, the foundation worked with   to help a group of teens go to the Olympics in London through the Playmakers program.  In 2016, 50 teens from the Denver area participated in a three day trip to the Olympic Training Center in Colorado Springs through the Playmakers program. \n The foundation's team of champion ambassadors works with youths worldwide through mentorship programs and motivational speeches as well as podcasts and blogs. In 2016,  , a Paralympian, was included on the team of champion ambassadors. \n The foundation partnered with the Agitos Foundation to support projects with   in 2015.  In 2016, 49 coaches from 23 countries received training in the \"Elite Para Powerlifting Coaching Course\" supported by the Agitos Foundation and the Foundation for Global Sports Development in preparation for the  . \n Since 2013 the foundation has partnered with the   to present the Olympic Celebration Tour. This tour helps generate interest in the sport of   by bringing an Olympic curler to member associations and curling clubs around the world. \n The foundation established the Athletes in Excellence Award, which honors competing and retired athletes around the globe who have been leaders and champions in sport as well as in their communities. In 2015, the honor was awarded to 12 athletes around the world.  The foundation awards the recognized athletes with a $10,000 unrestricted grant to further service and career goals. \n The organization also gives a Humanitarian Award to leader and champions for social, economic, political or environmental justice and equality. In 2010, the award was given to  , the founding chair of the  .  The award went to   the IPC president, in 2012.  In 2014, the organization honored  , the chairman of the medical commission of the   (IOC) and former vice chairman of the World Anti-Doping Agency.  In 2016, the award was given to   of the IOC. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Daylight_saving_time_in_Oceania", "title": "Daylight saving time in Oceania", "content": "Parts of  ,   and   are areas of   that currently observe   (DST).\n Currently,  ,  ,  ,  ,   and   apply DST each year, from the first Sunday in October to the first Sunday in April.\nThe  ,  ,   and the external territories do not observe DST.\n Daylight saving was first used in Australia during  , and was applied in all states. It was used again during the Second World War. A drought in Tasmania in 1967 led to the reintroduction during the summer, and this was repeated every summer since. In 1971, New South Wales, Victoria,  Queensland, South Australia, and the Australian Capital Territory followed Tasmania in observing daylight saving, Western Australia and the Northern Territory did not. Queensland abandoned daylight saving time in 1972. Originally   alone commenced daylight saving on the first Sunday in October, while the other states began on the last Sunday in October and finished on the last Sunday in March, until 2008 excepting in 2000 when all the states observing DST moved forward the commencement date to Sunday, 27 August 2000 because of the Sydney Olympic Games which commenced in mid-September. From 2008/09 daylight saving has been extended another four weeks in NSW, Victoria, SA and the ACT, in addition to Tasmania, from the first Sunday in October to the first Sunday in April. \n  again trialled daylight saving, for three years between 1989 and 1992, with a   held on 22 February 1992, which was defeated with a 54.5% ‘no’ vote - with regional and rural areas strongly opposed, while those in the metropolitan   were in favour. \n In December 2008, the     was officially registered, advocating the implementation of a dual-  arrangement for Daylight Saving in   while the rest of the state maintains  .   The party contested the   with 32 candidates and received around one percent of the state-wide primary vote, equating to around 2.5% across the 32 electorates contested. \n On 14 April 2010, and after being approached by the    ,     member  , introduced the   into  , calling for a   to be held at the next State election on the introduction of daylight saving into   under a dual-  arrangement.  The Bill was defeated in Queensland Parliament on 15 June 2011. \n In  , four   in 1975, 1984, 1992 and 2009 have rejected DST. \nIn 2006, the   approved a three-year daylight saving trial to be followed by a referendum to decide whether DST should be put in place permanently. However, public opposition mounted during the first year of the trial,  and the   announced a public campaign to bring the referendum forward to 2007.  The trial continued until the referendum, held on 16 May 2009.  The result was another rejection of DST, by a larger margin compared to the three previous referendums. Although as previously the suburbs of the state capital,  , supported the proposal, it was by a much narrower margin than before with significant swings against it in several areas, most notably in the   region. As a result, the Premier of Western Australia has said that the DST issue should not be considered for at least another 20 years. \n The Northern Territory experimented with daylight saving in the early part of the 20th century. It was last used in 1944.\n Despite its proximity to the equator and therefore a relatively small variation of daylight length,   implemented daylight saving time in 1998-99 but it ended after that.     restarted DST in 2009 starting on November 29 and ending on April 26, 2010. The decision was based on a report by the Attorney-General, Mr  . \"Mr Sayed-Khaiyum said that from the information available, the implementation of daylight saving in 1998 and 1999 received very encouraging response from the people and the business community. Apart from availability of more daylight time for sport, leisure and shopping, the working people are able to spend quality daylight time in the afternoons and evenings with their family and loved ones, including engaging in healthy activities such as gardening or going for a walk. In 1999, the Ministry of Labour reported that there was an overall increase in economic activity and productive work as a result of daylight saving.\"  For the 2010-2011 summer, DST started on fourth Sunday in October and ended on last Sunday in March. Fiji changed the ending of DST to the last Sunday in January in 2011.  In 2021 the Fiji government announced that Fiji would not observe daylight saving time in 2021–22. \n Although   is further away from equator than  , and therefore there is a slightly greater variation in the daylight length, Hawaii does not observe DST. Most of the inhabited islands are located close to the west end of the  , and  ,   and   are located more than 7 degrees west of the Hawaii–Aleutian Time Zone's   and should, theoretically, be located in the next   to the west. Therefore advancing the clock in Hawaii would make sunrise times close to 7:00 a.m. even in June. \n Hawaii did experiment with DST for three weeks between April 30, 1933 and May 21, 1933; there are no known official records as to why it was implemented or discontinued.  Hawaii has never observed daylight saving time under the  , having opted out of the Act's provisions in 1967. \n From 30 April 2007, DST begins at 02:00 NZST on the last Sunday in September each year, and ends at 03:00 NZDT (or 02:00 NZST as defined in the Time Act 1974) on the first Sunday in April.\n New Zealand time, including DST, is used by several   bases that are supplied from New Zealand. This results in the oddity that the   sets its clocks an hour further ahead during the southern summer, when the sun is constantly above the horizon, than in the southern winter, when the sun is constantly below the horizon. The extreme geographic position of the base means that no possible adjustment of the daily activity cycle can have any effect on the amount of sunlight received during those activities. However, the arrangement presumably  makes real time communications with New Zealand more practical, particularly in dealing with offices.\n The New Zealand dependencies of  ,   and   do not maintain DST. The latter two are on the other side of the   and differ between 22 and 24 hours from New Zealand proper.\n  observed DST from 2010 to 2021, starting on the last Sunday in September and ending on first Sunday in April. \n All   with civilian government in Oceania,  ,  , and the   lie in the tropics and do not observe DST.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Jonas_S%C3%B6derlund", "title": "Jonas Söderlund", "content": " (born June 1, 1971) is a Swedish   and Professor in the Department of Leadership and Organizational Behavior at the  , and author. He is known for his work in the fields of  ,   . \n Söderlund was born in  , Sweden in 1971, son of Söderlund Claes R. and Yvonne Elisabeth Söderlund. In 1995, he obtained his MSc in   and   from the   in Sweden. \n After his graduation Söderlund started teaching and continued his studies at the Linköping University, In 1998 he obtained his   of Business Administration, and in 2000 his PhD in its International Graduate School of Management and Industrial Engineering (IMIE). His thesis was entitled \"Time-limited and complex interaction – studies of industrial projects\". In 1998, he had attended the Program in General Management at the   as visiting doctoral student. \n In 2000, Söderlund started as Assistant Professor at the School of Management at the  , where he was promoted to Associate Professor of Business Administration in 2003. From 2003 to 2007 he also served as Director of the Linköping Project Center at the Linköping University. In 2007, he was appointed Professor in Project Management at the  \n In 2009, Söderlund was awarded the HR Research Award for Best Research on HRM 2009 by the   and the Institute for Personnel & Corporate Development (IPF). In 2011, he and Karin Bredin obtained the International Project Management Association (IPMA) Research Award 2011 for \"outstanding research on HRM in project-based organizations\". \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Japanese_cyberpunk", "title": "Japanese cyberpunk", "content": " refers to   fiction produced in Japan. There are two distinct subgenres of Japanese cyberpunk: live-action Japanese cyberpunk films, and cyberpunk   and   works. \n Japanese cyberpunk  , also referred to as Extreme Japanese Cyberpunk, refers to a sub-genre of   produced in  , starting in the 1980s. It bears some resemblance to the 'low-life high-tech'  , as understood in the West; however, it differs in its representation of industrial and metallic imagery and an incomprehensible narrative. The main directors associated with the Japanese cyberpunk movement are  ,  , and  .  The origins of the genre can be traced back to the 1982 film  , before the genre was primarily defined by the 1989 film  .  It has roots in the Japanese  , which arose from the   music scene in the 1970s, with  's   of the late 1970s to early 1980s introducing this subculture to   and paving the way for Japanese cyberpunk.\n Japanese cyberpunk also refers to a subgenre of manga and anime works with cyberpunk themes. This subgenre began in 1982 with the debut of  's   series  , with its   (which Otomo directed) later popularizing the subgenre.   inspired a wave of Japanese cyberpunk works, including manga and   series such as  ,  ,  , and  .  Cyberpunk anime and manga have been influential on global  , inspiring numerous works in animation, comics, film, music, television and video games. \n Japanese cyberpunk generally involves the characters, especially the protagonist, going through monstrous, incomprehensible   in an industrial setting. Many of these films have scenes that fall into the   genre; they often involve purely abstract or visual sequences that may or may not relate to the characters and plot. Recurring themes include: mutation, technology, dehumanization, repression and sexual deviance. \n In contrast to Western cyberpunk which has roots in   literature, Japanese cyberpunk has roots in   culture, specifically the Japanese   that arose from the   music scene in the 1970s. The filmmaker   introduced this subculture to   with his     (1978) and   (1980), which portrayed the rebellion and anarchy associated with punk, and went on to become highly influential in   circles.   in particular was an influential  , with a punk   aesthetic that paved the way for  's  . Ishii's next film was the frenetic   (1981), an unofficial   adaptation of a     by Otomo.  According to  , when Akira began to be published, cyberpunk literature had not yet been translated into Japanese, Otomo has distinct inspirations such as  's manga series   (1956–1966) and  . \n Ishii's most influential film was   (1982).  Since its release, it has had a strong effect on the underground Japanese film scene.  It starred  , who would, four years later, go on to direct his own cyberpunk film,  , in 1986. The early short films of  , such as   (1987)  and   (1986)  (which   was a remake of), are often credited as precursors of the movement.\n Some defining films in the genre include: \n Related films include:\n Japanese cyberpunk also refers to a subgenre of   and   works with cyberpunk themes. This subgenre began in 1982 with the debut of the   series  , with its   later popularizing the subgenre.   inspired a wave of Japanese cyberpunk works, including manga and   series such as  ,  ,  , and  . \n Cyberpunk themes are widely visible in   and  . In  , where   is popular and not only teenagers display such fashion styles, cyberpunk has been accepted and its influence is widespread.  's   whose influence dominated the early cyberpunk movement, was also set in  , one of Japan's largest industrial areas.\n Cyberpunk anime and manga draw upon a futuristic vision which has elements in common with western science fiction and therefore have received wide international acceptance outside Japan. \"The conceptualization involved in cyberpunk is more of forging ahead, looking at the new global culture. It is a culture that does not exist right now, so the Japanese concept of a cyberpunk future, seems just as valid as a Western one, especially as Western cyberpunk often incorporates many Japanese elements.\"  William Gibson became a frequent visitor to Japan, where he came to see that many of his visions of Japan were a reality:\n Modern Japan simply was cyberpunk. The   themselves knew it and delighted in it. I remember my first glimpse of  , when one of the young   journalists who had taken me there, his face drenched with the light of a thousand media-suns—all that towering, animated crawl of commercial information—said, \"You see? You see? It is   town.\" And it was. It so evidently was.  (1982 manga) and its   have influenced numerous works in animation, comics, film, music, television and video games.    has been cited as a major influence on   such as  ,   ,   ,   ,   , and  ,  television shows such as  ,  and video games such as  's   and  ,   's   series  and  's  .    cited   as artistic inspiration for the   effect in  .    has also been credited with influencing the   franchise, including the   and the   film and television series.    has also influenced the work of musicians such as  , who paid homage to   in the \" \" music video,  and  , whose album   is named after Tetsuo Shima.  The popular bike from the film, Kaneda's Motorbike, appears in  s film  ,  and  's video game  .    video game developer   also paid homage to the film's poster. \n  (1989) influenced a number of prominent filmmakers.  , creators of   (1999) and its sequels, showed the   to producer  , saying, \"We wanna do that for real.\"    series took several concepts from the film, including the  , which was inspired by the opening credits of  , and the way characters access the Matrix through holes in the back of their necks.  Other parallels have been drawn to  's  ,  's  , and  's  ;  Cameron cited   as an influence on  .    also influenced video games such as the   series,   ,   ,  and  . \n The     (1985), with its concept of a simulated reality, has a number of similarities to  ,   , and  .    (1990) has had a notable influence on filmmaker James Cameron, who was planning to adapt it into a film since 2000. It was an influence on his TV series  , and he is the producer of the 2018 film adaptation  .    artist André Lima Araújo cited cyberpunk manga and anime such as  ,  ,   and   as a major influence on his work, which includes   such as  ,  ,   and  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/National_School_Choice_Week", "title": "National School Choice Week", "content": " was founded in 2011 to promote the concept of all forms of school choice: district schools, district  ,  ,  , and  . The event, which takes place the last week of January each year, is sponsored by the National School Choice Awareness Foundation. \n In 2014, Republican Sen.   and Democratic Rep.   appeared at a National School Choice Week event at Minute Maid Park in Houston.  In 2015, National School Choice Week opened with a nationally televised event in Jacksonville, Florida, featuring speeches by former NFL player  , Democratic strategist Joe Trippi, and a video greeting by U.S. Senator  .  In 2018, U.S. Secretary of Education   spoke at a National School Choice Week event on Capitol Hill.   \n National education organizations that have participated in the week's events include the  ,   ,  the Council on American Private Education,  the National Coalition for Public School Options,  the  ,  the American Federation for Children,  the  ,  the  , the  ,  Choice Media, Education Reform Now, Families Empowered, the  ,  and the 50 State Campaign for Achievement Now. \n From 2015 to 2019, the US Senate passed a commemorative resolution recognizing School Choice Week,  and U.S. President   issued similar proclamations in 2017,  2018,  and 2019. \n The President of National School Choice Week is Andrew Campanella. He has served in this capacity since 2012. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Lim_Ji-yeon", "title": "Lim Ji-yeon", "content": "\n  ( :  ; born June 23, 1990) is a South Korean actress. After appearing in a number of short films and plays, she had her first feature film role in   (2014).  The role earned her a Best New Actress nomination at the  , and wins at the   and  , among other accolades. She subsequently starred in the film   (2015) and the television series   (2015), and gained international acclaim for the   hit series   (2022–2023); the latter brought Lim the   trophy at the  .\n Lim dreamed of becoming an actress after watching the musical   as a child. Due to her parents concerns, she went to study in humanities high school. Eventually, she entered the  , where she majored in acting and started walking the path of an actress after persuading her parents.  Lim was part of the Class of 2009 in the Department of Acting, alongside classmates such as  ,  , and  . \n Lim debuted in 2011 through the short film  . She also appeared in other short films such as   in 2013.  In 2013, Lim was cast to make her feature debut film in   directed by   while still being a student at Korea National University of Arts.  The film was released in 2014,  and her role as Jong Ga-heun earned her a few accolades such as Best New Actress in   and nominated in   .  Three months after the release of the film, Lim was selected as the model for   Hanyul cosmetics, citing her oriental elegance and modern beauty fit well with the brand pursuing Korean Beauty. \n In 2015, Lim took the role of ambitious concubine Dan-hee in a period drama film   directed by  .  June 2015, she made her small screen debut through   Her bubbly and lovely character as Lee Ji-yi won her New Star Award at  ,  and Best New Actress at  .  She also ventured into hosting of MBC Section TV Entertainment News  and the  , along with   and  . The same year, she won Excellence Award in Music/Talk Category – Female at  . \n In 2016, Lim appeared in another period drama   as Dam-seo who take revenge upon king due to a painful family history.  In August 2016, she starred in weekend drama   as a cheerful and positive North Korean woman defector who lives in South Korea, for which she practiced the North Korean dialect.  For her role as Kim Mi-poong, she won Excellence Award, Actress in a Serial Drama at  . She made a cameo appearance on the popular drama   because of her close relationship with writer Ha Myung-hee, whom she previously worked with  .  The same year, she starred in comedy film   directed by  . \n Lim returned to small screen in 2019   fantasy romantic comedy series about a skilled lawyer who enters a parallel world due to an unfortunate accident.  For her role, she won Top Excellence Award, Actress in a Monday-Tuesday Miniseries at 2019  .  The same year, she starred in crime drama in gambling world film   as Young-mi. Her web series   was pre-filmed in 2017 and was released through   Seezn in 2021.  She also starred in the 2021 mystery action fantasy film  , and received a nomination in   for Best Supporting Actress for the role. \n In May 2020, Lim signed with the Artist Company. \n In 2022, Lim lead the role of Gi-na in the web series  , alongside  , a mystery drama that pursues the truth of finding her missing sister among suspicious neighbors and discover more dark secrets about the apartment.  December the same year, she appeared in the part 2 of  's original series   where she played the role of Seoul, a character that was not in the original work. \n At the end of 2022, Lim challenged her first villain role in the Netflix's original series  , where she played the role of Park Yeon-jin, a weather presenter who led the group of delinquents in bullying and physically abusing the protagonist during high school. The series was popular and well-received among audiences, and her portrayal was met with favorable reviews and is said to be her life's character.  For her performance in  , she won Best Supporting Actress – Television at the   and Best Supporting Actress at the  . \n In June 2023, Lim starred alongside   in a suspense thriller drama and mystery   Her performance as a domestic violence victim was praised for being able to transform 180° from her previous role in  .  In particular, one of her scenes in the drama went viral for raising viewers' appetites and praised by critics for showing liberation and a hint of madness well after the death of her husband.  She also starred in the crime thriller drama  , which premiered in August 2023. \n In August 2023, Lim was selected by the Korean Film Directors Association at the 2023 Bechdel Day award as Actor of the Year (series category) for her performance in   and  . Judges evaluated her performance in   as did not confined the character as just \"flat villain\" but carved a path of complicated villain desire that they had never seen before. For her acting in  , she showed that even in the chilling moment of revenge, the animalistic acting of not wanting to starve her child in the belly convinced the extreme temperature difference within one person.  In 2024, Lim role in   earned her another Best Actress – Television nomination at the prestigious  . \n In June 2024, PlusM Entertainment confirmed Lim will appear in revenge film   alongside actors   and  . The movie is slated for August 2024 release.  Lim who showed her own unique style as the mysterious Jeong Yoon-sun in   won   award at the   and honoured   award by  . The film committee  cited Lim  .  Lim is confirmed to lead a survival romance historical drama  , making it seven years since her last historical drama in  .  The drama is confirmed to broadcast in November 2024. \n On May 30, 2023, Lim was appointed as an honorary police officer for the Seodaemun District Police Agency in Seoul, where she would be \"publicizing major police policies, various security activities, and drug crime prevention for the next 2 years\".  In February 2024, Lim was announced as the new brand ambassador for  , a Spanish luxury fashion brand. \n On April 1, 2023, Artist Company confirmed that Lim is dating actor  , whom she met while filming  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Tabuk_province", "title": "Tabuk Province", "content": " ( :    ) is a   of  , located along the northwestern coast of the country, facing   across the  . It has an area of 146,072 km  and a population of 910,030 (2017).  Its capital is  . The governor is   since 1987.  In recent years, the province has received substantial media attention due to the Saudi government's planned   City project in the province. \n The history of the Tabuk region dates back to 5,000 years ago. The region is identified with the land of  . The region is traversed by the  , which was a focus for attacks during the   of 1916–1918. \nThe province has traditionally been inhabited by the   tribe.\n Tabuk is an active commercial center, serving pilgrims passing through towards Mecca. Due to its moderate climate, it's also the site of several dairy and poultry farms. The region (Astra) exports flowers to Europe, mainly lilies, statices and gladiolas.  In the past, a   (1,050 mm / 3 ft 511⁄32 in  ) ran from   to   through Tabuk. Remains of the railway can be found in Tabuk, where a large station was built. The station has since been restored. \n The governors of the region since 1926 are as follows: \n \n This article about the geography of   is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Everything2", "title": "Everything2", "content": " (styled   or   for short) is a collaborative   consisting of a database of interlinked user-submitted written material. E2 is   for quality, but has no formal policy on subject matter. Writing on E2 covers a wide range of topics and genres, including encyclopedic articles, diary entries (known as \"daylogs\"), poetry, humor, and fiction.\n The predecessor of E2 was a similar database called Everything (later   \"Everything1\" or \"E1\") which was started around March 1998 by   and was initially closely aligned with and promoted by the technology-related news website   (by virtue of various key principals having attended the  ), even sharing (at the time) some administrators.  The Everything2 software offered vastly more features, and the Everything1 data was twice incorporated into E2: once on November 13, 1999, and again in January 2000.\n The Everything2 server used to be colocated with the Slashdot servers. However, some time after   acquired Slashdot, and moved the Slashdot servers, this hosting was terminated on short notice. This resulted in Everything2 being offline from roughly November 6 to December 9, 2003. Everything2 was then hosted by the   for a time. As the Everything2 site put it on October 2, 2006:\n Now, we have an arrangement with the University of Michigan, located in Ann Arbor. We exist thanks to their generosity (which is motivated by their academic curiosity, I suppose). They gave us some servers and act as our ISP, free of charge, and all they ask in exchange is that we not display advertisements. The Everything2 servers were moved to the nearby   in February 2007.\n E2 was privately owned by the Blockstackers Intergalactic company,  but does not make a profit and is viewed by its long-term users as a collaborative work-in-progress. Until mid-2007 it accepted donations of money and, on occasion, of computer hardware but no longer does so. Some of its administrators are affiliated with Blockstackers, some are not. The site is not a democracy, and the degree to which users influence decisions depends on the nature of the decisions and the administrators making them. As of January 23, 2012, it was announced that the site had been sold to long-time user and coder Jay Bonci under the name Everything2 Media LLC.\n Writeups in E1 were limited to 512   in size. This, plus the predominantly \"geek\" membership back then and the lack of chat facilities, meant the early work was often of poor quality and was filled with  . As E2 has expanded, stricter quality standards have developed, much of the old material has been removed, and the membership has become broader in interest, although smaller in number. Many   prefer to write encyclopedic articles similar to those on   (and indeed some actively contribute to both E2 and Wikipedia). Some write fiction or poetry, some discuss issues, and some write daily journals, called \"daylogs.\" Unlike Wikipedia, E2 does not have an enforced  . An informal survey of noder political beliefs  indicates that the user base tends to lean   politically. There are conservative voices as well, however, and while debate nodes (of any kind, political or not) are rarely tolerated, well-formed points of view from any part of the political or cultural spectrum are.\n Despite predating Wikipedia as a collaborative user-generated online encyclopedia, Everything2 never achieved Wikipedia's level of popularity.   scholar   ascribes this to a combination of factors including \"editorial issues\" and Everything2's launch before the  .  According to E2's \"Site Trajectory\",  traffic has dropped from 9976 new write-ups created in the month of August 2000, down to 93 new write-ups in February 2017.\n Some of the management regard Everything2 as a publication, to which authors submit content. Although Everything2 does not seek to become an  , a substantial amount of factual content has been submitted to Everything2.\n Policy states that \"Everything2 is not a bulletin board.\" Writeups which exist as replies to other writeups, or which add a minor point to them or which otherwise do not stand well alone are discouraged, not least because the deletion of the original writeup orphans any replies. This policy helps to moderate   on controversial topics.\n Everything2 is not a  , and there is no direct way for non-content editors to make corrections or amendments to another author's article. Avenues for correction involve discussing the writeup with its author; petitioning a content editor; adding a note in a special \"broken nodes\" section; or superseding the original writeup with an original, stand-alone follow-up.\n E2 users called   create entries called   and add information in multiple   Only logged-in users can create writeups, and only the author of a writeup or an editor appointed by the site administrators can edit a writeup. E2 categorizes writeups into thirteen types:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , and  . Two additional writeup types,   and  , are usable only by editors and are applied retroactively. Writeups are written in a simplified   dialect and do not contain images.\n There are other types of nodes that do not contain writeups; for instance, the administrators can create \"superdoc\" nodes (similar to  's  ) such as Everything New Nodes and Page of Cool that allow interaction, and each user has a \"homenode\" where he or she can add a short autobiography or other text (or a picture, if the user has posted ten writeups—see  , below).\n The   in a writeup rests with the author, and no agreement to any kind of license is entered into by writing on E2 (except for giving the site permission to publish). Authors retain the right to place their work in the public domain, to release it under a   license such as one of those offered by the   project or  , or to request the removal of their work from the site at some later date.\n For a long time, the posting of copyrighted song lyrics and poetry to the site without approval from the copyright holders, while certainly frowned upon, was not actually prohibited. E2 chose to only passively enforce copyright law, in a manner similar to an ISP (for which see  ). This policy changed in August 2003 to a more active one where writeups containing copyrighted material had to either conform to   guidelines (length limits, proportion of quoted material to new text) or be posted with permission.\n The administrators loosely based E2's incentive system on a dual currency system borrowed from many  . Users may earn   (\"XP\"), which count strictly toward level progress, or convertible currency (\"GP\"), which may be used to purchase lesser, temporary privileges. Every time a user creates a writeup, he or she earns five XP. Users with at least ten contributed writeups and 500 experience points can vote (up or down) on a writeup. A positive vote grants the writeup's author one experience point while also having a roughly ⅓ chance of giving one GP to the voter. After voting on a writeup, a noder can see the writeup's \"reputation,\" or number of positive and negative votes (staff do not need to vote in order to see a writeup's reputation). The site's editors may remove writeups that do not meet editorial standards from public view. Authors have the ability to withdraw their own writeups. In both cases the removed writeup is sent to its author's personal \"drafts\" space, where it may be prepared for re-submission or deleted. The only effect writeup deletion has on the author's account is that the five XP granted for creating the writeup is removed. Writeups deleted before March 2011 are visible to the author on a legacy page called \"Node Heaven\"; newer or more recently removed items become drafts.\n New levels are attained by reaching a predefined, but arbitrary total of XP and writeups, which are given in the FAQ.  The system grants special powers at certain experience levels, such as \"cool\",  which rewards the author with 20 XP and sends the writeup to the \"cool user picks\" column on the front page; the ability to create basic   on the site; space for uploading a picture to a user's \"homenode\"; and the ability to hide one's self in the list of logged-in users.\n Website views used to be tracked, but due to a glitch this ability was removed. The glitch looped the view counter and crashed the site on more than one occasion.\n Everything2 provides two communication tools: the Chatterbox  and the message system.\n The Chatterbox is similar to an   channel. It is also nicknamed the catbox. It appears as a panel on the right side of the page that logged-in users can use to read conversations and participate in them. The site's administrators used to have the ability to \"borg\"—prevent from using the Chatterbox or message system—those users whose behavior violated the unwritten standards of politeness and decorum. This was done through a   called EDB (short for \"Everything Death Borg\"), which announced when it had \"swallowed\" a user. This silencing lasted for five minutes, though persistent   were silenced for a longer period—sometimes permanently. As of 2003 , the EDB was no longer much used, only making mostly token appearances for humorous effect. Noders who consistently cause trouble (usually by  ) can be silenced permanently and can be forbidden from noding altogether, though this is rarely done. This would be initiated by a chanops, (A staff member with a + by his or her username that monitors potential abuse ). There is also a utility called 'chatterlight', which provides the chatlog / message buffer with a larger portion of the screen.\n The message system lets users send private messages to other users. The messages are stored in the user's mailbox to be read when he or she next logs in. The main use for the message system is giving constructive criticism to the author of a writeup; however, it can be and is used like any medium of private communication. Messages received can be archived or deleted at the receiver's discretion.\n  in E2 are simply words or phrases surrounded by [square brackets]. Any words inside square brackets in a writeup will become a link to the E2 node of that title. If a node with that title does not yet exist, following the link will bring up the option to create it.\n For the first several years of its existence, E2 did not permit links to third-party web sites in submitted content. In February 2009, a degree of support for linking external URLs was implemented.  A hard linked URL will be clearly marked as an external link with the same link icon that Wikipedia uses.  Heavy use of external URLs is discouraged as E2 content is expected to stand on its own within a largely self-supportive infrastructure.\n  are a variant form of hard links. While a hard link to the node   would look like  , the pipe link allows the author a greater degree of freedom without restricting what nodes can be linked to. For example, one could write \" \" The sentence looks like this to the reader: \"  have started to become common sources in my students' research papers.\" Rolling over the phrase with the mouse (e.g. \"online encyclopedias\") shows the hidden content (in this case, \"Wikipedia\") as the link's title.\n Noders can link to a specific writeup within a node by appending  ,  ,   or   to a pipe link. For example, the pipe link   links directly to the writeup of the type   within the   node. If the node contains more than one writeup of the specified type, the pipe link returns a \"Duplicates Found\" page linking to every writeup of the specified type within the node.\n Pipe links on E2 often add \" \" content, such as commentary, humor and hidden information. \n At the bottom of every node, the system displays up to 64  , though each node can store an unlimited number thereof. \"Guest Users\"—any viewers not logged in—can see 24, a logged-in user can see up to 48, and the senior administrators (\"gods,\" though this term has fallen out of favour in recent years) can see up to 64. These are two-way links intended to approximate \"thought processes,\" similar in concept to  's tangle proxy. Whenever a logged-in user moves from one node to another, be it through a hard link, another soft link, or through the title search box, the system creates (or strengthens) the bidirectional soft link between the two; however, some nodes—namely the special pages and the user profiles—will not display the soft links so created. By repeatedly moving from one node to another, users can and do deliberately create and increase the degree of integration of such soft links; some users will use these soft links to make anonymous comments on others' writing. The site's administrators have the ability to remove soft links at their discretion.\n  are special, editor-created links that serve to redirect between nodes.  Firm links are typically used to link multiple forms of a single name or title to aid searching and ensure that readers find the content that they are seeking.  A typical use of firm links would be to permanently link the empty node titled 'USA' to a node titled 'United States of America' that contained writeups about the topic. Alternatively, automatic forwarding can be set up for the same thing, in much the same way as forwards exist on Wikipedia.\n E2 is run by the   Everything Engine ( ), a  -based system; its data is stored in a   database. \n In 2001,   cited E2 as an example of an emerging class of autonomous, self-organizing sites.  A 2001 column in   called E2 \"awe-inspiring in its expansiveness and depth\" and \"a   of knowledge management\".  Writing for  ,   cited Everything2 alongside   and The Vines Network as an example of \"a revolutionary change in media\" in 2001. The websites represented \"a new kind of bottom-up media in which readers and users—not just editors and producers—set the agenda\", safeguarding themselves against elitism or becoming disconnected from their readership \"since their readers are defining and participating in content\". \n A 2005   op-ed by university student Claude Willan discussed Everything2 in the context of     disaffection.  The column began by discussing   as a subversive collective identity for   activities, and used Borf's co-opting into an anonymous collective body as a launching point for a meditation on the Millennial generation's sense that modern society's \"images don't relate to us\" and \"all we can do to make ourselves heard is to twist these images back on themselves.\" The youthful impulse towards collectivism played out for this generation on the internet, \"where identity is automatically annulled\" and \"anonymity allows collective projects to flourish with no individual gain, only collective gain.\" Willan gave the \"collectivist writing project Everything2.com\" as an example of this phenomenon: \"run by people you may never meet or talk to, and who specialize in creating fiction or journalism.\" Willan quoted Everything2 user loquacious defining the site as \"a reference collection, a novel that writes itself, poetry that reads itself, and the shiny toy that never grows dull\"; for Willan, the elusiveness of Everything2's nature reflected the slipperiness of the Millennial generation's undefinable collective identity. \n In 2003,   listed E2 as one of the best collaborative encyclopedias on the Web.  E2 was nominated for a 2004   for Technical Achievement. \n In their study of art in the  ,  ,   scholars   and   discuss Everything2 in the context of the necessity for art to expand its recognition in order to \"perform a meaningful role in society\", remaining effective by \"inviting attention, encouraging new understanding, but resisting full co-optation\" to avoid becoming clichéd or banal.  They call Everything2 \"an exceptionally quirky but highly readable open-source encyclopedia.\" They draw a contrast between Everything2's XP-driven   encouraging \"eccentric or provocative subjects\" and Wikipedia's \"purely egalitarian\" precedent where all visitors can edit articles and \"all entries are at the same level\"; they also contrast Slashdot's conversational writing that links to external news with Everything2's crafted writing that usually links internally to other Everything2 writeups, which fosters \"a focused, if inbred, community.\" \n In  , new media scholar Jeff Rice views   from a   perspective, identifying within cool a variety of constituent rhetorical moves and using this framework to analyze new media. Rice proposes that   is one of cool's component rhetorical moves  and offers  's concept of   as an example of cool media due to its interlinked, juxtaposed writing. Rice describes Everything2 as a website that most closely resembles Nelson's concept: users forge connections between disparate materials, juxtaposing writings \"at the point a pattern (word, concept, idea) appears.\" Writing on Everything2 never stands alone, always layering over and interacting with other writings, actualizing many aspects of \"Nelson's concept of hypertext as a writing space outside of [..] 'the paperdigm'\" (Nelson's term for technology that duplicates the writing practices of  ). \n In his study of   as providers of socializing functions and tools for organizing online communities, Cliff Lampe describes Everything2 as \"a compelling example of   interactions.\" Everything2 was one of the first online communities \"to implement reputation and rating systems as a means of governing user behavior.\"  The reputation system was initially implemented to improve a user's reputation primarily by the number of writeups the user posted; in practice this incentivized the production of many short, low-quality writeups and led to the community coining the derogatory term \"Noding for Numbers\".  Everything2 responded by revising its reputation system to favor user ratings of writeups over the number of write-ups posted. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/The_Intelligencer_%26_Wheeling_News_Register", "title": null, "content": " are combined daily newspapers under   in  , and are the flagship publications of  .  The   is published weekday mornings and Saturdays, while the   is published weekday afternoons and Sundays.\n Founded as the   in August 1852 by Eli B. Swearingen and Oliver Taylor,    is the oldest continuously published daily newspaper in the state of West Virginia. The paper was initially established as a means to promote   and the   in the  . \n  \n \n This article about a West Virginia newspaper is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Anita_DeFrantz", "title": "Anita DeFrantz", "content": "\n  (born October 4, 1952) is an American Olympic rower, member of the  , and twice vice-president of   (FISA).\n DeFrantz was born on October 4, 1952, in  ,  .  A member of the   in her home city,  she was captain of the American rowing team at the   winning the bronze medal in  . In 1980, the United States   in  ,  ,  : DeFrantz qualified as part of the   team, but she was unable to compete.  She was one of 461 athletes to receive a  .\n In 1986, the   (IOC) appointed DeFrantz to membership in the organization. She became the first chair of the   in 1992, and the first female vice-president of the IOC executive committee in 1997, serving until 2001. On June 25, 2012, DeFrantz told   that she would like to return to the IOC Executive Committee.  She was elected back onto the IOC Executive Board on September 10, 2013, and she was elected to a four-year term as IOC Vice President at the   in  ,   on September 15, 2017. \n DeFrantz is also on the board of the   Foundation (AOF) which runs the   (AOTO) program which is an international organization of Olympian and   artists promoting the Olympic values and ideals through educational and cultural programs and exhibitions. \n In 1980, DeFrantz was awarded the   for her contributions to the Olympic Movement.  In 2017, a plaque honoring her was unveiled in the  's Court of Honor. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Thomas_G._Shanks", "title": "Thomas G. Shanks", "content": " (born April 9, 1942, in  ) is an American computer programmer, author, and   history researcher.\n While working for a San Diego–based astrological computing company as programmer and research director, Shanks did extensive research in the field of worldwide time zone and   history. He published the results of this research in the two volumes   and  .  Shanks' published data are quoted frequently in the    .\n \n This biographical article relating to a computer specialist in the United States is a  . You can help Wikipedia by  .", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Uppsala_University", "title": "Uppsala University", "content": "\n  ( ) ( :  ) is a     in  ,  . Founded in 1477, it is the   and the   still in operation. \n Initially founded in the 15th century, the university rose to significance during the rise of   at the end of the 16th century and was then given relative   with a large donation from     in the early 17th century. Uppsala also has an important historical place in Swedish national culture, and   for the Swedish establishment: in  , religion, literature, politics, and music. Many aspects of Swedish academic culture in general, such as the white  , originated in Uppsala. It shares some peculiarities, such as the   system, with   and the  .\n Uppsala belongs to the   of European universities and to  .  It has ranked among the world's 100 best universities in several international rankings. \n The university has nine faculties distributed over three disciplinary domains: Humanities and Social Sciences, Medicine and Pharmacy, and Science and Technology. As of 2020 , it had approximately 52,000 registered students at the undergraduate and postgraduate levels and 2,200 PhD students. \n Architecturally, Uppsala University has traditionally had a strong presence in  , the neighbourhood around   on the western side of the  . Despite some contemporary building developments further away from the centre, Uppsala's historic centre continues to be dominated by the presence of the university. \n As with most medieval universities, Uppsala University initially grew out of an ecclesiastical centre.  The   had been one of the most important   in   since Christianity first spread to this region in the ninth century. Uppsala had also long been a hub for regional trade and had contained settlements dating back into the deep  . As was also the case with most medieval universities, Uppsala had initially been chartered through a  . Uppsala's bull, which granted the university its corporate rights, was issued by   in 1477 and established several provisions. Among the most important of these was that the university was officially given the same freedoms and privileges as the  . This included the right to establish the four traditional faculties of  , law (  and  ), medicine, and philosophy, and to award the bachelor's, master's, licentiate, and doctoral degrees. The archbishop of Uppsala was also named as the university's   and was charged with maintaining the rights and privileges of the university and its members. \n The turbulent period of the reformation of King   resulted in a drop in the already relatively insignificant number of students in Uppsala, which was seen as a centre of Catholicism and potential disloyalty to the Crown.  Swedish students generally travelled to one of the Protestant universities in Germany, especially  . There is some evidence of academic studies in Uppsala during the 16th century; the Faculty of Theology is mentioned in a document from 1526, King   appointed   (later archbishop) rector of the university in 1566, and his successor and brother   appointed several professors in the period 1569–1574. At the end of the century, the situation had changed, and Uppsala became a bastion of Lutheranism, which Duke Charles, the third of the sons of Gustavus Vasa to eventually become king (as  ) used to consolidate his power and eventually oust his nephew   from the throne.   in 1593 established   orthodoxy in Sweden, and Charles and the Council of state gave new privileges to the university on 1 August of the same year.\n Theology still had precedence, but in the privileges of 1593, the importance of a university to educate secular servants of the state was also emphasized. Three of the seven professorial chairs which were established were in Theology; of the other four, three were in Astronomy, Physics (or general natural sciences) and Latin eloquence. A fourth chair was given to Ericus Jacobi Skinnerus, who was also appointed rector, but whose discipline was not mentioned in the charter. Of the professors, several were taken over from the   in Stockholm, which had been functioning for a few years but closed in 1593. An eighth chair, in Medicine, was established in 1595 but received no appointee for several years. In 1599 the number of students was approximately 150. In 1600 the first post-reformation conferment of degrees took place. In the same year, the antiquarian and mystic   designed and engraved the seal of the university, which is today used as part of the logotype.\n The medieval university had mainly been a theology school. The aspirations of the emergent new great power of Sweden demanded a different kind of learning.  Sweden both grew through conquests and went through a complete overhaul of its administrative structure.  It required a much larger class of civil servants and educators than before. Preparatory schools,  , were also founded during this period in various cathedral towns, notably   (the first one) in 1623. Besides Uppsala, new universities were founded in more distant parts of the  , the   (present-day Tartu) in   (1632) and the   in   (1640). After the Scanian provinces were taken from Denmark,   was founded in 1666.\n Instrumental in the reforms of the early 17th-century Swedish state was the long-dominant Chancellor  , who had spent his own student days in German universities and who for the last years before his death was also chancellor of the university. King   showed the university a keen interest and increased the professorial chairs from eight to thirteen in 1620, and again to seventeen in 1621. In 1624 the king donated \"for all eternity\" all his own inherited personal property in the provinces of   and  , some 300 farms, mills and other sources of income. The king's former private tutor,  , who was made chancellor of the university in 1622, donated the Skyttean chair in Eloquence and Government which still exists. The university received a stable structure with its constitution of 1626. The head of the university was to be the  , and his deputy was the \" \" (always the    ). The immediate rule was the responsibility of the  , to which belonged all the professors of the university, and the  , who was elected for a semester at the time; the latter position circulated among the professors, each of whom sometimes held it several times.\n During the late 16th and early 17th centuries (and perhaps even earlier), the university was located in the old chapter house parallel to the south side of the cathedral, later renamed the  . In 1622–1625 a new university building was built east of the cathedral, the so-called  , named after the reigning king. In the 1630s, the total number of students was about one thousand.\n  was generous to the university, gave scholarships to Swedish students to study abroad and recruited foreign scholars to Uppsala chairs, among them several from the  , notably, the philologist   (professor Skytteanus), whose little library and museum building at   now belongs to the  . The Queen, who would eventually declare her abdication in the great hall of  , visited the university on many occasions; in 1652 she was present at an anatomical demonstration arranged at the castle for the young physician  . Rudbeck, one of several sons of  , a former Uppsala professor who became  , was sent for a year to the progressive   in the Netherlands. Returning in 1654, he received an assistantship in Medicine 1655 and had already gone to work on a program for improving aspects of the university. He planted the first  , the one which would eventually be tended by   and is kept today as a museum of 18th-century botany under the name   (\"the  \"). With the patronage of the university chancellor  , Rudbeck was made full professor in 1660, was elected rector for two terms, despite his youth, and started a revision of the work of the other professors and a building spree with himself as an architect. His most significant remaining architectural work is the anatomical theatre, which was added to Gustavianum in the 1660s and crowned with the characteristic cupola for which the building is today known.\n A gifted scientist, architect and engineer, Rudbeck was the dominant personality of the university in the late 17th century who laid some of the groundwork for Linnaeus and others, but he is perhaps more known today for the pseudohistorical speculations of his  , which consumed much of his later life. When large parts of Uppsala burned down in 1702, Gustavianum, which contained the university library and its many valuable manuscripts, escaped the fire; local lore has it that the ageing Rudbeck stood on the roof directing the work of fighting the fire.\n The early part of the 18th century was still characterized by the combination of Lutheran orthodoxy and classical philology of the previous century, but eventually, a larger emphasis on sciences and practically useful knowledge developed. The innovative mathematician and physicist   (1698–1765) was made a professor in 1728, the physicist and astronomer   in 1729, and   was made professor of medicine with botany in 1741. The university was not immune to the parliamentary struggle between the parties known as the \"Hats\" and the \"Caps,\" with the former having a preference for hard sciences and practical knowledge. The Hat government then in power established a chair in economics ( ) in 1741 and called Anders Berch as its first incumbent. This was the first professorship in economics outside Germany, and possibly the third in Europe (the first chairs having been established in the   and   in 1727). In 1759, following a donation, another chair in the economy was established, the Borgströmian professorship in \"practical economy,\" which meant the practical application of the natural sciences for economic purposes (it eventually developed into a chair for physiological botany).\n There were very radical attempts at reforms which were never implemented, but important changes took place. University studies had until this time been very informal in their overall organization, with the all-purpose  -degree being the only one frequently conferred and many never graduating, as there was no degree applicable to their intended area of work (and well-connected aristocratic students often not graduating as they did not need to). A few professional degrees for various purposes were introduced in 1749–1750, but the radical suggestion of binding students to a single program of study adapted to a particular profession was never implemented. The reforms of this era have been compared to those of the 1960s and 1970s (Sten Lindroth).\n Although it took some time after the fire of 1702,   and   were both eventually restored, both by  , perhaps the most important Swedish architect of the era. He also modified  , designed a new conservatory for Linnaeus' botanical garden and built the new Consistory house, which was to be the administrative core of the university.\n Another magnificent royal donation was that of the large baroque garden of the castle, given by   to the university when it was obvious that the old botanical garden was insufficient. A large new conservatory was built by the architect  . Additional grounds adjacent to the baroque garden have since been added. The old garden of Rudbeck and Linnaeus was largely left to decay but was reconstructed in the years between 1918 and 1923 according to the specifications of Linnaeus in his work   from 1745.\n The issue of women's right to study at universities was raised during the very last session of the estate parliament in 1865 in a motion from Carl Johan Svensén, a member of the farmers' estate. The reception was mixed, with the most negative views coming from the clergy. In the following years, the issue continued to be debated at the universities. In 1870, it was decided to let women take the secondary school examination (\" \") that gave the right to entry at universities and the right to study and complete degrees at the faculties of Medicine in Uppsala and Lund and at the   in Stockholm. A common view was that female sensitivity and compassion would make women capable of working as physicians, but their right to work was still restricted to private practice. Women's rights to higher education were extended in 1873 when all degrees except those in the faculties of theology and the licentiate degree in Law were made accessible for women.\n The first female student in Sweden was   (1838–1885), who had already worked as a private tutor for several years when she took \"studentexamen\" in 1871. With a royal dispensation, she was allowed to enter university in Uppsala in 1872, the year before studies at the Philosophical faculty would actually be made generally available to women. She studied modern European languages and was the first woman in Sweden to complete an academic degree when she finished a film. kand. in 1875. She became the first woman to be employed as a teacher in a public school for boys. The first woman in Sweden to complete a doctoral degree was   (1855–1900), who entered Uppsala university in 1877 and became a PhD in history in 1883. Other female students of this period include   (1869–1954) who later became a noted educator, activist and writer on women's emancipation and suffrage. Defending a dissertation in history in 1900, she became the second woman to finish a doctorate at a Swedish university. In 1892, she founded the Uppsala Women's Student Association, which set up   performances and other things enjoyed by male students but from which the women were excluded at the time. The members of the Association were the first woman to wear student caps in public, an important sign of their status.   (1861–1911) was the first Swedish woman to finish a law degree and the first to become a \"docent,\" but was not permitted to even hold the position of acting professor despite being formally qualified for this in everything but her sex. After years of conflicts with the professor of civil law A. O. Winroth, who wrote the paper on \"Om tjenstehjonsförhållandet\" and with the university board, she died in 1911 from an overdose of sleeping powder.\n According to the constitution of 1809, only \"native Swedish men\" could be appointed to higher civil servant positions, including professorships. This was changed in 1925, and the first woman to hold a professorial chair at Uppsala University was  , appointed professor of human geography in 1949.\n  who studied at the university became the first Swedish woman to receive an academic degree.\n The governing board of the university is the  , with representatives of the faculties as well as members representing the students and non-academic employees (three professors and three students), and ten university outsiders appointed by the  . All these members in the consistory have the right to vote.\n The unions active at the university also have three representatives in the consistory; these members have the right to speak but not any right to vote.\n Since the last reorganization in 1999, the university has had a separate body called the  , which is a wider, but mostly advisory group representing teaching staff/researchers and students. The executive head of the university is the  , whose deputy is the  . There are (also since 1999) three vice rectors, each heading one of the three \"disciplinary domains\" (Arts and Social Sciences, Medicine and Pharmacy, and Science and Technology) into which the nine faculties are divided. Each faculty has a faculty board and is headed by a   ( ). The position of dean is held part-time by a professor of the faculty.\n Through the division of faculties and the addition of a previously independent school of Pharmacy as a new faculty, the traditional four-faculty organization of European universities has evolved into the present nine faculties. The disciplinary domains and their faculties are as depicted below. \n Uppsala University also hosts the  , a collaborative academic effort by its six faculties: Theology, Law, History and Philosophy, Social Sciences, Languages, and Educational Sciences. The Forum aims to facilitate and promote research and education related to the   countries:  ,  ,  ,  ,  ,   and  , on the national and international level, with  , Faculty of Theology, serving as the Forum's director. \n The university library holds about 5.25 million volumes of books and periodicals (131,293 shelf meters), 61,959 manuscripts, 7,133 music prints, and 345,734 maps and other graphic documents. The holdings of the collection of manuscripts and music include, among other things, the Gothic Bible manuscript  .\n The most widely recognized building of the   is  , the \"revived Carolina,\" thus named in reference to   (see illustration), which held the university library from the earliest times until 1691, when it was moved to the upper floor of Gustavianum, where it miraculously survived the great city fire of 1702. In the mid-18th century, there were plans to move it back to Academia Carolina or a new building in the same spot. The building was demolished in 1778 to make place for a new library, but this was never built and the area next to the cathedral where it stood is today a lawn. The present Carolina Rediviva was built in a different place and completed in 1841.\n The present university library system comprises 19 branches, including the one in the Carolina building.\n The Uppsala Academic Hospital or  , which functions as a teaching hospital for the Faculty of Medicine and the Nursing School, is run by the Uppsala County Council in cooperation with the university. As of 2003 , the hospital had 7,719 employees and as of 2004  1,079 places for patients.\n The university hospital is actually older than the university, as it goes back to the earliest hospital, founded in Uppsala in 1302, and much later merged with the university clinic. This was used for 400 years until the great fire of 1702 which destroyed large parts of central Uppsala. A new hospital, which later became the Uppsala county hospital, was built in its place but was moved out of the town in 1811.\n The first clinic with the specific intention to facilitate the practical education of medical students was the  , founded in 1708 and located at the Oxenstierna Palace at Riddartorget beside the cathedral (see illustration above). The building (the former residence of the president of the Royal Chancellery  ) today houses the Faculty of Law.\n The present   was founded in 1850 as an organizational merger of the county hospital and the university clinic, and a new building was inaugurated in 1867 on the hill below   to the southeast. From this building, which is still in use, the present hospital complex has grown.\n The Svedberg Laboratory (named after  ) is a university facility that contains the  ,  which is used for research as well as for   for the treatment of cancer with close cooperation with the oncology clinic at  .  Such an accelerator and its gantries costs between $60 million and $100 million,  and makes Uppsala University Hospital one of the approximately 40 centres in the world to provide such cancer treatment.\n The Hägerström Lectures are a yearly series of talks by prominent philosophers hosted by the   at  . \n The initiative for the Hägerström Lectures was taken by Stig Kanger, Chair Professor of Theoretical Philosophy at Uppsala University, from 1968 until his death in 1988. The idea was to invite a distinguished philosopher for a week to give a series of five open lectures unified by a common theme, and provide an opportunity for teachers and students at the Department of Philosophy in Uppsala to meet the guest for informal discussions. The series was inaugurated in 1971 and named in honor of the former Chair in Practical Philosophy (1911-1933),  , the founding father of the Uppsala School of ethics and the jurisprudential movement known as Scandinavian Legal Realism. The Hägerström Lectures were held annually until 2009, biannually between 2009 and 2022, and have been held annually again since 2022. From 2017 onward, the number of lectures each year has been reduced from five to three. \nThe first Hägerström Lecturer was Konrad Marc-Wogau, Kanger’s predecessor as Chair in Theoretical Philosophy at Uppsala University (1946-1968). The list of speakers since then includes several of the most eminent and influential philosophers of the last half century in a broad range of areas of specialization, including  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,   and  . \n The buildings and locations where the university has activities or which are significantly connected to its history are listed below. Some of the historic buildings in central Uppsala have had to be retired, as their protected status has made it impossible to make modifications necessary to meet requirements to adjust to the needs of students with disabilities.\n Up until June 2010, students at Uppsala University were obliged to become members of one of the  , corporations of students traditionally according to the province of origin (not strictly upheld now, for practical reasons). The system of dividing students into nations according to origin can ultimately be traced back to the nations at the medieval   and other early medieval universities, but the Uppsala nations appear only about 1630–1640, most likely under influence of the   which existed at some of the German universities visited by Swedish students. In Sweden, nations exist only in Uppsala and  . The nations were originally seen as subversive organisations promoting less virtuous aspects of student life, but in 1663 the   made membership in a nation legal, each nation being placed under the inspectorship of a professor.\n The current thirteen nations all have a history stretching back to the early-to-mid 17th century, but some of them are the result of mergers of older, smaller nations that took place in the early 19th century to facilitate the financing of building projects.\n The nations at Uppsala University are:\n Since the 1960s there is a fourteenth nation, the   (referring to the  ) which has no membership fee and exists as a legal device to get around the compulsory membership for students who prefer not to become affiliated with the traditional nations. However, this nation was made redundant in 2010, when membership in a nation ceased to be mandatory.\n The   was founded in 1849 as a corporation representing all students, irrespective of nation. The pharmaceutical institute became integrated in Uppsala university during 1968 and formed the Faculty of Pharmacy at Uppsala University, and the pharmaceutical educations moved to Uppsala university during 1972. At the same time, the Pharmaceutical Student Union (Pharmaceutical Association of Uppsala Students) became a Student Union at Uppsala University. The students at the faculty of Pharmacy were also exempt from compulsory membership in the nations, but most pharmacy students belonged to one. However, they were obliged to take up membership in the Pharmaceutical Student Union, an organisation having the same role as the nations and Uppsala Student union at the rest of the university.\n The compulsory membership in a student union was abolished on 1 July 2010; however, the unions will still be representing organisations in the university boards and committees. The status as a student union will be decided upon by the university board for periods of three years at a time. On 20 February 2013, the university board decided that there will be four student unions at the university from July 2013 – June 2016: the Uppsala Student Union (for students at the faculties of Art, Social Sciences, Languages, Theology, Law, Educational Sciences and Medicine), the Pharmaceutical Student Union (for students at the Faculty of Pharmacy), the Uppsala Union of Engineering and Science Students (at the Faculty of Science and Technology), and Rindi (the union for students at Campus Gotland).  In February 2016, two additional associations were given the status as student unions: Uppsala Business & Economics Students Association (for students of economics) and Uppsala Law Student Associations (for students of law).  Thus, there are now six student unions at Uppsala university. \n The University's   was founded in 1627. Its main purpose is to play at academic ceremonies but holds concerts on other occasions as well. Its leader has the title of  . The position has been held by composers such as  ,   and  . Affiliated with the university are three choirs, the mixed   ( ), founded in 1830, the male choir  , founded in 1853, and the Academy Chamber Choir of Uppsala, founded in 1957. A number of other choirs and orchestras are affiliated with the nations.\n An important name in the recent history of the choirs is  , who was the conductor of both Orphei Drängar and the Chamber Choir. In honour of Ericson, the   endowed the Eric Ericson Chair in Choral Directing, and the Uppsala University Choral Centre was inaugurated in 2000. The centre arranges courses in choral directing.  \n Like many cities, there is a shortage of   in Uppsala, a problem which has existed for many years. Both native Swedes and foreign students are finding it difficult to find accommodation when first enrolling on the university.  This problem is however not as bad as it was with several major housing construction projects having been completed after 2010. \n There has never been a custom in Sweden for the universities to arrange housing for students, in fact, universities are by law not allowed to own housing. Students are expected to set their own living accommodations on the private market. To make it easier for students to find moderately priced housing, special student rooms and student apartments have been built by the student nations and student unions. However, the student housing is insufficient to accommodate all students. About 40,000 students are eligible to live in the 11,000 available rooms and apartments.  Because of the low rent in these apartments and the general lack of housing in Uppsala the student apartments are highly attractive and many try to hold on to the contracts as long as possible even after graduating. \n Some of the most popular housing accommodations for students are Flogsta, Kantorsgatan, Studentstaden, Studentvägen, Klostergatan, Rackarbergsgatan and many more.\n Flogsta is one of the international students' biggest and most popular housing choices.\n Sports play a very small role in the life of the university, compared to British and especially U.S. universities, but have existed in various forms since the early 17th century. Uppsala University is more noted for its musical and   traditions. Both have partial roots in the 17th-century institution of extracurricular exercises for students from the nobility.\n To ease the recruitment of students from the nobility, the university started in the 1630s to offer training in a number of   or \"exercises\" (Swedish:  ) deemed necessary for the well-rounded education of a young nobleman:  ,  ,  ,   and modern languages such as   and  . The initiative came from Chancellor  , who saw the value in a well-educated class of   and the danger to his own class if its members would fall behind in academic education compared to those students who came from the lower estates. An \"exercise yard,\" built for the riding and fencing exercises, was demolished in the late 19th century to give place to the new University Hall. Modern languages were made part of the regular academic curriculum in the 19th century. The surviving \"exercises\" include:\n Besides the  , other sports have had a presence in Uppsala student life. The  , \"Uppsala Swimming Society,\" which is the oldest swimming club in the world, was founded in 1796 by the mathematician  . It had no formal connection to the university, but all its earliest members came from academic life. Svanberg even arranged a mock graduation ceremony, a  , in a parody of the university ceremonies, where those who had graduated from its swimming training were awarded \"degrees\" of master ( ) and bachelor ( ). These degrees stuck, and Swedish swimming schools still use these degrees for different levels of swimming skills.\n An attempt was made in the 1870s to introduce academic rowing after the   model. The   acquired a rowing boat in 1877, soon followed by the  teborgs nation, and for a number of years rowing competitions were held between teams from the two nations. Although rowing never got the strong position it has at the English universities, an annual Uppsala-Lund   has been arranged since 1992, between rowing teams from Uppsala and  . The race is held on the   in Uppsala on even years, and on a river in the vicinity of Lund on odd years. Each year there is at least one full eight crew with cox competing, with both men's and women's teams present. With the recent victory for Uppsala in 2005, the score stands 24–23 in Uppsala's favour.\n Uppsala University is one of the most prominent   in Sweden and is commonly ranked within the top 100 in the world by several ranking agencies.  For example, for over ten years, it has been ranked among the 80 best universities in the world in the  .  \n Times Higher Education ranked Uppsala the 101–125th most reputable university worldwide in 2023 and the 68th most international university in the world in 2023. \n QS Rankings by Subject 2023:  \n QS Rankings by Broad Subject Area 2023:\n Times Higher Education Rankings by Subject 2023:\n Uppsala University is associated with 8 Nobel Prize laureates,  and numerous royalty, academics and public figures.\n As the dominant academic institution in Sweden for several centuries, Uppsala University has educated a large proportion of Swedish politicians and civil servants ever since its first period of expansion in the early part of the 17th century. These range from Chancellor of the Realm ( )   (1611–1657) and Lord Chief Justice ( )   (1622–1686) to the first Social Democratic  ,   (1860–1925). Other alumni are   (1905–1961), United Nations   who was (posthumously) awarded the   in 1961, and the Swedish diplomat   (born 1928), who was Head of the   1981–1997, of the   2000–2003, and previously Swedish Minister of Foreign Affairs 1978–1979. Hammarskjöld and Blix both graduated from the Uppsala Faculty of Law, as did the Swedish Minister of Foreign Affairs  , who was assassinated in 2003.\n Most Swedish clergymen, including most bishops and archbishops, have been educated at the university, including, in more recent times,   (1866–1931), Professor of the History of Religions in the Faculty of Theology, later  , and awarded the Nobel Peace Prize in 1930 for his work as leader of the   movement.\n The university became prominent in the sciences in the 18th century with names such as the physician and botanist   (1707–1778), the father of biological and mineralogical  , and his numerous important pupils, the physicist and astronomer   (1701–1744), inventor of the Celsius scale the predecessor of the   scale, and the chemist   (1735–1784). Another scientist from this era is   (1688–1772), better remembered today as a religious mystic. The university played an important role in the Swedish agricultural revolution of the 18th century;  , the initiator of the reforms, studied at Uppsala. Several of the elements were discovered by Uppsala scientists during this period or later.  , one of the fathers of modern chemistry, received his doctorate in medicine in Uppsala in 1804, but later moved to Stockholm. Uppsala scientists of the 19th century include the physicist   (1814–1874). During the 20th century, several   in the sciences have been Uppsala alumni or professors at the university.\n Many well-known Swedish writers have studied in Uppsala:   (1598–1672) is often called the father of Swedish poetry. The poet and song composer   (1740–1795), without doubt, the best-loved and best-remembered Swedish 18th-century poet, matriculated but left the university after less than a year. The writer, historian and composer   (1783–1847), professor of history, and the poet   (1790–1855), professor of poetry, were principal figures of early 19th-century Swedish romanticism. The less than happy experiences of the Uppsala student life of novelist and playwright   (1849–1912), resulted in his   (1877), a collection of short stories set in Uppsala (\"From   and Svartbäcken,\" the title refers to two districts in Uppsala). Other Uppsala alumni are the poet   (1864–1931), who refused the   in 1918 but received it posthumously in 1931, the novelist and playwright   (1891–1974),   in 1951, and the poet and novelist   (1900–1941), for whom one branch of the university library has been named. The Communist leader   (1886–1969) wrote a novel called  , based on his experience as a student in Uppsala.\n Uppsala University has signed student exchange agreements with about 400 universities across all parts of the world.  It takes part in the   and the Nordplus programme. It also benefits from its membership in the   of universities.\n In May 2010 Uppsala joined the   (MNU) together with   (USA),   (UK),   (Canada),   (New Zealand),   (Germany), and   (Australia). \n Along with  , Uppsala is the historic and traditional centre of Swedish academic life, making it a popular object of reference in  , art, and film. Specifically, Uppsala University has appeared notably in   or   by  .\n The Norwegian pop singer   dedicated one of her biggest successes to Uppsala University, publishing in 1969 the song \"Ein Student aus Uppsala\".  The song, originally written in  , lasted 14 weeks in the German charts.\n Uppsala University appears as a research centre in the strategy game  .\n Uppsala University appears in the novel   by   and  . The fictional author V. M. Straka of   sends Mr. Grahn a confidential letter on Uppsala Universitet letterhead and stamps his signature with \"Straka Uppsala Arkiv\" (included as an insert to the book).\n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Weird_fiction", "title": "Weird fiction", "content": "\n  is a subgenre of   originating in the late 19th and early 20th centuries. Weird fiction either eschews or radically reinterprets traditional antagonists of    , such as  ,  , and  .  Writers on the subject of weird fiction, such as  , sometimes use \"the  \" to represent this type of writing. The tentacle is a limb-type absent from most of the monsters of European  , but often attached to the monstrous creatures created by weird fiction writers, such as  ,  ,  , and  . \n Weird fiction often attempts to inspire   as well as fear in response to its fictional creations, causing commentators like Miéville to paraphrase   in saying that weird fiction evokes a sense of the  .  Although \"weird fiction\" has been chiefly used as a historical description for works through the 1930s, it experienced a resurgence in the 1980s and 1990s, under the label of  , which continues into the 21st century. \n  defines weird fiction as a term \"used loosely to describe  ,   and   tales embodying transgressive material\".  China Miéville defines it as \"usually, roughly, conceived of as a rather breathless and generically slippery macabre fiction, a dark fantastic ('horror' plus 'fantasy') often featuring nontraditional alien monsters (thus plus 'science fiction')\".  Discussing the \"Old Weird Fiction\" published in the late 19th and early 20th centuries, Jeffrey Andrew Weinstock says, \"Old Weird fiction utilises elements of horror, science fiction and fantasy to showcase the impotence and insignificance of human beings within a much larger universe populated by often malign powers and forces that greatly exceed the human capacities to understand or control them.\"    and   describe weird fiction as a   of literature, usually appearing within the horror fiction genre, rather than a separate genre of fiction in its own right. \n Although the term \"weird fiction\" did not appear until the 20th century,   is often regarded as the pioneering author of weird fiction. Poe was identified by Lovecraft as the first author of a distinct type of   different from traditional Gothic literature, and later commentators on the term have also suggested Poe was the first \"weird fiction\" writer.    is also seen as an early writer working in the sub-genre. \n Literary critics in the nineteenth century would sometimes use the term \"weird\" to describe supernatural fiction. For instance, the   in an 1859 article praised Poe,   and   by saying the three writers had the \"power of weird imagination\".  The Irish magazine  , in an 1898 review of   by  , described the novel as \"wild and weird\" and not Gothic.  Weinstock has suggested there was a period of \"Old Weird Fiction\" that lasted from the late 19th to early 20th centuries.    and Miéville have both argued that there was a period of \"Haute Weird\" between 1880 and 1940, when authors important to Weird Fiction, such as   and   were publishing their work. \n In the late nineteenth century, a number of British writers associated with the   wrote what was later described as weird fiction. These writers included Machen,  ,  , and  .  Other pioneering British weird fiction writers included  ,   ,  ,  Arthur Machen,  and  . \n The American     published many such stories in the United States from March 1923 to September 1954. The magazine's editor   often used the term \"weird fiction\" to describe the type of material that the magazine published.  The writers who wrote for the magazine   are thus closely identified with the weird fiction subgenre, especially  , Clark Ashton Smith,   and  .  Other pulp magazines that published weird fiction included   (edited by  ),  and   (edited by  ). \n H. P. Lovecraft popularised the term \"weird fiction\" in his essays.  In \" \", Lovecraft gives his definition of weird fiction:\n The true weird tale has something more than secret murder, bloody bones, or a sheeted form clanking chains according to rule. A certain atmosphere of breathless and unexplainable dread of outer, unknown forces must be present; and there must be a hint, expressed with a seriousness and portentousness becoming its subject, of that most terrible conception of the human brain—a malign and particular suspension or defeat of those fixed laws of Nature which are our only safeguard against the assaults of chaos and the daemons of unplumbed space.  describes several subdivisions of the weird tale: supernatural horror (or  ), the  , quasi  ,  , and ambiguous   and argues that \"the weird tale\" is primarily the result of the philosophical and aesthetic predispositions of the authors associated with this type of fiction. \n Although Lovecraft was one of the few early 20th-century writers to describe his work as \"weird fiction\",  the term has enjoyed a contemporary revival in   fiction. Many horror writers have also situated themselves within the weird tradition, including  , who describes his fiction as  ,  and  ,  whose early work was influenced by Lovecraft. \n The following notable authors have been described as writers of weird fiction. They are listed alphabetically by last name, and organised by the time period when they began to publish weird fiction.\n  and   and   have suggested that weird fiction has seen a recent resurgence, a phenomenon they term the  . Tales which fit this category, as well as extensive discussion of the phenomenon, appear in the anthology  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Foundation_for_Excellence_in_Education", "title": "Foundation for Excellence in Education", "content": "The   is a non-profit think tank on education reform based in  .\n The foundation was established by  , shortly after his tenure as Governor of Florida from 1999 to 2007. \n The education reform policies suggested by the foundation have influenced  , the former Republican Governor of  , now President of Purdue University.   , the British Secretary of State for Education, spoke at the 2014 Foundation for Excellence in Education Summit on November 20, 2014. \n Former US Secretary of State   served as its Chairman beginning in January 2015.  Currently, former Governor Jeb Bush serves as Chairman and former House Majority Leader Eric Cantor serves as Vice Chairman. \n It has received donations from  ,   and  , as well as Connections Education, a subsidiary of  , and  , a subsidiary of  . \n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Yang_Hye-ji", "title": "Yang Hye-ji", "content": " ( :  ; born 20 January 1996) is South Korean actress.  She is best known for her roles in dramas such as  ,  ,   and  . \n She is also related to actor  , her uncle from the maternal side of the family. \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Outline_of_Saudi_Arabia", "title": "Outline of Saudi Arabia", "content": "\n The following   is provided as an overview of and topical guide to Saudi Arabia:\n  is a   that comprises the central portion of the   of  .   It is bordered by   on the northwest,   on the north and northeast,  ,  , and the   on the east,   on the southeast, and   on the south. The   lies to the northeast and the   to its west. It has an estimated population of 34,218,169, and its size is approximately 2,150,000 square km (830,000 square miles). \n The Kingdom is sometimes called \"The Land of The Two Holy Mosques\" in reference to   and  , the two holiest places of  . The Kingdom was founded by  , whose efforts began in 1902 when he captured the Al-Saud's ancestral home of  , and culminated in 1932 with the proclamation, and recognition of the Kingdom of Saudi Arabia.\n Saudi Arabia is the world's leading   and   exports fuel the  .  Oil accounts for more than 90 percent of exports and nearly 75 percent of government revenues, facilitating the creation of a  ,  which the government has found difficult to fund during periods of low  .    groups such as   and   have repeatedly expressed concern about the state of  , although these concerns have been dismissed by the Saudi government.\n \n \n \n \n \n \n \n \n \n \n \n \n The Kingdom of Saudi Arabia is a member of: \n  \n \n \n \n \n \n \n \n \n   \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Southern_Illinois_University_Press", "title": "Southern Illinois University Press", "content": " or  , founded in 1956, is a   located in  ,  , owned and operated by  .\n The press publishes approximately 50 titles annually, among its more than 1,200 titles currently in print.\n Southern Illinois University Press is a member of the  . \n Southern Illinois University Press was founded by President Delyte Morris in the mid-1950s, and its first book—Charles E. Colby's  —was published on October 20, 1956. Publishing primarily in the humanities and social sciences, in a wide range of subject areas: art and architecture, classical studies, history (world and American), literary criticism, philosophy, religion, rhetoric and composition, speech communication, and theatre.\n The Press has become especially well known  for its publications in First Amendment Studies, Restoration and Eighteenth Century Theatre, and Rhetoric and Composition, and for two multi-volume scholarly works: The Early, Middle, and Later Works of John Dewey, and The Papers of Ulysses S. Grant. In addition, the Press has developed and maintained lists that celebrate and document the history and culture of southern Illinois, the state and the Midwest region. \n In recent years, Southern Illinois University Press has focused its list on a smaller number of areas of publication: American history (  and  ), aviation, botany, film studies, legal history, poetry, regional studies, rhetoric and composition, and theatre.\n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/West_Liberty,_West_Virginia", "title": "West Liberty, West Virginia", "content": "\n  is a   in  , United States.  The population was 1,557 at the  .  It is part of the  .\n West Liberty was given its name during the  .   It served as the   of   from 1777 to 1797.\n West Liberty is located at   (40.165495, −80.594656). \n According to the  , the town has a total area of 0.68 square miles (1.76 km ), all  land. \n At the   there were 1,542 people, 243 households, and 119 families living in the town. The population density was 2,267.6 inhabitants per square mile (875.5/km ). There were 263 housing units at an average density of 386.8 per square mile (149.3/km ). The   of the town was 94.3% White, 3.2% African American, 0.3% Asian, 0.1% from other races, and 2.0% from two or more races. Hispanic or Latino of any race were 1.2%. \n Of the 243 households 18.1% had children under the age of 18 living with them, 34.6% were married couples living together, 7.4% had a female householder with no husband present, 7.0% had a male householder with no wife present, and 51.0% were non-families. 27.2% of households were one person and 9.5% were one person aged 65 or older. The average household size was 2.23 and the average family size was 2.85.\n The median age in the town was 20.9 years. 5% of residents were under the age of 18; 73.2% were between the ages of 18 and 24; 8.2% were from 25 to 44; 9.2% were from 45 to 64; and 4.2% were 65 or older. The gender makeup of the town was 43.3% male and 56.7% female.\n At the   there were 1,220 people, 241 households, and 120 families living in the town. The population density was 1,865.9 inhabitants per square mile (724.7/km ). There were 285 housing units at an average density of 435.9 per square mile (169.3/km ).  The   of the town was 96.64% White, 1.89% African American, 0.08% Native American, 0.33% Asian, 0.33% from other races, and 0.74% from two or more races. Hispanic or Latino of any race were 0.74%. \n Of the 241 households 15.8% had children under the age of 18 living with them, 39.4% were married couples living together, 5.8% had a female householder with no husband present, and 50.2% were non-families. 26.1% of households were one person and 5.8% were one person aged 65 or older. The average household size was 2.29 and the average family size was 2.93.\n The age distribution was 6.7% under the age of 18, 70.0% from 18 to 24, 10.9% from 25 to 44, 8.2% from 45 to 64, and 4.2% 65 or older. The median age was 21 years. For every 100 females there were 103.0 males. For every 100 females age 18 and over, there were 101.4 males.\n The median household income was $28,393 and the median family income  was $38,125. Males had a median income of $18,750 versus $19,375 for females. The per capita income for the town was $7,573. About 13.3% of families and 29.0% of the population were below the  , including 8.2% of those under age 18 and 15.7% of those age 65 or over.\n West Liberty is the site of  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/Stephen_Curry", "title": "Stephen Curry", "content": "\n \n\n  (   ;  born March 14, 1988) is an American professional   player and   for the   of the   (NBA). Often considered the greatest   of all time,   Curry is credited with revolutionizing the sport by inspiring teams and players at all levels to more prominently utilize the  .  He is a four-time  , a two-time   (MVP), an  , an  , an  , and the inaugural  . He is also a two-time  , a ten-time  , and a ten-time   selection (including four on the First Team). Internationally, he has won two gold medals at the   and a gold medal at the   as part of the  .\n Curry is the son of former NBA player   and the older brother of current NBA player  . He played   for the  , where he set career scoring records for Davidson and the  , and helped the Wildcats advance to the   in  . He was named   twice, and set the   (162) during his sophomore year. Curry was selected by the Warriors as the seventh overall pick in the  .\n In  , Curry won his first league MVP award and led the Warriors to their   since 1975. The following season, he became the first player to be elected MVP by a unanimous vote and   while shooting above  . That same year, the Warriors broke the record for the   (73) en route to the  , which they lost to the   in  . Curry helped the Warriors win back-to-back titles in   and  , and reach the  , losing to the   in six games. Following injury struggles and missed playoff appearances in 2020 and 2021, Curry won his fourth championship with the Warriors and first Finals MVP award, defeating the   in the  . The same season, he became the  , surpassing  . \n Curry is the holder of numerous other records, notably for his   and three-point shooting. He has the   (91.0%) and has   a record eight times. In  , he set the NBA record for three-pointers made in a regular season with 272, surpassed that record in 2015 (286), and again in 2016 (402).\n Curry was born on March 14, 1988,  at the   in  , to   (  Adams) and  .  He grew up in  , where his father spent most of his NBA career with the  .  Dell often took Curry and his younger brother   to his games, where they would shoot with the Hornets during warm-ups.  The family briefly moved to  , where Dell finished out his career as a member of the  .  During this time, Curry played for the Queensway Christian College boys' basketball team, leading them to an undefeated season.  He was also a member of Toronto 5–0, a club team that plays across  ,  pitting him against fellow future NBA players   and  .  Curry led the team to a 33–4 record, en route to winning the provincial championship. \n After Dell's retirement, the family moved back to Charlotte and Curry enrolled at  ,  where he was named all-conference and all-state, and led his team to three conference titles and three state playoff appearances. Because of his father's storied career at  , Curry wanted to play   for the Hokies, but was only offered a   spot due in part to his slender 160-pound frame.  He ultimately chose to attend  , who had aggressively recruited him from the tenth grade. \n Before Curry even played in his first game for the Wildcats, head coach   praised him at a Davidson alumni event, saying: \"Wait 'til you see Steph Curry. He is something special.\"  In his first collegiate game against  , Curry finished with 15 points but committed 13  . In the next game against  , he scored 32 points, dished out four  , and grabbed nine  . Curry finished the season leading the   in scoring with 21.5 points per game. He was second in the nation among freshmen in scoring, behind only   of  . Curry's scoring helped the Wildcats to a 29–5 overall record and a Southern Conference regular-season title. On March 2, 2007, in the     against  , Curry made his 113th   of the year, breaking  's NCAA freshman season record for three-pointers. \n Curry eclipsed the school freshman scoring record with his 502nd point against   on February 6, 2007.  On March 15, 2007, Davidson marched into the NCAA tournament as a 13th seed set to play  ; despite Curry's game-high 30 points, Davidson lost 82–70.  At the end of his   season, Curry was named Southern Conference Freshman of the Year, SoCon Tournament MVP, and selected to the SoCon All-tournament team, All-freshman team, and All-SoCon First Team.  He was also an honorable mention in  s All-Mid-Major. After the season ended, he was selected for the USA team to appear at the 2007 FIBA U-19 World Championships in which he averaged 9.4 points, 3.8 rebounds, and 2.2 assists in 19.4 minutes, helping Team USA to a silver medal finish. \n In his sophomore season in  , Curry had grown to his adult height of 6 ft 2 in (1.88 m) and again led the   in scoring, averaging 25.5 points per game while adding 4.7 rebounds per game and 2.8 assists per game. He led the Wildcats to a 26–6 regular-season record and a 20–0 conference record. As a result of Curry's exceptional play, Davidson earned its third straight   bid.\n On March 21, 2008, Davidson matched up with seventh-seeded  . Gonzaga led by 11 points early in the second half but Curry went on to score 30 points in the half  to push Davidson to their first NCAA Tournament win since 1969 with a score of 82–76. Curry ended the game with 40 points while also going 8-for-10 from three-point range.  On March 23, Davidson played second-seeded   in the second round of the NCAA Tournament. Georgetown was ranked eighth nationally and entered the game as a heavy favorite after an appearance in the   in 2007. Curry managed just five points in the first half of the game as Davidson trailed by as many as 17 points, but his 25 second-half points led Davidson to a 74–70 comeback victory. \n On March 28, 2008, Curry led Davidson to another win, against third-seeded  . Curry scored 33 points as Davidson won 73–56 to advance to the  .  Curry joined  ,  , and   as the only college players to score over 30 points in their first four career NCAA tournament games.  Curry also tied   of   for the single-season record for most three-pointers with 158.  On March 30, 2008, he set the record, against the top-seeded  , with his 159th three-pointer of the season. Curry scored 25 points in the game but Davidson lost 59–57, and the Jayhawks went on to win the championship. \n Curry finished the season averaging 25.9 points, 2.9 assists, and 2.1 steals per game. He was named to the  '   Second Team on March 31, 2008.  He also was named the Most Outstanding Player of the Midwest Region of the  , becoming the first player from a team not making the   to do so since   of   in 1994.  Curry was nominated for an ESPY in the Breakthrough Player of the Year category. \n After Davidson's loss against   in the NCAA Regional Finals, Curry announced that he would return for his junior year.  He stated that he wanted to develop as a  , his likely position in the NBA. On November 18, 2008, Curry scored a career-high 44 points in Davidson's 82–78 loss to  .  He extended a career-long streak by scoring at least 25 points for the seventh straight game.  On November 21, Curry registered a career-high 13 assists, to go along with 30 points in Davidson's 97–70 win over  .  On November 25, against Loyola, Curry was held scoreless as Loyola constantly double-teamed him. It was Curry's only scoreless collegiate game and just his second without double-digit points. He finished 0-for-3 from the field as Davidson won the game 78–48.  In Davidson's next game 11 days later, Curry matched his career high of 44 in a 72–67 win over  . \n Curry surpassed the 2000-point mark for his career on January 3, 2009, as he scored 21 points against  .  On February 14, 2009, Curry rolled his ankle in the second half of a win over Furman. The injury caused Curry to miss the February 18 game against  , the first and only game he missed in his college career.  On February 28, 2009, Curry became Davidson's all-time leading scorer with 34 points in a 99–56 win against  . That gave Curry 2,488 points for his career, surpassing previous school leader John Gerdy.  Davidson won the 2008–09 Southern Conference regular season championship for the south division, finishing 18–2 in the conference. \n In the  , Davidson played   in the quarterfinals and won 84–68. Curry scored 43 points, which is the third most points in Southern Conference tournament history.  In the semifinals, against the  , Curry had 20 points but Davidson lost 52–59. Despite lobbying from Davidson head coach   and Charleston coach  ,  the Wildcats failed to get an NCAA tournament bid. Instead, they received the sixth seed in the  . Davidson played the third seed,  , on the road in the first round. Curry scored 32 points as the Wildcats beat the Gamecocks 70–63.  Davidson then lost 80–68 to the   in the second round. Curry registered 26 points, nine rebounds, and five assists in what was his final game for the Wildcats. \n In his final season at Davidson, Curry averaged 28.6 points, 5.6 assists, and 2.5 steals. He was the   and was named a consensus first team All-American.  Curry opted out of his senior year at Davidson, but he stated that he still planned to earn his degree.  He completed his bachelor's degree in sociology in May 2022.  Curry's completion of his degree qualified him for jersey or number retirement; Davidson reserves that honor for players who complete their degrees at the school. In a ceremony held on August 31, 2022, Curry became the first Davidson player to have his number retired (six others have jerseys retired, but their numbers remain in circulation). At the ceremony, he also entered Davidson's athletic hall of fame and physically received his Davidson diploma. \n On June 25, 2009, his father's 45th birthday, Curry was selected as the seventh overall pick in the   by the  .  Although the Warriors already had another lean, 6-foot-3, offensive-minded guard in  , coach   had a penchant for using small lineups in his   system, and had warmed to the idea of selecting Curry.  However, Ellis announced at a media session that he and Curry were too small to play together.  Curry appeared in 80 games (77 starts) during the  , averaging 17.5 points, 4.5 rebounds, 5.9 assists, and 1.90 steals in 36.2 minutes.  His second half of the season vaulted him into the rookie of the year race.  He was named Western Conference Rookie of the Month for January, March, and April, finishing as the only Western Conference rookie to win the award three times.  He finished runner-up for the   behind   and was a unanimous   selection, becoming the first Warriors player since   in 2001–02 to earn All-Rookie First Team honors.  He scored 30-plus points eight times, setting the most 30-point games by any rookie in 2009–10 and the most since   had 13 and   had 10 in 2003–04. Curry had five 30-point/10-assist games, which tied   for the second-most 30-point/10-assist games by a rookie (  is first with 25). He became just the sixth rookie in NBA history to post a 35-point, 10-assist, 10-rebound game when he registered his first career triple-double with 36 points, 13 assists, and 10 rebounds against the   on February 10. In the Warriors' season finale against the   on April 14, Curry recorded a then- career-high 42 points, nine rebounds and eight assists, becoming the first rookie since Robertson in February 1961 to register at least those numbers in each category in the same game. Curry finished his rookie season with 166 three-pointers, which were, at the time, the most ever by a rookie in NBA history. \n In  , Curry appeared in 74 games (all starts), averaging 18.6 points, 3.9 rebounds, 5.8 assists, and 1.47 steals in 33.6 minutes per contest.  His   of .934 (212–227 FT) set a new Warriors single-season record, surpassing the previous mark of .924 set by   in 1977–78. He also became the first Warriors player to lead the NBA in free throw percentage since   in 1996–97.  Curry registered 20-or-more points 35 times, including seven 30-plus performances. He posted a season-high 39 points and a then- career-high 14 made field goals (on 20 attempts) against the   on December 5. In February 2011, during  , Curry won the   and registered 13 points, eight assists, and six rebounds in 28 minutes as a member of the Sophomore squad in the  .  In May 2011, he was named the recipient of the  ,  and underwent surgery on his right ankle. \n In the  -shortened  , Curry appeared in 26 games (23 starts), averaging 14.7 points, 3.4 rebounds, 5.3 assists, and 1.50 steals in 28.2 minutes per contest. He missed 40 games due to right ankle and foot injuries,  including the last 28 games with a sprained right ankle and subsequent surgery on the ankle, which was performed on April 25.  In 2012, Golden State included Curry in a trade offer to the   for  , which the Bucks rejected due to Curry's history with bad ankles. Ellis was traded instead.  According to then- Warriors general manager  , they offered Curry with the intention of steering the deal to Ellis.  The deal opened an opportunity for Curry to lead the team. \n Prior to the start of the  , Curry signed a four-year, $44 million contract extension with the Warriors.  At the time, many basketball writers considered the move risky for Golden State because of Curry's injury history.  Over the course of the year, Curry and former backcourt teammate   gained a reputation for their perimeter scoring, earning them the nickname the \" \".  In 2012–13, Curry appeared in 78 games (all starts), averaging career highs of 22.9 points (seventh in NBA) and 6.9 assists to go with 4.0 rebounds and 1.62 steals in 38.2 minutes.  He set a new NBA single-season three-point record with 272 three-pointers, eclipsing the previous mark set by   (269 in 2005–06), doing so on 53 less attempts than Allen did with Seattle. \n Curry earned Western Conference Player of the Month honors for the month of April. During this time he averaged 25.4 points, 8.1 assists, 3.9 rebounds, and 2.13 steals in eight games in the final month of the season to become the third Warrior to win the award, joining   (November 1990 and January 1989) and   (January 1981). He tallied two of the NBA's top six scoring games with 54 points on February 27 at New York and 47 on April 12 at Los Angeles, becoming the first Warrior to score 45-plus at New York and Los Angeles in the same season since Rick Barry in 1966, joining Barry,  , and   as the only four Warriors to do so. Curry's 54 points against the Knicks included a then- career-best and then- franchise-record 11 three-pointers, becoming the first player in NBA history to score 50-plus points while hitting 10-plus three-pointers in a game. It was the most scored by a Warrior since   tallied 59 points in 1984. In 2013, he appeared in the playoffs for the first time in his career, with the Warriors earning the sixth seed in the Western Conference. In 12 playoff games (all starts), he averaged 23.4 points, 8.1 assists, and 3.8 rebounds. He set a new franchise record with 42 playoff three-pointers, eclipsing the Warriors' career playoff mark of 29 previously held by Jason Richardson, giving him a total of 314 three-pointers for the season to become the first player in NBA history to make at least 300 three-pointers in a single season. \n In  , Curry appeared in 78 games (all starts), averaging career highs of 24.0 points (seventh in the NBA) and 8.5 assists (fifth in the NBA) to go with 4.3 rebounds and 1.63 steals, becoming the first player in Warriors franchise history to average 24 points and eight assists in a single season (ninth player in NBA history). He led the league in three-pointers made for a second consecutive season with 261, becoming the first player since Ray Allen in 2001–02 and 2002–03 to lead the league in three-pointers in back-to-back seasons. He was named Western Conference Player of the Month for April and earned   honors, becoming the first Warriors player named to the First or Second Team since 1993–94.  On December 7 against the  , Curry eclipsed Jason Richardson (700) as the franchise's leader in career three-pointers.  In February, he made his first   appearance,  becoming the Warriors' first All-Star starter since   in 1995.  He scored a season-high 47 points on April 13 against the   for his third 40-point game of the year. He finished the regular season tied for second in the NBA in triple-doubles with four, the most by a Warrior in a single season since Chamberlain had five in 1963–64.  Seeded sixth for the second consecutive  , the Warriors were defeated in seven games by the  . \n Prior to the start of the  , the Warriors hired former NBA player and general manager   as their new head coach.  Kerr implemented significant changes to Golden State's schemes, including playing at a faster pace and giving Curry more freedom to shoot, helping the team evolve into a title contender.  On February 4, Curry scored a season-high 51 points in a win over the  .  He was the leading vote-getter for the   and won the   on All-Star Saturday night.  On April 9, he broke his own league record for three-pointers made in a season during a game against the  .  The Warriors finished the year with 67 wins and Curry was voted the   after posting averages of 23.8 points, 7.7 assists, and 2 steals per game.  Over the course of the season, he sat out 17 fourth quarters due to Golden State's wide margins of victory. \n In Game 5 of the Conference Semifinals against the  , Curry became the first player in league history to register six three-pointers and six steals in a game.  In Game 6, he made a playoff career-high 8 three-pointers en route to a series-clinching victory.  In Game 3 of the Conference Finals against the  , he broke the NBA record for most three-pointers made in a single postseason.  The Warriors went on to defeat the Rockets to earn a Finals matchup with the  , where Curry struggled to start the series, converting on only 22 percent of his field goals in Game 2.  In Game 5, he scored 37 points,  and in Game 6, Golden State closed out the series to win their first championship in 40 years.  For the Finals, Curry averaged 26 points and 6.3 assists per game.  The Warriors' playoff run was the first in which an All-NBA first team selection eliminated all other first team selections en route to a championship. \n To start the 2015–16 season, Curry became the first player since   in 1989–90 to score 118 points in his team's first three games,  including a season-high 53 points against the   in the third game.  The Warriors made NBA history on November 24 when they became the first team ever to start 16–0 with a win over the  ,  before improving to 24–0 on December 11 with a double-overtime win over the  .  Their streak was broken the following day against the  .  On December 28, Curry recorded his sixth career triple-double with 23 points, a career-high 14 rebounds, and 10 assists in a 122–103 win over the  . During the game, Curry was guarded by his brother   for the first time in their NBA careers.  On January 22, he recorded his second triple-double of the season with 39 points, 12 assists, and 10 rebounds in a 122–110 win over the  . He made 8 three-pointers in the game to reach 200 for the season, becoming the first player in NBA history to make 200 three-pointers in four straight seasons.  On February 3, he made 11 three-pointers (including seven in the first quarter) and scored 51 points (including a career-high 36 points in the first half) to lead the Warriors past the   134–121. His 51 points tied   and Michael Jordan for the   record. \n During the 2016 NBA All-Star Weekend, Curry competed in his third straight All-Star game for the West, and competed in the Three-Point Contest, where he lost in the final round to former teammate Klay Thompson. At 48–4, the Warriors entered the All-Star break with the best record through 52 games in NBA history, one win better than the   and  . \n On February 25, Curry scored 51 points and made 10 three-pointers to lead the Warriors past the   130–114, becoming the first player to record at least three 50-point games since   and   in 2008–09. He also became the first player in NBA history to score at least 50 points in a game with only one free throw attempted.  Curry surpassed  's record of 127 consecutive games with a made three-pointer.  In the following game, two days later, the Warriors defeated the   in overtime 121–118, owing to a long-distance game-winning shot made by Curry with 0.6 seconds remaining. In doing so, he tied the then- NBA single-game record (12) with   and   and finished with 46 points.  He also broke his own NBA record for made three-pointers in a season, setting a new mark at 288.  In February 2016, Curry averaged over 35 points per game, while shooting at least 50% from both the field and three-point range, becoming the first player in NBA history to achieve this feat in a calendar month.  On March 7, in a win over the Magic, Curry scored 41 points and became the first player in NBA history to make 300 regular-season three-pointers.  On April 1, Curry missed a three-pointer to tie the game against the Celtics with 5.3 seconds left, as the Warriors suffered their first home defeat since January 27, 2015, snapping an NBA-record 54-game winning streak in the regular season at  .  On April 7, Curry scored 27 points to help the Warriors become the second team in NBA history to win 70 games in a season with a 112–101 win over the  .  Three days later in a rematch against the Spurs, Curry scored 37 points in a 92–86 win, not only tying the 1996 Bulls, but snapping San Antonio's undefeated home streak and also ending a long losing streak in AT&T Center. \n In the Warriors' regular-season finale on April 13 against the  , Curry scored 46 points with 10 made three-pointers, becoming the first player in NBA history to make 400 three-pointers in a season (finishing with 402).  With a 125–104 win over the Grizzlies, the Warriors became the first 73-win team in NBA history, surpassing the  ' 72–10 record to finish the 2015–16 season with just nine losses.  With the conclusion of the regular season, Curry became the seventh player in NBA history to join the   and the first to achieve this feat while averaging over 30 points per game.  Curry led the league in   (30.1 points per game),   (2.14), and   (90.8), becoming the first player to lead all three statistics in a season.  For his record-breaking season, Curry was named the league's first ever unanimous  , becoming the 11th player in history to win the award in consecutive seasons and the first guard to do so since   in 2004–05 and 2005–06.  His scoring average increase of 6.3 is the largest ever by a reigning MVP. \n In the 2016 playoffs, the Warriors defeated the   in the first round despite Curry only playing in the first half of Games 1 and 4 due to injury.  A right   injury kept him out of the first three games of the second round.  In Game 4 of the second-round series against the  , Curry came off the bench to score 40 points in a 132–125 overtime win;  17 of those points came in the extra period, an NBA record for points scored by an individual in overtime.  Curry led the Warriors to a 4–1 victory over the Trail Blazers, as they moved on to the Western Conference Finals to face the Oklahoma City Thunder. After going down 3–1, he helped the Warriors rally to win the series 4–3 and advance to their second straight  . \n In the Finals, Curry's play relative to his regular season performance remained inconsistent, as it had been since he returned from injury against Portland;  still, he broke  's record of 27 three-pointers made in a Finals.  Despite being up 3–1 in the series, the Warriors were defeated by the   in seven games and became the first team in NBA Finals history to lose a series after leading 3–1. In the game seven loss, Curry scored 17 points on 6-of-19 shooting. \n On October 28, 2016, Curry hit four three-pointers against the   to reach 1,600 for his career, becoming the 19th player to do so, as well as the fastest to reach the mark.  On November 4, Curry's NBA-record streak of 157 straight games with at least one made three-pointer was snapped during the Warriors' 117–97 loss to the   after he went 0-of-10 from three-point range. He had hit a three-pointer in every regular-season game since November 11, 2014.  Three days later, he hit 13 three-pointers against New Orleans, becoming the first player in NBA history to make as many three-pointers in a regular-season game.  Curry shot 16-of-26 overall against the Pelicans for his first 40-point game of the season, finishing with 46 in a 116–106 win.  On December 11, Curry hit 2 three-pointers against the   to pass   for 17th on the NBA's career three-pointers list. \n With 14 points against the   on December 30, Curry (11,903) passed   (11,894) for seventh place on the Warriors' all-time scoring list.  In a loss to the   on January 6, 2017, Curry had his second 40-point game of the season and reached the 12,000-point threshold, becoming the seventh player in Warriors franchise history to score 12,000 career points.  On January 19, Curry was named a starter on the Western Conference All-Star team for the  .  On February 2, he hit his 200th three-pointer of the season in the Warriors' 133–120 win over the  , making him the first player in NBA history to have 200 or more three-pointers in five consecutive seasons.  On March 5, he scored 31 points and moved into the top 10 on the NBA's career three-point list in a 112–105 win over the  . Curry hit 5 three-pointers, passing   for 10th place. \n Curry helped the Warriors sweep through the first two rounds of the playoffs.  In Game 1 of the Western Conference Finals against the  , Curry scored 40 points and hit a tying three-pointer with 1:48 remaining to help the Warriors rally from a 25-point deficit to win 113–111; the Warriors overcame their largest halftime deficit ever in the postseason at 20 points.  This was the second time in the season that the Warriors came back from a 20-point deficit against the Spurs.  In a 120–108 Game 3 win, Curry scored 21 points and became the franchise leader in postseason points, passing  . They went up 3–0 in the series, becoming the third team in NBA history to win their first 11 playoff games.  His 36 points in Game 4 led to a 129–115 victory that saw the Warriors advance to the NBA Finals for a third straight year while becoming the first team in league history to start the playoffs 12–0.  In Game 2 of the   against the  , Curry recorded his first career postseason triple-double with 32 points, 11 assists and 10 rebounds to help the Warriors go up 2–0 in the series with a 132–113 win.  Curry helped the Warriors clinch the series and the championship in Game 5 with 34 points, 10 assists, and six rebounds, as Golden State claimed its second title in three years. \n On July 1, 2017, Curry agreed to a five-year, $201 million extension with the Warriors, becoming the first NBA player to sign a   contract worth over $200 million.  He officially signed the contract on July 25.  On December 1, he scored 23 points and passed   for eighth place on the career three-pointers made list in a 133–112 win over the  .  On December 4, in a 125–115 win over the  , Curry hit 5 three-pointers to become the fastest NBA player to achieve the milestone of 2,000 career three-pointers, achieving that mark in just 597 games, 227 less than the previous fastest player to achieve that mark,  .  In that same game, Curry injured his right ankle and subsequently missed 11 games,  returning to action on December 30 and scoring 38 points with a season-high 10 three-pointers in a 141–128 win over the  . Curry shot 13 of 17 and 10 of 13 from deep in 26 minutes for his ninth 30-point game of the season. It also marked Curry's ninth career game with 10 or more 3s, the most by any player in NBA history. \n On January 6, in a 121–105 win over the  , Curry scored 45 points in three quarters.  On January 25, he scored 25 points in a 126–113 win over the  . Curry became the fifth player in Warriors franchise history to score 14,000 points, ending the game with 14,023 and joining   (17,783),   (16,447),   (16,266), and   (16,235) on the franchise list.  On January 27, he scored 49 points—with 13 of those over the final 1:42—and hit 8 three-pointers, lifting the Warriors past the   109–105.  On February 22, he had a 44-point effort with 8 three-pointers in a 134–127 win over the  . It was his third 40-point game of the season.  On March 2, in a 114–109 win over the  , Curry made his 200th three-point field goal of the season, becoming the first player in NBA history with at least 200 three-pointers in six seasons, having reached the mark in every season since 2012–13.  Four days later, in a 114–101 win over the Nets, Curry became the seventh player in Warriors franchise history to make 5,000 career field goals, joining Chamberlain, Barry, Mullin, Arizin,  , and  . \n On March 23, against the Hawks, Curry suffered a Grade 2   (MCL) sprain to his left knee.  He subsequently missed nearly six weeks, returning to action in Game 2 of the Warriors' second-round playoff series against the Pelicans. He came off the bench to score 28 points in a 121–116 win.  In Game 3 of the Western Conference Finals, Curry scored 35 points with 5 three-pointers in a 126–85 win over the  . The 41-point victory was the largest in franchise history during the postseason.  In Game 6, Curry scored 29 points with 5 three-pointers, as the Warriors rallied from an early 17-point deficit to stave off elimination with a 115–86 victory over the Rockets.  In Game 7, Curry recorded 27 points, 10 assists, and nine rebounds, as the Warriors earned a fourth straight trip to the NBA Finals by beating the Rockets 101–92. \n In Game 2 of the  , Curry hit a Finals-record 9 three-pointers and scored 33 points in a 122–103 win over the Cavaliers.  In Game 4, Curry led all scorers with 37 points in a 108–85 win that helped the Warriors clinch their second straight championship with a series sweep over the Cavaliers.  Many felt that he should have won  .  In response, Curry stated: \"At the end of the day, I'm not going to let a [Finals] MVP trophy define my career. Three titles ... Wherever that puts us in the conversation in the history of the NBA ... I'm a three-time champ.\"  Rohan Nadkarni of   argued that \"the Golden State dynasty started with Stephen Curry. He, for numerous reasons stretching from his incredible talent to his previous ankle injuries, put the Warriors in place to win their third championship in four seasons.\" \n On October 21, 2018, Curry had 30 points and 6 three-pointers in a 100–98 loss to the  , thus moving past   for sixth place on the NBA's career three-point list.  Three days later, he scored 51 points with 11 three-pointers in only three quarters in a 144–122 win over the  . He scored 31 in the first half and finished with his sixth career 50-point game and made 10 or more 3s for the 10th time. Curry's third three-pointer of the night moved him past   (2,153) for fifth place on the NBA's career three-point list.  On October 28, he made seven three-pointers and finished with 35 points in a 120–114 win over the  .  Over the first seven games of the season, he made at least 5 three-pointers in all seven games, breaking  's record of six games in a row during the 1995–96 season.  The Warriors started the season with a 10–1 record. On November 8 against the  , Curry left the game during the third quarter with a groin injury  and the Warriors were unable to recover in a 134–111 loss.  Without Curry, the Warriors dropped to 12–7 on November 21 after enduring their first four-game losing streak since March 2013.  The Warriors ended November with a 15–8 record, with Curry's strained left groin sidelining him for 11 straight games. \n Despite Curry's 27 points in his return to the line-up on December 1, the Warriors were defeated 111–102 by the  .  On December 17, he scored 20 points in a 110–93 win over the  , becoming just the fifth player in Warriors franchise history to score 15,000 points during the regular season, joining   (17,783),   (16,447),   (16,266), and   (16,235).  On December 23, he scored 42 points and made a layup with 0.5 seconds left to lift the Warriors to a 129–127 win over the  .  On January 5, he had 10 three-pointers and scored 20 of his 42 points in the fourth quarter of the Warriors' 127–123 win over the  .  On January 11, in a 146–109 win over the  , Curry made 5 three-pointers to surpass   (2,282) and move into third place all-time in NBA history behind   (2,973) and   (2,560).  Two days later, he scored 48 points and hit a season high-tying 11 three-pointers in a 119–114 win over the  .  On January 16, he scored 41 points with 9 three-pointers to become the first player in NBA history to make eight or more 3s in three straight games, as the Warriors defeated the   147–140.  On January 31, he scored 41 points with 10 three-pointers in a 113–104 loss to the  .  On February 21, he scored 36 points with 10 three-pointers in a 125–123 win over the Kings.  On March 16 against the  , Curry reached 16,000 career points.  On March 29, he made 11 three-pointers and scored 37 points in a 131–130 overtime loss to the  .  On April 2, in a 116–102 win over the Nuggets, Curry made 5 or more three-pointers in a career-best nine straight games and moved past Mullin for fourth place on the Warriors all-time points list.  On April 5, he scored 40 points in a 120–114 win over the  , thus moving past Arizin for third place on the Warriors all-time points list. \n The Warriors entered the playoffs as the first seed in the Western Conference with a 57–25 record. In Game 1 of the Warriors' first-round playoff series against the Clippers, Curry scored 38 points and made 8 three-pointers to give him the most in postseason history, passing Ray Allen (385). He also had a postseason career-high 15 rebounds and seven assists in a 121–104 win.  In Game 6 of the second round, Curry bounced back from the first scoreless first half of his playoff career to score 33 points in the last two quarters to help the Warriors eliminate the   with a 118–113 win and advance to the Western Conference Finals.  In Game 1 of the Conference Finals, Curry matched his postseason career high with 9 three-pointers to finish with 36 points in a 116–94 win over the  .  Curry faced his brother Seth in that Finals series, making them the first set of brothers to face each other in an NBA playoff series.  He averaged a series career-high 36.5 points to help the Warriors sweep the Trail Blazers. It was the highest average by a player in a four-game sweep in NBA history.  Curry became the sixth player in NBA history to score 35 or more in the first four games of a series.  In Game 4, he had 37 points, 12 rebounds, and 11 assists in a 119–117 overtime win,  as he and   became the first teammates in league history to have a triple-double in the same playoff game.  In Game 3 of the  , Curry scored a playoff career-high 47 points to go with eight rebounds and seven assists in a 123–109 loss to the  .  In Game 5, he helped the Warriors stave off elimination with 31 points in a 106–105 win, cutting the Raptors' series lead to 3–2.  In Game 6, Curry scored 21 points, but shot just 6 for 17 and went 3 of 11 on three-pointers, including missing a contested three-pointer in the waning moments, as the Warriors lost the game and the series with a 114–110 defeat. \n Curry was expected to take on a greater offensive load in the   with Thompson out injured and   having left the Warriors as a free agent. On October 30, 2019, against the   in the fourth game of the season, Curry drove to the basket and collided with the Suns'  , who was trying to take a  . Baynes fell on Curry's left hand, which required surgery to repair his broken  . He was expected to be out at least three months.  On March 5, 2020, Curry returned against the   and recorded 23 points, six rebounds and seven assists in a 121–113 Warriors' loss. \n On December 27, 2020, Curry put up 36 points in a 129–128 win over the  . With this game, he joined Ray Allen and Reggie Miller as the only players to have scored more than 2,500 career three-pointers in NBA history.  On January 3, 2021, Curry scored a career-high 62 points in a 137–122 win against the  .  On January 4, he was named the  .  On January 23, in a game against the  , Curry hit 5 three-pointers, moving his career total up to 2,562, passing Miller to move up to second in the NBA's career three-pointers list, trailing only Allen.  At the  , he won his second Three-Point Contest after making his last shot in the final round to edge   28–27.  On March 15, against the  , Curry passed   (4,855) as the franchise's leader in career assists. \n On April 12, Curry scored 53 points in a 116–107 win against the  , and he surpassed   (17,783) to become the franchise's all-time scoring leader.  It was part of an 11-game stretch in April in which Curry scored at least 30 points in each game, surpassing  's previous record (10) for a player age 33 or older. He also made 78 three-pointers during that span, the most in NBA history over 11 regular season games.  Curry's play sparked media discussions about his candidacy for the  , and went on to become a finalist for the award for the third time in his career.  He was named the Western Conference Player of the Month for April after averaging 37.3 points on 51.8% shooting and scoring 30 or more points in 13 of his 15 games played. He became the first NBA player to average at least 35 points per game and shoot 50–45–90 in a calendar month and set an NBA record for made three-pointers in a month with 96, breaking  's mark of 82 set in November 2019.  Curry made 46.6% of his three-pointers in that span, including four games in which he made 10 or more three-pointers.  He scored 46 points in the regular-season finale against the  , finishing the season with a scoring average of 32.0 and holding off   to secure his second  .  He joined  ,  , and Wilt Chamberlain as the fourth player in NBA history to win multiple  , league MVP awards, and scoring titles in a career. \n On October 19, 2021, in the Warriors' season-opener, Curry recorded his eighth career triple-double with 21 points, 10 rebounds, and 10 assists in a 121–114 win against the  .  On November 8, Curry scored 50 points, with 10 assists on nine three-pointers made, in a 127–113 win over the  .  Curry recorded 50 points and 10 assists in the same game for the first time in his career and surpassed Chamberlain as the oldest player in history to achieve this feat.  On November 12 against the  , Curry became the NBA's career leader for three-pointers in both regular season and playoffs with 3,366, passing   (3,358).  On December 14 at   against the  , Curry made his 2,974th career three-pointer to pass   and become the  .  On January 21, 2022, Curry hit his first career   game-winner in a 105–103 win over the  , on a night where he put up 22 points and 12 assists.  On January 31, Curry scored 40 points, 21 of which in the fourth quarter, behind seven three-pointers and dished out nine assists to lead Golden State to a 122–108 victory over the  . His 21 fourth-quarter points were the highest of his career until February 2024. \n In the   held on February 20, Curry's Team LeBron defeated Team Durant 163–160. Curry scored 50 points (just 2 points shy of the All-Star Game record set by   in  );  he also set the record for most three-pointers made in an All-Star quarter (6), half (8), and game (16),  and was named the  .  On February 24, Curry had a season-high 14 assists with 18 points in a 132–95 blowout win over the  .  On March 10, Curry scored 34 points in a 113–102 win over the  . He became the 49th player in NBA history to rack up 20,000 points.  On March 14, his 34th birthday, Curry scored 47 points in a 126–112 win over the  .  On March 16, in a 110–88 loss to the  , Curry suffered a sprained ligament in his left foot after having it rolled over by a diving   and was ruled out indefinitely.  On April 1, he was ruled out for the remainder of the regular season. \n On May 9, in Game 4 of the   against the  , Curry became the first player in NBA history to make 500 career playoff three-pointers.  During the Western Conference Finals against the  , he averaged 23.8 points, 6.6 rebounds and 7.4 assists per game. After the Warriors won the series in five games, Curry was named the unanimous and inaugural winner of the   award.  On June 10, in Game 4 of the  , Curry logged 43 points, 10 rebounds, and four assists in a 107–97 victory over the   to even the series at 2–2. He became the first player in Finals history to make 5+ three-pointers in four consecutive games.  Curry (at age 34 years, 88 days) also became the second-oldest player in NBA Finals history to record a 40-point, 10-rebound game behind only   in 2020 (at age 35 years, 284 days).  In Game 5 of the Finals, Curry passed Boston Celtics legend   for 10th on the all-time Finals assists list.  In Game 6 of the Finals, Curry scored 34 points along with seven rebounds, seven assists, and led the Warriors to a 103–90 victory over the Celtics. He was named the   unanimously after averaging 31.2 points, 6.0 rebounds, 5.0 assists, and 2.0 steals per game.  He became the first player in Finals history to average at least 30 points, 5 rebounds, 5 assists, and 5 made three-pointers per game in a series. \n On November 2, 2022, Curry logged his 10th career triple-double with 23 points, 13 rebounds and 13 assists in a 116–109 loss against the  .  On November 7, Curry recorded 47 points, eight rebounds, eight assists, and zero turnovers as the Golden State Warriors beat the   116–113 to snap a five-game losing streak.  On November 11, Curry scored 40 points on 15–23 shooting from the field in a 106–101 win over the  . He became the first player in NBA history to record at least 40 points, 5 made three-pointers, and shoot over 65% from the field in consecutive games.  On November 16, Curry scored 50 points alongside nine rebounds and six assists in a 130–119 loss to the  .  On November 20, Curry posted a season-high 15 assists along with 33 points on 7-of-14 shooting from three-point range in a 127–120 win over the  .  Curry,  , and   combined for 23 made three-pointers, the most three-pointers made in a game by a trio in NBA history.  On December 10, in a rematch of the  , Curry recorded 32 points, six rebounds, and seven assists in a 123–107 win over the  . \n On January 25, 2023, in a 122–120 victory against the  , Curry was ejected with 1:14 remaining in the fourth quarter for throwing a mouthpiece on the ground, marking the third time that Curry was ejected during his career.  Curry left the game with a game-high 34 points.  The next day, Curry was named a   starter for the  , marking his ninth overall selection.  On January 30, Curry put up 38 points on 12-of-20 shooting from the field, alongside eight rebounds and 12 assists in a 128–120 win over the  . He also surpassed   (7,216) for the most field goals made in Warriors franchise history with 7,222.  On March 15, Curry scored 50 points on 8-of-14 shooting from three-point range in a 134–126 loss to the  . He became the first player in NBA history to score at least 10,000 career points off of three-pointers.  Curry also surpassed   for the most 50-point games at age 30 or older, tying Chamberlain's then- record of 7 games. \n In Game 7 of the Warriors' first round playoff series against the  , Curry scored a playoff career-high 50 points in a 120–100 win. He became the first player to score 50 points in a Game 7 and tied   for the most points in a playoff game at age 35 or older.  He also became the first player in playoff history to score at least 20 points from behind the arc and in the paint in the same game.  Following the series' completion, Curry joined Jordan as the only players in playoff history to record at least 200 points in a series at age 35 or older.  His 50 points also set a record for the most points scored in a Game 7.  In Game 4 of the Conference Semifinals against the Lakers, Curry logged his third postseason career triple-double with 31 points, 10 rebounds, 14 assists, and three steals in a 104–101 loss.  The Warriors were eliminated in six games, despite Curry's 32-point outing in a 122–101 closeout loss in Game 6. \n On November 1, 2023, Curry became the first player in NBA history to make a three-pointer in 250 consecutive regular season games.  On November 3, he scored a game-winning layup in a 141–139 win against the  .  On December 16, Curry scored 37 points on 14-for-22 shooting, including 6-for-8 from beyond the arc in a 124–120 victory over the  . He became the first player in NBA history to record at least 3,500 career three-pointers.  On January 27, 2024, Curry recorded 46 points and nine made three-pointers, in a 145–144 double-overtime loss to the  . \n On February 1, Curry was named to his tenth   and his first as a reserve.  On February 3, Curry scored a season-high 60 points on 22-of-38 shooting from the field with 10 three-pointers made in a 141–134 overtime loss to the  , setting several NBA records; he joined   as the only players in history to record a 60-point game after turning 35 years old; he became the second player after   to score at least 60 points with at most six free throws attempted; he joined   and   as the only players to record at least 60 points and 10 made three-pointers in a regular season game; he became the first player in history to average over 40 points per game on 50–40–100 splits in a four-game span. \n On February 8, Curry scored 42 points on 15-of-22 shooting from the field, including a season-high 11-of-16 shooting from three, in a 131–109 win over the  .  On February 10, Curry put up 30 points and nine rebounds, alongside a game-winning three-pointer in a 113–112 win over the  . \n On April 25, Curry was named the     over   and   after leading the league in clutch points that season. \n On August 30, 2024, Curry signed a one-year, $62.6 million contract extension with the Warriors throughout the 2026–27 season, becoming the first NBA player to earn $60 million in a single season.  He also joined   and   as the only players in history to amass $500 million in career earnings. \n On November 10, 2024, Curry recorded 36 points and seven assists in a 127–116 road victory over the  .  Two days later, he scored all of Golden State's final twelve points as part of a 37-point, 6-rebound and 9-assist outing in a 120–117 win over the   in  's first return to the Bay Area after leaving for Dallas in a sign-and-trade during the offseason. \n Curry's first experience with the   came at the  , where he helped Team USA capture the silver medal.  In 2010, he was selected to the senior squad, playing limited minutes at the   (later known as the FIBA Basketball World Cup) as the United States won the gold medal in an undefeated tournament.  In 2012, Curry was excluded from the list of 20 finalists selected for consideration for the   in  , which reportedly left him \"very disappointed\" but motivated to improve his game for future opportunities.  In 2014, he took on a larger role with the team, helping them to another undefeated tournament at the   and scoring 10 points in the final game.  On June 6, 2016, Curry withdrew from consideration for the   in  , citing ankle and knee ailments as the major reason behind the decision. \n Curry made his Olympic debut with the   in  , alongside his longtime head coach  .  He initially struggled from the field. In a tightly contested semifinal game against  , Curry led a 17-point comeback in a 95–91 win, finishing with a tournament-high 36 points, 8 rebounds, and 9-of-14 shooting from three-point range.  In the final two minutes, Curry made a successful  , layup, and two clutch free throws to maintain a lead of four points.  He set a national record for most points scored in an Olympic knockout game and an Olympic record for most three-pointers made in a knockout game, respectively.  His 36 points are the second-most ever scored in a game by an American, behind  's 37-point performance against   in 2012. In a postgame interview, teammate   called Curry's performance \"one of the greatest games I've ever seen him play\".  Curry followed up his performance with another successful outing in the final match against  , tallying 24 points, 5 assists, 2 steals, and 8-of-12 shooting from three-point range.  He made 4 consecutive three-pointers within the final 3 minutes to help seal the game and secure the United States' 5th straight Olympic gold medal and his career-first.  Curry finished the tournament as the team's leading scorer, averaging 14.8 points per game, and set a new Olympic record for most three-pointers made in a final.  For his performances, Curry was named to the  .  He joined  ,  , and   as the fourth player in NBA history to win at least four  , two  , a  , and an Olympic gold medal in a career. \n Listed at 6 feet 2 inches (1.88 m) and 185 pounds (86 kg), Curry plays almost exclusively at the   position combined with the signature play style of an elite  . He has career averages of 24.8 points, 6.4 assists, 4.7 rebounds, and 1.5 steals per game (through the end of the 2023–24 season),  His career free throw percentage of 91.0% is the  , and he has led the league in annual free-throw percentage four times.  He has been named   twice, including the first unanimous selection in league history ( ). \n Known for his  , athleticism, and playmaking, Curry is an offensive threat from underneath the rim to near  .  Using an unorthodox  , he is capable of releasing the ball in under half a second upon jumping, adding greater arc to his shots and making them difficult to block.  Therefore, Curry is able to adjust his release and balance to make shots from virtually anywhere on the court. For his high shooting proficiency and ball-handling, he has been referred to as the \"Baby-Faced Assassin\" since his collegiate basketball years  and \"Chef Curry\" while playing in the NBA.  For their shooting abilities, Curry and former teammate   are often referred to as the  . In the  , they set the record for combined three-pointers made in a season with 484, a record they broke the following season (525), and again in the 2015–16 season (678).  Curry is also known for putting pressure on defenses with his long range and led the league in field goals made from beyond 28 feet in the 2015–16 season.  A   scorer, he often shoots at his best in high-pressure moments and takes game-winning shots.  Curry has made 10 game-winning shots  in his career, the most by any player since the  .  He was named the     after leading the league in clutch points, made clutch field goals, and made clutch three-pointers. \n His career   (3P%) of .425% ranks as the 12th highest in NBA history.  In 2015–16, Curry posted the highest eFG% (.630) and 3P% (.454) ever recorded in a season while averaging over 30 points per game.  He holds four of the top-five seasons with most three-pointers made, led by his NBA record 402 three-pointers from the 2015–16 season, and has served as the annual leader a record eight times.  He is also the fastest player in league history to make 2,000 career three-pointers, doing so in 227 fewer games than the previous record-holder,  .  Additionally, Curry is the fastest player to make 100 three-pointers in a season, doing so in just 19 games, breaking his own previous record of 20 games. \n Owing to his offensive presence, Curry's scoring creates a \" \" effect that forces opposing defenders to frequently double-team him during both   and off-ball movement, creating mismatches that his teammates exploit.  With Curry, the Warriors average 10.8   per game; without Curry, they average 15.3 isolations per game. His absence slows the Warriors offense and leads to less passing and ball movement. With Curry, the Warriors average 1.05 points every shot that comes after an off-ball screen; without Curry, it drops to 0.95 points per game. His absence makes it much easier for defenders to switch on screens. Of Curry's success with or without other elite teammates,  ' Tom Haberstroh said, \"You can pluck All-Star after All-Star off the court like flower petals, and the Steph-led Warriors will still dominate like a champion. He's that transcendent of a player.\" \n Curry's short stature relative to the rest of the league impeded his defensive abilities for the majority of his career.  With a low  , he leverages his fast pace and reflexes to break defenses.  Some analysts, including Ethan Sherwood Strauss of  , have complimented his defensive play or called it underrated.  Strauss said in 2015 that Curry became \"one of the NBA's most effective defenders – ranking fifth among point guards in defensive real plus-minus.\"  Curry led the league in total steals in the   and   in the following season. \n Curry is often considered the greatest shooter  and one of the greatest players in NBA history.  He is credited with revolutionizing the game of basketball by inspiring teams, from high school to the NBA, to  .  Analysts have referred to him as \"the Michael Jordan of the three-point era\", saying that he did for the three-point shot what Jordan did for the  .   s Robert O'Connell cites Curry's February 27, 2013, game against the  , in which he made 11-of-13 shots from behind the arc en route to a 54-point performance, as the start of the three-point era.  The era has been referred to as \"the Steph Effect\"  or \"the NBA's Three-Point Revolution\".  Curry is also often compared to   in debates over the greatest   of all time, owing to their generational impact, winningness, and diverse skillsets. \n Regarded as the face of the  ,  Curry helped redefine three-point scoring as a central element of modern-day basketball strategy rather than a mere novelty.  His influence has inspired the league to transition from physical play around the basket to a \" \" approach that emphasizes three-point shooting.  This transformation can be attributed, in part, to teams attempting to counter the Warriors' dominance and young players aspiring to emulate Curry's range.  Curry regularly attempts shots from 30 to 35 feet at an efficiency of .54, compared to the league average of under .22 from this range and .35 for made three-pointers overall.  Kirk Goldsberry of ESPN opined that \"Curry isn't just the best 3-point shooter ever, he's the best deep 3-point shooter ever.\"  As Curry himself noted, \"I'm sure coaches tell their high school players that shooting the way I do takes work and time;\" Jesse Dougherty of   stated that \"coaches have to explain that while Curry's skill set is something to aspire to, his game is built on fundamentals.\"  His ability to make these shots is complemented by a high degree of ball-handling skills, release, and capacity to shoot effectively with one or more defenders contesting his attempts.  Sally Jenkins, also of  , highlighted the degree of difficulty of Curry's shooting, citing a period in which he achieved a .67 success rate on shots taken from 28 to 50 feet.  Jeff Austin of   noted that Curry \"had to develop tremendous strength in his wrists to shoot and maintain that form from 40 and 50 feet.\"  Goldsberry concludes that \"no player in the history of the NBA has combined range, volume, and efficiency from downtown as well as Curry,\" making him \"the most efficient volume scorer on the planet.\"  The developers of the   video game series have even expressed concerns about accurately replicating Curry's unique abilities. \n Where Curry ranks as one of the greatest NBA players has been more subject to debate.   , a two-time NBA MVP and one of the league's all-time efficient shooters, said Curry is \"already an all-time great\" and that people question his greatness \"because he doesn't dominate the game physically. He dances. He pays a tax for that. He pays a tax for his great teammates.\"   , a six-time NBA champion with the  , said that Curry's \"willingness to sacrifice\" for Durant is \"one of the great stories in history.\" Crediting Curry as \"one of the greatest guards the game has ever seen\", he said: \"If you have a mind for the game, you know that it takes sacrifice to be great. All the greats have to sacrifice something. Otherwise you can't win.\"  In 2018,   ranked Curry at No. 19 in their list of \"50 greatest NBA players of all time\".  In a 2019 feature,   stated that \"Curry and the Warriors are a great match of player and system\" and that \"the entire ecosystem is predicated on the idea that a player doesn't need to dominate the ball to dominate a game. Curry took that noble idea and elevated it beyond any reasonable expectation.\"  In 2020,   ranked Curry as the 13th greatest basketball player of all time, the second-highest active player behind  . Nick Friedell of ESPN described Curry as \"the greatest shooter of all time\", noting his game-changing influence \"is seen on every level of basketball as younger generations shoot more than ever while trying to replicate his game.\"  In October 2021, Curry was honored as one of the league's greatest players of all time as a member of the  .  In an \"NBA 75\" feature, Marcus Thompson II of   opined that \"in 20 years, Curry will be talked about with excitement reserved for the most legendary. Like the elders of today talk about   and  , and how their children revere   and  .\"  After winning his fourth NBA championship and first Finals MVP award in 2022,   ranked Curry as the 10th greatest player in NBA history the following year. Angel Diaz cited his generational impact with \"nothing left (for Curry) to accomplish\" as reasons for his place among the sport's greats. \n On July 30, 2011, Curry married longtime girlfriend and Toronto-area native   in Charlotte.  Curry and Alexander met at their church in Charlotte when they were 15 and 14 years old, respectively.  Together, they have two daughters who were born in 2012 and 2015,  and two sons who were born in 2018 and 2024, respectively. \n In July 2019, Curry paid $31 million for a home in  .  Curry's younger brother,  , is also a professional basketball player,  and his younger sister, Sydel, played volleyball at  . \n Curry is a   and has been outspoken about his faith.  He spoke about his faith during his MVP speech by saying: \"People should know who I represent and why I am who I am, and that's because of my Lord and Savior.\" He also said the reason that he pounds his chest and points up is that he has a \"heart for God\" and as a reminder that he plays for God.  On some of his \"Curry One\" basketball shoes, there is a lace loop scripted \"4:13\". It is a reference to the Bible verse   4:13, which reads: \"I can do all things through Christ who strengthens me.\"  Curry has a tattoo of   13:8 in Hebrew on his wrist (\"Love never fails...\").  Curry is also an investor in Active Faith, a Christian sports apparel brand. \n During the   weekend, Curry's father entrusted him to Biserka Petrović, mother of future   player  , while Dell competed in the Three-Point Contest. Following the 2015 NBA Finals, Curry gave Biserka one of his Finals-worn jerseys, which will reportedly be added to the collection of the Dražen Petrović Memorial Center, a museum to the late player in the Croatian capital of Zagreb. \n Curry is diagnosed with   and wears contact lenses to correct his vision.  He is also an avid golfer; he started playing golf at the age of 10, played golf in high school, and frequently plays golf with former teammate  .  A   golfer, Curry participates in celebrity golf tournaments and has played golf alongside  .  In August 2017, Curry competed in the   on an unrestricted sponsor exemption.  Although he missed the first cut, he scored 4-over-74 for both days he participated, surpassing most expectations for an amateur competing in the pro event.  In July 2023, Curry won the  , an annual celebrity golf tournament held at the   in  . He shot a   during the second round and won the tournament on the final hole with a walk-off   putt. \n In August 2019, Curry and  , a   in Washington, D.C., jointly announced that the school would add NCAA Division I teams in men's and women's golf starting in the 2020–21 school year, with Curry guaranteeing full funding of both teams for six years.  Curry is also a fan of English soccer club  \n \"No NBA athlete has a larger contingent of fans at every arena, lining up 20- and 30-deep hoping for a glimpse, if not an autograph. This crazy popularity is why his jersey sales consistently rank No. 1, why he was voted to be the captain of the [2018] Western Conference All-Star team and why 9-year-old girls feel comfortable enough to write letters asking for his help – and actually get it.\"\n Curry is one of the most successful players in the NBA, and has also become an international celebrity, on par with four-time MVP  .  Like James, he has been considered the face of the NBA, but has said that he is not motivated by that and is not looking \"to take LeBron's throne or whatever. You know, I'm trying to chase rings, and that's all I'm about. So that's where the conversation stops for me.\"  His flashy play and penchant for coming up big in the clutch have made him a fan favorite, and his smaller physique is said to have made his success seem more attainable for younger fans of the NBA.    associated with Curry is highly sought after; his 2009   ranks among the   and is the most expensive   ever sold, purchased by Alt Fund II for a record $5.9 million in July 2021.  Curry has led the NBA in jersey sales for five cumulative years; three consecutive times from the 2015–16 to 2017–18 seasons and two consecutive times from the 2022–23 to 2023–24 seasons, respectively. \n  has ranked Curry among the most famous international athletes. He is the   by season and has been ranked in   list of the world's   for his endorsements six times.  ESPN's Kirk Goldsberry reasoned that one reason for Curry's popularity is that while most people are not tall enough to dunk, everyone can attempt a shot, which is something Curry inspires.  Owen Davis of   echoed this sentiment, stating: \"After all, not everyone is blessed with supreme height and athleticism, but everyone can learn to pass, dribble and shoot. Curry is proof that if you work hard enough, you can still find ways to dominate, no matter your size.\" \n Monte Poole of   found Curry to be \"the most human of superstars,\" with a childlike aura to him when he plays with success. His fanbase ranges from very young children to the elderly, and casual or committed fans enjoy his style of play. Poole stated that \"the joy factor exponentially increases\" when Curry is on the court and that \"the sight of this relatively ordinary specimen sending much bigger players into silent surrender is an intoxicant for the Warriors and their fans.\" \n Curry is widely known for his partnership with  , serving as the \"face of their footwear line\" and the President of his signature shoe and apparel line called the \"Curry Brand\".  Originally signed to  , Curry began a partnership with Under Armour in the 2013 offseason.  After becoming the   and one of the most popular athletes in the world, sales of Curry's shoe line became an influential factor for the brand, with stock prices pivoting based on its success. \n In September 2017, it was announced that Curry had signed an exclusive autograph contract with Steiner Sports Memorabilia. The full product line included hand-signed official basketballs and jerseys, autographed photographs, framed signs and wall-art, game-used memorabilia, and limited-edition pieces. \n In October 2018, Curry announced his involvement with the relaunch of  , a mobile companion device that pairs with a primary smartphone.  Curry is an investor and the leading brand ambassador for Palm, a small startup based in San Francisco which licenses the Palm name from  . He is also involved with designing and testing accessories and even helped to name the device. \n In 2021, Curry, among other high-profile athletes and celebrities, was a paid spokesperson for  , a cryptocurrency exchange. In November 2022,  , erasing billions of dollars in customer funds, with Curry, alongside other spokespeople, being sued for promoting unregistered securities through a  .  In February 2022, the   ruled in a lawsuit against   that the   extends to   using  . \n Since 2018, Curry has served as the   of Thirty Ink, a  -based company that works to provide equitable opportunities to people through brand, media, experiences, and philanthropy, as the four major verticals. Since 2019, Curry has been the Global Brand Ambassador for  . The company partnered with Curry on a one-day   at the Warriors Shop in   for 20 Bay Area children. Curry posed as a team shop employee during the event and helped find sports gear around the store. \n In 2012, Curry started donating three   for every three-pointer he made to the  's   campaign to combat  . He was first introduced to the malaria cause by Davidson teammate Bryant Barr when they were both in school. Curry visited the   in 2015 and delivered a five-minute speech to dignitaries as part of President Barack Obama's launch of his   strategy for 2015–2020. \n In 2015, Curry wore sneakers that bore the name \"Deah Shaddy Barakat\"—a victim of the  . According to his sister Suzanne, Deah was known for his \"love for basketball and anything Steph Curry.\"  Deah donned Curry's No. 30 as his jersey number for his intramural basketball team at  , and recreated Curry's pose from his   photoshoot.  Curry said that Deah's family \"did a great job of reaching out to me and making me aware of the details of his life and personality ... It was really kind of a cool deal to be able to use the platform yesterday to honor Deah and his family ... I'm going to send them the shoes I wore yesterday. And hopefully, they know that I've been thinking about them.\"  Following his   win and historic   season, Curry donated his prize vehicle—a 2016  —to the  , a local non-profit organization located in the backyard of  . \n In December 2018, while on a podcast, Curry jokingly questioned whether the  's   actually took place, which received substantial media attention and criticism.   went on to offer Curry a tour of the   and discuss further. He partnered with   in creating signature shoes inspired by the comment and subsequent discussion. After wearing them to a game, he signed and auctioned them off on  . The shoes sold for $58,100 after 113 bids, with the money being donated for   education initiatives. \n In July 2019, Curry and his wife launched the   in  . \n In April 2018,   announced a wide-ranging, multiyear multimedia deal with Curry's newly formed production company Unanimous Media (named for Curry becoming the first NBA player in history to be elected the league's MVP by a unanimous vote), located on the Sony Pictures studio lot in Culver City. The film and TV deal included electronics, gaming and virtual reality and is focused on faith and family-friendly content.  In October 2018, Curry signed on as executive producer of the film  , scheduled for release in April 2019.  Curry was also executive producer of the film  , scheduled for US theatrical release in select theaters on June 17, 2019.  The film focused on the responses by family members of victims of the 2015  . Curry remarked, \"In the face of adversity, in the face of tragedy, how can I get through it?\" \nBeginning in 2019, Curry became both the executive producer and resident golf pro on the American     television series  .  On June 24, 2020, Curry released a trailer for his new show on his YouTube channel called Ultimate Home Championships, a show featuring people such as  ,  , and Kristopher London, where contestants competed in wacky at-home challenges using things in their home. In 2020, Unanimous Media signed a deal with  's  .  The same year, Curry served as the executive producer of an animated revival of the 1970s sitcom   along with the series' original executive producer,  , and   creator  . The series was green-lit by   in 2020.  In 2021, Curry signed on as executive producer of  , a documentary short film about basketball legend  . The same year, Unanimous Media signed a deal with  .  In 2023, Unanimous Media and   co-produced  , a sports   chronicling Curry's path to NBA stardom.   secured the streaming rights and a release date of July 21, 2023. \n Curry and his wife endorsed   for President of the United States during the  . \n In December 2021, Curry voiced his support for the  , an election reform bill aimed at expanding voting rights. \n In 2023, Curry opposed the development of multi-family housing in the wealthy enclave of  , where he and his family live,  citing safety and privacy for themselves and their children. \n Curry endorsed  , the Democratic nominee and an avid Warriors fan, for the  . \n \n \n \n \n \n \n \n \n \n \n \n \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/IANA_time_zone_database", "title": null, "content": "\n The   is a collaborative compilation of information about the world's   and rules for observing  , primarily intended for use with computer programs and operating systems.  Paul Eggert has been its editor and maintainer since 2005,  with the organizational backing of  .  The tz database is also known as  , the   or the   (after the  ), and occasionally as the  , referring to the founding contributor, Arthur David Olson. \n Its uniform naming convention for entries in the database, such as   and  , was designed by Paul Eggert.  The database attempts to record historical time zones and all civil changes since 1970, the   epoch.  It also records  . \n The database, as well as some reference  , is in the  .  New editions of the database and code are published as changes warrant, usually several times per year. \n Within the tz database, a   is any national region where local clocks have all agreed since 1970.  This definition concerns itself first with geographic areas which have had consistent local clocks. A timezone is different from a region with a particular    , which is often referred to as a \"time zone\".  Therefore, each of the timezones defined by the tz database may use multiple offsets from UTC, such as offsets for standard time and  . \n The tz database is published as a set of   which list the rules and zone transitions in a human-readable format.  For use, these text files are   into a set of platform-independent  —one per timezone.  The reference source code includes such a compiler called   (zone information compiler), as well as code to read those files and use them in standard   such as   and  .\n Each timezone has one or more \"zone lines\" in one of the tz database text files.  The first zone line for a timezone gives the name of the timezone; any subsequent zone lines for that timezone leave the name blank, indicating that they apply to the same zone as the previous line.  Each zone line for a zone specifies, for a range of date and time, the   for standard time, the name of the set of rules that govern   (or a hyphen if standard time always applies), the format for time zone abbreviations, and, for all but the last zone line, the date and time at which the range of date and time governed by that line ends.\n The rules for   are specified in named rule sets.  Each rule set has one or more rule lines in the text files.  A rule line contains the name of the rule set to which it belongs, the first year in which the rule applies, the last year in which the rule applies (or \"only\" if it applies only in one year or \"max\" if it is the rule then in effect), the type of year to which the rule applies (\"-\" if it applies to all years in the specified range, which is almost always the case, otherwise a name used as an argument to a script that indicates whether the year is of the specified type), the month in which the rule takes effect, the day on which the rule takes effect (which could either be a specific day or a specification such as \"the last Sunday of the month\"), the time of day at which the rule takes effect, the amount of time to add to the   when the rule is in effect, and the letter or letters to use in the time zone abbreviation (for example, \"S\" if the rule governs standard time and \"D\" if it governs daylight saving time).\n The timezones have unique names in the form \" / \", e.g. \"America/New_York\". A choice was also made to use English names or equivalents, and to omit punctuation and common suffixes.  The underscore character is used in place of spaces.  Hyphens are used where they appear in the name of a location.  The   and   names each have a maximum length of 14 characters. \n  is the name of a  , an  , or \"Etc\". The continents and oceans used are  ,  ,  ,  ,  ,  ,  ,  ,  , and  .\n The oceans are included since some islands are hard to connect to a certain continent. Some are geographically connected to one continent and politically to another. See also  .\n The special area of \"Etc\" is used for some administrative zones, particularly for \"Etc/UTC\" which represents  . In order to conform with the   style, those zone names beginning with \"Etc/GMT\" have their sign reversed from the standard   convention.  In the \"Etc\" area, zones west of GMT have a positive sign and those east have a negative sign in their name (e.g \"Etc/GMT-14\" is 14 hours ahead of GMT).\n  is the name of a specific location within the area – usually a city or small island.\n Country names are not normally used in this scheme, primarily because they would not be robust, owing to frequent political and boundary changes. The names of large cities tend to be more permanent.   Usually the most populous city in a region is chosen to represent the entire timezone, although another city may be selected if it is more widely known, and another location, including a location other than a city, may be used if it results in a less ambiguous name.  In the event that the name of the location used to represent the timezone changes, the convention is to create an alias  in future editions so that both the old and new names refer to the same database entry.\n In some cases the   is itself represented as a compound name, for example the timezone \"America/Indiana/Indianapolis\". Three-level names include those under \"America/Argentina/...\", \"America/Kentucky/...\", \"America/Indiana/...\", and \"America/North_Dakota/...\".\n The location selected is representative for the entire area.  However, if there were differences within the area before 1970, the time zone rules only apply in the named location.\n These are rule lines for the standard United States daylight saving time rules, rule lines for the daylight saving time rules in effect in the US   (called \"NYC\" as   is the city representing that zone) in some years, and zone lines for the America/New_York timezone, as of release version   of the time zone database.  The zone and rule lines reflect the  .\n For each timezone that has multiple offsets (usually due to daylight saving time), the tz database records the exact moment of transition. The format can accommodate changes in the dates and times of transitions as well. Zones may have historical rule changes going back many decades (as shown in the example above).\n The file   is in the public domain and lists the zones. Columns and row sorting are described in the comments of the file, as follows:\n Data before 1970 aims to be correct for the city identifying the region, but is not necessarily correct for the entire region. This is because new regions are created only as required to distinguish clocks since 1970.\n For example, between 1963-10-23 and 1963-12-09 in Brazil only the states of  ,  ,  , and   had summer time. However, a requested split from   was rejected in 2010 with the reasoning that, since 1970, the clocks were the same in the whole region. \n , which is represented by  , is incorrect for the year 1945 when the   used daylight saving time rules different from Berlin's. \n There are two zones that cover an area that was covered by two countries after 1970. The database follows the definitions of countries as per  , whose predecessor, ISO 3166, was first published in 1974.\n \nThe tz reference code and database is maintained by a group of volunteers. Arthur David Olson makes most of the changes to the tz reference code. Paul Eggert makes most of the changes to the tz database. Proposed changes are sent to the tz mailing list, which is gatewayed to the comp.time.tz  . Source files are distributed via the IANA FTP server. Typically, these files are taken by a software distributor like  , compiled, and then the source and binaries are packaged as part of that distribution. End users can either rely on their software distribution's update procedures, which may entail some delay, or obtain the source directly and build the binary files themselves. The   has published    , \"Procedures for Maintaining the Time Zone Database\" documenting best practices based on similar principles.\n The standard path for the timezone database is   in Linux distributions,  , and some other   systems.\n Geographical boundaries in the form of coordinate sets are not part of the tz database, but boundaries are published by Evan Siroky  in   and   formats.\n The Unicode   (CLDR) refers to zones in the tz database.  However, as the name for a zone can change from one tz database release to another, the CLDR assigns the   for the city used in the name for the zone, or an internally-assigned code if there is no such city for the zone, to a tzdb zone. \n The tz database is used for time zone processing and conversions in many computer software systems, including:\n The Olson timezone IDs are also used by the Unicode   (CLDR) and   (ICU). For example, the CLDR Windows–Tzid table maps Microsoft Windows time zone IDs to the standard Olson names, although such a mapping cannot be perfect because the number of time zones in Windows systems is significantly lower than in the IANA TZ database. \n The project's origins go back to 1986 or earlier. \n On 30 September 2011, a lawsuit,  , was filed concerning   in the database.   As a result, on 6 October 2011, the database's mailing list and   site were shut down.   The case revolved around the database maintainers' use of  , by  , and  , by Thomas G. Shanks and Rique Pottenger.  It complained of unauthorised reproduction of atlas data in the timezone mailing list archive and in some auxiliary link collections maintained with the database, though it did not actually point at the database itself.  The complaint related only to the compilation of historical timezone data, and did not cover extant tzdata world timezone tables. \n This lawsuit was resolved on 22 February 2012 after the involvement of the  , when Astrolabe voluntarily   the lawsuit without having ever   the defendants and agreed to a covenant not to sue in the future. \n  took responsibility for the maintenance of the database on 14 October 2011.   The full database and a description of plans for its maintenance are available online from  . \n", "language": "en"},
{"url": "https://en.wikipedia.org/wiki/International_Standard_Identifier_for_Libraries_and_Related_Organizations", "title": "International Standard Identifier for Libraries and Related Organizations", "content": "\n The   ( ), ISO 15511, assigns   to libraries and related organisations, such as archives and museums. \n The   is the international authority for maintaining the standard and its registry. \n An ISIL is alphanumeric, with a maximum of 16 characters.  Valid symbols are A-Z, 0-9,   (/), hyphen-minus and colon.\n An ISIL consists of a prefix identifying the authority which issued the ISIL, a dash, and then an   issued by that authority. All two letter prefixes are reserved for the   country code, followed by an identifier assigned by that country's national library authority. Global-level identifiers can also be assigned, which are not associated with a particular country, e.g. 'oclc-' for the  . The suffix is generally a pre-existing system of identifying libraries; thus, ISIL unifies existing systems around the world rather than instituting an entire system from scratch.\n This  - or  -related article is a  . You can help Wikipedia by  .", "language": "en"}
]